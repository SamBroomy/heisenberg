{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "import polars_distance as pld\n",
    "from pprint import pprint\n",
    "from loguru import logger\n",
    "import polars.selectors as cs\n",
    "import kuzu as kz\n",
    "from pathlib import Path\n",
    "from typing import Type, Callable\n",
    "from usearch.index import Index, Matches\n",
    "import numpy as np\n",
    "from typing import NamedTuple, Self, TypedDict\n",
    "from functools import partial\n",
    "from numpy.typing import NDArray\n",
    "import duckdb\n",
    "from duckdb import DuckDBPyConnection\n",
    "from time import time\n",
    "\n",
    "pl.Config.set_tbl_rows(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x111ed76f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duck_db_path = Path(\"./data/db/duck_db/data.db\")\n",
    "duck_db_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "con = duckdb.connect(database=duck_db_path.as_posix())\n",
    "\n",
    "con.execute(\"SET enable_progress_bar = false;\")\n",
    "con.install_extension(\"spatial\")\n",
    "con.load_extension(\"spatial\")\n",
    "\n",
    "# Set DuckDB optimizations\n",
    "con.execute(\"PRAGMA memory_limit='16GB'\")  # Adjust based on your system\n",
    "con.execute(\"PRAGMA threads=8\")  # Adjust based on your CPU cores\n",
    "con.execute(\"PRAGMA enable_object_cache=true\")  # Improve query caching\n",
    "# con.execute(\"PRAGMA profiling_mode = 'standard'\")  # Set profiling mode\n",
    "# con.execute(\"PRAGMA enable_profiling = 'json'\")  # Enable profiling\n",
    "# con.execute(\"PRAGMA profiling_output = './profile.json'\")  # Set profiling output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 23)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>asciiname</th><th>admin_level</th><th>admin0_code</th><th>admin1_code</th><th>admin2_code</th><th>admin3_code</th><th>admin4_code</th><th>feature_class</th><th>feature_code</th><th>ISO</th><th>ISO3</th><th>ISO_Numeric</th><th>official_name</th><th>fips</th><th>latitude</th><th>longitude</th><th>population</th><th>area</th><th>alternatenames</th><th>country_name</th><th>fts_score</th></tr><tr><td>u32</td><td>str</td><td>str</td><td>u8</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>u16</td><td>str</td><td>str</td><td>f32</td><td>f32</td><td>i32</td><td>f32</td><td>str</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>10861316</td><td>&quot;Kenya&quot;</td><td>&quot;Kenya&quot;</td><td>3</td><td>&quot;CD&quot;</td><td>&quot;05&quot;</td><td>null</td><td>&quot;10861316&quot;</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM3&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-11.69712</td><td>27.479509</td><td>0</td><td>null</td><td>null</td><td>&quot;Democratic Republic of the Con…</td><td>8.966241</td></tr><tr><td>192950</td><td>&quot;Republic of Kenya&quot;</td><td>&quot;Republic of Kenya&quot;</td><td>0</td><td>&quot;KE&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;A&quot;</td><td>&quot;PCLI&quot;</td><td>&quot;KE&quot;</td><td>&quot;KEN&quot;</td><td>404</td><td>&quot;Kenya&quot;</td><td>&quot;KE&quot;</td><td>1.0</td><td>38.0</td><td>51393010</td><td>582650.0</td><td>&quot;A Cheinia,Ceinia,Cenia,Chenia,…</td><td>&quot;Kenya&quot;</td><td>6.047672</td></tr><tr><td>400741</td><td>&quot;Eastern Province&quot;</td><td>&quot;Eastern Province&quot;</td><td>1</td><td>&quot;KE&quot;</td><td>&quot;03&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM1H&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>38.0</td><td>4631779</td><td>null</td><td>&quot;Aust-Kenya,Eastern,Eastern Pro…</td><td>&quot;Republic of Kenya&quot;</td><td>6.944599</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 23)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬──────────┬───────────┬───────────┬───────────┐\n",
       "│ geonameId ┆ name      ┆ asciiname ┆ admin_lev ┆ … ┆ area     ┆ alternate ┆ country_n ┆ fts_score │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ el        ┆   ┆ ---      ┆ names     ┆ ame       ┆ ---       │\n",
       "│ u32       ┆ str       ┆ str       ┆ ---       ┆   ┆ f32      ┆ ---       ┆ ---       ┆ f64       │\n",
       "│           ┆           ┆           ┆ u8        ┆   ┆          ┆ str       ┆ str       ┆           │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 10861316  ┆ Kenya     ┆ Kenya     ┆ 3         ┆ … ┆ null     ┆ null      ┆ Democrati ┆ 8.966241  │\n",
       "│           ┆           ┆           ┆           ┆   ┆          ┆           ┆ c         ┆           │\n",
       "│           ┆           ┆           ┆           ┆   ┆          ┆           ┆ Republic  ┆           │\n",
       "│           ┆           ┆           ┆           ┆   ┆          ┆           ┆ of the    ┆           │\n",
       "│           ┆           ┆           ┆           ┆   ┆          ┆           ┆ Con…      ┆           │\n",
       "│ 192950    ┆ Republic  ┆ Republic  ┆ 0         ┆ … ┆ 582650.0 ┆ A Cheinia ┆ Kenya     ┆ 6.047672  │\n",
       "│           ┆ of Kenya  ┆ of Kenya  ┆           ┆   ┆          ┆ ,Ceinia,C ┆           ┆           │\n",
       "│           ┆           ┆           ┆           ┆   ┆          ┆ enia,Chen ┆           ┆           │\n",
       "│           ┆           ┆           ┆           ┆   ┆          ┆ ia,…      ┆           ┆           │\n",
       "│ 400741    ┆ Eastern   ┆ Eastern   ┆ 1         ┆ … ┆ null     ┆ Aust-Keny ┆ Republic  ┆ 6.944599  │\n",
       "│           ┆ Province  ┆ Province  ┆           ┆   ┆          ┆ a,Eastern ┆ of Kenya  ┆           │\n",
       "│           ┆           ┆           ┆           ┆   ┆          ┆ ,Eastern  ┆           ┆           │\n",
       "│           ┆           ┆           ┆           ┆   ┆          ┆ Pro…      ┆           ┆           │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴──────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"\"\"SELECT * , fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
    "\n",
    "        FROM admin_search\n",
    "        WHERE fts_score IS NOT NULL\n",
    "            \"\"\", {\"term\": \"Kenya\"}).pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_FOLDER = Path(\"./sql\")\n",
    "\n",
    "\n",
    "def sql_file(sql_path: Path | str, **kwargs) -> str:\n",
    "    if isinstance(sql_path, str):\n",
    "        sql_path = Path(sql_path)\n",
    "    if not sql_path.exists():\n",
    "        sql_path = SQL_FOLDER / sql_path\n",
    "        if not sql_path.exists():\n",
    "            raise FileNotFoundError(f\"SQL file {sql_path} not found\")\n",
    "    sql = sql_path.read_text()\n",
    "    if kwargs:\n",
    "        sql = sql.format(**kwargs)\n",
    "\n",
    "    # Validate no {kwarg} left in string (regex)\n",
    "    # if uninit_kwargs := re.findall(r\"\\{.*\\}\", sql):\n",
    "    #     raise ValueError(\n",
    "    #         f\"SQL file {sql_path} still has unprocessed kwargs: {list(set(uninit_kwargs))} in:\\n\\n{sql}\"\n",
    "    #     )\n",
    "\n",
    "    return sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 17:01:17.566\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_file\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mTable 'allCountries' already exists\u001b[0m\n",
      "\u001b[32m2025-05-04 17:01:17.569\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_file\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mTable 'allPostCodes' already exists\u001b[0m\n",
      "\u001b[32m2025-05-04 17:01:17.572\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_file\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mTable 'admin1CodesASCII' already exists\u001b[0m\n",
      "\u001b[32m2025-05-04 17:01:17.575\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_file\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mTable 'admin2Codes' already exists\u001b[0m\n",
      "\u001b[32m2025-05-04 17:01:17.578\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_file\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mTable 'adminCode5' already exists\u001b[0m\n",
      "\u001b[32m2025-05-04 17:01:17.581\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_file\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mTable 'alternateNamesV2' already exists\u001b[0m\n",
      "\u001b[32m2025-05-04 17:01:17.584\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_file\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mTable 'countryInfo' already exists\u001b[0m\n",
      "\u001b[32m2025-05-04 17:01:17.587\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_file\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mTable 'featureCodes' already exists\u001b[0m\n",
      "\u001b[32m2025-05-04 17:01:17.590\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_file\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mTable 'hierarchy' already exists\u001b[0m\n",
      "\u001b[32m2025-05-04 17:01:17.594\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_file\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mTable 'iso_languagecodes' already exists\u001b[0m\n",
      "\u001b[32m2025-05-04 17:01:17.597\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_file\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mTable 'timeZones' already exists\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x1060729b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GID = \"geonameId\"\n",
    "\n",
    "\n",
    "def table_exists(con: DuckDBPyConnection, table_name: str) -> bool:\n",
    "    return table_name in con.execute(\"SHOW TABLES\").pl()[\"name\"]\n",
    "\n",
    "\n",
    "# Read and load 'allCountries.txt'\n",
    "# Function to read and load other files with different schemas\n",
    "def load_file(\n",
    "    # con: DuckDBPyConnection,\n",
    "    file_path: str,\n",
    "    schema: dict[str, Type[pl.DataType]],\n",
    "    table_name: str,\n",
    "    table_definition: str | None = None,\n",
    "    pipe: Callable[[pl.LazyFrame], pl.LazyFrame] | None = None,\n",
    "    has_header: bool = False,\n",
    "    skip_rows: int = 0,\n",
    "    overwrite: bool = False,\n",
    "    extra_expr: pl.Expr | None = None,\n",
    "):\n",
    "    if table_exists(con, table_name):\n",
    "        logger.debug(f\"Table '{table_name}' already exists\")\n",
    "        if not overwrite:\n",
    "            return\n",
    "        logger.debug(f\"Overwriting table '{table_name}'\")\n",
    "        con.execute(f\"DROP TABLE {table_name} CASCADE\")\n",
    "        logger.debug(f\"Table '{table_name}' dropped\")\n",
    "    time_start = time()\n",
    "    load = con.begin()\n",
    "    try:\n",
    "        logger.info(f\"Loading '{file_path}'...\")\n",
    "        # Time scan\n",
    "        time_scan = time()\n",
    "        q = pl.scan_csv(\n",
    "            file_path,\n",
    "            separator=\"\\t\",\n",
    "            has_header=has_header,\n",
    "            schema=schema,\n",
    "            skip_rows=skip_rows,\n",
    "        )\n",
    "        q = q.with_columns(\n",
    "            pl.col(pl.Utf8).str.strip_chars().str.strip_chars(\"\\\"':\").str.strip_chars()\n",
    "        )\n",
    "        if extra_expr is not None:\n",
    "            q = q.with_columns(extra_expr)\n",
    "        if pipe is not None:\n",
    "            q = q.pipe(pipe)\n",
    "        if GID in schema:\n",
    "            q = q.sort(GID, nulls_last=True)\n",
    "        logger.debug(f\"Scan time: {time() - time_scan:.6f}s\")\n",
    "\n",
    "        q = q.with_columns(cs.by_dtype(pl.String).str.strip_chars().replace(\"\", None))\n",
    "\n",
    "        # Time collect\n",
    "        time_collect = time()\n",
    "        df = q.collect()\n",
    "        logger.debug(f\"Collect time: {time() - time_collect:.6f}s\")\n",
    "\n",
    "        # Time write\n",
    "        time_write = time()\n",
    "        save_path = Path(f\"./data/processed/geonames/{table_name}.parquet\")\n",
    "        save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df.write_parquet(save_path.as_posix())\n",
    "        logger.debug(f\"Write time: {time() - time_write:.6f}s\")\n",
    "\n",
    "        # Time create\n",
    "        time_create = time()\n",
    "        # Create table with predefined schema if provided\n",
    "        time_create = time()\n",
    "        if table_definition:\n",
    "            # Create the table with specified schema\n",
    "            load.execute(table_definition)\n",
    "            load.from_arrow(df.to_arrow()).insert_into(table_name)\n",
    "        else:\n",
    "            # Use automatic schema derivation (your current approach)\n",
    "            load.from_arrow(df.to_arrow()).create(table_name)\n",
    "\n",
    "        logger.debug(f\"Create time: {time() - time_create:.6f}s\")\n",
    "\n",
    "        time_commit = time()\n",
    "        load.commit()\n",
    "        logger.debug(f\"Commit time: {time() - time_commit:.6f}s\")\n",
    "        analyze_time = time()\n",
    "        con.execute(\"VACUUM ANALYZE;\")\n",
    "        logger.debug(f\"Analyze time: {time() - analyze_time:.6f}s\")\n",
    "    except Exception as e:\n",
    "        logger.exception(\"Error loading '{file_path}'\")\n",
    "        logger.debug(e.with_traceback(None))\n",
    "        # Time rollback\n",
    "        time_rollback = time()\n",
    "        load.rollback()\n",
    "        logger.warning(f\"Rollback time: {time() - time_rollback:.6f}s\")\n",
    "        raise e\n",
    "    finally:\n",
    "        logger.info(f\"Total time: {time() - time_start:.6f}s\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def drop_duplicates(df: pl.LazyFrame) -> pl.LazyFrame:\n",
    "    cols = [\n",
    "        \"name\",\n",
    "        \"asciiname\",\n",
    "        \"feature_class\",\n",
    "        \"feature_code\",\n",
    "        \"admin0_code\",\n",
    "        \"admin1_code\",\n",
    "        \"admin2_code\",\n",
    "        \"admin3_code\",\n",
    "        \"admin4_code\",\n",
    "        \"timezone\",\n",
    "    ]\n",
    "    return (\n",
    "        df.sort(\"modification_date\", descending=True)\n",
    "        .unique(cols, keep=\"first\")\n",
    "        .filter(~pl.all_horizontal(pl.col(cols).is_null()))\n",
    "        .sort(\"geonameId\")\n",
    "    )\n",
    "\n",
    "\n",
    "schema_all_countries = {\n",
    "    GID: pl.UInt32,\n",
    "    \"name\": pl.Utf8,\n",
    "    \"asciiname\": pl.Utf8,\n",
    "    \"alternatenames\": pl.Utf8,\n",
    "    \"latitude\": pl.Float32,\n",
    "    \"longitude\": pl.Float32,\n",
    "    \"feature_class\": pl.Categorical,\n",
    "    \"feature_code\": pl.Categorical,\n",
    "    \"admin0_code\": pl.Categorical,\n",
    "    \"cc2\": pl.Utf8,\n",
    "    \"admin1_code\": pl.Utf8,\n",
    "    \"admin2_code\": pl.Utf8,\n",
    "    \"admin3_code\": pl.Utf8,\n",
    "    \"admin4_code\": pl.Utf8,\n",
    "    \"population\": pl.Int64,\n",
    "    \"elevation\": pl.Int32,\n",
    "    \"dem\": pl.Int32,\n",
    "    \"timezone\": pl.Categorical,\n",
    "    \"modification_date\": pl.Date,\n",
    "}\n",
    "\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/allCountries.txt\",\n",
    "    schema_all_countries,\n",
    "    \"allCountries\",\n",
    "    table_definition=sql_file(\"create_table_allCountries.sql\"),\n",
    "    pipe=drop_duplicates,\n",
    ")\n",
    "\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/allCountriesPostCode.txt\",\n",
    "    {\n",
    "        \"admin_code0\": pl.Categorical,\n",
    "        \"postal_code\": pl.Utf8,\n",
    "        \"place_name\": pl.Utf8,\n",
    "        \"admin_name1\": pl.Utf8,\n",
    "        \"admin_code1\": pl.Utf8,\n",
    "        \"admin_name2\": pl.Utf8,\n",
    "        \"admin_code2\": pl.Utf8,\n",
    "        \"admin_name3\": pl.Utf8,\n",
    "        \"admin_code3\": pl.Utf8,\n",
    "        \"latitude\": pl.Float32,\n",
    "        \"longitude\": pl.Float32,\n",
    "        \"accuracy\": pl.Int32,\n",
    "    },\n",
    "    \"allPostCodes\",\n",
    ")\n",
    "\n",
    "\n",
    "# Load other files with respective schemas\n",
    "load_file(\n",
    "    \"./data/raw/geonames/admin1CodesASCII.txt\",\n",
    "    {\n",
    "        \"code\": pl.Utf8,\n",
    "        \"name\": pl.Utf8,\n",
    "        \"name_ascii\": pl.Utf8,\n",
    "        GID: pl.UInt32,\n",
    "    },\n",
    "    \"admin1CodesASCII\",\n",
    "    table_definition=sql_file(\"create_table_admin1CodesASCII.sql\"),\n",
    ")\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/admin2Codes.txt\",\n",
    "    {\n",
    "        \"code\": pl.Utf8,\n",
    "        \"name\": pl.Utf8,\n",
    "        \"asciiname\": pl.Utf8,\n",
    "        GID: pl.UInt32,\n",
    "    },\n",
    "    \"admin2Codes\",\n",
    "    table_definition=sql_file(\"create_table_admin2Codes.sql\"),\n",
    ")\n",
    "\n",
    "\n",
    "def drop_invalid_gids(df: pl.LazyFrame, con: DuckDBPyConnection) -> pl.LazyFrame:\n",
    "    ids = con.execute(\"SELECT geonameId FROM allCountries\").pl().unique().to_series()\n",
    "    return df.filter(pl.col(GID).is_in(ids))\n",
    "\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/adminCode5.txt\",\n",
    "    {\n",
    "        GID: pl.UInt32,\n",
    "        \"adm5code\": pl.Utf8,\n",
    "    },\n",
    "    \"adminCode5\",\n",
    "    table_definition=sql_file(\"create_table_adminCode5.sql\"),\n",
    "    pipe=partial(drop_invalid_gids, con=con),\n",
    ")\n",
    "\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/alternateNamesV2.txt\",\n",
    "    {\n",
    "        \"alternateNameId\": pl.Int32,\n",
    "        GID: pl.UInt32,\n",
    "        \"isolanguage\": pl.Utf8,\n",
    "        \"alternate_name\": pl.Utf8,\n",
    "        \"isPreferredName\": pl.Int8,\n",
    "        \"isShortName\": pl.Int8,\n",
    "        \"isColloquial\": pl.Int8,\n",
    "        \"isHistoric\": pl.Int8,\n",
    "        \"from\": pl.Utf8,\n",
    "        \"to\": pl.Utf8,\n",
    "    },\n",
    "    \"alternateNamesV2\",\n",
    "    table_definition=sql_file(\"create_table_alternateNamesV2.sql\"),\n",
    "    extra_expr=cs.by_dtype(pl.Int8).cast(pl.Boolean).fill_null(False),\n",
    "    pipe=partial(drop_invalid_gids, con=con),\n",
    ")\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/countryInfo.txt\",\n",
    "    {\n",
    "        \"ISO\": pl.Categorical,\n",
    "        \"ISO3\": pl.Categorical,\n",
    "        \"ISO_Numeric\": pl.Int32,\n",
    "        \"fips\": pl.Categorical,\n",
    "        \"Country\": pl.Utf8,\n",
    "        \"Capital\": pl.Utf8,\n",
    "        \"Area\": pl.Float32,\n",
    "        \"Population\": pl.Int32,\n",
    "        \"Continent\": pl.Categorical,\n",
    "        \"tld\": pl.Utf8,\n",
    "        \"CurrencyCode\": pl.Utf8,\n",
    "        \"CurrencyName\": pl.Utf8,\n",
    "        \"Phone\": pl.Utf8,\n",
    "        \"Postal_Code_Format\": pl.Utf8,\n",
    "        \"Postal_Code_Regex\": pl.Utf8,\n",
    "        \"Languages\": pl.Utf8,\n",
    "        GID: pl.UInt32,\n",
    "        \"neighbours\": pl.Utf8,\n",
    "        \"EquivalentFipsCode\": pl.Utf8,\n",
    "    },\n",
    "    \"countryInfo\",\n",
    "    table_definition=sql_file(\"create_table_countryInfo.sql\"),\n",
    "    skip_rows=51,\n",
    ")\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/featureCodes_en.txt\",\n",
    "    {\n",
    "        \"code\": pl.Categorical,\n",
    "        \"name\": pl.Utf8,\n",
    "        \"description\": pl.Utf8,\n",
    "    },\n",
    "    \"featureCodes\",\n",
    "    table_definition=sql_file(\"create_table_featureCodes.sql\"),\n",
    ")\n",
    "\n",
    "\n",
    "def remove_old_ids(df: pl.LazyFrame, con: DuckDBPyConnection) -> pl.LazyFrame:\n",
    "    ids = con.execute(\"SELECT geonameId FROM allCountries\").pl().unique().to_series()\n",
    "    return (\n",
    "        df.filter(pl.col(\"parentId\").is_in(ids) & pl.col(\"childId\").is_in(ids))\n",
    "        .with_columns(\n",
    "            pl.when(pl.col(\"type\").str.contains(\"adm\", literal=True))\n",
    "            .then(pl.col(\"type\").str.to_uppercase())\n",
    "            .otherwise(pl.col(\"type\"))\n",
    "        )\n",
    "        .unique([\"parentId\", \"childId\"])\n",
    "    )\n",
    "\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/hierarchy.txt\",\n",
    "    {\n",
    "        \"parentId\": pl.UInt32,\n",
    "        \"childId\": pl.UInt32,\n",
    "        \"type\": pl.Utf8,\n",
    "    },\n",
    "    \"hierarchy\",\n",
    "    table_definition=sql_file(\"create_table_hierarchy.sql\"),\n",
    "    pipe=partial(remove_old_ids, con=con),\n",
    ")\n",
    "con.execute(sql_file(\"create_table_unique_ids.sql\"))\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/iso-languagecodes.txt\",\n",
    "    {\n",
    "        \"ISO_639_3\": pl.Utf8,\n",
    "        \"ISO_639_2\": pl.Utf8,\n",
    "        \"ISO_639_1\": pl.Utf8,\n",
    "        \"Language_Name\": pl.Utf8,\n",
    "    },\n",
    "    \"iso_languagecodes\",\n",
    "    table_definition=sql_file(\"create_table_iso_languagecodes.sql\"),\n",
    ")\n",
    "\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/timeZones.txt\",\n",
    "    {\n",
    "        \"CountryCode\": pl.Utf8,\n",
    "        \"TimeZoneId\": pl.Utf8,\n",
    "        \"GMT_offset_1_Jan_2024\": pl.Float32,\n",
    "        \"DST_offset_1_Jul_2024\": pl.Float32,\n",
    "        \"rawOffset\": pl.Float32,\n",
    "    },\n",
    "    \"timeZones\",\n",
    "    table_definition=sql_file(\"create_table_timeZones.sql\"),\n",
    "    skip_rows=1,\n",
    ")\n",
    "# # Ignore loading the geo data for now\n",
    "if not table_exists(con, \"shapes\"):\n",
    "    con.execute(sql_file(\"create_table_shapes.sql\"))\n",
    "    logger.debug(\"Table 'shapes' created\")\n",
    "\n",
    "# # File is corupted atm\n",
    "# load_file(\n",
    "#     \"./data/raw/geonames/userTags.txt\",\n",
    "#     {\n",
    "#         GID: pl.Int32,\n",
    "#         \"tag\": pl.Utf8,\n",
    "#     },\n",
    "#     \"userTags\",\n",
    "# )\n",
    "con.execute(sql_file(\"create_table_equivalent.sql\"))\n",
    "con.execute(sql_file(\"create_view_cities.sql\"))\n",
    "con.execute(sql_file(\"create_view_locations_full.sql\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create country table\n",
    "# con.execute(sql_file(\"create_table_equivalent.sql\")).pl()\n",
    "# con.execute(sql_file(\"create_table_admin0.sql\")).execute(\"\"\"PRAGMA create_fts_index(\n",
    "#     admin0,\n",
    "#     geonameId,\n",
    "#     name,\n",
    "#     asciiname,\n",
    "#     official_name,\n",
    "#     alternatenames,\n",
    "#     admin0_code,\n",
    "#     ISO3,\n",
    "#     ISO_Numeric,\n",
    "#     fips,\n",
    "#     stemmer = 'none',\n",
    "#     stopwords = 'none',\n",
    "#     ignore = '(\\\\.|[^a-z0-9])+',\n",
    "#     overwrite = 1\n",
    "# );\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 17:01:18.364\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[34m\u001b[1mLoaded 534106 entities and 508066 hierarchical relationships\u001b[0m\n",
      "\u001b[32m2025-05-04 17:01:18.364\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[34m\u001b[1mEntity columns:\u001b[0m\n",
      "\u001b[32m2025-05-04 17:01:18.365\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m14\u001b[0m - \u001b[34m\u001b[1mHierarchy columns:\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "entities_df = con.execute(f\"\"\"\n",
    "    SELECT {GID}, name, feature_class, feature_code\n",
    "    FROM unique_ids\n",
    "\"\"\").pl()\n",
    "\n",
    "hierarchy_df = con.execute(\"\"\"\n",
    "    SELECT parentId, childId, type\n",
    "    FROM hierarchy\n",
    "\"\"\").pl()\n",
    "logger.debug(\n",
    "    f\"Loaded {len(entities_df)} entities and {len(hierarchy_df)} hierarchical relationships\"\n",
    ")\n",
    "logger.debug(\"Entity columns:\", entities_df.columns)\n",
    "logger.debug(\"Hierarchy columns:\", hierarchy_df.columns)\n",
    "\n",
    "# 2. Setup Kuzu database connection\n",
    "gdb_path = Path(\"./data/db/graph_db\")\n",
    "gdb_path.mkdir(parents=True, exist_ok=True)\n",
    "gdb = kz.Database(gdb_path.as_posix())\n",
    "conn = kz.Connection(gdb)\n",
    "\n",
    "# 3. Create the schema in Kuzu if needed\n",
    "if \"Entity\" not in conn.execute(\"CALL SHOW_TABLES() RETURN *;\").get_as_pl().get_column(\n",
    "    \"name\"\n",
    "):\n",
    "    conn.execute(sql_file(\"create_node_entity.sql\"))\n",
    "    logger.debug(\"Created Entity table\")\n",
    "\n",
    "if \"IsIn\" not in conn.execute(\"CALL SHOW_TABLES() RETURN *;\").get_as_pl().get_column(\n",
    "    \"name\"\n",
    "):\n",
    "    conn.execute(sql_file(\"create_relation_IsIn.sql\"))\n",
    "    logger.debug(\"Created IsIn table\")\n",
    "\n",
    "    # 4. Check if tables already have data\n",
    "are_nodes = (\n",
    "    conn.execute(\"MATCH (e:Entity) RETURN count(e) > 0 AS HasData\")\n",
    "    .get_as_pl()\n",
    "    .get_column(\"HasData\")[0]\n",
    ")\n",
    "are_edges = (\n",
    "    conn.execute(\"MATCH ()-[r:IsIn]->() RETURN count(r) > 0 AS HasData\")\n",
    "    .get_as_pl()\n",
    "    .get_column(\"HasData\")[0]\n",
    ")\n",
    "\n",
    "if not are_nodes:\n",
    "    conn.execute(\n",
    "        f\"COPY Entity FROM (LOAD FROM entities_df RETURN {GID}, name, feature_class, feature_code)\"\n",
    "    )\n",
    "    logger.debug(\"Loaded Entity\")\n",
    "\n",
    "if not are_edges:\n",
    "    conn.execute(\n",
    "        \"COPY IsIn FROM (LOAD FROM hierarchy_df RETURN parentId, childId, type)\"\n",
    "    )\n",
    "    logger.debug(\"Loaded IsIn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>feature_class</th><th>feature_code</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>6255146</td><td>&quot;Africa&quot;</td><td>&quot;L&quot;</td><td>&quot;CONT&quot;</td></tr><tr><td>11812257</td><td>&quot;Commonwealth of Nations&quot;</td><td>&quot;A&quot;</td><td>&quot;ZN&quot;</td></tr><tr><td>7729889</td><td>&quot;Eastern Africa&quot;</td><td>&quot;L&quot;</td><td>&quot;RGN&quot;</td></tr><tr><td>11820342</td><td>&quot;Horn of Africa&quot;</td><td>&quot;L&quot;</td><td>&quot;RGN&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 4)\n",
       "┌───────────┬─────────────────────────┬───────────────┬──────────────┐\n",
       "│ geonameId ┆ name                    ┆ feature_class ┆ feature_code │\n",
       "│ ---       ┆ ---                     ┆ ---           ┆ ---          │\n",
       "│ i32       ┆ str                     ┆ str           ┆ str          │\n",
       "╞═══════════╪═════════════════════════╪═══════════════╪══════════════╡\n",
       "│ 6255146   ┆ Africa                  ┆ L             ┆ CONT         │\n",
       "│ 11812257  ┆ Commonwealth of Nations ┆ A             ┆ ZN           │\n",
       "│ 7729889   ┆ Eastern Africa          ┆ L             ┆ RGN          │\n",
       "│ 11820342  ┆ Horn of Africa          ┆ L             ┆ RGN          │\n",
       "└───────────┴─────────────────────────┴───────────────┴──────────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_children_query(geoname_id: int) -> str:\n",
    "    query = f\"\"\"MATCH (p:Entity {{geonameId: {geoname_id}}})-[:IsIn]->(c:Entity)\n",
    "    RETURN c.{GID} AS {GID}, c.name AS name, c.feature_class AS feature_class, c.feature_code AS feature_code;\"\"\"\n",
    "    return query\n",
    "\n",
    "\n",
    "def get_parents_query(geoname_id):\n",
    "    query = f\"\"\"MATCH (c:Entity {{geonameId: {geoname_id}}})<-[:IsIn]-(p:Entity)\n",
    "    RETURN p.{GID} AS {GID}, p.name AS name, p.feature_class AS feature_class, p.feature_code AS feature_code;\"\"\"\n",
    "    return query\n",
    "\n",
    "\n",
    "# MATCH (c:Entity) WHERE CAST(c.geonameId, \"INT64\") IN list_creation({formatted_ids}) RETURN *;\n",
    "def get_children_querys(\n",
    "    geoname_ids: list[int] | pl.Series, traverse: bool = False\n",
    ") -> str:\n",
    "    query = f\"\"\"MATCH (p:Entity)-[:IsIn{\"*\" if traverse else \"\"}]->(c:Entity)\n",
    "    WHERE p.geonameId IN CAST({geoname_ids}, \"UINT32[]\")\n",
    "    RETURN DISTINCT c.{GID} AS {GID}, c.name AS name, c.feature_class AS feature_class, c.feature_code AS feature_code;\"\"\"\n",
    "    return query\n",
    "\n",
    "\n",
    "def get_parents_querys(\n",
    "    geoname_ids: list[int] | pl.Series, traverse: bool = False\n",
    ") -> str:\n",
    "    query = f\"\"\"MATCH (c:Entity)<-[:IsIn{\"*\" if traverse else \"\"}]-(p:Entity)\n",
    "    WHERE c.geonameId IN CAST({geoname_ids}, \"UINT32[]\")\n",
    "    RETURN DISTINCT p.{GID} AS {GID}, p.name AS name, p.feature_class AS feature_class, p.feature_code AS feature_code;\"\"\"\n",
    "    return query\n",
    "\n",
    "\n",
    "def get_highest_parent_query():\n",
    "    query = f\"\"\"\n",
    "    MATCH (entity:Entity)\n",
    "    WHERE NOT (entity)<-[:IsIn]-(:Entity)\n",
    "    RETURN entity.{GID} AS {GID}, entity.name AS name, entity.feature_class AS feature_class, entity.feature_code AS feature_code;\"\"\"\n",
    "    return query\n",
    "\n",
    "\n",
    "conn.execute(get_parents_query(49518)).get_as_pl()\n",
    "conn.execute(get_children_query(6252001)).get_as_pl()\n",
    "conn.execute(get_children_querys([49518, 51537])).get_as_pl()\n",
    "conn.execute(get_parents_querys([49518, 51537])).get_as_pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 17:01:18.501\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbuild_unified_admin_table\u001b[0m:\u001b[36m4\u001b[0m - \u001b[34m\u001b[1mStarting simplified admin search table construction...\u001b[0m\n",
      "\u001b[32m2025-05-04 17:01:18.504\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbuild_unified_admin_table\u001b[0m:\u001b[36m8\u001b[0m - \u001b[34m\u001b[1mTable admin_search already exists. Skipping.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def build_unified_admin_table(con, conn=None, overwrite=True):\n",
    "    \"\"\"Build a simplified admin_search table focusing on admin codes for hierarchy.\"\"\"\n",
    "\n",
    "    logger.debug(\"Starting simplified admin search table construction...\")\n",
    "\n",
    "    # Check if table exists\n",
    "    if table_exists(con, \"admin_search\") and not overwrite:\n",
    "        logger.debug(\"Table admin_search already exists. Skipping.\")\n",
    "        con.execute(\"VACUUM ANALYZE;\")\n",
    "        return\n",
    "\n",
    "    # Create the table with proper schema\n",
    "    con.execute(sql_file(\"create_unified_admin_table.sql\"))\n",
    "\n",
    "    # Define admin level feature code patterns\n",
    "    level_codes = {\n",
    "        0: [\"PCL\", \"PCLI\", \"PCLD\", \"PCLF\", \"PCLS\", \"TERR\"],\n",
    "        1: [\"ADM1\", \"ADM1H\"],\n",
    "        2: [\"ADM2\", \"ADM2H\"],\n",
    "        3: [\"ADM3\", \"ADM3H\"],\n",
    "        4: [\"ADM4\", \"ADM4H\"],\n",
    "    }\n",
    "\n",
    "    # Process each admin level\n",
    "    for level in range(0, 5):\n",
    "        logger.info(f\"Processing admin level {level} entities...\")\n",
    "\n",
    "        # Identify entities of this admin level by feature code\n",
    "        feature_patterns = \"', '\".join([code for code in level_codes[level]])\n",
    "\n",
    "        # Direct insert of entities with the matching feature codes\n",
    "        if level == 0:  # Countries (admin0)\n",
    "            insert_query = f\"\"\"\n",
    "            INSERT INTO admin_search\n",
    "            SELECT\n",
    "                a.geonameId,\n",
    "                a.name,\n",
    "                a.asciiname,\n",
    "                0 AS admin_level,\n",
    "                a.admin0_code,\n",
    "                NULL AS admin1_code,\n",
    "                NULL AS admin2_code,\n",
    "                NULL AS admin3_code,\n",
    "                NULL AS admin4_code,\n",
    "                a.feature_class,\n",
    "                a.feature_code,\n",
    "                c.ISO,\n",
    "                c.ISO3,\n",
    "                c.ISO_Numeric,\n",
    "                c.Country AS official_name,\n",
    "                c.fips,\n",
    "                a.latitude,\n",
    "                a.longitude,\n",
    "                c.population,\n",
    "                c.area,\n",
    "                a.alternatenames,\n",
    "                c.Country AS country_name\n",
    "            FROM\n",
    "                allCountries a\n",
    "            LEFT JOIN\n",
    "                countryInfo c ON a.geonameId = c.geonameId\n",
    "            WHERE\n",
    "                a.feature_code IN ('{feature_patterns}')\n",
    "                OR a.feature_code LIKE '{level_codes[level][0]}%'\n",
    "            \"\"\"\n",
    "        else:\n",
    "            # For admin levels 1-4\n",
    "            insert_query = f\"\"\"\n",
    "            INSERT INTO admin_search\n",
    "            SELECT\n",
    "                a.geonameId,\n",
    "                a.name,\n",
    "                a.asciiname,\n",
    "                {level} AS admin_level,\n",
    "                a.admin0_code,\n",
    "                {(\"a.admin1_code\" if level >= 1 else \"NULL::VARCHAR AS admin1_code\")},\n",
    "                {(\"a.admin2_code\" if level >= 2 else \"NULL::VARCHAR AS admin2_code\")},\n",
    "                {(\"a.admin3_code\" if level >= 3 else \"NULL::VARCHAR AS admin3_code\")},\n",
    "                {(\"a.admin4_code\" if level >= 4 else \"NULL::VARCHAR AS admin4_code\")},\n",
    "                a.feature_class,\n",
    "                a.feature_code,\n",
    "                NULL AS ISO,\n",
    "                NULL AS ISO3,\n",
    "                NULL AS ISO_Numeric,\n",
    "                NULL AS official_name,\n",
    "                NULL AS fips,\n",
    "                a.latitude,\n",
    "                a.longitude,\n",
    "                a.population,\n",
    "                NULL AS area,\n",
    "                a.alternatenames,\n",
    "                c.name AS country_name\n",
    "            FROM\n",
    "                allCountries a\n",
    "            LEFT JOIN\n",
    "                allCountries c ON a.admin0_code = c.admin0_code AND c.feature_code = 'PCLI'\n",
    "            WHERE\n",
    "                (a.feature_code IN ('{feature_patterns}')\n",
    "                OR a.feature_code LIKE '{level_codes[level][0]}%')\n",
    "                AND a.admin0_code IS NOT NULL\n",
    "            \"\"\"\n",
    "\n",
    "        # Execute the query to insert data\n",
    "        con.execute(insert_query)\n",
    "\n",
    "        # Report count\n",
    "        count = con.execute(\n",
    "            f\"SELECT COUNT(*) FROM admin_search WHERE admin_level = {level}\"\n",
    "        ).fetchone()[0]\n",
    "        logger.debug(f\"Added {count} entities for admin level {level}\")\n",
    "\n",
    "    # Create FTS index for the unified table\n",
    "    logger.debug(\"Creating FTS index for admin_search table...\")\n",
    "    con.execute(\"\"\"\n",
    "    PRAGMA create_fts_index(\n",
    "        admin_search,\n",
    "        geonameId,\n",
    "        name, asciiname, alternatenames, official_name, ISO, ISO3,\n",
    "        stemmer = 'none',\n",
    "        stopwords = 'none',\n",
    "        ignore = '(\\\\.|[^a-z0-9])+',\n",
    "        overwrite = 1\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    # Final optimization\n",
    "    logger.debug(\"Running VACUUM ANALYZE to optimize the database...\")\n",
    "    con.execute(\"VACUUM ANALYZE;\")\n",
    "\n",
    "    logger.debug(\"Admin search table construction complete!\")\n",
    "    logger.debug(\"Writing admin_search table to parquet...\")\n",
    "    con.table(\"admin_search\").pl().write_parquet(\n",
    "        Path(\"./data/processed/geonames/admin_search.parquet\").as_posix(),\n",
    "        partition_by=[\"admin_level\"],\n",
    "    )\n",
    "    logger.debug(\"Admin search table written to parquet.\")\n",
    "\n",
    "\n",
    "build_unified_admin_table(con, conn, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 17:01:18.540\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbuild_places_search_table\u001b[0m:\u001b[36m4\u001b[0m - \u001b[34m\u001b[1mStarting places search table construction...\u001b[0m\n",
      "\u001b[32m2025-05-04 17:01:18.559\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbuild_places_search_table\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mProcessing major_populated features...\u001b[0m\n",
      "\u001b[32m2025-05-04 17:01:19.593\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbuild_places_search_table\u001b[0m:\u001b[36m282\u001b[0m - \u001b[34m\u001b[1mAdded 98815 major_populated features\u001b[0m\n",
      "\u001b[32m2025-05-04 17:01:19.594\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbuild_places_search_table\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mProcessing landmarks features...\u001b[0m\n",
      "\u001b[32m2025-05-04 17:01:22.853\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbuild_places_search_table\u001b[0m:\u001b[36m282\u001b[0m - \u001b[34m\u001b[1mAdded 486523 landmarks features\u001b[0m\n",
      "\u001b[32m2025-05-04 17:01:22.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbuild_places_search_table\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mProcessing natural_features features...\u001b[0m\n",
      "\u001b[32m2025-05-04 17:01:28.956\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbuild_places_search_table\u001b[0m:\u001b[36m282\u001b[0m - \u001b[34m\u001b[1mAdded 1242873 natural_features features\u001b[0m\n",
      "\u001b[32m2025-05-04 17:01:28.956\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbuild_places_search_table\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mProcessing facilities features...\u001b[0m\n",
      "\u001b[32m2025-05-04 17:01:34.269\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbuild_places_search_table\u001b[0m:\u001b[36m282\u001b[0m - \u001b[34m\u001b[1mAdded 687277 facilities features\u001b[0m\n",
      "\u001b[32m2025-05-04 17:01:34.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbuild_places_search_table\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mProcessing infrastructure features...\u001b[0m\n",
      "\u001b[32m2025-05-04 17:01:36.586\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbuild_places_search_table\u001b[0m:\u001b[36m282\u001b[0m - \u001b[34m\u001b[1mAdded 118958 infrastructure features\u001b[0m\n",
      "\u001b[32m2025-05-04 17:01:36.587\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbuild_places_search_table\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mProcessing government features...\u001b[0m\n",
      "\u001b[32m2025-05-04 17:01:39.004\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbuild_places_search_table\u001b[0m:\u001b[36m282\u001b[0m - \u001b[34m\u001b[1mAdded 72718 government features\u001b[0m\n",
      "\u001b[32m2025-05-04 17:01:39.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbuild_places_search_table\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mAdding remaining features with low importance...\u001b[0m\n",
      "\u001b[32m2025-05-04 17:02:19.854\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbuild_places_search_table\u001b[0m:\u001b[36m341\u001b[0m - \u001b[34m\u001b[1mAdded 8970557 remaining features with low importance\u001b[0m\n",
      "\u001b[32m2025-05-04 17:02:19.855\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbuild_places_search_table\u001b[0m:\u001b[36m344\u001b[0m - \u001b[34m\u001b[1mCreating FTS index for places_search table...\u001b[0m\n",
      "\u001b[32m2025-05-04 17:02:42.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbuild_places_search_table\u001b[0m:\u001b[36m368\u001b[0m - \u001b[1mImportance tier distribution:\u001b[0m\n",
      "\u001b[32m2025-05-04 17:02:42.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbuild_places_search_table\u001b[0m:\u001b[36m370\u001b[0m - \u001b[1m  Tier 1: 16,143 features\u001b[0m\n",
      "\u001b[32m2025-05-04 17:02:42.566\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbuild_places_search_table\u001b[0m:\u001b[36m370\u001b[0m - \u001b[1m  Tier 2: 245,036 features\u001b[0m\n",
      "\u001b[32m2025-05-04 17:02:42.566\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbuild_places_search_table\u001b[0m:\u001b[36m370\u001b[0m - \u001b[1m  Tier 3: 1,210,956 features\u001b[0m\n",
      "\u001b[32m2025-05-04 17:02:42.566\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbuild_places_search_table\u001b[0m:\u001b[36m370\u001b[0m - \u001b[1m  Tier 4: 1,476,176 features\u001b[0m\n",
      "\u001b[32m2025-05-04 17:02:42.566\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbuild_places_search_table\u001b[0m:\u001b[36m370\u001b[0m - \u001b[1m  Tier 5: 8,729,410 features\u001b[0m\n",
      "\u001b[32m2025-05-04 17:02:42.567\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbuild_places_search_table\u001b[0m:\u001b[36m372\u001b[0m - \u001b[34m\u001b[1mWriting places_search table to parquet...\u001b[0m\n",
      "\u001b[32m2025-05-04 17:02:53.046\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbuild_places_search_table\u001b[0m:\u001b[36m377\u001b[0m - \u001b[34m\u001b[1mSaved places_search table to parquet file\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def build_places_search_table(con, overwrite=True):\n",
    "    \"\"\"Build places_search table with balanced importance scoring.\"\"\"\n",
    "\n",
    "    logger.debug(\"Starting places search table construction...\")\n",
    "\n",
    "    if table_exists(con, \"places_search\") and not overwrite:\n",
    "        logger.debug(\"Table places_search already exists. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # Create the table with physical importance_tier column\n",
    "    con.execute(sql_file(\"create_places_search_table.sql\"))\n",
    "\n",
    "    # Define feature categories with more nuanced scoring\n",
    "    feature_categories = {\n",
    "        \"major_populated\": {\n",
    "            \"codes\": [\n",
    "                \"PPLA\",\n",
    "                \"PPLA2\",\n",
    "                \"PPLA3\",\n",
    "                \"PPLA4\",\n",
    "                \"PPLC\",\n",
    "                \"PPLF\",\n",
    "                \"PPLG\",\n",
    "                \"PPLR\",\n",
    "                \"PPLS\",\n",
    "            ],\n",
    "            \"min_population\": 0,\n",
    "            \"base_score\": 0.6,\n",
    "            \"pop_weight\": 0.7,\n",
    "            \"feature_weight\": 0.3,\n",
    "        },\n",
    "        \"landmarks\": {\n",
    "            \"codes\": [\n",
    "                \"CSTL\",\n",
    "                \"MNMT\",\n",
    "                \"RUIN\",\n",
    "                \"TOWR\",\n",
    "                \"ARCH\",\n",
    "                \"HSTS\",\n",
    "                \"CAVE\",\n",
    "                \"ANS\",\n",
    "                \"THTR\",\n",
    "                \"AMTH\",\n",
    "                \"MUS\",\n",
    "                \"LIBR\",\n",
    "                \"OPRA\",\n",
    "                \"PAL\",\n",
    "                \"PGDA\",\n",
    "                \"TMPL\",\n",
    "                \"SHRN\",\n",
    "                \"CH\",\n",
    "                \"MSQE\",\n",
    "                \"SYG\",\n",
    "                \"CVNT\",\n",
    "                \"MTRO\",\n",
    "                \"AIRP\",\n",
    "                \"PRT\",\n",
    "                \"RSTN\",\n",
    "                \"BUSTN\",\n",
    "                \"MAR\",\n",
    "            ],\n",
    "            \"min_population\": 0,\n",
    "            \"base_score\": 0.4,\n",
    "            \"pop_weight\": 0.3,\n",
    "            \"feature_weight\": 0.7,\n",
    "        },\n",
    "        \"natural_features\": {\n",
    "            \"codes\": [\n",
    "                \"MT\",\n",
    "                \"PK\",\n",
    "                \"PASS\",\n",
    "                \"VLC\",\n",
    "                \"ISL\",\n",
    "                \"BCH\",\n",
    "                \"BAY\",\n",
    "                \"CAPE\",\n",
    "                \"LK\",\n",
    "                \"FLLS\",\n",
    "                \"CNYN\",\n",
    "                \"VAL\",\n",
    "                \"DSRT\",\n",
    "                \"GLCR\",\n",
    "                \"RSV\",\n",
    "            ],\n",
    "            \"min_population\": 0,\n",
    "            \"base_score\": 0.3,\n",
    "            \"pop_weight\": 0.2,\n",
    "            \"feature_weight\": 0.8,\n",
    "        },\n",
    "        \"facilities\": {\n",
    "            \"codes\": [\n",
    "                \"HTL\",\n",
    "                \"RSRT\",\n",
    "                \"MALL\",\n",
    "                \"MKT\",\n",
    "                \"SCH\",\n",
    "                \"UNIV\",\n",
    "                \"HSP\",\n",
    "                \"ZOO\",\n",
    "                \"STDM\",\n",
    "                \"PRK\",\n",
    "                \"RECG\",\n",
    "                \"RECR\",\n",
    "                \"SPA\",\n",
    "                \"ATHF\",\n",
    "                \"ASYL\",\n",
    "            ],\n",
    "            \"min_population\": 0,\n",
    "            \"base_score\": 0.2,\n",
    "            \"pop_weight\": 0.5,\n",
    "            \"feature_weight\": 0.5,\n",
    "        },\n",
    "        \"infrastructure\": {\n",
    "            \"codes\": [\n",
    "                \"BDG\",\n",
    "                \"DAM\",\n",
    "                \"LOCK\",\n",
    "                \"LTHSE\",\n",
    "                \"BRKW\",\n",
    "                \"PIER\",\n",
    "                \"QUAY\",\n",
    "                \"PRMN\",\n",
    "                \"OILR\",\n",
    "                \"PS\",\n",
    "                \"PSH\",\n",
    "                \"PSN\",\n",
    "                \"CTRM\",\n",
    "                \"CTRF\",\n",
    "            ],\n",
    "            \"min_population\": 0,\n",
    "            \"base_score\": 0.15,\n",
    "            \"pop_weight\": 0.3,\n",
    "            \"feature_weight\": 0.7,\n",
    "        },\n",
    "        \"government\": {\n",
    "            \"codes\": [\n",
    "                \"ADMF\",\n",
    "                \"GOVL\",\n",
    "                \"CTHSE\",\n",
    "                \"DIP\",\n",
    "                \"BANK\",\n",
    "                \"PO\",\n",
    "                \"PP\",\n",
    "                \"CSTM\",\n",
    "                \"SCHC\",\n",
    "                \"MILB\",\n",
    "                \"INSM\",\n",
    "            ],\n",
    "            \"min_population\": 0,\n",
    "            \"base_score\": 0.25,\n",
    "            \"pop_weight\": 0.4,\n",
    "            \"feature_weight\": 0.6,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Process each category with improved scoring\n",
    "    for category, config in feature_categories.items():\n",
    "        logger.info(f\"Processing {category} features...\")\n",
    "\n",
    "        feature_codes = \"', '\".join(config[\"codes\"])\n",
    "\n",
    "        calculation = f\"\"\"\n",
    "        {config[\"base_score\"]} +\n",
    "                    (\n",
    "                        CASE\n",
    "                            WHEN a.population > 10000000 THEN 0.4\n",
    "                            WHEN a.population > 1000000 THEN 0.35\n",
    "                            WHEN a.population > 100000 THEN 0.3\n",
    "                            WHEN a.population > 10000 THEN 0.25\n",
    "                            WHEN a.population > 1000 THEN 0.2\n",
    "                            WHEN a.population > 100 THEN 0.15\n",
    "                            WHEN a.population > 0 THEN 0.1\n",
    "                            ELSE 0.05\n",
    "                        END * {config[\"pop_weight\"]}\n",
    "                        +\n",
    "                        CASE\n",
    "                            WHEN a.feature_code IN ('PPLC', 'CSTL', 'MNMT') THEN 0.4\n",
    "                            WHEN a.feature_code IN ('AIRP', 'TOWR', 'MUS', 'RUIN', 'PAL', 'PGDA') THEN 0.35\n",
    "                            WHEN a.feature_code IN ('UNIV', 'PPLA', 'RSTN', 'MAR', 'HTL') THEN 0.3\n",
    "                            WHEN a.feature_code IN ('MT', 'PK', 'VLC', 'ISL', 'BCH') THEN 0.25\n",
    "                            WHEN a.feature_code IN ('CH', 'HSP', 'SCH', 'THTR', 'STDM') THEN 0.2\n",
    "                            ELSE 0.1\n",
    "                        END * {config[\"feature_weight\"]}\n",
    "                        +\n",
    "                        CASE\n",
    "                            WHEN LENGTH(a.alternatenames) > 1000 THEN 0.2\n",
    "                            WHEN LENGTH(a.alternatenames) > 500 THEN 0.15\n",
    "                            WHEN LENGTH(a.alternatenames) > 100 THEN 0.1\n",
    "                            WHEN LENGTH(a.alternatenames) > 0 THEN 0.05\n",
    "                            ELSE 0\n",
    "                        END * 0.2\n",
    "                    )\"\"\"\n",
    "\n",
    "        insert_query = f\"\"\"\n",
    "        INSERT INTO places_search\n",
    "        SELECT\n",
    "            a.geonameId,\n",
    "            a.name,\n",
    "            a.asciiname,\n",
    "            a.admin0_code,\n",
    "            a.admin1_code,\n",
    "            a.admin2_code,\n",
    "            a.admin3_code,\n",
    "            a.admin4_code,\n",
    "            a.feature_class,\n",
    "            a.feature_code,\n",
    "            f.name AS feature_name,\n",
    "            a.latitude,\n",
    "            a.longitude,\n",
    "            a.population,\n",
    "            a.elevation,\n",
    "            a.alternatenames,\n",
    "            c.Country AS country_name,\n",
    "            -- More balanced importance scoring\n",
    "            {config[\"base_score\"]} +\n",
    "            (\n",
    "                -- Population component\n",
    "                CASE\n",
    "                    WHEN a.population > 10000000 THEN 0.4\n",
    "                    WHEN a.population > 1000000 THEN 0.35\n",
    "                    WHEN a.population > 100000 THEN 0.3\n",
    "                    WHEN a.population > 10000 THEN 0.25\n",
    "                    WHEN a.population > 1000 THEN 0.2\n",
    "                    WHEN a.population > 100 THEN 0.15\n",
    "                    WHEN a.population > 0 THEN 0.1\n",
    "                    ELSE 0.05\n",
    "                END * {config[\"pop_weight\"]}\n",
    "                +\n",
    "                -- Feature type component\n",
    "                CASE\n",
    "                    -- Capital cities and major landmarks\n",
    "                    WHEN a.feature_code IN ('PPLC', 'CSTL', 'MNMT') THEN 0.4\n",
    "                    -- Major tourist destinations\n",
    "                    WHEN a.feature_code IN ('AIRP', 'TOWR', 'MUS', 'RUIN', 'PAL', 'PGDA') THEN 0.35\n",
    "                    -- Important facilities\n",
    "                    WHEN a.feature_code IN ('UNIV', 'PPLA', 'RSTN', 'MAR', 'HTL') THEN 0.3\n",
    "                    -- Notable natural features\n",
    "                    WHEN a.feature_code IN ('MT', 'PK', 'VLC', 'ISL', 'BCH') THEN 0.25\n",
    "                    -- General infrastructure\n",
    "                    WHEN a.feature_code IN ('CH', 'HSP', 'SCH', 'THTR', 'STDM') THEN 0.2\n",
    "                    -- Other features\n",
    "                    ELSE 0.1\n",
    "                END * {config[\"feature_weight\"]}\n",
    "                +\n",
    "                -- Name recognition bonus (if it has many alternate names)\n",
    "                CASE\n",
    "                    WHEN LENGTH(a.alternatenames) > 1000 THEN 0.2\n",
    "                    WHEN LENGTH(a.alternatenames) > 500 THEN 0.15\n",
    "                    WHEN LENGTH(a.alternatenames) > 100 THEN 0.1\n",
    "                    WHEN LENGTH(a.alternatenames) > 0 THEN 0.05\n",
    "                    ELSE 0\n",
    "                END * 0.2\n",
    "            ) AS importance_score,\n",
    "            -- Calculate tier directly during insert\n",
    "            CASE\n",
    "                WHEN (\n",
    "                    {calculation}\n",
    "\n",
    "                ) >= 0.8 THEN 1  -- Top tier\n",
    "                WHEN ({calculation}) >= 0.6 THEN 2  -- High importance\n",
    "                WHEN ({calculation}) >= 0.4 THEN 3  -- Medium importance\n",
    "                WHEN ({calculation}) >= 0.2 THEN 4  -- Low importance\n",
    "                ELSE 5  -- Minimal importance\n",
    "            END AS importance_tier\n",
    "        FROM\n",
    "            allCountries a\n",
    "        LEFT JOIN\n",
    "            featureCodes f ON a.feature_class || '.' || a.feature_code = f.code\n",
    "        LEFT JOIN\n",
    "            countryInfo c ON a.admin0_code = c.ISO\n",
    "        WHERE\n",
    "            a.feature_code IN ('{feature_codes}')\n",
    "            AND a.population >= {config[\"min_population\"]}\n",
    "            AND a.admin0_code IS NOT NULL\n",
    "            AND NOT EXISTS (\n",
    "                SELECT 1 FROM admin_search\n",
    "                WHERE admin_search.geonameId = a.geonameId\n",
    "            )\n",
    "        \"\"\"\n",
    "        # Execute the query to insert data and get the number of rows added\n",
    "        count = con.execute(insert_query).fetchone()[0]\n",
    "        logger.debug(f\"Added {count} {category} features\")\n",
    "\n",
    "    # Add remaining features\n",
    "    logger.info(\"Adding remaining features with low importance...\")\n",
    "\n",
    "    processed_codes = []\n",
    "    for config in feature_categories.values():\n",
    "        processed_codes.extend(config[\"codes\"])\n",
    "\n",
    "    insert_remaining_query = f\"\"\"\n",
    "    INSERT INTO places_search\n",
    "    SELECT\n",
    "        a.geonameId,\n",
    "        a.name,\n",
    "        a.asciiname,\n",
    "        a.admin0_code,\n",
    "        a.admin1_code,\n",
    "        a.admin2_code,\n",
    "        a.admin3_code,\n",
    "        a.admin4_code,\n",
    "        a.feature_class,\n",
    "        a.feature_code,\n",
    "        f.name AS feature_name,\n",
    "        a.latitude,\n",
    "        a.longitude,\n",
    "        a.population,\n",
    "        a.elevation,\n",
    "        a.alternatenames,\n",
    "        c.Country AS country_name,\n",
    "        -- Base score for remaining features\n",
    "        0.1 +\n",
    "        CASE\n",
    "            WHEN a.population > 0 THEN LOG10(a.population) / 20\n",
    "            ELSE 0\n",
    "        END +\n",
    "        CASE\n",
    "            WHEN LENGTH(a.alternatenames) > 0 THEN 0.05\n",
    "            ELSE 0\n",
    "        END AS importance_score,\n",
    "        -- Calculate tier\n",
    "        CASE\n",
    "            WHEN (0.1 + CASE WHEN a.population > 0 THEN LOG10(a.population) / 20 ELSE 0 END) >= 0.2 THEN 4\n",
    "            ELSE 5\n",
    "        END AS importance_tier\n",
    "    FROM\n",
    "        allCountries a\n",
    "    LEFT JOIN\n",
    "        featureCodes f ON a.feature_class || '.' || a.feature_code = f.code\n",
    "    LEFT JOIN\n",
    "        countryInfo c ON a.admin0_code = c.ISO\n",
    "    WHERE\n",
    "        a.feature_code NOT IN ('{\"', '\".join(processed_codes)}')\n",
    "        AND NOT (a.feature_code LIKE 'ADM%' OR a.feature_code LIKE 'PCL%')\n",
    "        AND a.admin0_code IS NOT NULL\n",
    "        AND a.feature_class IN ('P', 'S', 'T', 'H', 'L', 'V', 'R')\n",
    "        AND a.name IS NOT NULL AND a.name != ''\n",
    "    \"\"\"\n",
    "\n",
    "    count = con.execute(insert_remaining_query).fetchone()[0]\n",
    "    logger.debug(f\"Added {count} remaining features with low importance\")\n",
    "\n",
    "    # Create FTS index\n",
    "    logger.debug(\"Creating FTS index for places_search table...\")\n",
    "    con.execute(\"\"\"\n",
    "    PRAGMA create_fts_index(\n",
    "        places_search,\n",
    "        geonameId,\n",
    "        name, asciiname, alternatenames,\n",
    "        stemmer = 'none',\n",
    "        stopwords = 'none',\n",
    "        ignore = '(\\\\.|[^a-z0-9])+',\n",
    "        overwrite = 1\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    # Update statistics\n",
    "    con.execute(\"VACUUM ANALYZE;\")\n",
    "\n",
    "    # Show tier distribution\n",
    "    tier_dist = con.execute(\"\"\"\n",
    "        SELECT importance_tier, COUNT(*) as count\n",
    "        FROM places_search\n",
    "        GROUP BY importance_tier\n",
    "        ORDER BY importance_tier\n",
    "    \"\"\").pl()\n",
    "\n",
    "    logger.info(\"Importance tier distribution:\")\n",
    "    for row in tier_dist.iter_rows(named=True):\n",
    "        logger.info(f\"  Tier {row['importance_tier']}: {row['count']:,} features\")\n",
    "\n",
    "    logger.debug(\"Writing places_search table to parquet...\")\n",
    "    con.table(\"places_search\").pl().write_parquet(\n",
    "        \"./data/processed/geonames/places_search.parquet\",\n",
    "        partition_by=[\"importance_tier\"],\n",
    "    )\n",
    "    logger.debug(\"Saved places_search table to parquet file\")\n",
    "\n",
    "\n",
    "build_places_search_table(con, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()\n",
    "\n",
    "con = duckdb.connect(database=duck_db_path.as_posix(), read_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The idea here is now we want to have a more flexible search function.\n",
    "# As we have done above we have have created one big admin_search table, where the core idea of that is to allow us to search over multiple admin levels at once.\n",
    "# This will enable us to have two types of searches:\n",
    "# 1. Search for a specific admin level (e.g. admin1, admin2, etc.) and return results for that level.\n",
    "#   - This is useful when we want to find specific entities at a certain level.\n",
    "#   - It will take in a list of exactly length 5 that contains str or None for each admin level.\n",
    "#   - We can search for the exact level we want and return results for that level.\n",
    "# 2. Search for a term that is more flexible where you may not know what the exact level is.\n",
    "#   - This is useful when we want to find entities that match a term but may not know the exact level.\n",
    "#   - It will take in a list of potentially variable sizes (up to 5) that contains str only. The idea is that its essentially a window function and can sort of map it to the structured input of before.\n",
    "#      - Lets say we have a flexible the input of [A, B, C] where we are unsure of the level for each of the inputs. What we get is esentially a window function we are able to search over.\n",
    "#      - That input could be mapped to the structured input of [A, B, C, None, None] or [None, A, B, C, None] or [None, None, A, B, C], [A, None, B, None, C] etc. (and so on).\n",
    "#      - But we know that for 'A' there are three possible levels for it, so we can search over all of these levels (e.g. admin0, admin1, admin2) and return the results for that level. 'B' could be admin1, admin2, admin3 and so on. The idea is that we can use the number of terms that we have / that aren't None to determine the levels we want to search over.\n",
    "#   - This means that we need to be able to search over multiple levels at once and return results for all of them.\n",
    "#   - Once we have the results we can try and filter the next level based on the previous results.\n",
    "#   - Due to the nature of the flexible search it may not filter down nicely as the structured search, but we can try to filter it down as accurately as possible.\n",
    "\n",
    "\n",
    "def get_latest_adjusted_score_level(columns: list[str]) -> int | None:\n",
    "    adjusted_score_columns = [\n",
    "        col for col in columns if col.startswith(\"adjusted_score_\")\n",
    "    ]\n",
    "    if not adjusted_score_columns:\n",
    "        return None\n",
    "    # Extract the level from the column name and find the maximum level\n",
    "    levels = [int(col.rsplit(\"_\", maxsplit=1)[-1]) for col in adjusted_score_columns]\n",
    "    max_level = max(levels)\n",
    "    return max_level\n",
    "\n",
    "\n",
    "def search_score_admin(\n",
    "    df: pl.LazyFrame,\n",
    "    level: int,\n",
    "    text_weight: float = 0.35,\n",
    "    pop_weight: float = 0.35,\n",
    "    feature_weight: float = 0.15,\n",
    "    parent_weight: float = 0.15,\n",
    "    search_term: str | None = None,\n",
    ") -> pl.LazyFrame:\n",
    "    \"\"\"\n",
    "    A scoring function for geographic entities that better prioritizes\n",
    "    significant locations.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame with search results\n",
    "    - level: Admin level (0=country, 1=admin1, etc.)\n",
    "    - text_weight: Weight for text matching score\n",
    "    - pop_weight: Weight for population-based importance\n",
    "    - feature_weight: Weight for feature type significance\n",
    "    - parent_weight: Weight for parent entity scores\n",
    "    - search_term: Original search term (for exact match detection)\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with adjusted scores\n",
    "    \"\"\"\n",
    "    assert level in range(5), \"Level must be between 0 and 4\"\n",
    "    score_col = f\"adjusted_score_{level}\"\n",
    "    columns = df.collect_schema().names()\n",
    "\n",
    "    # ===== 1. Text relevance score =====\n",
    "    fts_column = f\"fts_score_{level}\"\n",
    "    if \"fts_score\" in columns:\n",
    "        df = df.rename({\"fts_score\": fts_column})\n",
    "\n",
    "        df = df.with_columns(\n",
    "            # Calculate z-score\n",
    "            z_score=(\n",
    "                (pl.col(fts_column) - pl.col(fts_column).mean())\n",
    "                / pl.when(pl.col(fts_column).std() > 0)\n",
    "                .then(pl.col(fts_column).std())\n",
    "                .otherwise(1.0)\n",
    "            ),\n",
    "        ).with_columns(\n",
    "            # Apply sigmoid transformation: 1/(1+e^(-z))\n",
    "            text_score=(1 / (1 + pl.col.z_score.mul(-1.5).exp()))\n",
    "        )\n",
    "        if search_term:\n",
    "            df = df.with_columns(\n",
    "                text_score=pl.when(\n",
    "                    pl.col.name.str.to_lowercase() == search_term.lower()\n",
    "                )\n",
    "                .then(1)\n",
    "                .otherwise(pl.col.text_score)\n",
    "                .clip(0, 1)\n",
    "            )\n",
    "    else:\n",
    "        logger.warning(\n",
    "            f\"Column '{fts_column}' not found in DataFrame. Skipping Z-score normalization.\"\n",
    "        )\n",
    "        df = df.with_columns(text_score=pl.lit(0.5))\n",
    "\n",
    "    # ===== 2. Population importance - stronger scaling =====\n",
    "    pop_col = \"population\"\n",
    "    if pop_col in columns:\n",
    "        df = df.with_columns(\n",
    "            # Sigmoid normalized population factor\n",
    "            pop_score=pl.when(pl.col(pop_col) > 0)\n",
    "            .then(\n",
    "                (\n",
    "                    # Stronger population scaling using logarithmic curve\n",
    "                    1 - 1 / (1 + (pl.col(pop_col).log10() / 3))\n",
    "                )\n",
    "            )\n",
    "            .otherwise(0.1)\n",
    "        )\n",
    "    else:\n",
    "        logger.warning(\n",
    "            f\"Column '{pop_col}' not found in DataFrame. Skipping population factor.\"\n",
    "        )\n",
    "        df = df.with_columns(pop_score=pl.lit(0.3))\n",
    "\n",
    "    # ===== 3. Feature type importance =====\n",
    "    feature_col = \"feature_code\"\n",
    "    if feature_col in columns:\n",
    "        df = df.with_columns(\n",
    "            # More nuanced feature type scoring based on importance\n",
    "            feature_score=pl.when(pl.col(feature_col) == \"PCLI\")\n",
    "            .then(1.0)  # Independent countries\n",
    "            .when(pl.col(feature_col).str.starts_with(\"PCL\"))\n",
    "            .then(0.9)  # Other country-like entities\n",
    "            .when(pl.col(feature_col) == \"PPLC\")\n",
    "            .then(0.95)  # Capital cities\n",
    "            .when(pl.col(feature_col).str.starts_with(\"PPL\"))\n",
    "            .then(0.8)  # Major populated places\n",
    "            .when(pl.col(feature_col).str.starts_with(\"ADM1\"))\n",
    "            .then(0.85)  # First-level admin (provinces/states)\n",
    "            .when(pl.col(feature_col).str.starts_with(\"ADM2\"))\n",
    "            .then(0.75)  # Second-level admin (counties)\n",
    "            .when(pl.col(feature_col).str.starts_with(\"ADM3\"))\n",
    "            .then(0.65)  # Third-level admin (districts)\n",
    "            .when(pl.col(feature_col).str.starts_with(\"ADM\"))\n",
    "            .then(0.55)  # Other admin units\n",
    "            .otherwise(0.5)\n",
    "        )\n",
    "    else:\n",
    "        logger.warning(\n",
    "            f\"Column '{feature_col}' not found in DataFrame. Skipping feature factor.\"\n",
    "        )\n",
    "        df = df.with_columns(feature_score=pl.lit(0.5))\n",
    "\n",
    "    # ===== 4. Country/region prominence - prioritize major countries =====\n",
    "    country_col = \"admin0_code\"\n",
    "    if country_col in columns:\n",
    "        # List of major countries to prioritize\n",
    "        major_countries = [\n",
    "            \"US\",\n",
    "            \"GB\",\n",
    "            \"DE\",\n",
    "            \"FR\",\n",
    "            \"JP\",\n",
    "            \"CN\",\n",
    "            \"IN\",\n",
    "            \"BR\",\n",
    "            \"RU\",\n",
    "            \"CA\",\n",
    "            \"AU\",\n",
    "        ]\n",
    "        df = df.with_columns(\n",
    "            country_score=pl.when(pl.col(country_col).is_in(major_countries))\n",
    "            .then(0.8)  # Major countries\n",
    "            .otherwise(0.5)  # Other countries\n",
    "        )\n",
    "    else:\n",
    "        df = df.with_columns(country_score=pl.lit(0.5))\n",
    "\n",
    "    # ===== 5. Parent score influence =====\n",
    "    # TODO: No longer need for the function\n",
    "    if get_latest_adjusted_score_level(columns) is not None:\n",
    "        df = df.with_columns(\n",
    "            average_parent_score=pl.mean_horizontal(cs.starts_with(\"adjusted_score_\"))\n",
    "        ).with_columns(\n",
    "            parent_factor=pl.when(pl.col.average_parent_score > 0)\n",
    "            .then(pl.col.average_parent_score / pl.col.average_parent_score.max())\n",
    "            .otherwise(0.5)\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        logger.warning(\"No parent score column found. Skipping parent factor.\")\n",
    "        df = df.with_columns(parent_factor=pl.lit(0.5))\n",
    "\n",
    "    # ===== 6. Final score calculation =====\n",
    "    # Base score calculation\n",
    "    df = df.with_columns(\n",
    "        (\n",
    "            pl.col(\"text_score\").mul(text_weight)\n",
    "            + pl.col(\"pop_score\").mul(pop_weight)\n",
    "            + pl.col(\"feature_score\").mul(feature_weight)\n",
    "            + pl.col(\"parent_factor\").mul(parent_weight)\n",
    "        ).alias(\"base_score\")\n",
    "    )\n",
    "\n",
    "    # Apply country prominence boost to the final score\n",
    "    df = df.with_columns(\n",
    "        (pl.col(\"base_score\") * (0.7 + (0.3 * pl.col(\"country_score\")))).alias(\n",
    "            score_col\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # For debugging, keep all intermediate scores\n",
    "    return df.sort(score_col, descending=True)\n",
    "\n",
    "\n",
    "def build_path_conditions(df: pl.DataFrame, admin_cols: list[str]) -> str:\n",
    "    \"\"\"\n",
    "    Build SQL conditions by scanning backwards to find the last non-null value.\n",
    "    \"\"\"\n",
    "    if not admin_cols or df.is_empty():\n",
    "        return \"\"\n",
    "\n",
    "    # Extract relevant columns and filter out all-null rows\n",
    "    paths_df = (\n",
    "        df.select(admin_cols).filter(~pl.all_horizontal(pl.all().is_null())).unique()\n",
    "    )\n",
    "\n",
    "    path_conditions = []\n",
    "    for row in paths_df.iter_rows(named=True):\n",
    "        # Scan backward to find the last non-null column\n",
    "        last_non_null_idx = -1\n",
    "        for idx in range(len(admin_cols) - 1, -1, -1):\n",
    "            if row[admin_cols[idx]] is not None:\n",
    "                last_non_null_idx = idx\n",
    "                break\n",
    "\n",
    "        if last_non_null_idx == -1:\n",
    "            continue  # Skip rows with all nulls\n",
    "\n",
    "        # Build conditions up through the last non-null column\n",
    "        conditions = []\n",
    "        for idx in range(last_non_null_idx + 1):\n",
    "            col = admin_cols[idx]\n",
    "            val = row[col]\n",
    "            if val is None:\n",
    "                conditions.append(f\"{col} IS NULL\")\n",
    "            else:\n",
    "                conditions.append(f\"{col} = '{val}'\")\n",
    "\n",
    "        path_conditions.append(f\"({' AND '.join(conditions)})\")\n",
    "\n",
    "    return \" OR \".join(path_conditions)\n",
    "\n",
    "\n",
    "def search_admin(\n",
    "    term: str,\n",
    "    levels: list[int] | int,\n",
    "    con: DuckDBPyConnection,\n",
    "    previous_results: pl.DataFrame | None = None,\n",
    "    limit: int = 100,\n",
    "    all_cols: bool = False,\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Search for admin entities across one or multiple admin levels with path-aware filtering.\n",
    "\n",
    "    Parameters:\n",
    "    - term: The search term to look for\n",
    "    - levels: A list of admin levels to search over (0-4) or a single level\n",
    "    - con: The DuckDB connection object\n",
    "    - previous_results: Previous search results to filter against\n",
    "    - limit: The maximum number of results to return\n",
    "\n",
    "    Returns:\n",
    "    - A DataFrame with the search results\n",
    "    \"\"\"\n",
    "    # Normalize levels to a list\n",
    "    if isinstance(levels, int):\n",
    "        levels = [levels]\n",
    "    elif not isinstance(levels, list):\n",
    "        raise ValueError(\"Levels must be an integer or a list of integers\")\n",
    "\n",
    "    # Validate levels\n",
    "    if not all(0 <= level <= 4 for level in levels):\n",
    "        raise ValueError(\"All levels must be between 0 and 4\")\n",
    "\n",
    "    # Build level constraint\n",
    "    level_conditions = \" OR \".join([f\"admin_level = {level}\" for level in levels])\n",
    "    where_clauses = [f\"({level_conditions})\"]\n",
    "\n",
    "    # Special handling for country (admin_level = 0) exact matches\n",
    "    has_country_level = 0 in levels\n",
    "    country_exact_matches = None\n",
    "\n",
    "    select: list[str] = (\n",
    "        [\n",
    "            \"geonameId\",\n",
    "            \"name\",\n",
    "            \"asciiname\",\n",
    "            \"admin0_code\",\n",
    "            \"admin1_code\",\n",
    "            \"admin2_code\",\n",
    "            \"admin3_code\",\n",
    "            \"admin4_code\",\n",
    "            \"feature_class\",\n",
    "            \"feature_code\",\n",
    "            \"population\",\n",
    "            \"latitude\",\n",
    "            \"longitude\",\n",
    "        ]\n",
    "        if not all_cols\n",
    "        else [\"*\"]\n",
    "    )\n",
    "\n",
    "    if has_country_level and len(term) <= 3:\n",
    "        # If the term is short (<= 3 characters), we can assume it's a country code\n",
    "        # First try exact matches for country codes\n",
    "        exact_match_query = f\"\"\"\n",
    "        SELECT {\", \".join(select)},\n",
    "        -- High fixed score for exact matches\n",
    "        CASE\n",
    "            WHEN LOWER(ISO) = LOWER($term) THEN 10.0\n",
    "            WHEN LOWER(ISO3) = LOWER($term) THEN 8.0\n",
    "            WHEN LOWER(fips) = LOWER($term) THEN 4.0\n",
    "        END AS fts_score\n",
    "        FROM admin_search\n",
    "        WHERE admin_level = 0 AND (\n",
    "            LOWER(ISO) = LOWER($term) OR\n",
    "            LOWER(ISO3) = LOWER($term) OR\n",
    "            LOWER(fips) = LOWER($term)\n",
    "        )\n",
    "        \"\"\"\n",
    "\n",
    "        country_exact_matches = con.execute(exact_match_query, {\"term\": term}).pl()\n",
    "\n",
    "        # If we found exact matches, exclude these from the FTS search\n",
    "        if not country_exact_matches.is_empty():\n",
    "            country_ids = country_exact_matches[\"geonameId\"].to_list()\n",
    "            where_clauses.append(\n",
    "                f\"(admin_level != 0 OR geonameId NOT IN ({','.join(map(str, country_ids))}))\"\n",
    "            )\n",
    "\n",
    "    admin_cols = []\n",
    "    # Build path filtering from previous results\n",
    "    if previous_results is not None and not previous_results.is_empty():\n",
    "        # Determine which admin code columns to use based on the previous results\n",
    "        for i in range(5):\n",
    "            col = f\"admin{i}_code\"\n",
    "            if (\n",
    "                col in previous_results.columns\n",
    "                and previous_results[col].drop_nulls().shape[0] > 0\n",
    "            ):\n",
    "                admin_cols.append(col)\n",
    "\n",
    "        # Build path conditions using the admin code columns\n",
    "        if admin_cols:\n",
    "            path_conditions = build_path_conditions(previous_results, admin_cols)\n",
    "            if path_conditions:\n",
    "                where_clauses.append(f\"({path_conditions})\")\n",
    "\n",
    "    # Build the WHERE clause\n",
    "    where_clause = \" AND \".join(where_clauses)\n",
    "\n",
    "    # Build and execute the FTS search\n",
    "    fts_query = f\"\"\"\n",
    "\n",
    "    WITH filtered_results AS (\n",
    "        SELECT {\",\".join(select)}, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
    "        FROM admin_search\n",
    "        WHERE {where_clause}\n",
    "    )\n",
    "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
    "    SELECT * FROM filtered_results\n",
    "    WHERE fts_score IS NOT NULL\n",
    "    ORDER BY fts_score DESC\n",
    "    LIMIT $limit\n",
    "    \"\"\"\n",
    "    logger.debug(f\"Executing FTS query: {fts_query}\")\n",
    "    fts_results = con.execute(fts_query, {\"term\": term, \"limit\": limit * 2}).pl()\n",
    "\n",
    "    # Combine exact matches with FTS results if we had exact matches\n",
    "    if country_exact_matches is not None and not country_exact_matches.is_empty():\n",
    "        # Ensure both have the same columns\n",
    "        if not fts_results.is_empty():\n",
    "            # Dont need this any more.\n",
    "            # Make sure both have the same columns in the same order\n",
    "            # all_columns = list(\n",
    "            #     set(country_exact_matches.columns).union(set(fts_results.columns))\n",
    "            # )\n",
    "\n",
    "            # Add any missing columns with None values\n",
    "            # for col in all_columns:\n",
    "            #     if col not in country_exact_matches.columns:\n",
    "            #         country_exact_matches = country_exact_matches.with_columns(\n",
    "            #             pl.lit(None).alias(col)\n",
    "            #         )\n",
    "            #     if col not in fts_results.columns:\n",
    "            #         fts_results = fts_results.with_columns(pl.lit(None).alias(col))\n",
    "\n",
    "            # Combine and sort by score\n",
    "            results = pl.concat(\n",
    "                [country_exact_matches.lazy(), fts_results.lazy()],\n",
    "                how=\"vertical_relaxed\",\n",
    "            )\n",
    "            results = results.sort(\"fts_score\", descending=True)\n",
    "        else:\n",
    "            # If no FTS results, just use exact matches\n",
    "            results = country_exact_matches.lazy()\n",
    "    else:\n",
    "        # Just use FTS results\n",
    "        results = fts_results.lazy()\n",
    "\n",
    "    # Trying to get the adjusted scores from the previous results working with the flexible search. The issue is that we need to be able to join the previous results with the current results based on the admin codes. (Tracking the path back is much harder than when doing hierarchical search, as there are potentially multiple paths to the same entity. Unsure how to do this yet. )\n",
    "    # logger.info(admin_cols)\n",
    "    # if previous_results is not None and not previous_results.is_empty():\n",
    "    #     for i in range(1, len(admin_cols)+1):\n",
    "    #         logger.info(i)\n",
    "    #         logger.warning(f\"adjusted_score_{min(levels)-1}\")\n",
    "    #         tmp_cols = admin_cols[:i]\n",
    "    #         logger.info(f\"{tmp_cols=}\")\n",
    "    #         logger.info(f\"{results.collect_schema().names()=}\")\n",
    "    #         logger.info(f\"{previous_results.select(\n",
    "    #                 cs.by_name(tmp_cols), cs.starts_with(\"adjusted_score_\")\n",
    "    #             ).collect_schema().names()=}\")\n",
    "\n",
    "    #         results = results.join(\n",
    "    #             previous_results.select(\n",
    "    #                 cs.by_name(tmp_cols), pl.col(f\"adjusted_score_{min(levels)-1}\")\n",
    "    #             ),\n",
    "    #             on=tmp_cols,\n",
    "    #             how=\"left\",\n",
    "    #         )\n",
    "    #         logger.info(results.collect_schema())\n",
    "    #         if f\"adjusted_score_{min(levels)-1}_right\" in results.collect_schema().names():\n",
    "    #             results = results.with_columns(pl.coalesce(cs.starts_with(f\"adjusted_score_{min(levels)-1}\"))).drop(cs.ends_with(\"right\"))\n",
    "\n",
    "    # Original way that works for hierarchical search but not flexible search. Want to try and get this working for flexible search as well.\n",
    "    # For now we will just ignore any previous score when doing the flexible search as it complicates things too much.\n",
    "    # A simple way to work out if we are doing a flexible search is to check the length of the admin_cols and the length of the levels.\n",
    "    if (\n",
    "        previous_results is not None and not previous_results.is_empty()\n",
    "        # and 1 == len(levels)\n",
    "    ):\n",
    "        # Join with previous results to get adjusted scores\n",
    "        results = results.join(\n",
    "            previous_results.lazy().select(\n",
    "                cs.by_name(admin_cols), cs.starts_with(\"adjusted_score_\")\n",
    "            ),\n",
    "            on=admin_cols,\n",
    "            how=\"left\",\n",
    "        )\n",
    "\n",
    "    return (\n",
    "        results.pipe(search_score_admin, min(levels), search_term=term)\n",
    "        .sort(f\"adjusted_score_{min(levels)}\", descending=True)\n",
    "        .unique(\"geonameId\", keep=\"first\", maintain_order=True)\n",
    "        .head(limit)\n",
    "        .select(\n",
    "            (cs.by_name(select), cs.starts_with(\"adjusted_score_\"))\n",
    "            if not all_cols\n",
    "            else \"*\"\n",
    "        )\n",
    "        .collect()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_score_place(\n",
    "    df: pl.LazyFrame,\n",
    "    text_weight: float = 0.4,\n",
    "    importance_weight: float = 0.35,\n",
    "    feature_weight: float = 0.15,\n",
    "    distance_weight: float = 0.1,\n",
    "    search_term: str | None = None,\n",
    "    center_lat: float | None = None,\n",
    "    center_lon: float | None = None,\n",
    ") -> pl.LazyFrame:\n",
    "    \"\"\"\n",
    "    Score places based on multiple factors.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame with search results\n",
    "    - level: Admin level (0=country, 1=admin1, etc.)\n",
    "    - text_weight: Weight for text matching score\n",
    "    - importance_weight: Weight for pre-calculated importance\n",
    "    - feature_weight: Weight for feature type relevance\n",
    "    - distance_weight: Weight for geographic proximity (if center point provided)\n",
    "    - search_term: Original search term for exact matching\n",
    "    - center_lat/lon: Center point for distance calculation (from previous admin results)\n",
    "    \"\"\"\n",
    "    score_col = \"place_score\"\n",
    "    columns = df.collect_schema().names()\n",
    "\n",
    "    # Text relevance score (FTS)\n",
    "    fts_column = \"fts_score\"\n",
    "    if fts_column in columns:\n",
    "        # Normalize FTS score\n",
    "        df = df.with_columns(\n",
    "            z_score=(\n",
    "                (pl.col(fts_column) - pl.col(fts_column).mean())\n",
    "                / pl.when(pl.col(fts_column).std() > 0)\n",
    "                .then(pl.col(fts_column).std())\n",
    "                .otherwise(1.0)\n",
    "            ),\n",
    "        ).with_columns(text_score=(1 / (1 + pl.col.z_score.mul(-1.5).exp())))\n",
    "\n",
    "        # Exact match bonus\n",
    "        if search_term:\n",
    "            df = df.with_columns(\n",
    "                text_score=pl.when(\n",
    "                    pl.col.name.str.to_lowercase() == search_term.lower()\n",
    "                )\n",
    "                .then(1)\n",
    "                .when(pl.col.name.str.to_lowercase().str.contains(search_term.lower()))\n",
    "                .then(pl.col.text_score + 0.25)\n",
    "                .otherwise(pl.col.text_score)\n",
    "                .clip(0, 1)\n",
    "            )\n",
    "    else:\n",
    "        df = df.with_columns(text_score=pl.lit(0.5))\n",
    "\n",
    "    # 2. Importance score (already normalized between 0-1)\n",
    "    if \"importance_score\" in columns:\n",
    "        df = df.with_columns(importance_norm=pl.col(\"importance_score\").clip(0, 1))\n",
    "    else:\n",
    "        df = df.with_columns(importance_norm=pl.lit(0.5))\n",
    "\n",
    "    # Feature type scoring for places\n",
    "    if \"feature_code\" in columns:\n",
    "        df = df.with_columns(\n",
    "            # Capital/admin centers\n",
    "            feature_score=pl.when(\n",
    "                pl.col(\"feature_code\").is_in(\n",
    "                    [\"PPLC\", \"PPLA\", \"PPLA2\", \"PPLA3\", \"PPLA4\"]\n",
    "                )\n",
    "            )\n",
    "            .then(1.0)\n",
    "            # Major landmarks\n",
    "            .when(pl.col(\"feature_code\").is_in([\"CSTL\", \"MNMT\", \"RUIN\", \"TOWR\"]))\n",
    "            .then(0.95)\n",
    "            # Cultural venues\n",
    "            .when(pl.col(\"feature_code\").is_in([\"MUS\", \"THTR\", \"AMTH\", \"LIBR\", \"OPRA\"]))\n",
    "            .then(0.9)\n",
    "            # Populated places\n",
    "            .when(pl.col(\"feature_code\").is_in([\"PPL\", \"PPLF\", \"PPLS\", \"PPLX\"]))\n",
    "            .then(0.85)\n",
    "            # Transportation hubs\n",
    "            .when(pl.col(\"feature_code\").is_in([\"AIRP\", \"RSTN\", \"PRT\", \"MAR\"]))\n",
    "            .then(0.8)\n",
    "            # Educational/medical/institutions\n",
    "            .when(pl.col(\"feature_code\").is_in([\"UNIV\", \"SCH\", \"HSP\", \"HTL\", \"RSRT\"]))\n",
    "            .then(0.75)\n",
    "            # Commercial\n",
    "            .when(pl.col(\"feature_code\").is_in([\"MALL\", \"MKT\"]))\n",
    "            .then(0.7)\n",
    "            # Religious sites\n",
    "            .when(pl.col(\"feature_code\").is_in([\"CH\", \"MSQE\", \"TMPL\", \"SHRN\"]))\n",
    "            .then(0.65)\n",
    "            # Natural features\n",
    "            .when(\n",
    "                pl.col(\"feature_code\").is_in(\n",
    "                    [\"MT\", \"PK\", \"VLC\", \"ISL\", \"BCH\", \"LK\", \"BAY\"]\n",
    "                )\n",
    "            )\n",
    "            .then(0.6)\n",
    "            .otherwise(0.3)\n",
    "        )\n",
    "    else:\n",
    "        df = df.with_columns(feature_score=pl.lit(0.5))\n",
    "\n",
    "        # 4. Distance score (if center point provided)\n",
    "    if (\n",
    "        center_lat is not None\n",
    "        and center_lon is not None\n",
    "        and \"latitude\" in columns\n",
    "        and \"longitude\" in columns\n",
    "    ):\n",
    "        # Haversine distance calculation\n",
    "        df = (\n",
    "            df.with_columns(\n",
    "                x=pl.struct(latitude=\"latitude\", longitude=\"longitude\"),\n",
    "                y=pl.struct(\n",
    "                    latitude=center_lat,\n",
    "                    longitude=center_lon,\n",
    "                    schema={\n",
    "                        \"latitude\": pl.Float32,\n",
    "                        \"longitude\": pl.Float32,\n",
    "                    },\n",
    "                ),\n",
    "            )\n",
    "            .with_columns(distance_km=pld.col(\"x\").dist.haversine(\"y\", unit=\"km\"))\n",
    "            .drop(\"x\", \"y\")\n",
    "            .with_columns(\n",
    "                # Convert distance to score (closer = higher score)\n",
    "                # Using exponential decay: score = e^(-distance/50)\n",
    "                distance_score=(-pl.col(\"distance_km\") / 50).exp()\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        df = df.with_columns(distance_score=pl.lit(0.5))\n",
    "\n",
    "    df = df.with_columns(\n",
    "        (\n",
    "            pl.col(\"text_score\").mul(text_weight)\n",
    "            + pl.col(\"importance_norm\").mul(importance_weight)\n",
    "            + pl.col(\"feature_score\").mul(feature_weight)\n",
    "            + pl.col(\"distance_score\").mul(distance_weight)\n",
    "        ).alias(score_col)\n",
    "    )\n",
    "    # 6. Apply tier boost (prioritize higher importance tiers)\n",
    "    if \"importance_tier\" in columns:\n",
    "        df = df.with_columns(\n",
    "            pl.col(score_col)\n",
    "            * pl.when(pl.col(\"importance_tier\") == 1)\n",
    "            .then(1.2)\n",
    "            .when(pl.col(\"importance_tier\") == 2)\n",
    "            .then(1.1)\n",
    "            .when(pl.col(\"importance_tier\") == 3)\n",
    "            .then(1.0)\n",
    "            .when(pl.col(\"importance_tier\") == 4)\n",
    "            .then(0.9)\n",
    "            .otherwise(0.8)\n",
    "            .alias(score_col)\n",
    "        )\n",
    "\n",
    "    return df.sort(score_col, descending=True)\n",
    "\n",
    "\n",
    "def search_place(\n",
    "    term: str,\n",
    "    con: DuckDBPyConnection,\n",
    "    previous_results: pl.DataFrame | None = None,\n",
    "    limit: int = 100,\n",
    "    min_importance_tier: int = 5,\n",
    "    center_lat: float | None = None,\n",
    "    center_lon: float | None = None,\n",
    "    all_cols: bool = False,\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Search for places within the places_search table.\n",
    "\n",
    "    Parameters:\n",
    "    - term: The search term for the place\n",
    "    - con: Database connection\n",
    "    - previous_results: Previous admin search results to filter by\n",
    "    - limit: Maximum number of results\n",
    "    - min_importance_tier: Minimum importance tier to include\n",
    "    - progressive_search: Whether to start with high-importance places first\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with search results\n",
    "    \"\"\"\n",
    "    logger.debug(f\"Searching for places with term: {term}\")\n",
    "\n",
    "    select: list[str] = (\n",
    "        [\n",
    "            \"geonameId\",\n",
    "            \"name\",\n",
    "            \"asciiname\",\n",
    "            \"admin0_code\",\n",
    "            \"admin1_code\",\n",
    "            \"admin2_code\",\n",
    "            \"admin3_code\",\n",
    "            \"admin4_code\",\n",
    "            \"feature_class\",\n",
    "            \"feature_code\",\n",
    "            \"population\",\n",
    "            \"latitude\",\n",
    "            \"longitude\",\n",
    "            \"importance_score\",\n",
    "            \"importance_tier\",\n",
    "        ]\n",
    "        if not all_cols\n",
    "        else [\"*\"]\n",
    "    )\n",
    "\n",
    "    where_clauses = []\n",
    "    admin_cols = []\n",
    "    # Build path filtering from previous results\n",
    "    if previous_results is not None and not previous_results.is_empty():\n",
    "        # Determine which admin code columns to use based on the previous results\n",
    "        for i in range(5):\n",
    "            col = f\"admin{i}_code\"\n",
    "            if (\n",
    "                col in previous_results.columns\n",
    "                and previous_results[col].drop_nulls().shape[0] > 0\n",
    "            ):\n",
    "                admin_cols.append(col)\n",
    "\n",
    "        # Build path conditions using the admin code columns\n",
    "        if admin_cols:\n",
    "            path_conditions = build_path_conditions(previous_results, admin_cols)\n",
    "            if path_conditions:\n",
    "                where_clauses.append(f\"({path_conditions})\")\n",
    "\n",
    "    # Build the WHERE clause\n",
    "    where_clause = \" AND \".join(where_clauses)\n",
    "\n",
    "    # Extract center point from previous results if not provided\n",
    "    if center_lat is None and center_lon is None and previous_results is not None:\n",
    "        if (\n",
    "            \"latitude\" in previous_results.columns\n",
    "            and \"longitude\" in previous_results.columns\n",
    "        ):\n",
    "            logger.debug(\n",
    "                \"No center point provided. Using centroid of previous results.\"\n",
    "            )\n",
    "            # Use the centroid of previous results\n",
    "            center_data = previous_results.select(\n",
    "                [\n",
    "                    pl.mean(\"latitude\").alias(\"center_lat\"),\n",
    "                    pl.mean(\"longitude\").alias(\"center_lon\"),\n",
    "                ]\n",
    "            ).row(0)\n",
    "            center_lat, center_lon = center_data\n",
    "            logger.debug(\n",
    "                f\"Using center point from previous results: ({center_lat}, {center_lon})\"\n",
    "            )\n",
    "\n",
    "        # If progressive search didn't return enough results, or not using progressive search\n",
    "    query = f\"\"\"\n",
    "    WITH filtered_results AS (\n",
    "        SELECT {\",\".join(select)},\n",
    "            fts_main_places_search.match_bm25(geonameId, $term) AS fts_score\n",
    "        FROM places_search\n",
    "        WHERE {where_clause}\n",
    "            AND importance_tier <= {min_importance_tier}\n",
    "    )\n",
    "    SELECT * FROM filtered_results\n",
    "    WHERE fts_score IS NOT NULL\n",
    "    ORDER BY fts_score DESC,\n",
    "        importance_score DESC\n",
    "    LIMIT $limit\n",
    "    \"\"\"\n",
    "    logger.debug(f\"Executing FTS query: {query}\")\n",
    "    results = con.execute(\n",
    "        query,\n",
    "        {\n",
    "            \"term\": term,\n",
    "            \"limit\": limit * 3,\n",
    "        },\n",
    "    ).pl()\n",
    "    logger.debug(f\"Found {results.shape[0]} results\")\n",
    "    # Return empty frame if no results\n",
    "    if results.is_empty():\n",
    "        return results\n",
    "\n",
    "    # Score and sort results\n",
    "    return (\n",
    "        results.lazy()\n",
    "        .pipe(\n",
    "            search_score_place,\n",
    "            search_term=term,\n",
    "            center_lat=center_lat,\n",
    "            center_lon=center_lon,\n",
    "        )\n",
    "        .sort(\"place_score\", descending=True)\n",
    "        .head(limit)\n",
    "        .select(\n",
    "            (\n",
    "                cs.by_name(select),\n",
    "                cs.by_name(\"place_score\"),\n",
    "                cs.starts_with(\"adjusted_score_\"),\n",
    "            )\n",
    "            if not all_cols\n",
    "            else \"*\"\n",
    "        )\n",
    "        .collect()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AdminHierarchy(NamedTuple):\n",
    "    admin0: str | None = None\n",
    "    admin1: str | None = None\n",
    "    admin2: str | None = None\n",
    "    admin3: str | None = None\n",
    "    admin4: str | None = None\n",
    "    place: str | None = None\n",
    "\n",
    "    @classmethod\n",
    "    def from_list(cls, search_terms: list[str | None]) -> Self:\n",
    "        # Handle both 5 and 6 length lists\n",
    "        if len(search_terms) not in [5, 6]:\n",
    "            raise ValueError(\"Search terms must be a list of length 5 or 6\")\n",
    "\n",
    "        # Pad with None if only 5 elements provided\n",
    "        terms = search_terms + [None] if len(search_terms) == 5 else search_terms\n",
    "\n",
    "        return cls(\n",
    "            admin0=terms[0],\n",
    "            admin1=terms[1],\n",
    "            admin2=terms[2],\n",
    "            admin3=terms[3],\n",
    "            admin4=terms[4],\n",
    "            place=terms[5],\n",
    "        )\n",
    "\n",
    "    def get_admin_values(self) -> list[str | None]:\n",
    "        \"\"\"Return a list of admin values\"\"\"\n",
    "        return [self.admin0, self.admin1, self.admin2, self.admin3, self.admin4]\n",
    "\n",
    "    def find_last_non_null_admin_index(self) -> int:\n",
    "        \"\"\"Find the index of the last non-null admin level\"\"\"\n",
    "        admin_values = self.get_admin_values()\n",
    "        return max(\n",
    "            (i for i, term in enumerate(admin_values) if term is not None),\n",
    "            default=-1\n",
    "        )\n",
    "\n",
    "    def move_last_admin_to_place(self) -> 'AdminHierarchy':\n",
    "        \"\"\"Move the last non-null admin level to the place field\"\"\"\n",
    "        last_idx = self.find_last_non_null_admin_index()\n",
    "\n",
    "        if last_idx == -1 or self.place is not None:\n",
    "            return self\n",
    "\n",
    "        admin_values = list(self.get_admin_values())\n",
    "        place_term = admin_values[last_idx]\n",
    "        admin_values[last_idx] = None\n",
    "\n",
    "        return AdminHierarchy(\n",
    "            admin0=admin_values[0],\n",
    "            admin1=admin_values[1],\n",
    "            admin2=admin_values[2],\n",
    "            admin3=admin_values[3],\n",
    "            admin4=admin_values[4],\n",
    "            place=place_term\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SearchResult(TypedDict, total=False):\n",
    "    admin0: pl.DataFrame\n",
    "    admin1: pl.DataFrame\n",
    "    admin2: pl.DataFrame\n",
    "    admin3: pl.DataFrame\n",
    "    admin4: pl.DataFrame\n",
    "    place: pl.DataFrame\n",
    "\n",
    "\n",
    "def find_next_null_admin_level(search_terms: AdminHierarchy | list[str | None]) -> int | None:\n",
    "    \"\"\"\n",
    "    Find the position of the first null admin level after the last non-null admin level.\n",
    "\n",
    "    Args:\n",
    "        search_terms: Either an AdminHierarchy or a list of search terms\n",
    "\n",
    "    Returns:\n",
    "        The index of the first null after the last non-null admin level,\n",
    "        0 if all admin levels are null, or\n",
    "        None if there is no null position available\n",
    "    \"\"\"\n",
    "    # Handle AdminHierarchy object\n",
    "    if isinstance(search_terms, AdminHierarchy):\n",
    "        admin_terms = search_terms.get_admin_values()\n",
    "    else:\n",
    "        # For list input, consider all but the last element if length is 6\n",
    "        admin_terms = search_terms[:-1] if len(search_terms) == 6 else search_terms\n",
    "\n",
    "    # If all admin terms are None, return 0\n",
    "    if all(term is None for term in admin_terms):\n",
    "        return 0\n",
    "\n",
    "    # Find the index of the last non-null admin term\n",
    "    last_non_null_idx = max(\n",
    "        (i for i, term in enumerate(admin_terms) if term is not None),\n",
    "        default=-1\n",
    "    )\n",
    "\n",
    "    # Find the first null after the last non-null\n",
    "    for i in range(last_non_null_idx + 1, len(admin_terms)):\n",
    "        if admin_terms[i] is None:\n",
    "            return i\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def search_admin_hierarchy(\n",
    "    search_terms: AdminHierarchy,\n",
    "    con: DuckDBPyConnection,\n",
    "    limit: int,\n",
    "    all_cols: bool,\n",
    ") -> tuple[SearchResult, pl.DataFrame | None]:\n",
    "    \"\"\"\n",
    "    Search through the admin hierarchy levels.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (results dictionary, last successful results DataFrame)\n",
    "    \"\"\"\n",
    "    results: SearchResult = {}\n",
    "    last_results: pl.DataFrame | None = None\n",
    "\n",
    "    for admin_level, term in enumerate(search_terms.get_admin_values()):\n",
    "        if term is None:\n",
    "            continue\n",
    "\n",
    "        logger.debug(f\"Searching for term '{term}' at admin level {admin_level}\")\n",
    "\n",
    "        search_results = search_admin(\n",
    "            term, admin_level, con, last_results, limit, all_cols\n",
    "        )\n",
    "\n",
    "        if not search_results.is_empty():\n",
    "            results[f\"admin{admin_level}\"] = search_results\n",
    "            last_results = search_results\n",
    "        else:\n",
    "            logger.debug(\n",
    "                f\"No results found for term '{term}' at admin level {admin_level}\"\n",
    "            )\n",
    "\n",
    "    return results, last_results\n",
    "\n",
    "\n",
    "def place_as_admin(\n",
    "    place_term: str,\n",
    "    admin_level: int,\n",
    "    con: DuckDBPyConnection,\n",
    "    last_results: pl.DataFrame | None,\n",
    "    limit: int,\n",
    "    all_cols: bool,\n",
    ") -> pl.DataFrame | None:\n",
    "    \"\"\"\n",
    "    Try searching a place term as an admin level.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame of results if successful, None otherwise\n",
    "    \"\"\"\n",
    "    logger.debug(f\"Trying place term '{place_term}' as admin level {admin_level}\")\n",
    "\n",
    "    results = search_admin(\n",
    "        place_term,\n",
    "        admin_level,\n",
    "        con,\n",
    "        last_results,\n",
    "        limit,\n",
    "        all_cols\n",
    "    )\n",
    "\n",
    "    if not results.is_empty():\n",
    "        return results\n",
    "    else:\n",
    "        logger.debug(\n",
    "            f\"No results found for place term '{place_term}' at admin level {admin_level}\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "\n",
    "def search_place_with_context(\n",
    "    place_term: str,\n",
    "    con: DuckDBPyConnection,\n",
    "    last_results: pl.DataFrame | None,\n",
    "    limit: int,\n",
    "    all_cols: bool = False,\n",
    ") -> pl.DataFrame | None:\n",
    "    \"\"\"\n",
    "    Search for a place with optional context from previous results.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame of results if successful, None otherwise\n",
    "    \"\"\"\n",
    "    logger.debug(f\"Searching for place: '{place_term}'\")\n",
    "\n",
    "    place_results = search_place(\n",
    "        place_term,\n",
    "        con,\n",
    "        previous_results=last_results,\n",
    "        limit=limit,\n",
    "        all_cols=all_cols,\n",
    "    )\n",
    "\n",
    "    if not place_results.is_empty():\n",
    "        return place_results\n",
    "    else:\n",
    "        logger.debug(f\"No place results found for '{place_term}'\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def hierarchical_search(\n",
    "    search_terms: AdminHierarchy,\n",
    "    con: DuckDBPyConnection,\n",
    "    limit: int = 20,\n",
    "    all_cols: bool = False,\n",
    "    try_place_as_admin: bool = True,\n",
    ") -> SearchResult:\n",
    "    \"\"\"\n",
    "    Perform hierarchical geographic search across admin levels.\n",
    "\n",
    "    Args:\n",
    "        search_terms: AdminHierarchy containing search terms\n",
    "        con: Database connection\n",
    "        limit: Maximum results to return per level\n",
    "        all_cols: Return all columns\n",
    "        try_place_as_admin: Whether to try place term as admin level\n",
    "\n",
    "    Returns:\n",
    "        Dictionary mapping level names to search results\n",
    "    \"\"\"\n",
    "    # Auto-promote last admin to place if place is None\n",
    "    if search_terms.place is None and try_place_as_admin:\n",
    "        search_terms = search_terms.move_last_admin_to_place()\n",
    "        if search_terms.place:\n",
    "            logger.debug(f\"Moved last non-null admin level '{search_terms.place}' to place term\")\n",
    "\n",
    "    # Search through admin hierarchy\n",
    "    results, last_results = search_admin_hierarchy(\n",
    "        search_terms, con, limit, all_cols\n",
    "    )\n",
    "\n",
    "    # Try place as admin if enabled\n",
    "    if try_place_as_admin and search_terms.place:\n",
    "        first_null_level = find_next_null_admin_level(search_terms)\n",
    "\n",
    "        if first_null_level is not None and first_null_level < 5:\n",
    "            fallback_results = place_as_admin(\n",
    "                search_terms.place,\n",
    "                first_null_level,\n",
    "                con,\n",
    "                last_results,\n",
    "                limit,\n",
    "                all_cols\n",
    "            )\n",
    "\n",
    "            if fallback_results is not None:\n",
    "                results[f\"admin{first_null_level}\"] = fallback_results\n",
    "                last_results = fallback_results\n",
    "\n",
    "    # Search for place\n",
    "    if search_terms.place:\n",
    "        place_results = search_place_with_context(\n",
    "            search_terms.place,\n",
    "            con,\n",
    "            last_results,\n",
    "            limit,\n",
    "            all_cols\n",
    "        )\n",
    "\n",
    "        if place_results is not None:\n",
    "            results[\"place\"] = place_results\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def flexible_search(\n",
    "    search_terms: list[str],\n",
    "    con: DuckDBPyConnection,\n",
    "    limit: int = 20,\n",
    "    all_cols: bool = False,\n",
    ") -> list[pl.DataFrame]:\n",
    "    \"\"\"\n",
    "    Perform flexible geographic search across admin levels.\n",
    "\n",
    "    Args:\n",
    "        search_terms: List of search terms\n",
    "        con: Database connection\n",
    "        limit: Maximum results to return per level\n",
    "        all_cols: Return all columns\n",
    "\n",
    "    Returns:\n",
    "        List of DataFrames with search results\n",
    "    \"\"\"\n",
    "    # Validate and clean input\n",
    "    if len(search_terms) > 6:\n",
    "        raise ValueError(\"Search terms must be a list of length <= 6\")\n",
    "\n",
    "    search_terms = [term for term in search_terms if term is not None and term.strip()]\n",
    "\n",
    "    if not search_terms:\n",
    "        raise ValueError(\"Search terms must not be empty\")\n",
    "\n",
    "    # Extract place term\n",
    "    place_search = search_terms[-1]\n",
    "    specific_place_term = len(search_terms) == 6\n",
    "\n",
    "    if specific_place_term:\n",
    "        search_terms.pop()  # Remove place term from admin terms\n",
    "\n",
    "    logger.debug(f\"Search terms: {search_terms}\")\n",
    "\n",
    "    # Search through admin terms\n",
    "    previous_results = None\n",
    "    results = []\n",
    "    empty_terms = 5 - len(search_terms)\n",
    "\n",
    "    for i, term in enumerate(search_terms):\n",
    "        logger.debug(f\"Searching for term '{term}' at admin level {i}\")\n",
    "        search_range = list(range(i, (empty_terms + i + 1)))\n",
    "        logger.debug(f\"Searching for: '{term}' in range {search_range}\")\n",
    "\n",
    "        search_results = search_admin(\n",
    "            term,\n",
    "            search_range,\n",
    "            con,\n",
    "            previous_results,\n",
    "            limit,\n",
    "            all_cols,\n",
    "        )\n",
    "\n",
    "        if not search_results.is_empty():\n",
    "            results.append(search_results)\n",
    "\n",
    "            # Special handling for last term when not specific place\n",
    "            if i == len(search_terms) - 1 and not specific_place_term:\n",
    "                logger.debug(\n",
    "                    f\"Appending results from term '{term}' to previous results for place search\"\n",
    "                )\n",
    "                if previous_results is not None:\n",
    "                    previous_results = pl.concat([previous_results, search_results], how=\"diagonal\")\n",
    "                else:\n",
    "                    previous_results = search_results\n",
    "            else:\n",
    "                previous_results = search_results\n",
    "        else:\n",
    "            logger.debug(f\"No results found for term '{term}' in range {search_range}\")\n",
    "\n",
    "    # Search for place\n",
    "    place_results = search_place_with_context(\n",
    "        place_search,\n",
    "        con,\n",
    "        previous_results,\n",
    "        limit,\n",
    "        all_cols\n",
    "    )\n",
    "\n",
    "    if place_results is not None:\n",
    "        results.append(place_results)\n",
    "    else:\n",
    "        # Fallback: try place as admin at available levels\n",
    "        if not specific_place_term:\n",
    "            # Try at next available admin level\n",
    "            next_level = len(search_terms)\n",
    "            if next_level < 5:\n",
    "                logger.debug(f\"Fallback: trying place '{place_search}' as admin{next_level}\")\n",
    "\n",
    "                fallback_results = place_as_admin(\n",
    "                    place_search,\n",
    "                    list(range(next_level, 5)),\n",
    "                    con,\n",
    "                    previous_results,\n",
    "                    limit,\n",
    "                    all_cols\n",
    "                )\n",
    "\n",
    "                if fallback_results is not None:\n",
    "                    results.append(fallback_results)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def backfill_hierarchy(row: dict, con: DuckDBPyConnection) -> dict:\n",
    "    \"\"\"\n",
    "    Backfill the complete hierarchy for a given row.\n",
    "\n",
    "    Args:\n",
    "        row: Dictionary containing admin codes\n",
    "        con: Database connection\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with complete hierarchy information\n",
    "    \"\"\"\n",
    "    def get_where_clause(codes: list[str | None]) -> str:\n",
    "        conditions = []\n",
    "        for i, code in enumerate(codes):\n",
    "            if code is not None:\n",
    "                conditions.append(f\"admin{i}_code = '{code}'\")\n",
    "            else:\n",
    "                conditions.append(f\"admin{i}_code IS NULL\")\n",
    "        return \"WHERE \" + \" AND \".join(conditions)\n",
    "\n",
    "    hierarchy = {}\n",
    "    codes = []\n",
    "\n",
    "    for i in range(5):\n",
    "        code = row.get(f\"admin{i}_code\")\n",
    "        codes.append(code)\n",
    "\n",
    "        if code is not None:\n",
    "            query = f\"SELECT geonameId, name FROM admin_search WHERE admin_level = {i} AND {get_where_clause(codes)} LIMIT 1\"\n",
    "            df = con.execute(query).pl()\n",
    "\n",
    "            if not df.is_empty():\n",
    "                hierarchy[f\"admin{i}\"] = df.to_dicts()[0]\n",
    "\n",
    "    return hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdminHierarchy(NamedTuple):\n",
    "    admin0: str | None = None\n",
    "    admin1: str | None = None\n",
    "    admin2: str | None = None\n",
    "    admin3: str | None = None\n",
    "    admin4: str | None = None\n",
    "    place: str | None = None\n",
    "\n",
    "    @classmethod\n",
    "    def from_list(cls, search_terms: list[str | None]) -> Self:\n",
    "        # Handle both 5 and 6 length lists\n",
    "        if len(search_terms) not in [5, 6]:\n",
    "            raise ValueError(\"Search terms must be a list of length 5 or 6\")\n",
    "\n",
    "        # Pad with None if only 5 elements provided\n",
    "        terms = search_terms + [None] if len(search_terms) == 5 else search_terms\n",
    "\n",
    "        return cls(\n",
    "            admin0=terms[0],\n",
    "            admin1=terms[1],\n",
    "            admin2=terms[2],\n",
    "            admin3=terms[3],\n",
    "            admin4=terms[4],\n",
    "            place=terms[5],\n",
    "        )\n",
    "\n",
    "\n",
    "class SearchResult(TypedDict, total=False):\n",
    "    admin0: pl.DataFrame\n",
    "    admin1: pl.DataFrame\n",
    "    admin2: pl.DataFrame\n",
    "    admin3: pl.DataFrame\n",
    "    admin4: pl.DataFrame\n",
    "    place: pl.DataFrame\n",
    "\n",
    "\n",
    "def find_next_null_admin_level(search_terms: AdminHierarchy | list[str | None]) -> int | None:\n",
    "    \"\"\"\n",
    "    Find the position of the first null admin level after the last non-null admin level.\n",
    "\n",
    "    Args:\n",
    "        search_terms: Either an AdminHierarchy or a list of search terms where the last element\n",
    "                     is the place term (optional in list form)\n",
    "\n",
    "    Returns:\n",
    "        The index of the first null after the last non-null admin level,\n",
    "        0 if all admin levels are null, or\n",
    "        None if there is no null position available\n",
    "\n",
    "    Examples:\n",
    "        [None, None, A, None, B, Place] -> None (no null after B)\n",
    "        [None, None, None, None, None, Place] -> 0 (all admin levels null)\n",
    "        [A, None, None, None, None, Place] -> 1 (next null after A)\n",
    "        [A, B, C, None, None, Place] -> 3 (next null after C)\n",
    "    \"\"\"\n",
    "    # Handle AdminHierarchy object\n",
    "    if isinstance(search_terms, AdminHierarchy):\n",
    "        admin_terms = [\n",
    "            search_terms.admin0,\n",
    "            search_terms.admin1,\n",
    "            search_terms.admin2,\n",
    "            search_terms.admin3,\n",
    "            search_terms.admin4\n",
    "        ]\n",
    "    else:\n",
    "        # For list input, consider all but the last element if length is 6\n",
    "        admin_terms = search_terms[:-1] if len(search_terms) == 6 else search_terms\n",
    "    # If all admin terms are None, return 0\n",
    "    if all(term is None for term in admin_terms):\n",
    "        return 0\n",
    "    # Find the index of the last non-null admin term\n",
    "    last_non_null_idx = max((i for i, term in enumerate(admin_terms) if term is not None), default=-1)\n",
    "    # Find the first null after the last non-null\n",
    "    for i in range(last_non_null_idx + 1, len(admin_terms)):\n",
    "        if admin_terms[i] is None:\n",
    "            return i\n",
    "    # If there's no null after the last non-null, return None\n",
    "    return None\n",
    "\n",
    "def hierarchical_search(\n",
    "    search_terms: AdminHierarchy,\n",
    "    con: DuckDBPyConnection,\n",
    "    limit: int = 20,\n",
    "    all_cols: bool = False,\n",
    "    try_place_as_admin: bool = True,\n",
    ") -> SearchResult:\n",
    "    \"\"\"\n",
    "    Perform hierarchical geographic search across admin levels.\n",
    "\n",
    "    Args:\n",
    "        search_terms: List of search terms, ordered by admin level (admin0 (country), admin1, admin2, etc.)\n",
    "        con: Database connection\n",
    "        limit: Maximum results to return per level\n",
    "\n",
    "    Returns:\n",
    "        Dictionary mapping level names to search results\n",
    "    \"\"\"\n",
    "\n",
    "    results: SearchResult = {}\n",
    "    last_results: pl.DataFrame | None = None\n",
    "\n",
    "    # if place is none then move the last non-null admin level to the place term as it will be searched as an admin level anyway that way\n",
    "    if search_terms.place is None:\n",
    "        # Get last non-null admin level\n",
    "        admin_values = [search_terms.admin0, search_terms.admin1,\n",
    "                        search_terms.admin2, search_terms.admin3, search_terms.admin4]\n",
    "        last_non_null_idx = max(\n",
    "            (i for i, term in enumerate(admin_values) if term is not None), default=-1\n",
    "        )\n",
    "        if last_non_null_idx != -1:\n",
    "            # Create a new tuple with the modifications - move last non-null to place\n",
    "            place_term = admin_values[last_non_null_idx]\n",
    "            new_admin_values = list(admin_values)\n",
    "            new_admin_values[last_non_null_idx] = None\n",
    "\n",
    "            # Create a new AdminHierarchy with the updated values\n",
    "            search_terms = AdminHierarchy(\n",
    "                admin0=new_admin_values[0],\n",
    "                admin1=new_admin_values[1],\n",
    "                admin2=new_admin_values[2],\n",
    "                admin3=new_admin_values[3],\n",
    "                admin4=new_admin_values[4],\n",
    "                place=place_term\n",
    "            )\n",
    "\n",
    "            logger.debug(f\"Moved last non-null admin level '{place_term}' to place term\")\n",
    "\n",
    "\n",
    "\n",
    "    for admin_level, term in enumerate([\n",
    "        search_terms.admin0,\n",
    "        search_terms.admin1,\n",
    "        search_terms.admin2,\n",
    "        search_terms.admin3,\n",
    "        search_terms.admin4\n",
    "    ]):\n",
    "        if term is None:\n",
    "            continue\n",
    "\n",
    "        logger.debug(f\"Searching for term '{term}' at admin level {admin_level}\")\n",
    "\n",
    "        # Perform the search\n",
    "        search_results = search_admin(\n",
    "            term, admin_level, con, last_results, limit, all_cols\n",
    "        )\n",
    "\n",
    "        # If results are found, store them in the results dictionary\n",
    "        if not search_results.is_empty():\n",
    "            results[f\"admin{admin_level}\"] = search_results\n",
    "            last_results = search_results\n",
    "        else:\n",
    "            logger.debug(\n",
    "                f\"No results found for term '{term}' at admin level {admin_level}\"\n",
    "            )\n",
    "\n",
    "    first_null_admin_level = find_next_null_admin_level(search_terms)\n",
    "    if first_null_admin_level is not None:\n",
    "        logger.debug(f\"First null admin level found at index {first_null_admin_level}\")\n",
    "        # If we have a place term, we can try searching it as an admin level\n",
    "        if first_null_admin_level < 5 and search_terms.place is not None:\n",
    "            logger.debug(\n",
    "                f\"Trying place term '{search_terms.place}' as admin level {first_null_admin_level}\"\n",
    "            )\n",
    "            fallback_results = search_admin(\n",
    "                search_terms.place,\n",
    "                first_null_admin_level,\n",
    "                con,\n",
    "                last_results,\n",
    "                limit,\n",
    "                all_cols\n",
    "            )\n",
    "            if not fallback_results.is_empty():\n",
    "                results[f\"admin{first_null_admin_level}\"] = fallback_results\n",
    "                # last_results = pl.concat(\n",
    "                #     [last_results, fallback_results], how=\"diagonal\"\n",
    "                # )\n",
    "                last_results = fallback_results\n",
    "            else:\n",
    "                logger.debug(\n",
    "                    f\"No results found for place term '{search_terms.place}' at admin level {first_null_admin_level}\"\n",
    "                )\n",
    "\n",
    "    if search_terms.place is not None:\n",
    "        logger.debug(f\"Searching for place: '{search_terms.place}'\")\n",
    "\n",
    "        # If we have admin results, use them to filter the place search\n",
    "        place_results = search_place(\n",
    "            search_terms.place,\n",
    "            con,\n",
    "            previous_results=last_results,\n",
    "            limit=limit\n",
    "        )\n",
    "\n",
    "        if not place_results.is_empty():\n",
    "            results[\"place\"] = place_results\n",
    "        else:\n",
    "            logger.debug(f\"No place results found for '{search_terms.place}'\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def flexible_search(\n",
    "    search_terms: list[str],\n",
    "    con: DuckDBPyConnection,\n",
    "    limit: int = 50,\n",
    "    all_cols: bool = False,\n",
    ") -> list[pl.DataFrame]:\n",
    "    \"\"\"\n",
    "    Perform flexible geographic search across admin levels.\n",
    "\n",
    "    Args:\n",
    "        search_terms: List of search terms, ordered by admin level (admin0 (country), admin1, admin2, etc.)\n",
    "        con: Database connection\n",
    "        limit: Maximum results to return per level\n",
    "\n",
    "    Returns:\n",
    "        Dictionary mapping level names to search results\n",
    "    \"\"\"\n",
    "    assert len(search_terms) <= 6, \"Search terms must be a list of length <= 6\"\n",
    "    search_terms = [term for term in search_terms if term is not None and term.strip()]\n",
    "\n",
    "    if len(search_terms) == 0:\n",
    "        raise ValueError(\"Search terms must not be empty\")\n",
    "\n",
    "    # Last term is the place search term\n",
    "    place_search: str = search_terms[-1]\n",
    "    specific_places_term: bool = False\n",
    "    if len(search_terms) == 6:\n",
    "        place_search = search_terms.pop()\n",
    "        specific_places_term = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    logger.debug(f\"Search terms: {search_terms}\")\n",
    "    empty_terms = 5 - len(search_terms)\n",
    "\n",
    "    previous_results: pl.DataFrame | None = None\n",
    "    results = []\n",
    "\n",
    "    for i, term in enumerate(search_terms):\n",
    "        logger.debug(f\"Searching for term '{term}' at admin level {i}\")\n",
    "        search_range = list(range(i, (empty_terms + i + 1)))\n",
    "        logger.debug(f\"Searching for: '{term}' in range {search_range}\")\n",
    "        search_results = search_admin(\n",
    "            term,\n",
    "            search_range,\n",
    "            con,\n",
    "            previous_results,\n",
    "            limit,\n",
    "            all_cols,\n",
    "        )\n",
    "        if not search_results.is_empty():\n",
    "            results.append(search_results)\n",
    "            # If last iteration of the loop and we dont have a specific place term, what we are esentially doing is chancing it by using the last term as an admin search and as a places term. Because of that if the admin search returns garbage because its a place we want to avoid being locked in to garbage so if thats the case we can append the results to the previous results and use that on the place search.\n",
    "            if i == len(search_terms) - 1 and not specific_places_term:\n",
    "                logger.debug(\n",
    "                    f\"Appending results from term '{term}' to previous results for place search\"\n",
    "                )\n",
    "                previous_results = pl.concat(\n",
    "                    [previous_results, search_results])\n",
    "            else:\n",
    "                previous_results = search_results\n",
    "        else:\n",
    "            logger.debug(f\"No results found for term '{term}' in range {search_range}\")\n",
    "\n",
    "    logger.debug(f\"Searching for place: '{place_search}'\")\n",
    "    place_results = search_place(\n",
    "        place_search,\n",
    "        con,\n",
    "        previous_results,\n",
    "        limit,\n",
    "        all_cols=all_cols,\n",
    "    )\n",
    "    if not place_results.is_empty():\n",
    "        results.append(place_results)\n",
    "    else:\n",
    "        logger.debug(f\"No place results found for '{place_search}'\")\n",
    "        # TODO: Fallback if no place found. If we have a place that hasn't been tried against the admin levels, we can try it as an admin level here.\n",
    "    return results\n",
    "\n",
    "\n",
    "def backfill_hierarchy(row: dict, con: DuckDBPyConnection) -> dict:\n",
    "    def get_where_clause(codes: list[str | None]) -> str:\n",
    "        return \"WHERE \" + \" AND \".join(\n",
    "            [\n",
    "                f\"admin{i}_code = '{code}'\"\n",
    "                if code is not None\n",
    "                else f\"admin{i}_code IS NULL\"\n",
    "                for i, code in enumerate(codes)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    hierarchy = {}\n",
    "    codes = []\n",
    "    for i in range(5):\n",
    "        print(i)\n",
    "        code = row.get(f\"admin{i}_code\")\n",
    "        codes.append(code)\n",
    "        if code is not None:\n",
    "            df = con.execute(\n",
    "                f\"SELECT geonameId, name FROM admin{i} {get_where_clause(codes)} LIMIT 1\"\n",
    "            ).pl()\n",
    "            if not df.is_empty():\n",
    "                hierarchy[f\"admin{i}\"] = df.to_dicts()[0]\n",
    "    return hierarchy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 21:21:20.126\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mhierarchical_search\u001b[0m:\u001b[36m232\u001b[0m - \u001b[34m\u001b[1mMoved last non-null admin level 'Beverly Hills' to place term\u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:20.127\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin_hierarchy\u001b[0m:\u001b[36m127\u001b[0m - \u001b[34m\u001b[1mSearching for term 'US' at admin level 0\u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:20.133\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 0) AND (admin_level != 0 OR geonameId NOT IN (6252001))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:20.160\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_score_admin\u001b[0m:\u001b[36m178\u001b[0m - \u001b[33m\u001b[1mNo parent score column found. Skipping parent factor.\u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:20.162\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin_hierarchy\u001b[0m:\u001b[36m127\u001b[0m - \u001b[34m\u001b[1mSearching for term 'CA' at admin level 1\u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:20.164\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 1) AND ((admin0_code = 'VI') OR (admin0_code = 'US') OR (admin0_code = 'UM') OR (admin0_code = 'GU') OR (admin0_code = 'UZ'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:20.184\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin_hierarchy\u001b[0m:\u001b[36m127\u001b[0m - \u001b[34m\u001b[1mSearching for term 'Los Angeles County' at admin level 2\u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:20.185\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 2) AND ((admin0_code = 'US' AND admin1_code = 'CA'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:20.217\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mplace_as_admin\u001b[0m:\u001b[36m158\u001b[0m - \u001b[34m\u001b[1mTrying place term 'Beverly Hills' as admin level 3\u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:20.218\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 3) AND ((admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '059') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '093') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '019') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '027') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '085') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '075') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '111') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '047') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '037') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '113') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '011') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '107') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '041') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '095') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '097') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '067') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '029') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '061') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '031') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '087'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:20.244\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place_with_context\u001b[0m:\u001b[36m191\u001b[0m - \u001b[34m\u001b[1mSearching for place: 'Beverly Hills'\u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:20.245\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m186\u001b[0m - \u001b[34m\u001b[1mSearching for places with term: Beverly Hills\u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:20.246\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m238\u001b[0m - \u001b[34m\u001b[1mNo center point provided. Using centroid of previous results.\u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:20.246\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m249\u001b[0m - \u001b[34m\u001b[1mUsing center point from previous results: (34.131099700927734, -118.60806274414062)\u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:20.246\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m268\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude,importance_score,importance_tier,\n",
      "            fts_main_places_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM places_search\n",
      "        WHERE ((admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '037' AND admin3_code = '11788500') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '037' AND admin3_code = '11789027') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '037' AND admin3_code = '11788576'))\n",
      "            AND importance_tier <= 5\n",
      "    )\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC,\n",
      "        importance_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:20.536\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m276\u001b[0m - \u001b[34m\u001b[1mFound 0 results\u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:20.537\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place_with_context\u001b[0m:\u001b[36m204\u001b[0m - \u001b[34m\u001b[1mNo place results found for 'Beverly Hills'\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 17)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>asciiname</th><th>admin0_code</th><th>admin1_code</th><th>admin2_code</th><th>admin3_code</th><th>admin4_code</th><th>feature_class</th><th>feature_code</th><th>population</th><th>latitude</th><th>longitude</th><th>adjusted_score_0</th><th>adjusted_score_1</th><th>adjusted_score_2</th><th>adjusted_score_3</th></tr><tr><td>u32</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i32</td><td>f32</td><td>f32</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>11788500</td><td>&quot;City of Beverly Hills&quot;</td><td>&quot;City of Beverly Hills&quot;</td><td>&quot;US&quot;</td><td>&quot;CA&quot;</td><td>&quot;037&quot;</td><td>&quot;11788500&quot;</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM3&quot;</td><td>0</td><td>34.07856</td><td>-118.402107</td><td>0.76254</td><td>0.6612</td><td>0.805971</td><td>0.545093</td></tr><tr><td>11789027</td><td>&quot;City of Hidden Hills&quot;</td><td>&quot;City of Hidden Hills&quot;</td><td>&quot;US&quot;</td><td>&quot;CA&quot;</td><td>&quot;037&quot;</td><td>&quot;11789027&quot;</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM3&quot;</td><td>0</td><td>34.163738</td><td>-118.661201</td><td>0.76254</td><td>0.6612</td><td>0.805971</td><td>0.362961</td></tr><tr><td>11788576</td><td>&quot;City of Agoura Hills&quot;</td><td>&quot;City of Agoura Hills&quot;</td><td>&quot;US&quot;</td><td>&quot;CA&quot;</td><td>&quot;037&quot;</td><td>&quot;11788576&quot;</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM3&quot;</td><td>0</td><td>34.151001</td><td>-118.76088</td><td>0.76254</td><td>0.6612</td><td>0.805971</td><td>0.362961</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 17)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ geonameId ┆ name      ┆ asciiname ┆ admin0_co ┆ … ┆ adjusted_ ┆ adjusted_ ┆ adjusted_ ┆ adjusted │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ de        ┆   ┆ score_0   ┆ score_1   ┆ score_2   ┆ _score_3 │\n",
       "│ u32       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆           ┆ str       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 11788500  ┆ City of   ┆ City of   ┆ US        ┆ … ┆ 0.76254   ┆ 0.6612    ┆ 0.805971  ┆ 0.545093 │\n",
       "│           ┆ Beverly   ┆ Beverly   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Hills     ┆ Hills     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 11789027  ┆ City of   ┆ City of   ┆ US        ┆ … ┆ 0.76254   ┆ 0.6612    ┆ 0.805971  ┆ 0.362961 │\n",
       "│           ┆ Hidden    ┆ Hidden    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Hills     ┆ Hills     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 11788576  ┆ City of   ┆ City of   ┆ US        ┆ … ┆ 0.76254   ┆ 0.6612    ┆ 0.805971  ┆ 0.362961 │\n",
       "│           ┆ Agoura    ┆ Agoura    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Hills     ┆ Hills     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hierarchical search with place\n",
    "st = [\"US\", \"CA\", \"Los Angeles County\", \"Beverly Hills\", None, None]\n",
    "search_terms = AdminHierarchy.from_list(st)\n",
    "results = hierarchical_search(search_terms, con)\n",
    "results.get(\"admin3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 21:21:26.713\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m307\u001b[0m - \u001b[34m\u001b[1mSearch terms: ['US', 'CA', 'San Francisco']\u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:26.714\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m315\u001b[0m - \u001b[34m\u001b[1mSearching for term 'US' at admin level 0\u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:26.714\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m317\u001b[0m - \u001b[34m\u001b[1mSearching for: 'US' in range [0, 1, 2]\u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:26.722\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 0 OR admin_level = 1 OR admin_level = 2) AND (admin_level != 0 OR geonameId NOT IN (6252001))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:26.749\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_score_admin\u001b[0m:\u001b[36m178\u001b[0m - \u001b[33m\u001b[1mNo parent score column found. Skipping parent factor.\u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:26.751\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m315\u001b[0m - \u001b[34m\u001b[1mSearching for term 'CA' at admin level 1\u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:26.751\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m317\u001b[0m - \u001b[34m\u001b[1mSearching for: 'CA' in range [1, 2, 3]\u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:26.753\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 1 OR admin_level = 2 OR admin_level = 3) AND ((admin0_code = 'UM') OR (admin0_code = 'VI') OR (admin0_code = 'UZ') OR (admin0_code = 'GU') OR (admin0_code = 'AF' AND admin1_code = '40' AND admin2_code = '302') OR (admin0_code = 'FR' AND admin1_code = '44' AND admin2_code = '55') OR (admin0_code = 'AS' AND admin1_code = '040') OR (admin0_code = 'MN' AND admin1_code = '15' AND admin2_code = '6619052') OR (admin0_code = 'GE' AND admin1_code = '71' AND admin2_code = '615141') OR (admin0_code = 'NO' AND admin1_code = '34' AND admin2_code = '3430') OR (admin0_code = 'US'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:26.846\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m315\u001b[0m - \u001b[34m\u001b[1mSearching for term 'San Francisco' at admin level 2\u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:26.847\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m317\u001b[0m - \u001b[34m\u001b[1mSearching for: 'San Francisco' in range [2, 3, 4]\u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:26.849\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 2 OR admin_level = 3 OR admin_level = 4) AND ((admin0_code = 'US' AND admin1_code = 'CA') OR (admin0_code = 'US' AND admin1_code = 'KS' AND admin2_code = '019') OR (admin0_code = 'US' AND admin1_code = 'NY' AND admin2_code = '013'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:26.878\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m333\u001b[0m - \u001b[34m\u001b[1mAppending results from term 'San Francisco' to previous results for place search\u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:26.879\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place_with_context\u001b[0m:\u001b[36m191\u001b[0m - \u001b[34m\u001b[1mSearching for place: 'San Francisco'\u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:26.879\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m186\u001b[0m - \u001b[34m\u001b[1mSearching for places with term: San Francisco\u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:26.880\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m238\u001b[0m - \u001b[34m\u001b[1mNo center point provided. Using centroid of previous results.\u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:26.881\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m249\u001b[0m - \u001b[34m\u001b[1mUsing center point from previous results: (36.2589225769043, -117.54204559326172)\u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:26.881\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m268\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude,importance_score,importance_tier,\n",
      "            fts_main_places_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM places_search\n",
      "        WHERE ((admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '075') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '073' AND admin3_code = '11788586') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '037' AND admin3_code = '11788599') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '073') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '065' AND admin3_code = '11788966') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '069') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '071') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '041' AND admin3_code = '11788433') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '085' AND admin3_code = '11789001') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '081' AND admin3_code = '11788664') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '019' AND admin3_code = '11788518') OR (admin0_code = 'US' AND admin1_code = 'CA') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '037' AND admin3_code = '11788545') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '059' AND admin3_code = '11788610') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '079' AND admin3_code = '11789043') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '037' AND admin3_code = '11788632') OR (admin0_code = 'US' AND admin1_code = 'KS' AND admin2_code = '019') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '079') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '081') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '077') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '081' AND admin3_code = '11788395') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '073' AND admin3_code = '11788573') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '069' AND admin3_code = '11788869') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '081' AND admin3_code = '11788953') OR (admin0_code = 'US' AND admin1_code = 'NY' AND admin2_code = '013') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '105'))\n",
      "            AND importance_tier <= 5\n",
      "    )\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC,\n",
      "        importance_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 21:21:27.151\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m276\u001b[0m - \u001b[34m\u001b[1mFound 150 results\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[shape: (11, 14)\n",
       " ┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       " │ geonameId ┆ name      ┆ asciiname ┆ admin0_co ┆ … ┆ populatio ┆ latitude  ┆ longitude ┆ adjusted │\n",
       " │ ---       ┆ ---       ┆ ---       ┆ de        ┆   ┆ n         ┆ ---       ┆ ---       ┆ _score_0 │\n",
       " │ u32       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ f32       ┆ f32       ┆ ---      │\n",
       " │           ┆           ┆           ┆ str       ┆   ┆ i32       ┆           ┆           ┆ f64      │\n",
       " ╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       " │ 6252001   ┆ United    ┆ United    ┆ US        ┆ … ┆ 327167434 ┆ 39.759998 ┆ -98.5     ┆ 0.768901 │\n",
       " │           ┆ States    ┆ States    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 2994106   ┆ Meuse     ┆ Meuse     ┆ FR        ┆ … ┆ 200417    ┆ 48.97176  ┆ 5.36371   ┆ 0.47306  │\n",
       " │ 1512440   ┆ Republic  ┆ Republic  ┆ UZ        ┆ … ┆ 32955400  ┆ 41.666672 ┆ 63.833328 ┆ 0.466216 │\n",
       " │           ┆ of Uzbeki ┆ of Uzbeki ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │           ┆ stan      ┆ stan      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 4043988   ┆ Guam      ┆ Guam      ┆ GU        ┆ … ┆ 165768    ┆ 13.47861  ┆ 144.81834 ┆ 0.447696 │\n",
       " │           ┆           ┆           ┆           ┆   ┆           ┆           ┆ 4         ┆          │\n",
       " │ 6619052   ┆ Guchin-Us ┆ Guchin-Us ┆ MN        ┆ … ┆ 0         ┆ 45.458321 ┆ 102.42089 ┆ 0.442675 │\n",
       " │           ┆           ┆           ┆           ┆   ┆           ┆           ┆ 8         ┆          │\n",
       " │ 6453342   ┆ Os        ┆ Os        ┆ NO        ┆ … ┆ 1870      ┆ 62.495361 ┆ 11.22807  ┆ 0.428154 │\n",
       " │ 7054038   ┆ Jabal us  ┆ Jabal us  ┆ AF        ┆ … ┆ 0         ┆ 35.11628  ┆ 69.18412  ┆ 0.425565 │\n",
       " │           ┆ Sarāj     ┆ Saraj     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 4796775   ┆ United    ┆ United    ┆ VI        ┆ … ┆ 106977    ┆ 18.348289 ┆ -64.98348 ┆ 0.423905 │\n",
       " │           ┆ States    ┆ States    ┆           ┆   ┆           ┆           ┆ 2         ┆          │\n",
       " │           ┆ Virgin    ┆ Virgin    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │           ┆ Islands   ┆ Islands   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 5881199   ┆ Swains    ┆ Swains    ┆ AS        ┆ … ┆ 37        ┆ -11.056   ┆ -171.0820 ┆ 0.417198 │\n",
       " │           ┆ Island    ┆ Island    ┆           ┆   ┆           ┆           ┆ 01        ┆          │\n",
       " │ 615141    ┆ Chkhorots ┆ Chkhorots ┆ GE        ┆ … ┆ 0         ┆ 42.61235  ┆ 42.21553  ┆ 0.378476 │\n",
       " │           ┆ ’q’us Mun ┆ 'q'us Mun ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │           ┆ itsip’ali ┆ itsip'ali ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │           ┆ t’e…      ┆ t'e…      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 5854968   ┆ United    ┆ United    ┆ UM        ┆ … ┆ 0         ┆ 5.875     ┆ -162.0570 ┆ 0.266668 │\n",
       " │           ┆ States    ┆ States    ┆           ┆   ┆           ┆           ┆ 07        ┆          │\n",
       " │           ┆ Minor     ┆ Minor     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │           ┆ Outlying  ┆ Outlying  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │           ┆ I…        ┆ I…        ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " └───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘,\n",
       " shape: (3, 15)\n",
       " ┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       " │ geonameId ┆ name      ┆ asciiname ┆ admin0_co ┆ … ┆ latitude  ┆ longitude ┆ adjusted_ ┆ adjusted │\n",
       " │ ---       ┆ ---       ┆ ---       ┆ de        ┆   ┆ ---       ┆ ---       ┆ score_0   ┆ _score_1 │\n",
       " │ u32       ┆ str       ┆ str       ┆ ---       ┆   ┆ f32       ┆ f32       ┆ ---       ┆ ---      │\n",
       " │           ┆           ┆           ┆ str       ┆   ┆           ┆           ┆ f64       ┆ f64      │\n",
       " ╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       " │ 5332921   ┆ Californi ┆ Californi ┆ US        ┆ … ┆ 37.250221 ┆ -119.7512 ┆ null      ┆ 0.685623 │\n",
       " │           ┆ a         ┆ a         ┆           ┆   ┆           ┆ 59        ┆           ┆          │\n",
       " │ 4269433   ┆ Chautauqu ┆ Chautauqu ┆ US        ┆ … ┆ 37.150059 ┆ -96.24537 ┆ null      ┆ 0.544447 │\n",
       " │           ┆ a County  ┆ a County  ┆           ┆   ┆           ┆ 7         ┆           ┆          │\n",
       " │ 5112358   ┆ Chautauqu ┆ Chautauqu ┆ US        ┆ … ┆ 42.30294  ┆ -79.40576 ┆ null      ┆ 0.437603 │\n",
       " │           ┆ a County  ┆ a County  ┆           ┆   ┆           ┆ 2         ┆           ┆          │\n",
       " └───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘,\n",
       " shape: (23, 16)\n",
       " ┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       " │ geonameId ┆ name      ┆ asciiname ┆ admin0_co ┆ … ┆ longitude ┆ adjusted_ ┆ adjusted_ ┆ adjusted │\n",
       " │ ---       ┆ ---       ┆ ---       ┆ de        ┆   ┆ ---       ┆ score_0   ┆ score_1   ┆ _score_2 │\n",
       " │ u32       ┆ str       ┆ str       ┆ ---       ┆   ┆ f32       ┆ ---       ┆ ---       ┆ ---      │\n",
       " │           ┆           ┆           ┆ str       ┆   ┆           ┆ f64       ┆ f64       ┆ f64      │\n",
       " ╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       " │ 5391997   ┆ City and  ┆ City and  ┆ US        ┆ … ┆ -122.4424 ┆ null      ┆ null      ┆ 0.720988 │\n",
       " │           ┆ County of ┆ County of ┆           ┆   ┆ 97        ┆           ┆           ┆          │\n",
       " │           ┆ San       ┆ San       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │           ┆ Francis…  ┆ Francis…  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 5392126   ┆ San       ┆ San       ┆ US        ┆ … ┆ -121.2714 ┆ null      ┆ null      ┆ 0.557838 │\n",
       " │           ┆ Joaquin   ┆ Joaquin   ┆           ┆   ┆ 46        ┆           ┆           ┆          │\n",
       " │           ┆ County    ┆ County    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 5391726   ┆ San Berna ┆ San Berna ┆ US        ┆ … ┆ -116.1784 ┆ null      ┆ null      ┆ 0.55709  │\n",
       " │           ┆ rdino     ┆ rdino     ┆           ┆   ┆ 59        ┆           ┆           ┆          │\n",
       " │           ┆ County    ┆ County    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 5392427   ┆ San Mateo ┆ San Mateo ┆ US        ┆ … ┆ -122.3556 ┆ null      ┆ null      ┆ 0.556374 │\n",
       " │           ┆ County    ┆ County    ┆           ┆   ┆ 59        ┆           ┆           ┆          │\n",
       " │ 5391832   ┆ San Diego ┆ San Diego ┆ US        ┆ … ┆ -116.7702 ┆ null      ┆ null      ┆ 0.555781 │\n",
       " │           ┆ County    ┆ County    ┆           ┆   ┆ 1         ┆           ┆           ┆          │\n",
       " │ 5391692   ┆ San       ┆ San       ┆ US        ┆ … ┆ -121.0749 ┆ null      ┆ null      ┆ 0.536643 │\n",
       " │           ┆ Benito    ┆ Benito    ┆           ┆   ┆ 97        ┆           ┆           ┆          │\n",
       " │           ┆ County    ┆ County    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 5392329   ┆ San Luis  ┆ San Luis  ┆ US        ┆ … ┆ -120.4522 ┆ null      ┆ null      ┆ 0.525668 │\n",
       " │           ┆ Obispo    ┆ Obispo    ┆           ┆   ┆ 02        ┆           ┆           ┆          │\n",
       " │           ┆ County    ┆ County    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 11788395  ┆ City of   ┆ City of   ┆ US        ┆ … ┆ -122.3433 ┆ null      ┆ null      ┆ 0.518985 │\n",
       " │           ┆ South San ┆ South San ┆           ┆   ┆ 61        ┆           ┆           ┆          │\n",
       " │           ┆ Francisco ┆ Francisco ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 5553701   ┆ Trinity   ┆ Trinity   ┆ US        ┆ … ┆ -123.1126 ┆ null      ┆ null      ┆ 0.388446 │\n",
       " │           ┆ County    ┆ County    ┆           ┆   ┆ 33        ┆           ┆           ┆          │\n",
       " │ 11788586  ┆ City of   ┆ City of   ┆ US        ┆ … ┆ -117.1743 ┆ null      ┆ null      ┆ 0.32964  │\n",
       " │           ┆ San       ┆ San       ┆           ┆   ┆ 47        ┆           ┆           ┆          │\n",
       " │           ┆ Marcos    ┆ Marcos    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
       " │ 11788433  ┆ City of   ┆ City of   ┆ US        ┆ … ┆ -122.5072 ┆ null      ┆ null      ┆ 0.32964  │\n",
       " │           ┆ San       ┆ San       ┆           ┆   ┆ 71        ┆           ┆           ┆          │\n",
       " │           ┆ Rafael    ┆ Rafael    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 11788966  ┆ City of   ┆ City of   ┆ US        ┆ … ┆ -116.9915 ┆ null      ┆ null      ┆ 0.32964  │\n",
       " │           ┆ San       ┆ San       ┆           ┆   ┆ 01        ┆           ┆           ┆          │\n",
       " │           ┆ Jacinto   ┆ Jacinto   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 11788953  ┆ City of   ┆ City of   ┆ US        ┆ … ┆ -122.2679 ┆ null      ┆ null      ┆ 0.32964  │\n",
       " │           ┆ San       ┆ San       ┆           ┆   ┆ 9         ┆           ┆           ┆          │\n",
       " │           ┆ Carlos    ┆ Carlos    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 11788599  ┆ City of   ┆ City of   ┆ US        ┆ … ┆ -117.8089 ┆ null      ┆ null      ┆ 0.32964  │\n",
       " │           ┆ San Dimas ┆ San Dimas ┆           ┆   ┆ 83        ┆           ┆           ┆          │\n",
       " │ 11789001  ┆ City of   ┆ City of   ┆ US        ┆ … ┆ -121.8174 ┆ null      ┆ null      ┆ 0.32964  │\n",
       " │           ┆ San Jose  ┆ San Jose  ┆           ┆   ┆ 13        ┆           ┆           ┆          │\n",
       " │ 11788573  ┆ City of   ┆ City of   ┆ US        ┆ … ┆ -117.1333 ┆ null      ┆ null      ┆ 0.32964  │\n",
       " │           ┆ San Diego ┆ San Diego ┆           ┆   ┆ 62        ┆           ┆           ┆          │\n",
       " │ 11788664  ┆ City of   ┆ City of   ┆ US        ┆ … ┆ -122.4312 ┆ null      ┆ null      ┆ 0.32964  │\n",
       " │           ┆ San Bruno ┆ San Bruno ┆           ┆   ┆ 97        ┆           ┆           ┆          │\n",
       " │ 11788632  ┆ City of   ┆ City of   ┆ US        ┆ … ┆ -118.1131 ┆ null      ┆ null      ┆ 0.32964  │\n",
       " │           ┆ San       ┆ San       ┆           ┆   ┆ 9         ┆           ┆           ┆          │\n",
       " │           ┆ Marino    ┆ Marino    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 11789043  ┆ City of   ┆ City of   ┆ US        ┆ … ┆ -120.6689 ┆ null      ┆ null      ┆ 0.314898 │\n",
       " │           ┆ San Luis  ┆ San Luis  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │           ┆ Obispo    ┆ Obispo    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 11788869  ┆ City of   ┆ City of   ┆ US        ┆ … ┆ -121.5382 ┆ null      ┆ null      ┆ 0.314898 │\n",
       " │           ┆ San Juan  ┆ San Juan  ┆           ┆   ┆ 39        ┆           ┆           ┆          │\n",
       " │           ┆ Bautista  ┆ Bautista  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " └───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘,\n",
       " shape: (50, 16)\n",
       " ┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       " │ geonameId ┆ name      ┆ asciiname ┆ admin0_co ┆ … ┆ longitude ┆ importanc ┆ importanc ┆ place_sc │\n",
       " │ ---       ┆ ---       ┆ ---       ┆ de        ┆   ┆ ---       ┆ e_score   ┆ e_tier    ┆ ore      │\n",
       " │ u32       ┆ str       ┆ str       ┆ ---       ┆   ┆ f32       ┆ ---       ┆ ---       ┆ ---      │\n",
       " │           ┆           ┆           ┆ str       ┆   ┆           ┆ f32       ┆ u8        ┆ f64      │\n",
       " ╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       " │ 5361792   ┆ KGO-AM    ┆ KGO-AM    ┆ US        ┆ … ┆ -122.1024 ┆ 0.66      ┆ 2         ┆ 0.733973 │\n",
       " │           ┆ (San Fran ┆ (San Fran ┆           ┆   ┆ 63        ┆           ┆           ┆          │\n",
       " │           ┆ cisco)    ┆ cisco)    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 5361738   ┆ KFAX-AM   ┆ KFAX-AM   ┆ US        ┆ … ┆ -122.1313 ┆ 0.66      ┆ 2         ┆ 0.733971 │\n",
       " │           ┆ (San Fran ┆ (San Fran ┆           ┆   ┆ 48        ┆           ┆           ┆          │\n",
       " │           ┆ cisco)    ┆ cisco)    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 5362388   ┆ KYA-FM    ┆ KYA-FM    ┆ US        ┆ … ┆ -122.1196 ┆ 0.66      ┆ 2         ┆ 0.73397  │\n",
       " │           ┆ (San Fran ┆ (San Fran ┆           ┆   ┆ 9         ┆           ┆           ┆          │\n",
       " │           ┆ cisco)    ┆ cisco)    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 5361988   ┆ KNBR-AM   ┆ KNBR-AM   ┆ US        ┆ … ┆ -122.2344 ┆ 0.66      ┆ 2         ┆ 0.733969 │\n",
       " │           ┆ (San Fran ┆ (San Fran ┆           ┆   ┆ 13        ┆           ┆           ┆          │\n",
       " │           ┆ cisco)    ┆ cisco)    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 5361890   ┆ KKHI-AM   ┆ KKHI-AM   ┆ US        ┆ … ┆ -122.2758 ┆ 0.66      ┆ 2         ┆ 0.733968 │\n",
       " │           ┆ (San Fran ┆ (San Fran ┆           ┆   ┆ 03        ┆           ┆           ┆          │\n",
       " │           ┆ cisco)    ┆ cisco)    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 5361759   ┆ KFRC-AM   ┆ KFRC-AM   ┆ US        ┆ … ┆ -122.2966 ┆ 0.66      ┆ 2         ┆ 0.733964 │\n",
       " │           ┆ (San Fran ┆ (San Fran ┆           ┆   ┆ 38        ┆           ┆           ┆          │\n",
       " │           ┆ cisco)    ┆ cisco)    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 5361840   ┆ KIQI-AM   ┆ KIQI-AM   ┆ US        ┆ … ┆ -122.3119 ┆ 0.66      ┆ 2         ┆ 0.733964 │\n",
       " │           ┆ (San Fran ┆ (San Fran ┆           ┆   ┆ 13        ┆           ┆           ┆          │\n",
       " │           ┆ cisco)    ┆ cisco)    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 5362186   ┆ KSFO-AM   ┆ KSFO-AM   ┆ US        ┆ … ┆ -122.3788 ┆ 0.66      ┆ 2         ┆ 0.733963 │\n",
       " │           ┆ (San Fran ┆ (San Fran ┆           ┆   ┆ 6         ┆           ┆           ┆          │\n",
       " │           ┆ cisco)    ┆ cisco)    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 5362031   ┆ KOIT-AM   ┆ KOIT-AM   ┆ US        ┆ … ┆ -122.3949 ┆ 0.66      ┆ 2         ┆ 0.733963 │\n",
       " │           ┆ (San Fran ┆ (San Fran ┆           ┆   ┆ 74        ┆           ┆           ┆          │\n",
       " │           ┆ cisco)    ┆ cisco)    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 5361727   ┆ KEST-AM   ┆ KEST-AM   ┆ US        ┆ … ┆ -122.3888 ┆ 0.66      ┆ 2         ┆ 0.733963 │\n",
       " │           ┆ (San Fran ┆ (San Fran ┆           ┆   ┆ 63        ┆           ┆           ┆          │\n",
       " │           ┆ cisco)    ┆ cisco)    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
       " │ 9956217   ┆ San       ┆ San       ┆ US        ┆ … ┆ -122.4208 ┆ 0.555     ┆ 3         ┆ 0.729259 │\n",
       " │           ┆ Francisco ┆ Francisco ┆           ┆   ┆ 6         ┆           ┆           ┆          │\n",
       " │           ┆ Ballet    ┆ Ballet    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 11808572  ┆ Madame    ┆ Madame    ┆ US        ┆ … ┆ -122.4148 ┆ 0.66      ┆ 2         ┆ 0.725712 │\n",
       " │           ┆ Tussauds  ┆ Tussauds  ┆           ┆   ┆ 64        ┆           ┆           ┆          │\n",
       " │           ┆ San       ┆ San       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │           ┆ Francisco ┆ Francisco ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 6948439   ┆ San       ┆ San       ┆ US        ┆ … ┆ -122.3909 ┆ 0.625     ┆ 2         ┆ 0.695739 │\n",
       " │           ┆ Francisco ┆ Francisco ┆           ┆   ┆ 99        ┆           ┆           ┆          │\n",
       " │           ┆ Airport   ┆ Airport   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │           ┆ station   ┆ station   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 5392002   ┆ San       ┆ San       ┆ US        ┆ … ┆ -117.2661 ┆ 0.51      ┆ 3         ┆ 0.668602 │\n",
       " │           ┆ Francisco ┆ Francisco ┆           ┆   ┆ 51        ┆           ┆           ┆          │\n",
       " │           ┆ Peak      ┆ Peak      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 5373717   ┆ Mission   ┆ Mission   ┆ US        ┆ … ┆ -122.4555 ┆ 0.575     ┆ 3         ┆ 0.61189  │\n",
       " │           ┆ San       ┆ San       ┆           ┆   ┆ 44        ┆           ┆           ┆          │\n",
       " │           ┆ Francisco ┆ Francisco ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │           ┆ Solano    ┆ Solano    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 5392028   ┆ San       ┆ San       ┆ US        ┆ … ┆ -122.4158 ┆ 0.485     ┆ 3         ┆ 0.598489 │\n",
       " │           ┆ Francisco ┆ Francisco ┆           ┆   ┆ 02        ┆           ┆           ┆          │\n",
       " │           ┆ Public    ┆ Public    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │           ┆ Library   ┆ Library   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 10243872  ┆ Embassy   ┆ Embassy   ┆ US        ┆ … ┆ -122.4012 ┆ 0.375     ┆ 4         ┆ 0.579384 │\n",
       " │           ┆ Suites    ┆ Suites    ┆           ┆   ┆ 53        ┆           ┆           ┆          │\n",
       " │           ┆ San       ┆ San       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │           ┆ Francisco ┆ Francisco ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │           ┆ A…        ┆ A…        ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 6480208   ┆ Embassy   ┆ Embassy   ┆ US        ┆ … ┆ -122.402  ┆ 0.375     ┆ 4         ┆ 0.579384 │\n",
       " │           ┆ Suites    ┆ Suites    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │           ┆ San       ┆ San       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │           ┆ Francisco ┆ Francisco ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │           ┆ A…        ┆ A…        ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 10244269  ┆ InterCont ┆ InterCont ┆ US        ┆ … ┆ -122.4046 ┆ 0.375     ┆ 4         ┆ 0.579383 │\n",
       " │           ┆ inental   ┆ inental   ┆           ┆   ┆ 48        ┆           ┆           ┆          │\n",
       " │           ┆ San       ┆ San       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │           ┆ Francisco ┆ Francisco ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 6480967   ┆ Marriott  ┆ Marriott  ┆ US        ┆ … ┆ -122.4047 ┆ 0.375     ┆ 4         ┆ 0.579383 │\n",
       " │           ┆ San       ┆ San       ┆           ┆   ┆ 01        ┆           ┆           ┆          │\n",
       " │           ┆ Francisco ┆ Francisco ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " └───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "result = flexible_search([\"US\", \"CA\", \"San Francisco\"], con)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 21:14:00.807\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m305\u001b[0m - \u001b[34m\u001b[1mSearch terms: ['United Kingdom', 'London', 'Westminster', 'Parlement']\u001b[0m\n",
      "\u001b[32m2025-05-04 21:14:00.808\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m313\u001b[0m - \u001b[34m\u001b[1mSearching for term 'United Kingdom' at admin level 0\u001b[0m\n",
      "\u001b[32m2025-05-04 21:14:00.808\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m315\u001b[0m - \u001b[34m\u001b[1mSearching for: 'United Kingdom' in range [0, 1]\u001b[0m\n",
      "\u001b[32m2025-05-04 21:14:00.809\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 0 OR admin_level = 1)\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 21:14:00.895\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_score_admin\u001b[0m:\u001b[36m178\u001b[0m - \u001b[33m\u001b[1mNo parent score column found. Skipping parent factor.\u001b[0m\n",
      "\u001b[32m2025-05-04 21:14:00.897\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m313\u001b[0m - \u001b[34m\u001b[1mSearching for term 'London' at admin level 1\u001b[0m\n",
      "\u001b[32m2025-05-04 21:14:00.897\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m315\u001b[0m - \u001b[34m\u001b[1mSearching for: 'London' in range [1, 2]\u001b[0m\n",
      "\u001b[32m2025-05-04 21:14:00.899\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 1 OR admin_level = 2) AND ((admin0_code = 'TZ') OR (admin0_code = 'NL') OR (admin0_code = 'JO') OR (admin0_code = 'MA') OR (admin0_code = 'IN' AND admin1_code = '29') OR (admin0_code = 'TT') OR (admin0_code = 'IN' AND admin1_code = '36') OR (admin0_code = 'AF') OR (admin0_code = 'BR') OR (admin0_code = 'US' AND admin1_code = 'HI') OR (admin0_code = 'UM') OR (admin0_code = 'BT') OR (admin0_code = 'AE') OR (admin0_code = 'ES') OR (admin0_code = 'CM') OR (admin0_code = 'UG' AND admin1_code = 'C') OR (admin0_code = 'GR') OR (admin0_code = 'NO') OR (admin0_code = 'NP') OR (admin0_code = 'TO') OR (admin0_code = 'LS') OR (admin0_code = 'TH') OR (admin0_code = 'SA') OR (admin0_code = 'VE') OR (admin0_code = 'SZ') OR (admin0_code = 'GB') OR (admin0_code = 'LY') OR (admin0_code = 'KH') OR (admin0_code = 'UG') OR (admin0_code = 'LA') OR (admin0_code = 'EG') OR (admin0_code = 'US') OR (admin0_code = 'VI') OR (admin0_code = 'WF' AND admin1_code = '98611') OR (admin0_code = 'MX') OR (admin0_code = 'SE') OR (admin0_code = 'DK') OR (admin0_code = 'BH') OR (admin0_code = 'ID') OR (admin0_code = 'BE'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 21:14:00.935\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m313\u001b[0m - \u001b[34m\u001b[1mSearching for term 'Westminster' at admin level 2\u001b[0m\n",
      "\u001b[32m2025-05-04 21:14:00.936\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m315\u001b[0m - \u001b[34m\u001b[1mSearching for: 'Westminster' in range [2, 3]\u001b[0m\n",
      "\u001b[32m2025-05-04 21:14:00.937\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 2 OR admin_level = 3) AND ((admin0_code = 'GB' AND admin1_code = 'ENG' AND admin2_code = 'GLA') OR (admin0_code = 'US' AND admin1_code = 'CT' AND admin2_code = '011'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 21:14:00.961\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m313\u001b[0m - \u001b[34m\u001b[1mSearching for term 'Parlement' at admin level 3\u001b[0m\n",
      "\u001b[32m2025-05-04 21:14:00.962\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m315\u001b[0m - \u001b[34m\u001b[1mSearching for: 'Parlement' in range [3, 4]\u001b[0m\n",
      "\u001b[32m2025-05-04 21:14:00.963\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 3 OR admin_level = 4) AND ((admin0_code = 'GB' AND admin1_code = 'ENG' AND admin2_code = 'GLA' AND admin3_code = 'P5'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 21:14:00.977\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m341\u001b[0m - \u001b[34m\u001b[1mNo results found for term 'Parlement' in range [3, 4]\u001b[0m\n",
      "\u001b[32m2025-05-04 21:14:00.978\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place_with_context\u001b[0m:\u001b[36m189\u001b[0m - \u001b[34m\u001b[1mSearching for place: 'Parlement'\u001b[0m\n",
      "\u001b[32m2025-05-04 21:14:00.978\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m186\u001b[0m - \u001b[34m\u001b[1mSearching for places with term: Parlement\u001b[0m\n",
      "\u001b[32m2025-05-04 21:14:00.980\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m238\u001b[0m - \u001b[34m\u001b[1mNo center point provided. Using centroid of previous results.\u001b[0m\n",
      "\u001b[32m2025-05-04 21:14:00.980\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m249\u001b[0m - \u001b[34m\u001b[1mUsing center point from previous results: (51.512908935546875, -0.15895000100135803)\u001b[0m\n",
      "\u001b[32m2025-05-04 21:14:00.980\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m268\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude,importance_score,importance_tier,\n",
      "            fts_main_places_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM places_search\n",
      "        WHERE ((admin0_code = 'GB' AND admin1_code = 'ENG' AND admin2_code = 'GLA' AND admin3_code = 'P5'))\n",
      "            AND importance_tier <= 5\n",
      "    )\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC,\n",
      "        importance_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 21:14:01.114\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m276\u001b[0m - \u001b[34m\u001b[1mFound 1 results\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 16)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>asciiname</th><th>admin0_code</th><th>admin1_code</th><th>admin2_code</th><th>admin3_code</th><th>admin4_code</th><th>feature_class</th><th>feature_code</th><th>population</th><th>latitude</th><th>longitude</th><th>importance_score</th><th>importance_tier</th><th>place_score</th></tr><tr><td>u32</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i32</td><td>f32</td><td>f32</td><td>f32</td><td>u8</td><td>f64</td></tr></thead><tbody><tr><td>6944334</td><td>&quot;Houses of Parliament&quot;</td><td>&quot;Houses of Parliament&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;GLA&quot;</td><td>&quot;P5&quot;</td><td>null</td><td>&quot;S&quot;</td><td>&quot;ADMF&quot;</td><td>0</td><td>51.49971</td><td>-0.12496</td><td>0.35</td><td>4</td><td>0.415895</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 16)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ geonameId ┆ name      ┆ asciiname ┆ admin0_co ┆ … ┆ longitude ┆ importanc ┆ importanc ┆ place_sc │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ de        ┆   ┆ ---       ┆ e_score   ┆ e_tier    ┆ ore      │\n",
       "│ u32       ┆ str       ┆ str       ┆ ---       ┆   ┆ f32       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆           ┆ str       ┆   ┆           ┆ f32       ┆ u8        ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 6944334   ┆ Houses of ┆ Houses of ┆ GB        ┆ … ┆ -0.12496  ┆ 0.35      ┆ 4         ┆ 0.415895 │\n",
       "│           ┆ Parliamen ┆ Parliamen ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ t         ┆ t         ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flexible search with potential place\n",
    "flex_terms = [\"United Kingdom\", \"London\", \"Westminster\", \"Parlement\"]\n",
    "flex_results = flexible_search(flex_terms, con)\n",
    "\n",
    "flex_results[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 21:38:52.810\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mhierarchical_search\u001b[0m:\u001b[36m232\u001b[0m - \u001b[34m\u001b[1mMoved last non-null admin level 'Le Lavandou' to place term\u001b[0m\n",
      "\u001b[32m2025-05-04 21:38:52.811\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin_hierarchy\u001b[0m:\u001b[36m127\u001b[0m - \u001b[34m\u001b[1mSearching for term 'FR' at admin level 0\u001b[0m\n",
      "\u001b[32m2025-05-04 21:38:52.819\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT *, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 0) AND (admin_level != 0 OR geonameId NOT IN (3017382))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 21:38:52.838\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_score_admin\u001b[0m:\u001b[36m178\u001b[0m - \u001b[33m\u001b[1mNo parent score column found. Skipping parent factor.\u001b[0m\n",
      "\u001b[32m2025-05-04 21:38:52.839\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin_hierarchy\u001b[0m:\u001b[36m127\u001b[0m - \u001b[34m\u001b[1mSearching for term 'Provence-Alpes-Côte d'Azur' at admin level 1\u001b[0m\n",
      "\u001b[32m2025-05-04 21:38:52.840\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT *, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 1) AND ((admin0_code = 'FR') OR (admin0_code = 'PF') OR (admin0_code = 'GF') OR (admin0_code = 'MF'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 21:38:52.876\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mplace_as_admin\u001b[0m:\u001b[36m158\u001b[0m - \u001b[34m\u001b[1mTrying place term 'Le Lavandou' as admin level 2\u001b[0m\n",
      "\u001b[32m2025-05-04 21:38:52.877\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT *, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 2) AND ((admin0_code = 'FR' AND admin1_code = '24') OR (admin0_code = 'FR' AND admin1_code = 'B9') OR (admin0_code = 'FR' AND admin1_code = 'B4') OR (admin0_code = 'FR' AND admin1_code = '11') OR (admin0_code = 'FR' AND admin1_code = '84') OR (admin0_code = 'FR' AND admin1_code = '93') OR (admin0_code = 'FR' AND admin1_code = '32') OR (admin0_code = 'FR' AND admin1_code = '52'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 21:38:52.909\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mplace_as_admin\u001b[0m:\u001b[36m172\u001b[0m - \u001b[34m\u001b[1mNo results found for place term 'Le Lavandou' at admin level 2\u001b[0m\n",
      "\u001b[32m2025-05-04 21:38:52.910\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place_with_context\u001b[0m:\u001b[36m191\u001b[0m - \u001b[34m\u001b[1mSearching for place: 'Le Lavandou'\u001b[0m\n",
      "\u001b[32m2025-05-04 21:38:52.910\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m186\u001b[0m - \u001b[34m\u001b[1mSearching for places with term: Le Lavandou\u001b[0m\n",
      "\u001b[32m2025-05-04 21:38:52.911\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m238\u001b[0m - \u001b[34m\u001b[1mNo center point provided. Using centroid of previous results.\u001b[0m\n",
      "\u001b[32m2025-05-04 21:38:52.912\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m249\u001b[0m - \u001b[34m\u001b[1mUsing center point from previous results: (46.79526901245117, 3.9487760066986084)\u001b[0m\n",
      "\u001b[32m2025-05-04 21:38:52.912\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m268\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "    WITH filtered_results AS (\n",
      "        SELECT *,\n",
      "            fts_main_places_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM places_search\n",
      "        WHERE ((admin0_code = 'FR' AND admin1_code = '24') OR (admin0_code = 'FR' AND admin1_code = '11') OR (admin0_code = 'FR' AND admin1_code = '93') OR (admin0_code = 'FR' AND admin1_code = '52') OR (admin0_code = 'FR' AND admin1_code = '32') OR (admin0_code = 'FR' AND admin1_code = 'B4') OR (admin0_code = 'FR' AND admin1_code = '84') OR (admin0_code = 'FR' AND admin1_code = 'B9'))\n",
      "            AND importance_tier <= 5\n",
      "    )\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC,\n",
      "        importance_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 21:38:53.173\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m276\u001b[0m - \u001b[34m\u001b[1mFound 60 results\u001b[0m\n",
      "\u001b[32m2025-05-04 21:38:53.176\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m15\u001b[0m - \u001b[34m\u001b[1mAdmin1 results:\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (10, 33)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ geonameId ┆ name      ┆ asciiname ┆ admin_lev ┆ … ┆ average_p ┆ parent_fa ┆ base_scor ┆ adjusted │\n",
      "│ ---       ┆ ---       ┆ ---       ┆ el        ┆   ┆ arent_sco ┆ ctor      ┆ e         ┆ _score_1 │\n",
      "│ u32       ┆ str       ┆ str       ┆ ---       ┆   ┆ re        ┆ ---       ┆ ---       ┆ ---      │\n",
      "│           ┆           ┆           ┆ u8        ┆   ┆ ---       ┆ f64       ┆ f64       ┆ f64      │\n",
      "│           ┆           ┆           ┆           ┆   ┆ f64       ┆           ┆           ┆          │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ 2985244   ┆ Provence- ┆ Provence- ┆ 1         ┆ … ┆ 0.746891  ┆ 1.0       ┆ 0.869319  ┆ 0.81716  │\n",
      "│           ┆ Alpes-Côt ┆ Alpes-Cot ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ e d'Azur  ┆ e d'Azur  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 2983751   ┆ Rhône-Alp ┆ Rhone-Alp ┆ 1         ┆ … ┆ 0.746891  ┆ 1.0       ┆ 0.73502   ┆ 0.690918 │\n",
      "│           ┆ es        ┆ es        ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 11071625  ┆ Auvergne- ┆ Auvergne- ┆ 1         ┆ … ┆ 0.746891  ┆ 1.0       ┆ 0.708504  ┆ 0.665994 │\n",
      "│           ┆ Rhône-Alp ┆ Rhone-Alp ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ es        ┆ es        ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 11071624  ┆ Hauts-de- ┆ Hauts-de- ┆ 1         ┆ … ┆ 0.746891  ┆ 1.0       ┆ 0.607866  ┆ 0.571394 │\n",
      "│           ┆ France    ┆ France    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 3012874   ┆ Île-de-Fr ┆ Ile-de-Fr ┆ 1         ┆ … ┆ 0.746891  ┆ 1.0       ┆ 0.605335  ┆ 0.569015 │\n",
      "│           ┆ ance      ┆ ance      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 2988289   ┆ Pays de   ┆ Pays de   ┆ 1         ┆ … ┆ 0.746891  ┆ 1.0       ┆ 0.605125  ┆ 0.568817 │\n",
      "│           ┆ la Loire  ┆ la Loire  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 3027939   ┆ Centre-Va ┆ Centre-Va ┆ 1         ┆ … ┆ 0.746891  ┆ 1.0       ┆ 0.604934  ┆ 0.568638 │\n",
      "│           ┆ l de      ┆ l de      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ Loire     ┆ Loire     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 2990119   ┆ Nord-Pas- ┆ Nord-Pas- ┆ 1         ┆ … ┆ 0.746891  ┆ 1.0       ┆ 0.599649  ┆ 0.563671 │\n",
      "│           ┆ de-Calais ┆ de-Calais ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 8378478   ┆ Alpes     ┆ Alpes     ┆ 1         ┆ … ┆ 0.746891  ┆ 1.0       ┆ 0.55539   ┆ 0.522067 │\n",
      "│           ┆ Maritimae ┆ Maritimae ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 8378477   ┆ Alpes     ┆ Alpes     ┆ 1         ┆ … ┆ 0.746891  ┆ 1.0       ┆ 0.546637  ┆ 0.513839 │\n",
      "│           ┆ Graiae    ┆ Graiae    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'admin4'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[87]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     28\u001b[39m     logger.debug(\n\u001b[32m     29\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAdmin4 results:\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     30\u001b[39m     )\n\u001b[32m     31\u001b[39m     \u001b[38;5;28mprint\u001b[39m(results[\u001b[33m\"\u001b[39m\u001b[33madmin4\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43madmin4\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[31mKeyError\u001b[39m: 'admin4'"
     ]
    }
   ],
   "source": [
    "st = [\"FR\", \"Provence-Alpes-Côte d'Azur\", None, None, \"Le Lavandou\"]\n",
    "search_terms = AdminHierarchy.from_list(st)\n",
    "# Search through the admin hierarchy\n",
    "results = hierarchical_search(\n",
    "    search_terms,\n",
    "    con=con,\n",
    "    all_cols=True,\n",
    ")\n",
    "\n",
    "# Access results for each level\n",
    "if \"country\" in results:\n",
    "    logger.debug(\"Country results:\")\n",
    "    print(results[\"country\"])\n",
    "if \"admin1\" in results:\n",
    "    logger.debug(\"Admin1 results:\")\n",
    "    print(results[\"admin1\"])\n",
    "if \"admin2\" in results:\n",
    "    logger.debug(\n",
    "        \"Admin2 results:\",\n",
    "    )\n",
    "    print(results[\"admin2\"])\n",
    "if \"admin3\" in results:\n",
    "    logger.debug(\n",
    "        \"Admin3 results:\",\n",
    "    )\n",
    "    print(results[\"admin3\"])\n",
    "if \"admin4\" in results:\n",
    "    logger.debug(\n",
    "        \"Admin4 results:\",\n",
    "    )\n",
    "    print(results[\"admin4\"])\n",
    "results[\"admin4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (20, 34)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>asciiname</th><th>admin_level</th><th>admin0_code</th><th>admin1_code</th><th>admin2_code</th><th>admin3_code</th><th>admin4_code</th><th>feature_class</th><th>feature_code</th><th>ISO</th><th>ISO3</th><th>ISO_Numeric</th><th>official_name</th><th>fips</th><th>latitude</th><th>longitude</th><th>population</th><th>area</th><th>alternatenames</th><th>country_name</th><th>fts_score_4</th><th>adjusted_score_0</th><th>adjusted_score_1</th><th>z_score</th><th>text_score</th><th>pop_score</th><th>feature_score</th><th>country_score</th><th>average_parent_score</th><th>parent_factor</th><th>base_score</th><th>adjusted_score_4</th></tr><tr><td>u32</td><td>str</td><td>str</td><td>u8</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>u16</td><td>str</td><td>str</td><td>f32</td><td>f32</td><td>i32</td><td>f32</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>6615009</td><td>&quot;Le Lavandou&quot;</td><td>&quot;Le Lavandou&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;832&quot;</td><td>&quot;83070&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>43.137779</td><td>6.36778</td><td>5759</td><td>null</td><td>&quot;83070,Le Lavandou&quot;</td><td>&quot;Republic of France&quot;</td><td>12.610318</td><td>0.746891</td><td>0.81716</td><td>4.949631</td><td>1.0</td><td>0.556236</td><td>0.55</td><td>0.8</td><td>0.782025</td><td>1.0</td><td>0.777183</td><td>0.730552</td></tr><tr><td>6456407</td><td>&quot;Le Mans&quot;</td><td>&quot;Le Mans&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;52&quot;</td><td>&quot;72&quot;</td><td>&quot;723&quot;</td><td>&quot;72181&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>48.004169</td><td>0.19694</td><td>142991</td><td>null</td><td>&quot;72181,Le Mans&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.568817</td><td>-0.214643</td><td>0.420197</td><td>0.632141</td><td>0.55</td><td>0.8</td><td>0.657854</td><td>0.841218</td><td>0.577001</td><td>0.542381</td></tr><tr><td>6455417</td><td>&quot;Le Vésinet&quot;</td><td>&quot;Le Vesinet&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;11&quot;</td><td>&quot;78&quot;</td><td>&quot;783&quot;</td><td>&quot;78650&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>48.89389</td><td>2.13222</td><td>16047</td><td>null</td><td>&quot;78650,Le Vesinet,Le Vésinet&quot;</td><td>&quot;Republic of France&quot;</td><td>3.724332</td><td>0.746891</td><td>0.569015</td><td>-0.160945</td><td>0.439937</td><td>0.583645</td><td>0.55</td><td>0.8</td><td>0.657953</td><td>0.841345</td><td>0.566956</td><td>0.532938</td></tr><tr><td>6456500</td><td>&quot;Le Mesnil-le-Roi&quot;</td><td>&quot;Le Mesnil-le-Roi&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;11&quot;</td><td>&quot;78&quot;</td><td>&quot;783&quot;</td><td>&quot;78396&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>48.936668</td><td>2.12667</td><td>6276</td><td>null</td><td>&quot;78396,Le Mesnil-le-Roi&quot;</td><td>&quot;Republic of France&quot;</td><td>3.822629</td><td>0.746891</td><td>0.569015</td><td>-0.104411</td><td>0.460926</td><td>0.558673</td><td>0.55</td><td>0.8</td><td>0.657953</td><td>0.841345</td><td>0.565561</td><td>0.531628</td></tr><tr><td>6456504</td><td>&quot;Le Pecq&quot;</td><td>&quot;Le Pecq&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;11&quot;</td><td>&quot;78&quot;</td><td>&quot;783&quot;</td><td>&quot;78481&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>48.896671</td><td>2.10611</td><td>15880</td><td>null</td><td>&quot;78481,Le Pecq&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.569015</td><td>-0.214643</td><td>0.420197</td><td>0.583383</td><td>0.55</td><td>0.8</td><td>0.657953</td><td>0.841345</td><td>0.559955</td><td>0.526357</td></tr><tr><td>6457186</td><td>&quot;Le Raincy&quot;</td><td>&quot;Le Raincy&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;11&quot;</td><td>&quot;93&quot;</td><td>&quot;932&quot;</td><td>&quot;93062&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>48.89917</td><td>2.52306</td><td>14501</td><td>null</td><td>&quot;93062,Le Raincy&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.569015</td><td>-0.214643</td><td>0.420197</td><td>0.581087</td><td>0.55</td><td>0.8</td><td>0.657953</td><td>0.841345</td><td>0.559151</td><td>0.525602</td></tr><tr><td>6455961</td><td>&quot;Le Versoud&quot;</td><td>&quot;Le Versoud&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;84&quot;</td><td>&quot;38&quot;</td><td>&quot;381&quot;</td><td>&quot;38538&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>45.216</td><td>5.8625</td><td>4797</td><td>null</td><td>&quot;38538,Le Versoud&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.665994</td><td>-0.214643</td><td>0.420197</td><td>0.550963</td><td>0.55</td><td>0.8</td><td>0.706443</td><td>0.90335</td><td>0.557909</td><td>0.524434</td></tr><tr><td>6455917</td><td>&quot;Le Poinçonnet&quot;</td><td>&quot;Le Poinconnet&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;24&quot;</td><td>&quot;36&quot;</td><td>&quot;362&quot;</td><td>&quot;36159&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>46.763889</td><td>1.71889</td><td>5870</td><td>null</td><td>&quot;36159,Le Poinconnet,Le Poinçon…</td><td>&quot;Republic of France&quot;</td><td>3.724332</td><td>0.746891</td><td>0.568638</td><td>-0.160945</td><td>0.439937</td><td>0.556779</td><td>0.55</td><td>0.8</td><td>0.657765</td><td>0.841104</td><td>0.557516</td><td>0.524065</td></tr><tr><td>6456350</td><td>&quot;Le Perréon&quot;</td><td>&quot;Le Perreon&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;84&quot;</td><td>&quot;69&quot;</td><td>&quot;692&quot;</td><td>&quot;69151&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>46.063061</td><td>4.60056</td><td>1566</td><td>null</td><td>&quot;69151,Le Perreyon,Le Pèrreyon,…</td><td>&quot;Republic of France&quot;</td><td>3.782694</td><td>0.746891</td><td>0.665994</td><td>-0.127379</td><td>0.452378</td><td>0.515722</td><td>0.55</td><td>0.8</td><td>0.706443</td><td>0.90335</td><td>0.556837</td><td>0.523427</td></tr><tr><td>6455958</td><td>&quot;Le Touvet&quot;</td><td>&quot;Le Touvet&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;84&quot;</td><td>&quot;38&quot;</td><td>&quot;381&quot;</td><td>&quot;38511&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>45.357498</td><td>5.94806</td><td>3256</td><td>null</td><td>&quot;38511,Le Touvet&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.665994</td><td>-0.214643</td><td>0.420197</td><td>0.53936</td><td>0.55</td><td>0.8</td><td>0.706443</td><td>0.90335</td><td>0.553848</td><td>0.520617</td></tr><tr><td>6455929</td><td>&quot;Le Cheylas&quot;</td><td>&quot;Le Cheylas&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;84&quot;</td><td>&quot;38&quot;</td><td>&quot;381&quot;</td><td>&quot;38100&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>45.371391</td><td>5.9925</td><td>2586</td><td>null</td><td>&quot;38100,Le Cheylas&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.665994</td><td>-0.214643</td><td>0.420197</td><td>0.532173</td><td>0.55</td><td>0.8</td><td>0.706443</td><td>0.90335</td><td>0.551332</td><td>0.518252</td></tr><tr><td>6457137</td><td>&quot;Le Boupère&quot;</td><td>&quot;Le Boupere&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;52&quot;</td><td>&quot;85&quot;</td><td>&quot;851&quot;</td><td>&quot;85031&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>46.79472</td><td>-0.92639</td><td>3126</td><td>null</td><td>&quot;85031,Le Boupere,Le Boupère&quot;</td><td>&quot;Republic of France&quot;</td><td>3.724332</td><td>0.746891</td><td>0.568817</td><td>-0.160945</td><td>0.439937</td><td>0.538105</td><td>0.55</td><td>0.8</td><td>0.657854</td><td>0.841218</td><td>0.550998</td><td>0.517938</td></tr><tr><td>6456023</td><td>&quot;Le Pellerin&quot;</td><td>&quot;Le Pellerin&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;52&quot;</td><td>&quot;44&quot;</td><td>&quot;442&quot;</td><td>&quot;44120&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>47.19833</td><td>-1.75389</td><td>5050</td><td>null</td><td>&quot;44120,Le Pellerin&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.568817</td><td>-0.214643</td><td>0.420197</td><td>0.552459</td><td>0.55</td><td>0.8</td><td>0.657854</td><td>0.841218</td><td>0.549112</td><td>0.516166</td></tr><tr><td>6456641</td><td>&quot;Le Thillay&quot;</td><td>&quot;Le Thillay&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;11&quot;</td><td>&quot;95&quot;</td><td>&quot;952&quot;</td><td>&quot;95612&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>49.004719</td><td>2.47083</td><td>4427</td><td>null</td><td>&quot;95612,Le Thillay&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.569015</td><td>-0.214643</td><td>0.420197</td><td>0.548608</td><td>0.55</td><td>0.8</td><td>0.657953</td><td>0.841345</td><td>0.547783</td><td>0.514916</td></tr><tr><td>6456026</td><td>&quot;Le Pouliguen&quot;</td><td>&quot;Le Pouliguen&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;52&quot;</td><td>&quot;44&quot;</td><td>&quot;443&quot;</td><td>&quot;44135&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>47.277</td><td>-2.4292</td><td>4410</td><td>null</td><td>&quot;44135,Le Pouliguen&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.568817</td><td>-0.214643</td><td>0.420197</td><td>0.548495</td><td>0.55</td><td>0.8</td><td>0.657854</td><td>0.841218</td><td>0.547725</td><td>0.514861</td></tr><tr><td>6456406</td><td>&quot;Le Lude&quot;</td><td>&quot;Le Lude&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;52&quot;</td><td>&quot;72&quot;</td><td>&quot;721&quot;</td><td>&quot;72176&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>47.645</td><td>0.15306</td><td>4344</td><td>null</td><td>&quot;72176,Le Lude&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.568817</td><td>-0.214643</td><td>0.420197</td><td>0.548049</td><td>0.55</td><td>0.8</td><td>0.657854</td><td>0.841218</td><td>0.547569</td><td>0.514715</td></tr><tr><td>6455915</td><td>&quot;Le Pêchereau&quot;</td><td>&quot;Le Pechereau&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;24&quot;</td><td>&quot;36&quot;</td><td>&quot;362&quot;</td><td>&quot;36154&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>46.57806</td><td>1.5475</td><td>1859</td><td>null</td><td>&quot;36154,Le Pechereau,Le Pêcherea…</td><td>&quot;Republic of France&quot;</td><td>3.724332</td><td>0.746891</td><td>0.568638</td><td>-0.160945</td><td>0.439937</td><td>0.521476</td><td>0.55</td><td>0.8</td><td>0.657765</td><td>0.841104</td><td>0.54516</td><td>0.512451</td></tr><tr><td>6456917</td><td>&quot;Le Gâvre&quot;</td><td>&quot;Le Gavre&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;52&quot;</td><td>&quot;44&quot;</td><td>&quot;445&quot;</td><td>&quot;44062&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>47.520561</td><td>-1.74861</td><td>1781</td><td>null</td><td>&quot;44062,Le Gavre,Le Gâvre&quot;</td><td>&quot;Republic of France&quot;</td><td>3.724332</td><td>0.746891</td><td>0.568817</td><td>-0.160945</td><td>0.439937</td><td>0.520051</td><td>0.55</td><td>0.8</td><td>0.657854</td><td>0.841218</td><td>0.544679</td><td>0.511998</td></tr><tr><td>6456022</td><td>&quot;Le Pallet&quot;</td><td>&quot;Le Pallet&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;52&quot;</td><td>&quot;44&quot;</td><td>&quot;442&quot;</td><td>&quot;44117&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>47.138329</td><td>-1.33583</td><td>3236</td><td>null</td><td>&quot;44117,Le Pallet&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.568817</td><td>-0.214643</td><td>0.420197</td><td>0.539171</td><td>0.55</td><td>0.8</td><td>0.657854</td><td>0.841218</td><td>0.544462</td><td>0.511794</td></tr><tr><td>6456919</td><td>&quot;Le Landreau&quot;</td><td>&quot;Le Landreau&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;52&quot;</td><td>&quot;44&quot;</td><td>&quot;442&quot;</td><td>&quot;44079&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>47.205002</td><td>-1.30556</td><td>2977</td><td>null</td><td>&quot;44079,Le Landreau&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.568817</td><td>-0.214643</td><td>0.420197</td><td>0.536592</td><td>0.55</td><td>0.8</td><td>0.657854</td><td>0.841218</td><td>0.543559</td><td>0.510945</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (20, 34)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ geonameId ┆ name      ┆ asciiname ┆ admin_lev ┆ … ┆ average_p ┆ parent_fa ┆ base_scor ┆ adjusted │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ el        ┆   ┆ arent_sco ┆ ctor      ┆ e         ┆ _score_4 │\n",
       "│ u32       ┆ str       ┆ str       ┆ ---       ┆   ┆ re        ┆ ---       ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆           ┆ u8        ┆   ┆ ---       ┆ f64       ┆ f64       ┆ f64      │\n",
       "│           ┆           ┆           ┆           ┆   ┆ f64       ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 6615009   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.777183  ┆ 0.730552 │\n",
       "│           ┆ Lavandou  ┆ Lavandou  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6456407   ┆ Le Mans   ┆ Le Mans   ┆ 4         ┆ … ┆ 0.657854  ┆ 0.841218  ┆ 0.577001  ┆ 0.542381 │\n",
       "│ 6455417   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.657953  ┆ 0.841345  ┆ 0.566956  ┆ 0.532938 │\n",
       "│           ┆ Vésinet   ┆ Vesinet   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6456500   ┆ Le Mesnil ┆ Le Mesnil ┆ 4         ┆ … ┆ 0.657953  ┆ 0.841345  ┆ 0.565561  ┆ 0.531628 │\n",
       "│           ┆ -le-Roi   ┆ -le-Roi   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6456504   ┆ Le Pecq   ┆ Le Pecq   ┆ 4         ┆ … ┆ 0.657953  ┆ 0.841345  ┆ 0.559955  ┆ 0.526357 │\n",
       "│ 6457186   ┆ Le Raincy ┆ Le Raincy ┆ 4         ┆ … ┆ 0.657953  ┆ 0.841345  ┆ 0.559151  ┆ 0.525602 │\n",
       "│ 6455961   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.706443  ┆ 0.90335   ┆ 0.557909  ┆ 0.524434 │\n",
       "│           ┆ Versoud   ┆ Versoud   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6455917   ┆ Le Poinço ┆ Le Poinco ┆ 4         ┆ … ┆ 0.657765  ┆ 0.841104  ┆ 0.557516  ┆ 0.524065 │\n",
       "│           ┆ nnet      ┆ nnet      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6456350   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.706443  ┆ 0.90335   ┆ 0.556837  ┆ 0.523427 │\n",
       "│           ┆ Perréon   ┆ Perreon   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6455958   ┆ Le Touvet ┆ Le Touvet ┆ 4         ┆ … ┆ 0.706443  ┆ 0.90335   ┆ 0.553848  ┆ 0.520617 │\n",
       "│ 6455929   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.706443  ┆ 0.90335   ┆ 0.551332  ┆ 0.518252 │\n",
       "│           ┆ Cheylas   ┆ Cheylas   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6457137   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.657854  ┆ 0.841218  ┆ 0.550998  ┆ 0.517938 │\n",
       "│           ┆ Boupère   ┆ Boupere   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6456023   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.657854  ┆ 0.841218  ┆ 0.549112  ┆ 0.516166 │\n",
       "│           ┆ Pellerin  ┆ Pellerin  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6456641   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.657953  ┆ 0.841345  ┆ 0.547783  ┆ 0.514916 │\n",
       "│           ┆ Thillay   ┆ Thillay   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6456026   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.657854  ┆ 0.841218  ┆ 0.547725  ┆ 0.514861 │\n",
       "│           ┆ Pouliguen ┆ Pouliguen ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6456406   ┆ Le Lude   ┆ Le Lude   ┆ 4         ┆ … ┆ 0.657854  ┆ 0.841218  ┆ 0.547569  ┆ 0.514715 │\n",
       "│ 6455915   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.657765  ┆ 0.841104  ┆ 0.54516   ┆ 0.512451 │\n",
       "│           ┆ Pêchereau ┆ Pechereau ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6456917   ┆ Le Gâvre  ┆ Le Gavre  ┆ 4         ┆ … ┆ 0.657854  ┆ 0.841218  ┆ 0.544679  ┆ 0.511998 │\n",
       "│ 6456022   ┆ Le Pallet ┆ Le Pallet ┆ 4         ┆ … ┆ 0.657854  ┆ 0.841218  ┆ 0.544462  ┆ 0.511794 │\n",
       "│ 6456919   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.657854  ┆ 0.841218  ┆ 0.543559  ┆ 0.510945 │\n",
       "│           ┆ Landreau  ┆ Landreau  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"admin4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 15:12:45.392\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m137\u001b[0m - \u001b[34m\u001b[1mSearch terms: ['FR', \"Provence-Alpes-Côte d'Azur\", 'Le Lavandou']\u001b[0m\n",
      "\u001b[32m2025-05-04 15:12:45.393\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m144\u001b[0m - \u001b[34m\u001b[1mSearching for term 'FR' at admin level 0\u001b[0m\n",
      "\u001b[32m2025-05-04 15:12:45.393\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m146\u001b[0m - \u001b[34m\u001b[1mSearching for: 'FR' in range [0, 1, 2]\u001b[0m\n",
      "\u001b[32m2025-05-04 15:12:45.399\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 0 OR admin_level = 1 OR admin_level = 2) AND (admin_level != 0 OR geonameId NOT IN (3017382))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 15:12:45.426\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_score_admin\u001b[0m:\u001b[36m178\u001b[0m - \u001b[33m\u001b[1mNo parent score column found. Skipping parent factor.\u001b[0m\n",
      "\u001b[32m2025-05-04 15:12:45.428\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m144\u001b[0m - \u001b[34m\u001b[1mSearching for term 'Provence-Alpes-Côte d'Azur' at admin level 1\u001b[0m\n",
      "\u001b[32m2025-05-04 15:12:45.428\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m146\u001b[0m - \u001b[34m\u001b[1mSearching for: 'Provence-Alpes-Côte d'Azur' in range [1, 2, 3]\u001b[0m\n",
      "\u001b[32m2025-05-04 15:12:45.430\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 1 OR admin_level = 2 OR admin_level = 3) AND ((admin0_code = 'NL' AND admin1_code = '02') OR (admin0_code = 'PF') OR (admin0_code = 'EG' AND admin1_code = '21') OR (admin0_code = 'CH' AND admin1_code = 'FR') OR (admin0_code = 'IT' AND admin1_code = '07' AND admin2_code = 'FR') OR (admin0_code = 'FR') OR (admin0_code = 'NO' AND admin1_code = '08' AND admin2_code = '1548') OR (admin0_code = 'NO' AND admin1_code = '21' AND admin2_code = '5014') OR (admin0_code = 'MF') OR (admin0_code = 'FR' AND admin1_code = '11' AND admin2_code = '93'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 15:12:45.533\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m144\u001b[0m - \u001b[34m\u001b[1mSearching for term 'Le Lavandou' at admin level 2\u001b[0m\n",
      "\u001b[32m2025-05-04 15:12:45.533\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m146\u001b[0m - \u001b[34m\u001b[1mSearching for: 'Le Lavandou' in range [2, 3, 4]\u001b[0m\n",
      "\u001b[32m2025-05-04 15:12:45.535\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 2 OR admin_level = 3 OR admin_level = 4) AND ((admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '06') OR (admin0_code = 'FR' AND admin1_code = '27' AND admin2_code = '21') OR (admin0_code = 'FR' AND admin1_code = 'B9') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '05') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '13' AND admin3_code = '131') OR (admin0_code = 'FR' AND admin1_code = '93') OR (admin0_code = 'FR' AND admin1_code = '52' AND admin2_code = '44' AND admin3_code = '444') OR (admin0_code = 'FR' AND admin1_code = '84') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '04') OR (admin0_code = 'FR' AND admin1_code = '28' AND admin2_code = '61' AND admin3_code = '612'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['admin0_code', 'admin1_code', 'admin2_code', 'admin3_code', 'admin4_code']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = flexible_search(st, con=con, limit=10)\n",
    "\n",
    "d = s[1]\n",
    "\n",
    "admin_cols = sorted(\n",
    "    [c for c in d.columns if c.startswith(\"admin\") and c.endswith(\"_code\")]\n",
    ")\n",
    "admin_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 15:12:53.935\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 0 OR admin_level = 1)\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 15:12:53.999\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_score_admin\u001b[0m:\u001b[36m178\u001b[0m - \u001b[33m\u001b[1mNo parent score column found. Skipping parent factor.\u001b[0m\n",
      "\u001b[32m2025-05-04 15:12:54.003\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 3 OR admin_level = 4) AND ((admin0_code = 'GB' AND admin1_code = 'ENG'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 15)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>asciiname</th><th>admin0_code</th><th>admin1_code</th><th>admin2_code</th><th>admin3_code</th><th>admin4_code</th><th>feature_class</th><th>feature_code</th><th>population</th><th>latitude</th><th>longitude</th><th>adjusted_score_0</th><th>adjusted_score_3</th></tr><tr><td>u32</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i32</td><td>f32</td><td>f32</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>7296052</td><td>&quot;Dover&quot;</td><td>&quot;Dover&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE033&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>0</td><td>51.126282</td><td>1.30099</td><td>0.756593</td><td>0.58045</td></tr><tr><td>2651049</td><td>&quot;Dover District&quot;</td><td>&quot;Dover District&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM3&quot;</td><td>114227</td><td>51.150002</td><td>1.23333</td><td>0.756593</td><td>0.523773</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 15)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ geonameId ┆ name      ┆ asciiname ┆ admin0_co ┆ … ┆ latitude  ┆ longitude ┆ adjusted_ ┆ adjusted │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ de        ┆   ┆ ---       ┆ ---       ┆ score_0   ┆ _score_3 │\n",
       "│ u32       ┆ str       ┆ str       ┆ ---       ┆   ┆ f32       ┆ f32       ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆           ┆ str       ┆   ┆           ┆           ┆ f64       ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 7296052   ┆ Dover     ┆ Dover     ┆ GB        ┆ … ┆ 51.126282 ┆ 1.30099   ┆ 0.756593  ┆ 0.58045  │\n",
       "│ 2651049   ┆ Dover     ┆ Dover     ┆ GB        ┆ … ┆ 51.150002 ┆ 1.23333   ┆ 0.756593  ┆ 0.523773 │\n",
       "│           ┆ District  ┆ District  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = search_admin(\"England\", [0, 1], con)\n",
    "# First find the administrative region\n",
    "admin_results = search_admin(\"Dover\", [3, 4], con, r)\n",
    "admin_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 15:16:54.095\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m182\u001b[0m - \u001b[34m\u001b[1mSearching for places with term: Dover Ferry Terminal\u001b[0m\n",
      "\u001b[32m2025-05-04 15:16:54.097\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m234\u001b[0m - \u001b[34m\u001b[1mNo center point provided. Using centroid of previous results.\u001b[0m\n",
      "\u001b[32m2025-05-04 15:16:54.097\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m245\u001b[0m - \u001b[34m\u001b[1mUsing center point from previous results: (51.13814163208008, 1.2671599388122559)\u001b[0m\n",
      "\u001b[32m2025-05-04 15:16:54.097\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m264\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude,importance_score,importance_tier,\n",
      "            fts_main_places_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM places_search\n",
      "        WHERE ((admin0_code = 'GB' AND admin1_code = 'ENG' AND admin2_code = 'G5' AND admin3_code = '29UE') OR (admin0_code = 'GB' AND admin1_code = 'ENG' AND admin2_code = 'G5' AND admin3_code = '29UE' AND admin4_code = '29UE033'))\n",
      "            AND importance_tier <= 5\n",
      "    )\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC,\n",
      "        importance_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 15:16:54.312\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m272\u001b[0m - \u001b[34m\u001b[1mFound 12 results\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (12, 16)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>asciiname</th><th>admin0_code</th><th>admin1_code</th><th>admin2_code</th><th>admin3_code</th><th>admin4_code</th><th>feature_class</th><th>feature_code</th><th>population</th><th>latitude</th><th>longitude</th><th>importance_score</th><th>importance_tier</th><th>place_score</th></tr><tr><td>u32</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i32</td><td>f32</td><td>f32</td><td>f32</td><td>u8</td><td>f64</td></tr></thead><tbody><tr><td>9253020</td><td>&quot;Dover Port&quot;</td><td>&quot;Dover Port&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE033&quot;</td><td>&quot;L&quot;</td><td>&quot;PRT&quot;</td><td>0</td><td>51.126041</td><td>1.32795</td><td>0.495</td><td>3</td><td>0.780731</td></tr><tr><td>7284378</td><td>&quot;Dover Transmitting Station&quot;</td><td>&quot;Dover Transmitting Station&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE010&quot;</td><td>&quot;S&quot;</td><td>&quot;TOWR&quot;</td><td>0</td><td>51.111698</td><td>1.24746</td><td>0.66</td><td>2</td><td>0.735205</td></tr><tr><td>6287214</td><td>&quot;Dover Castle&quot;</td><td>&quot;Dover Castle&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE033&quot;</td><td>&quot;S&quot;</td><td>&quot;CSTL&quot;</td><td>0</td><td>51.129581</td><td>1.32142</td><td>0.715</td><td>2</td><td>0.712171</td></tr><tr><td>6945262</td><td>&quot;Dover Priory Railway Station&quot;</td><td>&quot;Dover Priory Railway Station&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE033&quot;</td><td>&quot;S&quot;</td><td>&quot;RSTN&quot;</td><td>0</td><td>51.12582</td><td>1.30501</td><td>0.645</td><td>2</td><td>0.684453</td></tr><tr><td>6944960</td><td>&quot;Ramada Dover&quot;</td><td>&quot;Ramada Dover&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE021&quot;</td><td>&quot;S&quot;</td><td>&quot;HTL&quot;</td><td>0</td><td>51.167702</td><td>1.26965</td><td>0.375</td><td>4</td><td>0.516212</td></tr><tr><td>9885608</td><td>&quot;Best Western Dover Marina&quot;</td><td>&quot;Best Western Dover Marina&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE033&quot;</td><td>&quot;S&quot;</td><td>&quot;HTL&quot;</td><td>0</td><td>51.12212</td><td>1.31425</td><td>0.375</td><td>4</td><td>0.457329</td></tr><tr><td>10281873</td><td>&quot;Dover Marina Hotel and Spa&quot;</td><td>&quot;Dover Marina Hotel and Spa&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE033&quot;</td><td>&quot;S&quot;</td><td>&quot;HTL&quot;</td><td>0</td><td>51.127998</td><td>1.3132</td><td>0.375</td><td>4</td><td>0.436059</td></tr><tr><td>2651048</td><td>&quot;Dover&quot;</td><td>&quot;Dover&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE033&quot;</td><td>&quot;P&quot;</td><td>&quot;PPL&quot;</td><td>41709</td><td>51.12598</td><td>1.31257</td><td>0.381011</td><td>4</td><td>0.411717</td></tr><tr><td>10107778</td><td>&quot;Best Western Plus Dover Marina…</td><td>&quot;Best Western Plus Dover Marina…</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE033&quot;</td><td>&quot;S&quot;</td><td>&quot;HTL&quot;</td><td>0</td><td>51.121799</td><td>1.31413</td><td>0.375</td><td>4</td><td>0.403451</td></tr><tr><td>11810602</td><td>&quot;Dover Admiralty Pier Lighthous…</td><td>&quot;Dover Admiralty Pier Lighthous…</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE033&quot;</td><td>&quot;S&quot;</td><td>&quot;LTHSE&quot;</td><td>0</td><td>51.111408</td><td>1.32779</td><td>0.235</td><td>4</td><td>0.350119</td></tr><tr><td>11810600</td><td>&quot;Dover Breakwater West End Ligh…</td><td>&quot;Dover Breakwater West End Ligh…</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>null</td><td>&quot;S&quot;</td><td>&quot;LTHSE&quot;</td><td>0</td><td>51.113152</td><td>1.32989</td><td>0.235</td><td>4</td><td>0.328268</td></tr><tr><td>11810601</td><td>&quot;Dover Prince of Wales Pier Lig…</td><td>&quot;Dover Prince of Wales Pier Lig…</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE033&quot;</td><td>&quot;S&quot;</td><td>&quot;LTHSE&quot;</td><td>0</td><td>51.114101</td><td>1.323</td><td>0.235</td><td>4</td><td>0.311314</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (12, 16)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ geonameId ┆ name      ┆ asciiname ┆ admin0_co ┆ … ┆ longitude ┆ importanc ┆ importanc ┆ place_sc │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ de        ┆   ┆ ---       ┆ e_score   ┆ e_tier    ┆ ore      │\n",
       "│ u32       ┆ str       ┆ str       ┆ ---       ┆   ┆ f32       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆           ┆ str       ┆   ┆           ┆ f32       ┆ u8        ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 9253020   ┆ Dover     ┆ Dover     ┆ GB        ┆ … ┆ 1.32795   ┆ 0.495     ┆ 3         ┆ 0.780731 │\n",
       "│           ┆ Port      ┆ Port      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 7284378   ┆ Dover Tra ┆ Dover Tra ┆ GB        ┆ … ┆ 1.24746   ┆ 0.66      ┆ 2         ┆ 0.735205 │\n",
       "│           ┆ nsmitting ┆ nsmitting ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Station   ┆ Station   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6287214   ┆ Dover     ┆ Dover     ┆ GB        ┆ … ┆ 1.32142   ┆ 0.715     ┆ 2         ┆ 0.712171 │\n",
       "│           ┆ Castle    ┆ Castle    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6945262   ┆ Dover     ┆ Dover     ┆ GB        ┆ … ┆ 1.30501   ┆ 0.645     ┆ 2         ┆ 0.684453 │\n",
       "│           ┆ Priory    ┆ Priory    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Railway   ┆ Railway   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Station   ┆ Station   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6944960   ┆ Ramada    ┆ Ramada    ┆ GB        ┆ … ┆ 1.26965   ┆ 0.375     ┆ 4         ┆ 0.516212 │\n",
       "│           ┆ Dover     ┆ Dover     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 9885608   ┆ Best      ┆ Best      ┆ GB        ┆ … ┆ 1.31425   ┆ 0.375     ┆ 4         ┆ 0.457329 │\n",
       "│           ┆ Western   ┆ Western   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Dover     ┆ Dover     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Marina    ┆ Marina    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 10281873  ┆ Dover     ┆ Dover     ┆ GB        ┆ … ┆ 1.3132    ┆ 0.375     ┆ 4         ┆ 0.436059 │\n",
       "│           ┆ Marina    ┆ Marina    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Hotel and ┆ Hotel and ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Spa       ┆ Spa       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 2651048   ┆ Dover     ┆ Dover     ┆ GB        ┆ … ┆ 1.31257   ┆ 0.381011  ┆ 4         ┆ 0.411717 │\n",
       "│ 10107778  ┆ Best      ┆ Best      ┆ GB        ┆ … ┆ 1.31413   ┆ 0.375     ┆ 4         ┆ 0.403451 │\n",
       "│           ┆ Western   ┆ Western   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Plus      ┆ Plus      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Dover     ┆ Dover     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Marina…   ┆ Marina…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 11810602  ┆ Dover     ┆ Dover     ┆ GB        ┆ … ┆ 1.32779   ┆ 0.235     ┆ 4         ┆ 0.350119 │\n",
       "│           ┆ Admiralty ┆ Admiralty ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Pier Ligh ┆ Pier Ligh ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ thous…    ┆ thous…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 11810600  ┆ Dover Bre ┆ Dover Bre ┆ GB        ┆ … ┆ 1.32989   ┆ 0.235     ┆ 4         ┆ 0.328268 │\n",
       "│           ┆ akwater   ┆ akwater   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ West End  ┆ West End  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Ligh…     ┆ Ligh…     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 11810601  ┆ Dover     ┆ Dover     ┆ GB        ┆ … ┆ 1.323     ┆ 0.235     ┆ 4         ┆ 0.311314 │\n",
       "│           ┆ Prince of ┆ Prince of ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Wales     ┆ Wales     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Pier Lig… ┆ Pier Lig… ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then search for places within that region\n",
    "place_results = search_place(\n",
    "    \"Dover Ferry Terminal\",\n",
    "    con,\n",
    "    previous_results=admin_results,\n",
    "    limit=50,\n",
    ")\n",
    "\n",
    "place_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 15:17:17.170\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 0 OR admin_level = 1)\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 15:17:17.224\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_score_admin\u001b[0m:\u001b[36m178\u001b[0m - \u001b[33m\u001b[1mNo parent score column found. Skipping parent factor.\u001b[0m\n",
      "\u001b[32m2025-05-04 15:17:17.226\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 1 OR admin_level = 2 OR admin_level = 3) AND ((admin0_code = 'GB' AND admin1_code = 'ENG'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 15:17:17.255\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m182\u001b[0m - \u001b[34m\u001b[1mSearching for places with term: Caledonian Road\u001b[0m\n",
      "\u001b[32m2025-05-04 15:17:17.257\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m234\u001b[0m - \u001b[34m\u001b[1mNo center point provided. Using centroid of previous results.\u001b[0m\n",
      "\u001b[32m2025-05-04 15:17:17.257\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m245\u001b[0m - \u001b[34m\u001b[1mUsing center point from previous results: (51.547019958496094, -0.10943999886512756)\u001b[0m\n",
      "\u001b[32m2025-05-04 15:17:17.257\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m264\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude,importance_score,importance_tier,\n",
      "            fts_main_places_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM places_search\n",
      "        WHERE ((admin0_code = 'GB' AND admin1_code = 'ENG' AND admin2_code = 'GLA' AND admin3_code = 'G3'))\n",
      "            AND importance_tier <= 5\n",
      "    )\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC,\n",
      "        importance_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 15:17:17.490\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m272\u001b[0m - \u001b[34m\u001b[1mFound 10 results\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 16)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>asciiname</th><th>admin0_code</th><th>admin1_code</th><th>admin2_code</th><th>admin3_code</th><th>admin4_code</th><th>feature_class</th><th>feature_code</th><th>population</th><th>latitude</th><th>longitude</th><th>importance_score</th><th>importance_tier</th><th>place_score</th></tr><tr><td>u32</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i32</td><td>f32</td><td>f32</td><td>f32</td><td>u8</td><td>f64</td></tr></thead><tbody><tr><td>6952211</td><td>&quot;Caledonian Road &amp; Barnsbury Ra…</td><td>&quot;Caledonian Road &amp; Barnsbury Ra…</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;GLA&quot;</td><td>&quot;G3&quot;</td><td>null</td><td>&quot;S&quot;</td><td>&quot;RSTN&quot;</td><td>0</td><td>51.543449</td><td>-0.11492</td><td>0.635</td><td>2</td><td>0.925274</td></tr><tr><td>6954652</td><td>&quot;Caledonian Road Underground St…</td><td>&quot;Caledonian Road Underground St…</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;GLA&quot;</td><td>&quot;G3&quot;</td><td>null</td><td>&quot;S&quot;</td><td>&quot;MTRO&quot;</td><td>0</td><td>51.548538</td><td>-0.11823</td><td>0.485</td><td>3</td><td>0.713496</td></tr><tr><td>10115056</td><td>&quot;Caledonian Road Apartments&quot;</td><td>&quot;Caledonian Road Apartments&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;GLA&quot;</td><td>&quot;G3&quot;</td><td>null</td><td>&quot;S&quot;</td><td>&quot;HTL&quot;</td><td>0</td><td>51.542461</td><td>-0.11744</td><td>0.375</td><td>4</td><td>0.668034</td></tr><tr><td>6952558</td><td>&quot;Essex Road Railway Station&quot;</td><td>&quot;Essex Road Railway Station&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;GLA&quot;</td><td>&quot;G3&quot;</td><td>null</td><td>&quot;S&quot;</td><td>&quot;RSTN&quot;</td><td>0</td><td>51.5406</td><td>-0.0963</td><td>0.645</td><td>2</td><td>0.594382</td></tr><tr><td>12048395</td><td>&quot;Caledonian&quot;</td><td>&quot;Caledonian&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;GLA&quot;</td><td>&quot;G3&quot;</td><td>null</td><td>&quot;P&quot;</td><td>&quot;PPLX&quot;</td><td>0</td><td>51.540482</td><td>-0.11897</td><td>0.1</td><td>5</td><td>0.450015</td></tr><tr><td>9259001</td><td>&quot;Caledoninan Road&quot;</td><td>&quot;Caledoninan Road&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;GLA&quot;</td><td>&quot;G3&quot;</td><td>null</td><td>&quot;S&quot;</td><td>&quot;HTL&quot;</td><td>0</td><td>51.54245</td><td>-0.11744</td><td>0.375</td><td>4</td><td>0.418297</td></tr><tr><td>2646740</td><td>&quot;Holloway Road Underground Stat…</td><td>&quot;Holloway Road Underground Stat…</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;GLA&quot;</td><td>&quot;G3&quot;</td><td>null</td><td>&quot;S&quot;</td><td>&quot;MTRO&quot;</td><td>0</td><td>51.552792</td><td>-0.11282</td><td>0.485</td><td>3</td><td>0.409473</td></tr><tr><td>9259906</td><td>&quot;Travelodge Central City Road&quot;</td><td>&quot;Travelodge Central City Road&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;GLA&quot;</td><td>&quot;G3&quot;</td><td>null</td><td>&quot;S&quot;</td><td>&quot;HTL&quot;</td><td>0</td><td>51.52282</td><td>-0.08719</td><td>0.375</td><td>4</td><td>0.390436</td></tr><tr><td>6954632</td><td>&quot;Arsenal Underground Station&quot;</td><td>&quot;Arsenal Underground Station&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;GLA&quot;</td><td>&quot;G3&quot;</td><td>null</td><td>&quot;S&quot;</td><td>&quot;MTRO&quot;</td><td>0</td><td>51.558441</td><td>-0.10572</td><td>0.495</td><td>3</td><td>0.379636</td></tr><tr><td>12519726</td><td>&quot;City Road&quot;</td><td>&quot;City Road&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;GLA&quot;</td><td>&quot;G3&quot;</td><td>null</td><td>&quot;R&quot;</td><td>&quot;ST&quot;</td><td>0</td><td>51.53056</td><td>-0.10073</td><td>0.1</td><td>5</td><td>0.238988</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 16)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ geonameId ┆ name      ┆ asciiname ┆ admin0_co ┆ … ┆ longitude ┆ importanc ┆ importanc ┆ place_sc │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ de        ┆   ┆ ---       ┆ e_score   ┆ e_tier    ┆ ore      │\n",
       "│ u32       ┆ str       ┆ str       ┆ ---       ┆   ┆ f32       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆           ┆ str       ┆   ┆           ┆ f32       ┆ u8        ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 6952211   ┆ Caledonia ┆ Caledonia ┆ GB        ┆ … ┆ -0.11492  ┆ 0.635     ┆ 2         ┆ 0.925274 │\n",
       "│           ┆ n Road &  ┆ n Road &  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Barnsbury ┆ Barnsbury ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Ra…       ┆ Ra…       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6954652   ┆ Caledonia ┆ Caledonia ┆ GB        ┆ … ┆ -0.11823  ┆ 0.485     ┆ 3         ┆ 0.713496 │\n",
       "│           ┆ n Road    ┆ n Road    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Undergrou ┆ Undergrou ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ nd St…    ┆ nd St…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 10115056  ┆ Caledonia ┆ Caledonia ┆ GB        ┆ … ┆ -0.11744  ┆ 0.375     ┆ 4         ┆ 0.668034 │\n",
       "│           ┆ n Road    ┆ n Road    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Apartment ┆ Apartment ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ s         ┆ s         ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6952558   ┆ Essex     ┆ Essex     ┆ GB        ┆ … ┆ -0.0963   ┆ 0.645     ┆ 2         ┆ 0.594382 │\n",
       "│           ┆ Road      ┆ Road      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Railway   ┆ Railway   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Station   ┆ Station   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 12048395  ┆ Caledonia ┆ Caledonia ┆ GB        ┆ … ┆ -0.11897  ┆ 0.1       ┆ 5         ┆ 0.450015 │\n",
       "│           ┆ n         ┆ n         ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 9259001   ┆ Caledonin ┆ Caledonin ┆ GB        ┆ … ┆ -0.11744  ┆ 0.375     ┆ 4         ┆ 0.418297 │\n",
       "│           ┆ an Road   ┆ an Road   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 2646740   ┆ Holloway  ┆ Holloway  ┆ GB        ┆ … ┆ -0.11282  ┆ 0.485     ┆ 3         ┆ 0.409473 │\n",
       "│           ┆ Road Unde ┆ Road Unde ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ rground   ┆ rground   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Stat…     ┆ Stat…     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 9259906   ┆ Travelodg ┆ Travelodg ┆ GB        ┆ … ┆ -0.08719  ┆ 0.375     ┆ 4         ┆ 0.390436 │\n",
       "│           ┆ e Central ┆ e Central ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ City Road ┆ City Road ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6954632   ┆ Arsenal   ┆ Arsenal   ┆ GB        ┆ … ┆ -0.10572  ┆ 0.495     ┆ 3         ┆ 0.379636 │\n",
       "│           ┆ Undergrou ┆ Undergrou ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ nd        ┆ nd        ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Station   ┆ Station   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 12519726  ┆ City Road ┆ City Road ┆ GB        ┆ … ┆ -0.10073  ┆ 0.1       ┆ 5         ┆ 0.238988 │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = search_admin(\"England\", [0, 1], con)\n",
    "a = search_admin(\"Islington\", [1, 2, 3], con, r)\n",
    "b = search_place(\n",
    "    \"Caledonian Road\",\n",
    "    con,\n",
    "    previous_results=a,\n",
    "    limit=50,\n",
    ")\n",
    "b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'admin0': {'geonameId': 2635167,\n",
       "  'name': 'United Kingdom of Great Britain and Northern Ireland'},\n",
       " 'admin1': {'geonameId': 2634259, 'name': 'West Suffolk'},\n",
       " 'admin2': {'geonameId': 2648110, 'name': 'Greater London'},\n",
       " 'admin3': {'geonameId': 3333156, 'name': 'Islington'}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backfill_hierarchy(\n",
    "    {\n",
    "        \"admin0_code\": \"GB\",\n",
    "        \"admin1_code\": \"ENG\",\n",
    "        \"admin2_code\": \"GLA\",\n",
    "        \"admin3_code\": \"G3\",\n",
    "        \"geonameId\": 13269818,\n",
    "    },\n",
    "    con,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 21:41:13.161\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin_hierarchy\u001b[0m:\u001b[36m127\u001b[0m - \u001b[34m\u001b[1mSearching for term 'FL' at admin level 1\u001b[0m\n",
      "\u001b[32m2025-05-04 21:41:13.162\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 1)\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 21:41:13.183\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_score_admin\u001b[0m:\u001b[36m178\u001b[0m - \u001b[33m\u001b[1mNo parent score column found. Skipping parent factor.\u001b[0m\n",
      "\u001b[32m2025-05-04 21:41:13.184\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin_hierarchy\u001b[0m:\u001b[36m127\u001b[0m - \u001b[34m\u001b[1mSearching for term 'Lakeland' at admin level 3\u001b[0m\n",
      "\u001b[32m2025-05-04 21:41:13.186\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 3) AND ((admin0_code = 'NL' AND admin1_code = '16') OR (admin0_code = 'US' AND admin1_code = 'FL'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'adjusted_score_1': 0.6674183738082736,\n",
      " 'adjusted_score_3': 0.6025998219254551,\n",
      " 'admin0_code': 'US',\n",
      " 'admin1_code': 'FL',\n",
      " 'admin2_code': '105',\n",
      " 'admin3_code': '7170309',\n",
      " 'admin4_code': None,\n",
      " 'asciiname': 'City of Lakeland',\n",
      " 'feature_class': 'A',\n",
      " 'feature_code': 'ADM3',\n",
      " 'geonameId': 7170309,\n",
      " 'latitude': 28.05565071105957,\n",
      " 'longitude': -81.95420837402344,\n",
      " 'name': 'City of Lakeland',\n",
      " 'population': 97422}\n"
     ]
    },
    {
     "ename": "ParserException",
     "evalue": "Parser Error: syntax error at or near \"WHERE\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mParserException\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[96]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      5\u001b[39m row = results[\u001b[33m\"\u001b[39m\u001b[33madmin3\u001b[39m\u001b[33m\"\u001b[39m].row(\u001b[32m0\u001b[39m, named=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      8\u001b[39m pprint(row)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m pprint(\u001b[43mbackfill_hierarchy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[92]\u001b[39m\u001b[32m, line 408\u001b[39m, in \u001b[36mbackfill_hierarchy\u001b[39m\u001b[34m(row, con)\u001b[39m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m code \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    407\u001b[39m     query = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSELECT geonameId, name FROM admin_search WHERE admin_level = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m AND \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mget_where_clause(codes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m LIMIT 1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m408\u001b[39m     df = \u001b[43mcon\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m.pl()\n\u001b[32m    410\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m df.is_empty():\n\u001b[32m    411\u001b[39m         hierarchy[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33madmin\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m] = df.to_dicts()[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mParserException\u001b[39m: Parser Error: syntax error at or near \"WHERE\""
     ]
    }
   ],
   "source": [
    "results = hierarchical_search(\n",
    "    search_terms=AdminHierarchy.from_list([None, \"FL\", None, \"Lakeland\", None, None]), con=con,\n",
    "    try_place_as_admin=False\n",
    ")\n",
    "row = results[\"admin3\"].row(0, named=True)\n",
    "\n",
    "\n",
    "pprint(row)\n",
    "\n",
    "pprint(backfill_hierarchy(row, con))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 21:40:52.486\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mhierarchical_search\u001b[0m:\u001b[36m232\u001b[0m - \u001b[34m\u001b[1mMoved last non-null admin level 'Le Lavandou' to place term\u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.487\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin_hierarchy\u001b[0m:\u001b[36m127\u001b[0m - \u001b[34m\u001b[1mSearching for term 'FR' at admin level 0\u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.495\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 0) AND (admin_level != 0 OR geonameId NOT IN (3017382))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.564\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_score_admin\u001b[0m:\u001b[36m178\u001b[0m - \u001b[33m\u001b[1mNo parent score column found. Skipping parent factor.\u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.571\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin_hierarchy\u001b[0m:\u001b[36m127\u001b[0m - \u001b[34m\u001b[1mSearching for term 'Provence-Alpes-Côte d'Azur' at admin level 1\u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.575\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 1) AND ((admin0_code = 'PF') OR (admin0_code = 'FR') OR (admin0_code = 'MF') OR (admin0_code = 'GF'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.618\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin_hierarchy\u001b[0m:\u001b[36m127\u001b[0m - \u001b[34m\u001b[1mSearching for term 'Var' at admin level 2\u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.619\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 2) AND ((admin0_code = 'FR' AND admin1_code = '24') OR (admin0_code = 'FR' AND admin1_code = '11') OR (admin0_code = 'FR' AND admin1_code = 'B4') OR (admin0_code = 'FR' AND admin1_code = 'B9') OR (admin0_code = 'FR' AND admin1_code = '52') OR (admin0_code = 'FR' AND admin1_code = '93') OR (admin0_code = 'FR' AND admin1_code = '32') OR (admin0_code = 'FR' AND admin1_code = '84'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.653\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin_hierarchy\u001b[0m:\u001b[36m127\u001b[0m - \u001b[34m\u001b[1mSearching for term 'Arrondissement de Toulon' at admin level 3\u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.655\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 3) AND ((admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.689\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mplace_as_admin\u001b[0m:\u001b[36m158\u001b[0m - \u001b[34m\u001b[1mTrying place term 'Le Lavandou' as admin level 4\u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.690\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 4) AND ((admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '833') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '831') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '832'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.719\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place_with_context\u001b[0m:\u001b[36m191\u001b[0m - \u001b[34m\u001b[1mSearching for place: 'Le Lavandou'\u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.719\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m186\u001b[0m - \u001b[34m\u001b[1mSearching for places with term: Le Lavandou\u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.721\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m238\u001b[0m - \u001b[34m\u001b[1mNo center point provided. Using centroid of previous results.\u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.721\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m249\u001b[0m - \u001b[34m\u001b[1mUsing center point from previous results: (43.32274627685547, 6.215458869934082)\u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.721\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m268\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude,importance_score,importance_tier,\n",
      "            fts_main_places_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM places_search\n",
      "        WHERE ((admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '833' AND admin4_code = '83073') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '833' AND admin4_code = '83075') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '832' AND admin4_code = '83098') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '832' AND admin4_code = '83019') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '831' AND admin4_code = '83086') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '831' AND admin4_code = '83020') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '832' AND admin4_code = '83103') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '833' AND admin4_code = '83143') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '831' AND admin4_code = '83094') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '833' AND admin4_code = '83077') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '833' AND admin4_code = '83031') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '832' AND admin4_code = '83016') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '832' AND admin4_code = '83035') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '833' AND admin4_code = '83136') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '832' AND admin4_code = '83070'))\n",
      "            AND importance_tier <= 5\n",
      "    )\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC,\n",
      "        importance_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.938\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m276\u001b[0m - \u001b[34m\u001b[1mFound 42 results\u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.941\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mAdmin1 results:\u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.942\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m20\u001b[0m - \u001b[34m\u001b[1mAdmin2 results:\u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.942\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m22\u001b[0m - \u001b[34m\u001b[1mAdmin3 results:\u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.942\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mAdmin4 results:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (15, 18)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>asciiname</th><th>admin0_code</th><th>admin1_code</th><th>admin2_code</th><th>admin3_code</th><th>admin4_code</th><th>feature_class</th><th>feature_code</th><th>population</th><th>latitude</th><th>longitude</th><th>adjusted_score_0</th><th>adjusted_score_1</th><th>adjusted_score_2</th><th>adjusted_score_3</th><th>adjusted_score_4</th></tr><tr><td>u32</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i32</td><td>f32</td><td>f32</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>6615009</td><td>&quot;Le Lavandou&quot;</td><td>&quot;Le Lavandou&quot;</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;832&quot;</td><td>&quot;83070&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>5759</td><td>43.137779</td><td>6.36778</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.777905</td><td>0.730552</td></tr><tr><td>6457128</td><td>&quot;Le Pradet&quot;</td><td>&quot;Le Pradet&quot;</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;832&quot;</td><td>&quot;83098&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>10027</td><td>43.10556</td><td>6.02333</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.777905</td><td>0.568234</td></tr><tr><td>6457113</td><td>&quot;Le Beausset&quot;</td><td>&quot;Le Beausset&quot;</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;832&quot;</td><td>&quot;83016&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>9637</td><td>43.19833</td><td>5.80278</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.777905</td><td>0.559563</td></tr><tr><td>6457122</td><td>&quot;Le Luc&quot;</td><td>&quot;Le Luc&quot;</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;833&quot;</td><td>&quot;83073&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>10952</td><td>43.394402</td><td>6.3134</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.542154</td><td>0.558407</td></tr><tr><td>6457127</td><td>&quot;Le Muy&quot;</td><td>&quot;Le Muy&quot;</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;831&quot;</td><td>&quot;83086&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>9248</td><td>43.4725</td><td>6.56639</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.540235</td><td>0.556842</td></tr><tr><td>6456550</td><td>&quot;Le Val&quot;</td><td>&quot;Le Val&quot;</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;833&quot;</td><td>&quot;83143&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>4297</td><td>43.439442</td><td>6.07306</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.542154</td><td>0.549818</td></tr><tr><td>6456549</td><td>&quot;Le Thoronet&quot;</td><td>&quot;Le Thoronet&quot;</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;833&quot;</td><td>&quot;83136&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>2449</td><td>43.451939</td><td>6.30389</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.542154</td><td>0.544131</td></tr><tr><td>6456545</td><td>&quot;Le Revest-les-Eaux&quot;</td><td>&quot;Le Revest-les-Eaux&quot;</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;832&quot;</td><td>&quot;83103&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>3812</td><td>43.176601</td><td>5.9273</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.777905</td><td>0.529966</td></tr><tr><td>6617824</td><td>&quot;Le Castellet&quot;</td><td>&quot;Le Castellet&quot;</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;832&quot;</td><td>&quot;83035&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>3875</td><td>43.202702</td><td>5.777</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.777905</td><td>0.527065</td></tr><tr><td>6457115</td><td>&quot;Le Cannet-des-Maures&quot;</td><td>&quot;Le Cannet-des-Maures&quot;</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;833&quot;</td><td>&quot;83031&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>4328</td><td>43.39167</td><td>6.34083</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.542154</td><td>0.526716</td></tr><tr><td>6451513</td><td>&quot;Le Plan-de-la-Tour&quot;</td><td>&quot;Le Plan-de-la-Tour&quot;</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;831&quot;</td><td>&quot;83094&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>2714</td><td>43.340561</td><td>6.54639</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.540235</td><td>0.512782</td></tr><tr><td>6451462</td><td>&quot;Bormes-les-Mimosas&quot;</td><td>&quot;Bormes-les-Mimosas&quot;</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;832&quot;</td><td>&quot;83019&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>7982</td><td>43.151669</td><td>6.34306</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.777905</td><td>0.485188</td></tr><tr><td>6614863</td><td>&quot;Le Bourguet&quot;</td><td>&quot;Le Bourguet&quot;</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;831&quot;</td><td>&quot;83020&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>31</td><td>43.784168</td><td>6.51861</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.540235</td><td>0.478774</td></tr><tr><td>6451500</td><td>&quot;Méounes-lès-Montrieux&quot;</td><td>&quot;Meounes-les-Montrieux&quot;</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;833&quot;</td><td>&quot;83077&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>2165</td><td>43.281109</td><td>5.97</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.542154</td><td>0.464287</td></tr><tr><td>6457124</td><td>&quot;Les Mayons&quot;</td><td>&quot;Les Mayons&quot;</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;833&quot;</td><td>&quot;83075&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>641</td><td>43.312778</td><td>6.35806</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.542154</td><td>0.450247</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (15, 18)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ geonameId ┆ name      ┆ asciiname ┆ admin0_co ┆ … ┆ adjusted_ ┆ adjusted_ ┆ adjusted_ ┆ adjusted │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ de        ┆   ┆ score_1   ┆ score_2   ┆ score_3   ┆ _score_4 │\n",
       "│ u32       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆           ┆ str       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 6615009   ┆ Le        ┆ Le        ┆ FR        ┆ … ┆ 0.81716   ┆ 0.795429  ┆ 0.777905  ┆ 0.730552 │\n",
       "│           ┆ Lavandou  ┆ Lavandou  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6457128   ┆ Le Pradet ┆ Le Pradet ┆ FR        ┆ … ┆ 0.81716   ┆ 0.795429  ┆ 0.777905  ┆ 0.568234 │\n",
       "│ 6457113   ┆ Le        ┆ Le        ┆ FR        ┆ … ┆ 0.81716   ┆ 0.795429  ┆ 0.777905  ┆ 0.559563 │\n",
       "│           ┆ Beausset  ┆ Beausset  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6457122   ┆ Le Luc    ┆ Le Luc    ┆ FR        ┆ … ┆ 0.81716   ┆ 0.795429  ┆ 0.542154  ┆ 0.558407 │\n",
       "│ 6457127   ┆ Le Muy    ┆ Le Muy    ┆ FR        ┆ … ┆ 0.81716   ┆ 0.795429  ┆ 0.540235  ┆ 0.556842 │\n",
       "│ 6456550   ┆ Le Val    ┆ Le Val    ┆ FR        ┆ … ┆ 0.81716   ┆ 0.795429  ┆ 0.542154  ┆ 0.549818 │\n",
       "│ 6456549   ┆ Le        ┆ Le        ┆ FR        ┆ … ┆ 0.81716   ┆ 0.795429  ┆ 0.542154  ┆ 0.544131 │\n",
       "│           ┆ Thoronet  ┆ Thoronet  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6456545   ┆ Le Revest ┆ Le Revest ┆ FR        ┆ … ┆ 0.81716   ┆ 0.795429  ┆ 0.777905  ┆ 0.529966 │\n",
       "│           ┆ -les-Eaux ┆ -les-Eaux ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6617824   ┆ Le        ┆ Le        ┆ FR        ┆ … ┆ 0.81716   ┆ 0.795429  ┆ 0.777905  ┆ 0.527065 │\n",
       "│           ┆ Castellet ┆ Castellet ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6457115   ┆ Le Cannet ┆ Le Cannet ┆ FR        ┆ … ┆ 0.81716   ┆ 0.795429  ┆ 0.542154  ┆ 0.526716 │\n",
       "│           ┆ -des-Maur ┆ -des-Maur ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ es        ┆ es        ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6451513   ┆ Le Plan-d ┆ Le Plan-d ┆ FR        ┆ … ┆ 0.81716   ┆ 0.795429  ┆ 0.540235  ┆ 0.512782 │\n",
       "│           ┆ e-la-Tour ┆ e-la-Tour ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6451462   ┆ Bormes-le ┆ Bormes-le ┆ FR        ┆ … ┆ 0.81716   ┆ 0.795429  ┆ 0.777905  ┆ 0.485188 │\n",
       "│           ┆ s-Mimosas ┆ s-Mimosas ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6614863   ┆ Le        ┆ Le        ┆ FR        ┆ … ┆ 0.81716   ┆ 0.795429  ┆ 0.540235  ┆ 0.478774 │\n",
       "│           ┆ Bourguet  ┆ Bourguet  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6451500   ┆ Méounes-l ┆ Meounes-l ┆ FR        ┆ … ┆ 0.81716   ┆ 0.795429  ┆ 0.542154  ┆ 0.464287 │\n",
       "│           ┆ ès-Montri ┆ es-Montri ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ eux       ┆ eux       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6457124   ┆ Les       ┆ Les       ┆ FR        ┆ … ┆ 0.81716   ┆ 0.795429  ┆ 0.542154  ┆ 0.450247 │\n",
       "│           ┆ Mayons    ┆ Mayons    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search through the admin hierarchy\n",
    "results = hierarchical_search(\n",
    "    search_terms=AdminHierarchy.from_list([\n",
    "        \"FR\",\n",
    "        \"Provence-Alpes-Côte d'Azur\",\n",
    "        \"Var\",\n",
    "        \"Arrondissement de Toulon\",\n",
    "        \"Le Lavandou\",\n",
    "        None,\n",
    "    ]),\n",
    "    con=con,\n",
    ")\n",
    "\n",
    "# Access results for each level\n",
    "if \"country\" in results:\n",
    "    logger.debug(\"Country results:\", results[\"country\"])\n",
    "if \"admin1\" in results:\n",
    "    logger.debug(\"Admin1 results:\", results[\"admin1\"])\n",
    "if \"admin2\" in results:\n",
    "    logger.debug(\"Admin2 results:\", results[\"admin2\"])\n",
    "if \"admin3\" in results:\n",
    "    logger.debug(\"Admin3 results:\", results[\"admin3\"])\n",
    "if \"admin4\" in results:\n",
    "    logger.debug(\"Admin4 results:\", results[\"admin4\"])\n",
    "results[\"admin4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    con.execute(\"SELECT geonameId, latitude, longitude FROM allCountries\")\n",
    "    .pl()\n",
    "    .select(\n",
    "        pl.col(\"geonameId\"),\n",
    "        pl.concat_list(pl.col(\"latitude\"), pl.col(\"longitude\"))\n",
    "        .cast(pl.Array(pl.Float32, 2))\n",
    "        .alias(\"vectors\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_coordinates1 = np.array([51.549902, -0.121696], dtype=np.float32)\n",
    "my_coordinates2 = np.array([37.77493, -122.41942], dtype=np.float32)\n",
    "\n",
    "vidx = VectorIndex(\"latlon\", data, metric=\"haversine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (path := Path(\"./data/processed/latlon.index\")).exists():\n",
    "    logger.debug(\"Loading index...\")\n",
    "    index = Index.restore(path, view=True)\n",
    "    if index is None:\n",
    "        raise ValueError(\"Failed to load index\")\n",
    "else:\n",
    "    logger.debug(\"Creating index...\")\n",
    "    coordinates = df.select([\"latitude\", \"longitude\"]).to_numpy(order=\"c\")\n",
    "    labels = df[\"geonameId\"].to_numpy()\n",
    "    index: Index = Index(ndim=2, metric=\"haversine\", dtype=\"f32\")\n",
    "    index.add(keys=labels, vectors=coordinates, log=True)\n",
    "    index.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example function to search and return results with distances\n",
    "def search_with_distances(\n",
    "    index: Index,\n",
    "    my_coordinates: NDArray[np.float32],\n",
    "    original_df: pl.LazyFrame,\n",
    "    k=10,\n",
    "    exact=False,\n",
    "):\n",
    "    # Perform the search\n",
    "    output = index.search(vectors=my_coordinates, count=k, log=True, exact=exact)\n",
    "\n",
    "    logger.debug(f\"Visited members: {output.visited_members}\")\n",
    "    logger.debug(f\"Computed distances: {output.computed_distances}\")\n",
    "\n",
    "    # Extract keys (geonameids) and distances\n",
    "    keys = output.keys\n",
    "    distances = output.distances\n",
    "\n",
    "    # Create a DataFrame from the search results\n",
    "    results_df = pl.LazyFrame(\n",
    "        data={\"geonameId\": keys, \"distance\": distances},\n",
    "        schema={\"geonameId\": pl.UInt32, \"distance\": pl.Float32},\n",
    "    ).with_columns(pl.col(\"distance\") * 6371.0)\n",
    "\n",
    "    # Join the results with the original DataFrame to get detailed information\n",
    "    detailed_results_df = results_df.join(original_df, on=\"geonameId\", how=\"left\")\n",
    "\n",
    "    # Sort by distance\n",
    "    sorted_results_df = detailed_results_df.sort(\"distance\")\n",
    "\n",
    "    return sorted_results_df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_with_distances(index, my_coordinates2, df.lazy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output: Matches = index.search(vectors=my_coordinates1, count=10, log=True)\n",
    "logger.debug(f\"{output.computed_distances=}\")\n",
    "logger.debug(f\"{output.visited_members=}\")\n",
    "df.filter(pl.col(\"geonameId\").is_in(output.keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# con.execute(sql_file(\"create_view_*_NODES.sql\", table=\"admin0\"))\n",
    "\n",
    "# con.execute(sql_file(\"create_view_*_FTS.sql\", table=\"admin0\"))\n",
    "\n",
    "# # if (path := Path(\"./data/processed/latlon.index\")).exists():\n",
    "# #     logger.debug(\"Loading index...\")\n",
    "# #     index = Index.restore(path, view=True) or raise ValueError(\"Failed to load index\")\n",
    "# # else:\n",
    "# #     logger.debug(\"Creating index...\")\n",
    "# #     coordinates = df.select([\"latitude\", \"longitude\"]).to_numpy(order=\"c\")\n",
    "# #     labels = df[\"geonameid\"].to_numpy()\n",
    "# #     index: Index = Index(ndim=2, metric=\"haversine\", dtype=\"f32\")\n",
    "# #     index.add(keys=labels, vectors=coordinates, log=True)\n",
    "# #     index.save(path)\n",
    "\n",
    "\n",
    "# class VectorIndex:\n",
    "#     default_index_path = Path(\"./data/indexes/vector\")\n",
    "\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         index_name: str,\n",
    "#         data: pl.DataFrame | None = None,\n",
    "#         id_column: str = \"geonameId\",\n",
    "#         main_column: str = \"vectors\",\n",
    "#         metric: str = \"L2\",\n",
    "#         embedder: SentenceTransformer | None = None,\n",
    "#     ):\n",
    "#         self._index_path = self.default_index_path / f\"{index_name}.index\"\n",
    "#         self._id_column = id_column\n",
    "#         self._main_column = main_column\n",
    "#         self._metric = metric\n",
    "#         index = self.get_or_build_index(data, metric)\n",
    "#         if isinstance(index, Err):\n",
    "#             logger.debug(\n",
    "#                 f\"Index does not exist at '{self.index_path}', build index with 'build_index' method.\"\n",
    "#             )\n",
    "#             self._index = None  # type: ignore\n",
    "#         else:\n",
    "#             self._index: Index = index.ok_value\n",
    "\n",
    "#     @property\n",
    "#     def index(self) -> Index:\n",
    "#         return self._index\n",
    "\n",
    "#     @property\n",
    "#     def id_column(self) -> str:\n",
    "#         return self._id_column\n",
    "\n",
    "#     @property\n",
    "#     def main_column(self) -> str:\n",
    "#         return self._main_column\n",
    "\n",
    "#     @property\n",
    "#     def index_path(self) -> Path:\n",
    "#         return self._index_path\n",
    "\n",
    "#     @property\n",
    "#     def ndims(self) -> int:\n",
    "#         return self._ndims\n",
    "\n",
    "#     @property\n",
    "#     def metric(self) -> str:\n",
    "#         return self._metric\n",
    "\n",
    "#     def _build_index(\n",
    "#         self,\n",
    "#         df: pl.DataFrame,\n",
    "#         metric: str = \"L2\",  # TODO: Metric like\n",
    "#     ) -> Result[Index, str]:\n",
    "#         \"\"\"Data passed should be an Id and a vector.\"\"\"\n",
    "#         logger.debug(\"Creating index...\")\n",
    "#         vectors = df[self.main_column].to_numpy()\n",
    "#         labels = df[self.id_column].to_numpy()\n",
    "#         ndims = vectors.shape[1]  # Find n dims\n",
    "#         index: Index = Index(ndim=ndims, metric=metric, dtype=\"f32\")\n",
    "#         index.add(keys=labels, vectors=vectors, log=True)\n",
    "#         index.save(self.index_path)\n",
    "#         return Ok(index)\n",
    "\n",
    "#     def get_index(self) -> Result[Index, str]:\n",
    "#         if (path := self.index_path).exists():\n",
    "#             logger.debug(f\"Opening index at '{self.index_path}'\")\n",
    "#             index = Index.restore(path, view=True)\n",
    "#             if index is not None:\n",
    "#                 return Ok(index)\n",
    "#         return Err(f\"Index does not exist at '{self.index_path}'\")\n",
    "\n",
    "#     def get_or_build_index(\n",
    "#         self,\n",
    "#         df: pl.DataFrame | None = None,\n",
    "#         metric: str = \"L2\",  # TODO: as above\n",
    "#     ) -> Result[Index, str]:\n",
    "#         self.index_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#         if not self.index_path.exists():\n",
    "#             if df is None:\n",
    "#                 return Err(\n",
    "#                     \"Index does not exist. DataFrame is required to create index\"\n",
    "#                 )\n",
    "#             match self._build_index(df, metric):\n",
    "#                 case Ok(index):\n",
    "#                     ...\n",
    "#                 case Err(e):\n",
    "#                     return Err(e)\n",
    "#         else:\n",
    "#             match self.get_index():\n",
    "#                 case Ok(index):\n",
    "#                     ...\n",
    "#                 case Err(e):\n",
    "#                     return Err(e)\n",
    "\n",
    "#         self._ndims = index.ndim\n",
    "#         logger.debug(\"Opening index\")\n",
    "#         return Ok(index)\n",
    "\n",
    "#     def search(\n",
    "#         self,\n",
    "#         query: NDArray[np.float32],\n",
    "#         limit: int = 10,\n",
    "#         include: list[int] | None = None,\n",
    "#         exclude: list[int] | None = None,\n",
    "#     ) -> Result[pl.DataFrame, str]:\n",
    "#         return self.vector_search(query, limit, include, exclude)\n",
    "\n",
    "#     def vector_search(\n",
    "#         self,\n",
    "#         query: NDArray[np.float32],\n",
    "#         limit: int = 10,\n",
    "#         include: list[int] | None = None,\n",
    "#         exclude: list[int] | None = None,\n",
    "#         exact: bool = False,\n",
    "#     ) -> Result[pl.DataFrame, str]:\n",
    "#         output = self.index.search(vectors=query, count=limit, log=True, exact=exact)\n",
    "\n",
    "#         logger.debug(f\"Visited members: {output.visited_members}\")\n",
    "#         logger.debug(f\"Computed distances: {output.computed_distances}\")\n",
    "\n",
    "#         # Extract keys (geonameids) and distances\n",
    "#         keys = output.keys\n",
    "#         distances = output.distances\n",
    "\n",
    "#         # Create a DataFrame from the search results\n",
    "#         results_df = pl.LazyFrame(\n",
    "#             data={self.id_column: keys, \"score\": distances},\n",
    "#             schema={self.id_column: pl.UInt32, \"score\": pl.Float32},\n",
    "#         )\n",
    "#         if self.metric == \"haversine\":\n",
    "#             results_df = results_df.with_columns(pl.col(\"score\") * 6371.0)\n",
    "\n",
    "#         results_df = results_df.sort(\n",
    "#             \"score\"\n",
    "#         )  # TODO: ascending descending depending on metric.\n",
    "\n",
    "#         return Ok(results_df.collect())\n",
    "\n",
    "\n",
    "# class FTSIndex:\n",
    "#     default_index_path = Path(\"./data/indexes/fts\")\n",
    "\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         index_name: str,\n",
    "#         data: pl.DataFrame | None = None,\n",
    "#         id_column: str = \"geonameId\",\n",
    "#         main_column: str = \"name\",\n",
    "#     ):\n",
    "#         self._index_path = self.default_index_path / index_name\n",
    "#         self._column_types = {}\n",
    "#         self._id_column = id_column\n",
    "#         self._main_column = main_column\n",
    "#         index = self.get_or_build_index(data)\n",
    "#         if isinstance(index, Err):\n",
    "#             logger.debug(\n",
    "#                 f\"Index does not exist at '{self.index_path}', build index with 'build_index' method.\"\n",
    "#             )\n",
    "#             self._index = None  # type: ignore\n",
    "#         else:\n",
    "#             self._index: tantivy.Index = index.ok_value\n",
    "\n",
    "#     @property\n",
    "#     def index(self) -> tantivy.Index:\n",
    "#         self._index.reload()\n",
    "#         return self._index\n",
    "\n",
    "#     @property\n",
    "#     def column_types(self) -> dict[str, str]:\n",
    "#         return self._column_types\n",
    "\n",
    "#     @property\n",
    "#     def id_column(self) -> str:\n",
    "#         return self._id_column\n",
    "\n",
    "#     @property\n",
    "#     def main_column(self) -> str:\n",
    "#         return self._main_column\n",
    "\n",
    "#     @property\n",
    "#     def index_path(self) -> Path:\n",
    "#         return self._index_path\n",
    "\n",
    "#     @property\n",
    "#     def columns_not_id(self) -> list[str]:\n",
    "#         return [col for col in self.column_types if col != self.id_column]\n",
    "\n",
    "#     def _build_index(\n",
    "#         self,\n",
    "#         df: pl.DataFrame,\n",
    "#         split_field: dict[str, list[str] | str] | None = None,\n",
    "#     ) -> Result[tantivy.Index, str]:\n",
    "#         \"\"\"Only pass in data which you wish to build the ftx index with. split_field is a dictionary of fields to split by a delimiter. eg {\",\": [\"field1\", \"field2\"]} will split field1 and field2 by comma.\"\"\"\n",
    "#         # TODO: this programmatically into tantivy schema\n",
    "#         schema_builder = tantivy.SchemaBuilder()\n",
    "\n",
    "#         if self.id_column not in df.columns:\n",
    "#             return Err(f\"'{self.id_column}' column not found in DataFrame\")\n",
    "\n",
    "#         col_types = {}\n",
    "#         for col in df.columns:\n",
    "#             if col == self.id_column:\n",
    "#                 schema_builder.add_integer_field(\n",
    "#                     self.id_column, stored=True, indexed=True, fast=True\n",
    "#                 )\n",
    "#             # TODO: ADD support for other types\n",
    "#             else:\n",
    "#                 schema_builder.add_text_field(col)\n",
    "#             col_types[col] = df[col].dtype._string_repr()\n",
    "\n",
    "#         self._column_types = col_types\n",
    "\n",
    "#         schema = schema_builder.build()\n",
    "#         logger.debug(f\"Creating index with columns:\\n{json.dumps(col_types, indent=2)}\")\n",
    "\n",
    "#         index = tantivy.Index(schema, path=self.index_path.as_posix(), reuse=False)\n",
    "#         writer = index.writer()\n",
    "#         for row in df.rows(named=True):\n",
    "#             if split_field:\n",
    "#                 for splitter, fields in split_field.items():\n",
    "#                     if isinstance(fields, str):\n",
    "#                         fields = [fields]\n",
    "#                     for field in fields:\n",
    "#                         logger.debug(f\"Splitting {field} by {splitter}...\")\n",
    "#                         row[field] = row[field].split(splitter)\n",
    "#             writer.add_document(tantivy.Document(**row))\n",
    "#         writer.commit()\n",
    "#         writer.wait_merging_threads()\n",
    "#         return Ok(index)\n",
    "\n",
    "#     def get_index(self) -> Result[tantivy.Index, str]:\n",
    "#         if tantivy.Index.exists(self.index_path.as_posix()):\n",
    "#             logger.debug(f\"Opening index at '{self.index_path}'\")\n",
    "#             return Ok(tantivy.Index.open(self.index_path.as_posix()))\n",
    "#         return Err(f\"Index does not exist at '{self.index_path}'\")\n",
    "\n",
    "#     def get_or_build_index(\n",
    "#         self, df: pl.DataFrame | None = None\n",
    "#     ) -> Result[tantivy.Index, str]:\n",
    "#         if not self.index_path.exists() and df is None:\n",
    "#             return Err(\"Index does not exist. DataFrame is required to create index\")\n",
    "\n",
    "#         self.index_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#         if not tantivy.Index.exists(self.index_path.as_posix()):\n",
    "#             if df is None:\n",
    "#                 return Err(\"DataFrame is required to create index\")\n",
    "#             match self._build_index(df):\n",
    "#                 case Ok(index):\n",
    "#                     ...\n",
    "#                 case Err(e):\n",
    "#                     return Err(e)\n",
    "#         else:\n",
    "#             match self.get_index():\n",
    "#                 case Ok(index):\n",
    "#                     ...\n",
    "#                 case Err(e):\n",
    "#                     return Err(e)\n",
    "#         schema = json.loads((self.index_path / \"meta.json\").read_text())[\"schema\"]\n",
    "#         sc = {}\n",
    "#         for v in schema:\n",
    "#             type_ = v[\"type\"]\n",
    "#             if type_ == \"text\":\n",
    "#                 type_ = pl.Utf8\n",
    "#             elif type_ == \"i64\":\n",
    "#                 type_ = pl.UInt32\n",
    "#             sc[v[\"name\"]] = type_\n",
    "\n",
    "#         self._column_types = sc\n",
    "#         logger.debug(\"Schema Loaded\")\n",
    "#         logger.debug(\"Opening country index\")\n",
    "#         return Ok(index)\n",
    "\n",
    "#     def convert_fts_results(\n",
    "#         self, hits: tantivy.SearchResult, searcher: tantivy.Searcher\n",
    "#     ) -> pl.DataFrame:\n",
    "#         logger.debug(f\"FTS hits from search: {hits.count}\")  # type: ignore\n",
    "\n",
    "#         scores, gids = zip(\n",
    "#             *[\n",
    "#                 (score, searcher.doc(doc).get_first(self.id_column))\n",
    "#                 for score, doc in hits.hits\n",
    "#             ]\n",
    "#         )\n",
    "\n",
    "#         return (\n",
    "#             pl.LazyFrame(\n",
    "#                 {\"geonameId\": list(gids), \"score\": list(scores)},\n",
    "#                 schema={\"geonameId\": pl.UInt32, \"score\": pl.Float32},\n",
    "#             )\n",
    "#             .sort(\"score\", descending=True, maintain_order=True)\n",
    "#             .collect()\n",
    "#         )\n",
    "\n",
    "#     def search(\n",
    "#         self,\n",
    "#         query: str,\n",
    "#         limit: int = 10,\n",
    "#         include: list[int] | None = None,\n",
    "#         exclude: list[int] | None = None,\n",
    "#     ) -> Result[pl.DataFrame, str]:\n",
    "#         return self.fts_search(\n",
    "#             query,\n",
    "#             limit=limit,\n",
    "#             include=include,\n",
    "#             exclude=exclude,\n",
    "#         )\n",
    "\n",
    "#     def fts_search(\n",
    "#         self,\n",
    "#         query: str,\n",
    "#         limit: int = 10,\n",
    "#         include: list[int] | None = None,\n",
    "#         exclude: list[int] | None = None,\n",
    "#         main_term_query_boost: float = 3.0,\n",
    "#         fuzzy_term_query_boost: float = 2.0,\n",
    "#         max_fuzzy_distance: int = 2,\n",
    "#         phrase: bool = True,\n",
    "#     ) -> Result[pl.DataFrame, str]:\n",
    "#         # Create for list of queries (batch search)\n",
    "#         if phrase:\n",
    "#             query = f\"'{query}'\"\n",
    "#         else:\n",
    "#             query = query.strip(\"\\\"'\")\n",
    "#         query = query.strip()\n",
    "#         index = self.index\n",
    "\n",
    "#         searcher = index.searcher()\n",
    "\n",
    "#         bool_query_list: list[tuple[tantivy.Occur, tantivy.Query]] = []\n",
    "\n",
    "#         # Calculate fuzzy distance based on query length\n",
    "#         fuzzy_distance = min(max(0, len(query) - 2), max_fuzzy_distance)\n",
    "\n",
    "#         if self.main_column in self.columns_not_id:\n",
    "#             main_term_query = tantivy.Query.term_query(\n",
    "#                 index.schema, self.main_column, query\n",
    "#             )\n",
    "#             bool_query_list.append(\n",
    "#                 (\n",
    "#                     tantivy.Occur.Should,\n",
    "#                     tantivy.Query.boost_query(main_term_query, main_term_query_boost),\n",
    "#                 )\n",
    "#             )\n",
    "\n",
    "#             if fuzzy_distance > 0:\n",
    "#                 main_fuzzy_query = tantivy.Query.fuzzy_term_query(\n",
    "#                     index.schema, self.main_column, query, distance=fuzzy_distance\n",
    "#                 )\n",
    "\n",
    "#                 bool_query_list.append(\n",
    "#                     (\n",
    "#                         tantivy.Occur.Should,\n",
    "#                         tantivy.Query.boost_query(\n",
    "#                             main_fuzzy_query, fuzzy_term_query_boost\n",
    "#                         ),\n",
    "#                     )\n",
    "#                 )\n",
    "\n",
    "#             rest_of_query = index.parse_query(\n",
    "#                 query, list(set(self.columns_not_id) - {self.main_column})\n",
    "#             )\n",
    "#             bool_query_list.append((tantivy.Occur.Should, rest_of_query))\n",
    "\n",
    "#         if include:\n",
    "#             bool_query_list.append(\n",
    "#                 (\n",
    "#                     tantivy.Occur.Must,\n",
    "#                     tantivy.Query.term_set_query(index.schema, self.id_column, include),\n",
    "#                 )\n",
    "#             )\n",
    "#         if exclude:\n",
    "#             bool_query_list.append(\n",
    "#                 (\n",
    "#                     tantivy.Occur.MustNot,\n",
    "#                     tantivy.Query.term_set_query(index.schema, self.id_column, exclude),\n",
    "#                 )\n",
    "#             )\n",
    "#         if bool_query_list:\n",
    "#             final_query = tantivy.Query.boolean_query(bool_query_list)\n",
    "\n",
    "#         else:\n",
    "#             final_query: tantivy.Query = index.parse_query(\n",
    "#                 query, default_field_names=self.columns_not_id\n",
    "#             )\n",
    "\n",
    "#         logger.debug(final_query)\n",
    "\n",
    "#         hits: tantivy.SearchResult = searcher.search(final_query, limit=limit)\n",
    "\n",
    "#         if hits.count == 0:  # type: ignore\n",
    "#             if phrase:\n",
    "#                 logger.debug(\"No results found, retrying without phrase search...\")\n",
    "#                 return self.fts_search(\n",
    "#                     query,\n",
    "#                     limit,\n",
    "#                     include,\n",
    "#                     exclude,\n",
    "#                     main_term_query_boost,\n",
    "#                     fuzzy_term_query_boost,\n",
    "#                     max_fuzzy_distance,\n",
    "#                     phrase=False,\n",
    "#                 )\n",
    "#             return Err(\"No results found\")\n",
    "\n",
    "#         return Ok(self.convert_fts_results(hits, searcher))\n",
    "\n",
    "\n",
    "# class HybridIndex:\n",
    "#     def __init__(self, fts_idx: FTSIndex, vidx: VectorIndex):\n",
    "#         self._fts_idx = fts_idx\n",
    "#         self._vidx = vidx\n",
    "\n",
    "#     @property\n",
    "#     def vector_index(self) -> VectorIndex:\n",
    "#         return self._vidx\n",
    "\n",
    "#     @property\n",
    "#     def fts_index(self) -> FTSIndex:\n",
    "#         return self._fts_idx\n",
    "\n",
    "#     def search(\n",
    "#         self,\n",
    "#         query: str,\n",
    "#         limit: int = 10,\n",
    "#         include: list[int] | None = None,\n",
    "#         exclude: list[int] | None = None,\n",
    "#         main_term_query_boost: float = 3.0,\n",
    "#         fuzzy_term_query_boost: float = 2.0,\n",
    "#         max_fuzzy_distance: int = 2,\n",
    "#         phrase: bool = True,\n",
    "#     ) -> Result[pl.DataFrame, str]:\n",
    "#         v_search = self.vector_index.vector_search\n",
    "\n",
    "\n",
    "# country_index = FTSIndex(\"admin0\", con.table(\"admin0_FTS\").pl())\n",
    "# country_index.fts_search(\"An Danmhairg\").unwrap().join(\n",
    "#     con.table(\"admin0\").pl(), \"geonameId\", \"left\"\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
