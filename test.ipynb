{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "import polars_distance as pld\n",
    "from pprint import pprint\n",
    "from loguru import logger\n",
    "import polars.selectors as cs\n",
    "import kuzu as kz\n",
    "from pathlib import Path\n",
    "from typing import Type, Callable\n",
    "from usearch.index import Index, Matches\n",
    "import numpy as np\n",
    "from typing import NamedTuple, Self, TypedDict\n",
    "from functools import partial\n",
    "from numpy.typing import NDArray\n",
    "import duckdb\n",
    "from duckdb import DuckDBPyConnection\n",
    "from time import time\n",
    "\n",
    "pl.Config.set_tbl_rows(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x130b17e70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duck_db_path = Path(\"./data/db/duck_db/data.db\")\n",
    "duck_db_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "con = duckdb.connect(database=duck_db_path.as_posix())\n",
    "\n",
    "con.execute(\"SET enable_progress_bar = false;\")\n",
    "con.install_extension(\"spatial\")\n",
    "con.load_extension(\"spatial\")\n",
    "\n",
    "# Set DuckDB optimizations\n",
    "con.execute(\"PRAGMA memory_limit='16GB'\")  # Adjust based on your system\n",
    "con.execute(\"PRAGMA threads=8\")  # Adjust based on your CPU cores\n",
    "con.execute(\"PRAGMA enable_object_cache=true\")  # Improve query caching\n",
    "# con.execute(\"PRAGMA profiling_mode = 'standard'\")  # Set profiling mode\n",
    "# con.execute(\"PRAGMA enable_profiling = 'json'\")  # Enable profiling\n",
    "# con.execute(\"PRAGMA profiling_output = './profile.json'\")  # Set profiling output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 23)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>asciiname</th><th>admin_level</th><th>admin0_code</th><th>admin1_code</th><th>admin2_code</th><th>admin3_code</th><th>admin4_code</th><th>feature_class</th><th>feature_code</th><th>ISO</th><th>ISO3</th><th>ISO_Numeric</th><th>official_name</th><th>fips</th><th>latitude</th><th>longitude</th><th>population</th><th>area</th><th>alternatenames</th><th>country_name</th><th>fts_score</th></tr><tr><td>u32</td><td>str</td><td>str</td><td>u8</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>u16</td><td>str</td><td>str</td><td>f32</td><td>f32</td><td>i32</td><td>f32</td><td>str</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>10861316</td><td>&quot;Kenya&quot;</td><td>&quot;Kenya&quot;</td><td>3</td><td>&quot;CD&quot;</td><td>&quot;05&quot;</td><td>null</td><td>&quot;10861316&quot;</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM3&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-11.69712</td><td>27.479509</td><td>0</td><td>null</td><td>null</td><td>&quot;Democratic Republic of the Con…</td><td>8.966241</td></tr><tr><td>192950</td><td>&quot;Republic of Kenya&quot;</td><td>&quot;Republic of Kenya&quot;</td><td>0</td><td>&quot;KE&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;A&quot;</td><td>&quot;PCLI&quot;</td><td>&quot;KE&quot;</td><td>&quot;KEN&quot;</td><td>404</td><td>&quot;Kenya&quot;</td><td>&quot;KE&quot;</td><td>1.0</td><td>38.0</td><td>51393010</td><td>582650.0</td><td>&quot;A Cheinia,Ceinia,Cenia,Chenia,…</td><td>&quot;Kenya&quot;</td><td>6.047672</td></tr><tr><td>400741</td><td>&quot;Eastern Province&quot;</td><td>&quot;Eastern Province&quot;</td><td>1</td><td>&quot;KE&quot;</td><td>&quot;03&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM1H&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>38.0</td><td>4631779</td><td>null</td><td>&quot;Aust-Kenya,Eastern,Eastern Pro…</td><td>&quot;Republic of Kenya&quot;</td><td>6.944599</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 23)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬──────────┬───────────┬───────────┬───────────┐\n",
       "│ geonameId ┆ name      ┆ asciiname ┆ admin_lev ┆ … ┆ area     ┆ alternate ┆ country_n ┆ fts_score │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ el        ┆   ┆ ---      ┆ names     ┆ ame       ┆ ---       │\n",
       "│ u32       ┆ str       ┆ str       ┆ ---       ┆   ┆ f32      ┆ ---       ┆ ---       ┆ f64       │\n",
       "│           ┆           ┆           ┆ u8        ┆   ┆          ┆ str       ┆ str       ┆           │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 10861316  ┆ Kenya     ┆ Kenya     ┆ 3         ┆ … ┆ null     ┆ null      ┆ Democrati ┆ 8.966241  │\n",
       "│           ┆           ┆           ┆           ┆   ┆          ┆           ┆ c         ┆           │\n",
       "│           ┆           ┆           ┆           ┆   ┆          ┆           ┆ Republic  ┆           │\n",
       "│           ┆           ┆           ┆           ┆   ┆          ┆           ┆ of the    ┆           │\n",
       "│           ┆           ┆           ┆           ┆   ┆          ┆           ┆ Con…      ┆           │\n",
       "│ 192950    ┆ Republic  ┆ Republic  ┆ 0         ┆ … ┆ 582650.0 ┆ A Cheinia ┆ Kenya     ┆ 6.047672  │\n",
       "│           ┆ of Kenya  ┆ of Kenya  ┆           ┆   ┆          ┆ ,Ceinia,C ┆           ┆           │\n",
       "│           ┆           ┆           ┆           ┆   ┆          ┆ enia,Chen ┆           ┆           │\n",
       "│           ┆           ┆           ┆           ┆   ┆          ┆ ia,…      ┆           ┆           │\n",
       "│ 400741    ┆ Eastern   ┆ Eastern   ┆ 1         ┆ … ┆ null     ┆ Aust-Keny ┆ Republic  ┆ 6.944599  │\n",
       "│           ┆ Province  ┆ Province  ┆           ┆   ┆          ┆ a,Eastern ┆ of Kenya  ┆           │\n",
       "│           ┆           ┆           ┆           ┆   ┆          ┆ ,Eastern  ┆           ┆           │\n",
       "│           ┆           ┆           ┆           ┆   ┆          ┆ Pro…      ┆           ┆           │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴──────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\n",
    "    \"\"\"SELECT * , fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
    "\n",
    "        FROM admin_search\n",
    "        WHERE fts_score IS NOT NULL\n",
    "            \"\"\",\n",
    "    {\"term\": \"Kenya\"},\n",
    ").pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_FOLDER = Path(\"./sql\")\n",
    "\n",
    "\n",
    "def sql_file(sql_path: Path | str, **kwargs) -> str:\n",
    "    if isinstance(sql_path, str):\n",
    "        sql_path = Path(sql_path)\n",
    "    if not sql_path.exists():\n",
    "        sql_path = SQL_FOLDER / sql_path\n",
    "        if not sql_path.exists():\n",
    "            raise FileNotFoundError(f\"SQL file {sql_path} not found\")\n",
    "    sql = sql_path.read_text()\n",
    "    if kwargs:\n",
    "        sql = sql.format(**kwargs)\n",
    "\n",
    "    # Validate no {kwarg} left in string (regex)\n",
    "    # if uninit_kwargs := re.findall(r\"\\{.*\\}\", sql):\n",
    "    #     raise ValueError(\n",
    "    #         f\"SQL file {sql_path} still has unprocessed kwargs: {list(set(uninit_kwargs))} in:\\n\\n{sql}\"\n",
    "    #     )\n",
    "\n",
    "    return sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-07 13:44:53.601\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_file\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mTable 'allCountries' already exists\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:53.644\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_file\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mTable 'allPostCodes' already exists\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:53.693\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_file\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mTable 'admin1CodesASCII' already exists\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:53.715\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_file\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mTable 'admin2Codes' already exists\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:53.728\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_file\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mTable 'adminCode5' already exists\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:53.732\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_file\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mTable 'alternateNamesV2' already exists\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:53.735\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_file\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mTable 'countryInfo' already exists\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:53.738\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_file\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mTable 'featureCodes' already exists\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:53.741\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_file\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mTable 'hierarchy' already exists\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:53.746\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_file\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mTable 'iso_languagecodes' already exists\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:53.749\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_file\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mTable 'timeZones' already exists\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x130b17e70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GID = \"geonameId\"\n",
    "\n",
    "\n",
    "def table_exists(con: DuckDBPyConnection, table_name: str) -> bool:\n",
    "    return table_name in con.execute(\"SHOW TABLES\").pl()[\"name\"]\n",
    "\n",
    "\n",
    "# Read and load 'allCountries.txt'\n",
    "# Function to read and load other files with different schemas\n",
    "def load_file(\n",
    "    # con: DuckDBPyConnection,\n",
    "    file_path: str,\n",
    "    schema: dict[str, Type[pl.DataType]],\n",
    "    table_name: str,\n",
    "    table_definition: str | None = None,\n",
    "    pipe: Callable[[pl.LazyFrame], pl.LazyFrame] | None = None,\n",
    "    has_header: bool = False,\n",
    "    skip_rows: int = 0,\n",
    "    overwrite: bool = False,\n",
    "    extra_expr: pl.Expr | None = None,\n",
    "):\n",
    "    if table_exists(con, table_name):\n",
    "        logger.debug(f\"Table '{table_name}' already exists\")\n",
    "        if not overwrite:\n",
    "            return\n",
    "        logger.debug(f\"Overwriting table '{table_name}'\")\n",
    "        con.execute(f\"DROP TABLE {table_name} CASCADE\")\n",
    "        logger.debug(f\"Table '{table_name}' dropped\")\n",
    "    time_start = time()\n",
    "    load = con.begin()\n",
    "    try:\n",
    "        logger.info(f\"Loading '{file_path}'...\")\n",
    "        # Time scan\n",
    "        time_scan = time()\n",
    "        q = pl.scan_csv(\n",
    "            file_path,\n",
    "            separator=\"\\t\",\n",
    "            has_header=has_header,\n",
    "            schema=schema,\n",
    "            skip_rows=skip_rows,\n",
    "        )\n",
    "        q = q.with_columns(\n",
    "            pl.col(pl.Utf8).str.strip_chars().str.strip_chars(\"\\\"':\").str.strip_chars()\n",
    "        )\n",
    "        if extra_expr is not None:\n",
    "            q = q.with_columns(extra_expr)\n",
    "        if pipe is not None:\n",
    "            q = q.pipe(pipe)\n",
    "        if GID in schema:\n",
    "            q = q.sort(GID, nulls_last=True)\n",
    "        logger.debug(f\"Scan time: {time() - time_scan:.6f}s\")\n",
    "\n",
    "        q = q.with_columns(cs.by_dtype(pl.String).str.strip_chars().replace(\"\", None))\n",
    "\n",
    "        # Time collect\n",
    "        time_collect = time()\n",
    "        df = q.collect()\n",
    "        logger.debug(f\"Collect time: {time() - time_collect:.6f}s\")\n",
    "\n",
    "        # Time write\n",
    "        time_write = time()\n",
    "        save_path = Path(f\"./data/processed/geonames/{table_name}.parquet\")\n",
    "        save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df.write_parquet(save_path.as_posix())\n",
    "        logger.debug(f\"Write time: {time() - time_write:.6f}s\")\n",
    "\n",
    "        # Time create\n",
    "        time_create = time()\n",
    "        # Create table with predefined schema if provided\n",
    "        time_create = time()\n",
    "        if table_definition:\n",
    "            # Create the table with specified schema\n",
    "            load.execute(table_definition)\n",
    "            load.from_arrow(df.to_arrow()).insert_into(table_name)\n",
    "        else:\n",
    "            # Use automatic schema derivation (your current approach)\n",
    "            load.from_arrow(df.to_arrow()).create(table_name)\n",
    "\n",
    "        logger.debug(f\"Create time: {time() - time_create:.6f}s\")\n",
    "\n",
    "        time_commit = time()\n",
    "        load.commit()\n",
    "        logger.debug(f\"Commit time: {time() - time_commit:.6f}s\")\n",
    "        analyze_time = time()\n",
    "        con.execute(\"VACUUM ANALYZE;\")\n",
    "        logger.debug(f\"Analyze time: {time() - analyze_time:.6f}s\")\n",
    "    except Exception as e:\n",
    "        logger.exception(\"Error loading '{file_path}'\")\n",
    "        logger.debug(e.with_traceback(None))\n",
    "        # Time rollback\n",
    "        time_rollback = time()\n",
    "        load.rollback()\n",
    "        logger.warning(f\"Rollback time: {time() - time_rollback:.6f}s\")\n",
    "        raise e\n",
    "    finally:\n",
    "        logger.info(f\"Total time: {time() - time_start:.6f}s\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def drop_duplicates(df: pl.LazyFrame) -> pl.LazyFrame:\n",
    "    cols = [\n",
    "        \"name\",\n",
    "        \"asciiname\",\n",
    "        \"feature_class\",\n",
    "        \"feature_code\",\n",
    "        \"admin0_code\",\n",
    "        \"admin1_code\",\n",
    "        \"admin2_code\",\n",
    "        \"admin3_code\",\n",
    "        \"admin4_code\",\n",
    "        \"timezone\",\n",
    "    ]\n",
    "    return (\n",
    "        df.sort(\"modification_date\", descending=True)\n",
    "        .unique(cols, keep=\"first\")\n",
    "        .filter(~pl.all_horizontal(pl.col(cols).is_null()))\n",
    "        .sort(\"geonameId\")\n",
    "    )\n",
    "\n",
    "\n",
    "schema_all_countries = {\n",
    "    GID: pl.UInt32,\n",
    "    \"name\": pl.Utf8,\n",
    "    \"asciiname\": pl.Utf8,\n",
    "    \"alternatenames\": pl.Utf8,\n",
    "    \"latitude\": pl.Float32,\n",
    "    \"longitude\": pl.Float32,\n",
    "    \"feature_class\": pl.Categorical,\n",
    "    \"feature_code\": pl.Categorical,\n",
    "    \"admin0_code\": pl.Categorical,\n",
    "    \"cc2\": pl.Utf8,\n",
    "    \"admin1_code\": pl.Utf8,\n",
    "    \"admin2_code\": pl.Utf8,\n",
    "    \"admin3_code\": pl.Utf8,\n",
    "    \"admin4_code\": pl.Utf8,\n",
    "    \"population\": pl.Int64,\n",
    "    \"elevation\": pl.Int32,\n",
    "    \"dem\": pl.Int32,\n",
    "    \"timezone\": pl.Categorical,\n",
    "    \"modification_date\": pl.Date,\n",
    "}\n",
    "\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/allCountries.txt\",\n",
    "    schema_all_countries,\n",
    "    \"allCountries\",\n",
    "    table_definition=sql_file(\"create_table_allCountries.sql\"),\n",
    "    pipe=drop_duplicates,\n",
    ")\n",
    "\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/allCountriesPostCode.txt\",\n",
    "    {\n",
    "        \"admin_code0\": pl.Categorical,\n",
    "        \"postal_code\": pl.Utf8,\n",
    "        \"place_name\": pl.Utf8,\n",
    "        \"admin_name1\": pl.Utf8,\n",
    "        \"admin_code1\": pl.Utf8,\n",
    "        \"admin_name2\": pl.Utf8,\n",
    "        \"admin_code2\": pl.Utf8,\n",
    "        \"admin_name3\": pl.Utf8,\n",
    "        \"admin_code3\": pl.Utf8,\n",
    "        \"latitude\": pl.Float32,\n",
    "        \"longitude\": pl.Float32,\n",
    "        \"accuracy\": pl.Int32,\n",
    "    },\n",
    "    \"allPostCodes\",\n",
    ")\n",
    "\n",
    "\n",
    "# Load other files with respective schemas\n",
    "load_file(\n",
    "    \"./data/raw/geonames/admin1CodesASCII.txt\",\n",
    "    {\n",
    "        \"code\": pl.Utf8,\n",
    "        \"name\": pl.Utf8,\n",
    "        \"name_ascii\": pl.Utf8,\n",
    "        GID: pl.UInt32,\n",
    "    },\n",
    "    \"admin1CodesASCII\",\n",
    "    table_definition=sql_file(\"create_table_admin1CodesASCII.sql\"),\n",
    ")\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/admin2Codes.txt\",\n",
    "    {\n",
    "        \"code\": pl.Utf8,\n",
    "        \"name\": pl.Utf8,\n",
    "        \"asciiname\": pl.Utf8,\n",
    "        GID: pl.UInt32,\n",
    "    },\n",
    "    \"admin2Codes\",\n",
    "    table_definition=sql_file(\"create_table_admin2Codes.sql\"),\n",
    ")\n",
    "\n",
    "\n",
    "def drop_invalid_gids(df: pl.LazyFrame, con: DuckDBPyConnection) -> pl.LazyFrame:\n",
    "    ids = con.execute(\"SELECT geonameId FROM allCountries\").pl().unique().to_series()\n",
    "    return df.filter(pl.col(GID).is_in(ids))\n",
    "\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/adminCode5.txt\",\n",
    "    {\n",
    "        GID: pl.UInt32,\n",
    "        \"adm5code\": pl.Utf8,\n",
    "    },\n",
    "    \"adminCode5\",\n",
    "    table_definition=sql_file(\"create_table_adminCode5.sql\"),\n",
    "    pipe=partial(drop_invalid_gids, con=con),\n",
    ")\n",
    "\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/alternateNamesV2.txt\",\n",
    "    {\n",
    "        \"alternateNameId\": pl.Int32,\n",
    "        GID: pl.UInt32,\n",
    "        \"isolanguage\": pl.Utf8,\n",
    "        \"alternate_name\": pl.Utf8,\n",
    "        \"isPreferredName\": pl.Int8,\n",
    "        \"isShortName\": pl.Int8,\n",
    "        \"isColloquial\": pl.Int8,\n",
    "        \"isHistoric\": pl.Int8,\n",
    "        \"from\": pl.Utf8,\n",
    "        \"to\": pl.Utf8,\n",
    "    },\n",
    "    \"alternateNamesV2\",\n",
    "    table_definition=sql_file(\"create_table_alternateNamesV2.sql\"),\n",
    "    extra_expr=cs.by_dtype(pl.Int8).cast(pl.Boolean).fill_null(False),\n",
    "    pipe=partial(drop_invalid_gids, con=con),\n",
    ")\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/countryInfo.txt\",\n",
    "    {\n",
    "        \"ISO\": pl.Categorical,\n",
    "        \"ISO3\": pl.Categorical,\n",
    "        \"ISO_Numeric\": pl.Int32,\n",
    "        \"fips\": pl.Categorical,\n",
    "        \"Country\": pl.Utf8,\n",
    "        \"Capital\": pl.Utf8,\n",
    "        \"Area\": pl.Float32,\n",
    "        \"Population\": pl.Int32,\n",
    "        \"Continent\": pl.Categorical,\n",
    "        \"tld\": pl.Utf8,\n",
    "        \"CurrencyCode\": pl.Utf8,\n",
    "        \"CurrencyName\": pl.Utf8,\n",
    "        \"Phone\": pl.Utf8,\n",
    "        \"Postal_Code_Format\": pl.Utf8,\n",
    "        \"Postal_Code_Regex\": pl.Utf8,\n",
    "        \"Languages\": pl.Utf8,\n",
    "        GID: pl.UInt32,\n",
    "        \"neighbours\": pl.Utf8,\n",
    "        \"EquivalentFipsCode\": pl.Utf8,\n",
    "    },\n",
    "    \"countryInfo\",\n",
    "    table_definition=sql_file(\"create_table_countryInfo.sql\"),\n",
    "    skip_rows=51,\n",
    ")\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/featureCodes_en.txt\",\n",
    "    {\n",
    "        \"code\": pl.Categorical,\n",
    "        \"name\": pl.Utf8,\n",
    "        \"description\": pl.Utf8,\n",
    "    },\n",
    "    \"featureCodes\",\n",
    "    table_definition=sql_file(\"create_table_featureCodes.sql\"),\n",
    ")\n",
    "\n",
    "\n",
    "def remove_old_ids(df: pl.LazyFrame, con: DuckDBPyConnection) -> pl.LazyFrame:\n",
    "    ids = con.execute(\"SELECT geonameId FROM allCountries\").pl().unique().to_series()\n",
    "    return (\n",
    "        df.filter(pl.col(\"parentId\").is_in(ids) & pl.col(\"childId\").is_in(ids))\n",
    "        .with_columns(\n",
    "            pl.when(pl.col(\"type\").str.contains(\"adm\", literal=True))\n",
    "            .then(pl.col(\"type\").str.to_uppercase())\n",
    "            .otherwise(pl.col(\"type\"))\n",
    "        )\n",
    "        .unique([\"parentId\", \"childId\"])\n",
    "    )\n",
    "\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/hierarchy.txt\",\n",
    "    {\n",
    "        \"parentId\": pl.UInt32,\n",
    "        \"childId\": pl.UInt32,\n",
    "        \"type\": pl.Utf8,\n",
    "    },\n",
    "    \"hierarchy\",\n",
    "    table_definition=sql_file(\"create_table_hierarchy.sql\"),\n",
    "    pipe=partial(remove_old_ids, con=con),\n",
    ")\n",
    "con.execute(sql_file(\"create_table_unique_ids.sql\"))\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/iso-languagecodes.txt\",\n",
    "    {\n",
    "        \"ISO_639_3\": pl.Utf8,\n",
    "        \"ISO_639_2\": pl.Utf8,\n",
    "        \"ISO_639_1\": pl.Utf8,\n",
    "        \"Language_Name\": pl.Utf8,\n",
    "    },\n",
    "    \"iso_languagecodes\",\n",
    "    table_definition=sql_file(\"create_table_iso_languagecodes.sql\"),\n",
    ")\n",
    "\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/timeZones.txt\",\n",
    "    {\n",
    "        \"CountryCode\": pl.Utf8,\n",
    "        \"TimeZoneId\": pl.Utf8,\n",
    "        \"GMT_offset_1_Jan_2024\": pl.Float32,\n",
    "        \"DST_offset_1_Jul_2024\": pl.Float32,\n",
    "        \"rawOffset\": pl.Float32,\n",
    "    },\n",
    "    \"timeZones\",\n",
    "    table_definition=sql_file(\"create_table_timeZones.sql\"),\n",
    "    skip_rows=1,\n",
    ")\n",
    "# # Ignore loading the geo data for now\n",
    "if not table_exists(con, \"shapes\"):\n",
    "    con.execute(sql_file(\"create_table_shapes.sql\"))\n",
    "    logger.debug(\"Table 'shapes' created\")\n",
    "\n",
    "# # File is corupted atm\n",
    "# load_file(\n",
    "#     \"./data/raw/geonames/userTags.txt\",\n",
    "#     {\n",
    "#         GID: pl.Int32,\n",
    "#         \"tag\": pl.Utf8,\n",
    "#     },\n",
    "#     \"userTags\",\n",
    "# )\n",
    "con.execute(sql_file(\"create_table_equivalent.sql\"))\n",
    "con.execute(sql_file(\"create_view_cities.sql\"))\n",
    "con.execute(sql_file(\"create_view_locations_full.sql\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create country table\n",
    "# con.execute(sql_file(\"create_table_equivalent.sql\")).pl()\n",
    "# con.execute(sql_file(\"create_table_admin0.sql\")).execute(\"\"\"PRAGMA create_fts_index(\n",
    "#     admin0,\n",
    "#     geonameId,\n",
    "#     name,\n",
    "#     asciiname,\n",
    "#     official_name,\n",
    "#     alternatenames,\n",
    "#     admin0_code,\n",
    "#     ISO3,\n",
    "#     ISO_Numeric,\n",
    "#     fips,\n",
    "#     stemmer = 'none',\n",
    "#     stopwords = 'none',\n",
    "#     ignore = '(\\\\.|[^a-z0-9])+',\n",
    "#     overwrite = 1\n",
    "# );\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-07 13:44:54.565\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[34m\u001b[1mLoaded 534106 entities and 508066 hierarchical relationships\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:54.566\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[34m\u001b[1mEntity columns:\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:54.566\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m14\u001b[0m - \u001b[34m\u001b[1mHierarchy columns:\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "entities_df = con.execute(f\"\"\"\n",
    "    SELECT {GID}, name, feature_class, feature_code\n",
    "    FROM unique_ids\n",
    "\"\"\").pl()\n",
    "\n",
    "hierarchy_df = con.execute(\"\"\"\n",
    "    SELECT parentId, childId, type\n",
    "    FROM hierarchy\n",
    "\"\"\").pl()\n",
    "logger.debug(\n",
    "    f\"Loaded {len(entities_df)} entities and {len(hierarchy_df)} hierarchical relationships\"\n",
    ")\n",
    "logger.debug(\"Entity columns:\", entities_df.columns)\n",
    "logger.debug(\"Hierarchy columns:\", hierarchy_df.columns)\n",
    "\n",
    "# 2. Setup Kuzu database connection\n",
    "gdb_path = Path(\"./data/db/graph_db\")\n",
    "gdb_path.mkdir(parents=True, exist_ok=True)\n",
    "gdb = kz.Database(gdb_path.as_posix())\n",
    "conn = kz.Connection(gdb)\n",
    "\n",
    "# 3. Create the schema in Kuzu if needed\n",
    "if \"Entity\" not in conn.execute(\"CALL SHOW_TABLES() RETURN *;\").get_as_pl().get_column(\n",
    "    \"name\"\n",
    "):\n",
    "    conn.execute(sql_file(\"create_node_entity.sql\"))\n",
    "    logger.debug(\"Created Entity table\")\n",
    "\n",
    "if \"IsIn\" not in conn.execute(\"CALL SHOW_TABLES() RETURN *;\").get_as_pl().get_column(\n",
    "    \"name\"\n",
    "):\n",
    "    conn.execute(sql_file(\"create_relation_IsIn.sql\"))\n",
    "    logger.debug(\"Created IsIn table\")\n",
    "\n",
    "    # 4. Check if tables already have data\n",
    "are_nodes = (\n",
    "    conn.execute(\"MATCH (e:Entity) RETURN count(e) > 0 AS HasData\")\n",
    "    .get_as_pl()\n",
    "    .get_column(\"HasData\")[0]\n",
    ")\n",
    "are_edges = (\n",
    "    conn.execute(\"MATCH ()-[r:IsIn]->() RETURN count(r) > 0 AS HasData\")\n",
    "    .get_as_pl()\n",
    "    .get_column(\"HasData\")[0]\n",
    ")\n",
    "\n",
    "if not are_nodes:\n",
    "    conn.execute(\n",
    "        f\"COPY Entity FROM (LOAD FROM entities_df RETURN {GID}, name, feature_class, feature_code)\"\n",
    "    )\n",
    "    logger.debug(\"Loaded Entity\")\n",
    "\n",
    "if not are_edges:\n",
    "    conn.execute(\n",
    "        \"COPY IsIn FROM (LOAD FROM hierarchy_df RETURN parentId, childId, type)\"\n",
    "    )\n",
    "    logger.debug(\"Loaded IsIn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>feature_class</th><th>feature_code</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>11820342</td><td>&quot;Horn of Africa&quot;</td><td>&quot;L&quot;</td><td>&quot;RGN&quot;</td></tr><tr><td>6255146</td><td>&quot;Africa&quot;</td><td>&quot;L&quot;</td><td>&quot;CONT&quot;</td></tr><tr><td>11812257</td><td>&quot;Commonwealth of Nations&quot;</td><td>&quot;A&quot;</td><td>&quot;ZN&quot;</td></tr><tr><td>7729889</td><td>&quot;Eastern Africa&quot;</td><td>&quot;L&quot;</td><td>&quot;RGN&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 4)\n",
       "┌───────────┬─────────────────────────┬───────────────┬──────────────┐\n",
       "│ geonameId ┆ name                    ┆ feature_class ┆ feature_code │\n",
       "│ ---       ┆ ---                     ┆ ---           ┆ ---          │\n",
       "│ i32       ┆ str                     ┆ str           ┆ str          │\n",
       "╞═══════════╪═════════════════════════╪═══════════════╪══════════════╡\n",
       "│ 11820342  ┆ Horn of Africa          ┆ L             ┆ RGN          │\n",
       "│ 6255146   ┆ Africa                  ┆ L             ┆ CONT         │\n",
       "│ 11812257  ┆ Commonwealth of Nations ┆ A             ┆ ZN           │\n",
       "│ 7729889   ┆ Eastern Africa          ┆ L             ┆ RGN          │\n",
       "└───────────┴─────────────────────────┴───────────────┴──────────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_children_query(geoname_id: int) -> str:\n",
    "    query = f\"\"\"MATCH (p:Entity {{geonameId: {geoname_id}}})-[:IsIn]->(c:Entity)\n",
    "    RETURN c.{GID} AS {GID}, c.name AS name, c.feature_class AS feature_class, c.feature_code AS feature_code;\"\"\"\n",
    "    return query\n",
    "\n",
    "\n",
    "def get_parents_query(geoname_id):\n",
    "    query = f\"\"\"MATCH (c:Entity {{geonameId: {geoname_id}}})<-[:IsIn]-(p:Entity)\n",
    "    RETURN p.{GID} AS {GID}, p.name AS name, p.feature_class AS feature_class, p.feature_code AS feature_code;\"\"\"\n",
    "    return query\n",
    "\n",
    "\n",
    "# MATCH (c:Entity) WHERE CAST(c.geonameId, \"INT64\") IN list_creation({formatted_ids}) RETURN *;\n",
    "def get_children_querys(\n",
    "    geoname_ids: list[int] | pl.Series, traverse: bool = False\n",
    ") -> str:\n",
    "    query = f\"\"\"MATCH (p:Entity)-[:IsIn{\"*\" if traverse else \"\"}]->(c:Entity)\n",
    "    WHERE p.geonameId IN CAST({geoname_ids}, \"UINT32[]\")\n",
    "    RETURN DISTINCT c.{GID} AS {GID}, c.name AS name, c.feature_class AS feature_class, c.feature_code AS feature_code;\"\"\"\n",
    "    return query\n",
    "\n",
    "\n",
    "def get_parents_querys(\n",
    "    geoname_ids: list[int] | pl.Series, traverse: bool = False\n",
    ") -> str:\n",
    "    query = f\"\"\"MATCH (c:Entity)<-[:IsIn{\"*\" if traverse else \"\"}]-(p:Entity)\n",
    "    WHERE c.geonameId IN CAST({geoname_ids}, \"UINT32[]\")\n",
    "    RETURN DISTINCT p.{GID} AS {GID}, p.name AS name, p.feature_class AS feature_class, p.feature_code AS feature_code;\"\"\"\n",
    "    return query\n",
    "\n",
    "\n",
    "def get_highest_parent_query():\n",
    "    query = f\"\"\"\n",
    "    MATCH (entity:Entity)\n",
    "    WHERE NOT (entity)<-[:IsIn]-(:Entity)\n",
    "    RETURN entity.{GID} AS {GID}, entity.name AS name, entity.feature_class AS feature_class, entity.feature_code AS feature_code;\"\"\"\n",
    "    return query\n",
    "\n",
    "\n",
    "conn.execute(get_parents_query(49518)).get_as_pl()\n",
    "conn.execute(get_children_query(6252001)).get_as_pl()\n",
    "conn.execute(get_children_querys([49518, 51537])).get_as_pl()\n",
    "conn.execute(get_parents_querys([49518, 51537])).get_as_pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-07 13:44:54.700\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbuild_unified_admin_table\u001b[0m:\u001b[36m4\u001b[0m - \u001b[34m\u001b[1mStarting simplified admin search table construction...\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:54.703\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbuild_unified_admin_table\u001b[0m:\u001b[36m8\u001b[0m - \u001b[34m\u001b[1mTable admin_search already exists. Skipping.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def build_unified_admin_table(con, conn=None, overwrite=True):\n",
    "    \"\"\"Build a simplified admin_search table focusing on admin codes for hierarchy.\"\"\"\n",
    "\n",
    "    logger.debug(\"Starting simplified admin search table construction...\")\n",
    "\n",
    "    # Check if table exists\n",
    "    if table_exists(con, \"admin_search\") and not overwrite:\n",
    "        logger.debug(\"Table admin_search already exists. Skipping.\")\n",
    "        con.execute(\"VACUUM ANALYZE;\")\n",
    "        return\n",
    "\n",
    "    # Create the table with proper schema\n",
    "    con.execute(sql_file(\"create_unified_admin_table.sql\"))\n",
    "\n",
    "    # Define admin level feature code patterns\n",
    "    level_codes = {\n",
    "        0: [\"PCL\", \"PCLI\", \"PCLD\", \"PCLF\", \"PCLS\", \"TERR\"],\n",
    "        1: [\"ADM1\", \"ADM1H\"],\n",
    "        2: [\"ADM2\", \"ADM2H\"],\n",
    "        3: [\"ADM3\", \"ADM3H\"],\n",
    "        4: [\"ADM4\", \"ADM4H\"],\n",
    "    }\n",
    "\n",
    "    # Process each admin level\n",
    "    for level in range(0, 5):\n",
    "        logger.info(f\"Processing admin level {level} entities...\")\n",
    "\n",
    "        # Identify entities of this admin level by feature code\n",
    "        feature_patterns = \"', '\".join([code for code in level_codes[level]])\n",
    "\n",
    "        # Direct insert of entities with the matching feature codes\n",
    "        if level == 0:  # Countries (admin0)\n",
    "            insert_query = f\"\"\"\n",
    "            INSERT INTO admin_search\n",
    "            SELECT\n",
    "                a.geonameId,\n",
    "                a.name,\n",
    "                a.asciiname,\n",
    "                0 AS admin_level,\n",
    "                a.admin0_code,\n",
    "                NULL AS admin1_code,\n",
    "                NULL AS admin2_code,\n",
    "                NULL AS admin3_code,\n",
    "                NULL AS admin4_code,\n",
    "                a.feature_class,\n",
    "                a.feature_code,\n",
    "                c.ISO,\n",
    "                c.ISO3,\n",
    "                c.ISO_Numeric,\n",
    "                c.Country AS official_name,\n",
    "                c.fips,\n",
    "                a.latitude,\n",
    "                a.longitude,\n",
    "                c.population,\n",
    "                c.area,\n",
    "                a.alternatenames,\n",
    "                c.Country AS country_name\n",
    "            FROM\n",
    "                allCountries a\n",
    "            LEFT JOIN\n",
    "                countryInfo c ON a.geonameId = c.geonameId\n",
    "            WHERE\n",
    "                a.feature_code IN ('{feature_patterns}')\n",
    "                OR a.feature_code LIKE '{level_codes[level][0]}%'\n",
    "            \"\"\"\n",
    "        else:\n",
    "            # For admin levels 1-4\n",
    "            insert_query = f\"\"\"\n",
    "            INSERT INTO admin_search\n",
    "            SELECT\n",
    "                a.geonameId,\n",
    "                a.name,\n",
    "                a.asciiname,\n",
    "                {level} AS admin_level,\n",
    "                a.admin0_code,\n",
    "                {(\"a.admin1_code\" if level >= 1 else \"NULL::VARCHAR AS admin1_code\")},\n",
    "                {(\"a.admin2_code\" if level >= 2 else \"NULL::VARCHAR AS admin2_code\")},\n",
    "                {(\"a.admin3_code\" if level >= 3 else \"NULL::VARCHAR AS admin3_code\")},\n",
    "                {(\"a.admin4_code\" if level >= 4 else \"NULL::VARCHAR AS admin4_code\")},\n",
    "                a.feature_class,\n",
    "                a.feature_code,\n",
    "                NULL AS ISO,\n",
    "                NULL AS ISO3,\n",
    "                NULL AS ISO_Numeric,\n",
    "                NULL AS official_name,\n",
    "                NULL AS fips,\n",
    "                a.latitude,\n",
    "                a.longitude,\n",
    "                a.population,\n",
    "                NULL AS area,\n",
    "                a.alternatenames,\n",
    "                c.name AS country_name\n",
    "            FROM\n",
    "                allCountries a\n",
    "            LEFT JOIN\n",
    "                allCountries c ON a.admin0_code = c.admin0_code AND c.feature_code = 'PCLI'\n",
    "            WHERE\n",
    "                (a.feature_code IN ('{feature_patterns}')\n",
    "                OR a.feature_code LIKE '{level_codes[level][0]}%')\n",
    "                AND a.admin0_code IS NOT NULL\n",
    "            \"\"\"\n",
    "\n",
    "        # Execute the query to insert data\n",
    "        con.execute(insert_query)\n",
    "\n",
    "        # Report count\n",
    "        count = con.execute(\n",
    "            f\"SELECT COUNT(*) FROM admin_search WHERE admin_level = {level}\"\n",
    "        ).fetchone()[0]\n",
    "        logger.debug(f\"Added {count} entities for admin level {level}\")\n",
    "\n",
    "    # Create FTS index for the unified table\n",
    "    logger.debug(\"Creating FTS index for admin_search table...\")\n",
    "    con.execute(\"\"\"\n",
    "    PRAGMA create_fts_index(\n",
    "        admin_search,\n",
    "        geonameId,\n",
    "        name, asciiname, alternatenames, official_name, ISO, ISO3,\n",
    "        stemmer = 'none',\n",
    "        stopwords = 'none',\n",
    "        ignore = '(\\\\.|[^a-z0-9])+',\n",
    "        overwrite = 1\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    # Final optimization\n",
    "    logger.debug(\"Running VACUUM ANALYZE to optimize the database...\")\n",
    "    con.execute(\"VACUUM ANALYZE;\")\n",
    "\n",
    "    logger.debug(\"Admin search table construction complete!\")\n",
    "    logger.debug(\"Writing admin_search table to parquet...\")\n",
    "    con.table(\"admin_search\").pl().write_parquet(\n",
    "        Path(\"./data/processed/geonames/admin_search.parquet\").as_posix(),\n",
    "        partition_by=[\"admin_level\"],\n",
    "    )\n",
    "    logger.debug(\"Admin search table written to parquet.\")\n",
    "\n",
    "\n",
    "build_unified_admin_table(con, conn, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-07 13:44:54.818\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbuild_places_search_table\u001b[0m:\u001b[36m4\u001b[0m - \u001b[34m\u001b[1mStarting places search table construction...\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:54.827\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbuild_places_search_table\u001b[0m:\u001b[36m7\u001b[0m - \u001b[34m\u001b[1mTable places_search already exists. Skipping.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def build_places_search_table(con, overwrite=True):\n",
    "    \"\"\"Build places_search table with balanced importance scoring.\"\"\"\n",
    "\n",
    "    logger.debug(\"Starting places search table construction...\")\n",
    "\n",
    "    if table_exists(con, \"places_search\") and not overwrite:\n",
    "        logger.debug(\"Table places_search already exists. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # Create the table with physical importance_tier column\n",
    "    con.execute(sql_file(\"create_places_search_table.sql\"))\n",
    "\n",
    "    # Define feature categories with more nuanced scoring\n",
    "    feature_categories = {\n",
    "        \"major_populated\": {\n",
    "            \"codes\": [\n",
    "                \"PPLA\",\n",
    "                \"PPLA2\",\n",
    "                \"PPLA3\",\n",
    "                \"PPLA4\",\n",
    "                \"PPLC\",\n",
    "                \"PPLF\",\n",
    "                \"PPLG\",\n",
    "                \"PPLR\",\n",
    "                \"PPLS\",\n",
    "            ],\n",
    "            \"min_population\": 0,\n",
    "            \"base_score\": 0.6,\n",
    "            \"pop_weight\": 0.7,\n",
    "            \"feature_weight\": 0.3,\n",
    "        },\n",
    "        \"landmarks\": {\n",
    "            \"codes\": [\n",
    "                \"CSTL\",\n",
    "                \"MNMT\",\n",
    "                \"RUIN\",\n",
    "                \"TOWR\",\n",
    "                \"ARCH\",\n",
    "                \"HSTS\",\n",
    "                \"CAVE\",\n",
    "                \"ANS\",\n",
    "                \"THTR\",\n",
    "                \"AMTH\",\n",
    "                \"MUS\",\n",
    "                \"LIBR\",\n",
    "                \"OPRA\",\n",
    "                \"PAL\",\n",
    "                \"PGDA\",\n",
    "                \"TMPL\",\n",
    "                \"SHRN\",\n",
    "                \"CH\",\n",
    "                \"MSQE\",\n",
    "                \"SYG\",\n",
    "                \"CVNT\",\n",
    "                \"MTRO\",\n",
    "                \"AIRP\",\n",
    "                \"PRT\",\n",
    "                \"RSTN\",\n",
    "                \"BUSTN\",\n",
    "                \"MAR\",\n",
    "            ],\n",
    "            \"min_population\": 0,\n",
    "            \"base_score\": 0.4,\n",
    "            \"pop_weight\": 0.3,\n",
    "            \"feature_weight\": 0.7,\n",
    "        },\n",
    "        \"natural_features\": {\n",
    "            \"codes\": [\n",
    "                \"MT\",\n",
    "                \"PK\",\n",
    "                \"PASS\",\n",
    "                \"VLC\",\n",
    "                \"ISL\",\n",
    "                \"BCH\",\n",
    "                \"BAY\",\n",
    "                \"CAPE\",\n",
    "                \"LK\",\n",
    "                \"FLLS\",\n",
    "                \"CNYN\",\n",
    "                \"VAL\",\n",
    "                \"DSRT\",\n",
    "                \"GLCR\",\n",
    "                \"RSV\",\n",
    "            ],\n",
    "            \"min_population\": 0,\n",
    "            \"base_score\": 0.3,\n",
    "            \"pop_weight\": 0.2,\n",
    "            \"feature_weight\": 0.8,\n",
    "        },\n",
    "        \"facilities\": {\n",
    "            \"codes\": [\n",
    "                \"HTL\",\n",
    "                \"RSRT\",\n",
    "                \"MALL\",\n",
    "                \"MKT\",\n",
    "                \"SCH\",\n",
    "                \"UNIV\",\n",
    "                \"HSP\",\n",
    "                \"ZOO\",\n",
    "                \"STDM\",\n",
    "                \"PRK\",\n",
    "                \"RECG\",\n",
    "                \"RECR\",\n",
    "                \"SPA\",\n",
    "                \"ATHF\",\n",
    "                \"ASYL\",\n",
    "            ],\n",
    "            \"min_population\": 0,\n",
    "            \"base_score\": 0.2,\n",
    "            \"pop_weight\": 0.5,\n",
    "            \"feature_weight\": 0.5,\n",
    "        },\n",
    "        \"infrastructure\": {\n",
    "            \"codes\": [\n",
    "                \"BDG\",\n",
    "                \"DAM\",\n",
    "                \"LOCK\",\n",
    "                \"LTHSE\",\n",
    "                \"BRKW\",\n",
    "                \"PIER\",\n",
    "                \"QUAY\",\n",
    "                \"PRMN\",\n",
    "                \"OILR\",\n",
    "                \"PS\",\n",
    "                \"PSH\",\n",
    "                \"PSN\",\n",
    "                \"CTRM\",\n",
    "                \"CTRF\",\n",
    "            ],\n",
    "            \"min_population\": 0,\n",
    "            \"base_score\": 0.15,\n",
    "            \"pop_weight\": 0.3,\n",
    "            \"feature_weight\": 0.7,\n",
    "        },\n",
    "        \"government\": {\n",
    "            \"codes\": [\n",
    "                \"ADMF\",\n",
    "                \"GOVL\",\n",
    "                \"CTHSE\",\n",
    "                \"DIP\",\n",
    "                \"BANK\",\n",
    "                \"PO\",\n",
    "                \"PP\",\n",
    "                \"CSTM\",\n",
    "                \"SCHC\",\n",
    "                \"MILB\",\n",
    "                \"INSM\",\n",
    "            ],\n",
    "            \"min_population\": 0,\n",
    "            \"base_score\": 0.25,\n",
    "            \"pop_weight\": 0.4,\n",
    "            \"feature_weight\": 0.6,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Process each category with improved scoring\n",
    "    for category, config in feature_categories.items():\n",
    "        logger.info(f\"Processing {category} features...\")\n",
    "\n",
    "        feature_codes = \"', '\".join(config[\"codes\"])\n",
    "\n",
    "        calculation = f\"\"\"\n",
    "        {config[\"base_score\"]} +\n",
    "                    (\n",
    "                        CASE\n",
    "                            WHEN a.population > 10000000 THEN 0.4\n",
    "                            WHEN a.population > 1000000 THEN 0.35\n",
    "                            WHEN a.population > 100000 THEN 0.3\n",
    "                            WHEN a.population > 10000 THEN 0.25\n",
    "                            WHEN a.population > 1000 THEN 0.2\n",
    "                            WHEN a.population > 100 THEN 0.15\n",
    "                            WHEN a.population > 0 THEN 0.1\n",
    "                            ELSE 0.05\n",
    "                        END * {config[\"pop_weight\"]}\n",
    "                        +\n",
    "                        CASE\n",
    "                            WHEN a.feature_code IN ('PPLC', 'CSTL', 'MNMT') THEN 0.4\n",
    "                            WHEN a.feature_code IN ('AIRP', 'TOWR', 'MUS', 'RUIN', 'PAL', 'PGDA') THEN 0.35\n",
    "                            WHEN a.feature_code IN ('UNIV', 'PPLA', 'RSTN', 'MAR', 'HTL') THEN 0.3\n",
    "                            WHEN a.feature_code IN ('MT', 'PK', 'VLC', 'ISL', 'BCH') THEN 0.25\n",
    "                            WHEN a.feature_code IN ('CH', 'HSP', 'SCH', 'THTR', 'STDM') THEN 0.2\n",
    "                            ELSE 0.1\n",
    "                        END * {config[\"feature_weight\"]}\n",
    "                        +\n",
    "                        CASE\n",
    "                            WHEN LENGTH(a.alternatenames) > 1000 THEN 0.2\n",
    "                            WHEN LENGTH(a.alternatenames) > 500 THEN 0.15\n",
    "                            WHEN LENGTH(a.alternatenames) > 100 THEN 0.1\n",
    "                            WHEN LENGTH(a.alternatenames) > 0 THEN 0.05\n",
    "                            ELSE 0\n",
    "                        END * 0.2\n",
    "                    )\"\"\"\n",
    "\n",
    "        insert_query = f\"\"\"\n",
    "        INSERT INTO places_search\n",
    "        SELECT\n",
    "            a.geonameId,\n",
    "            a.name,\n",
    "            a.asciiname,\n",
    "            a.admin0_code,\n",
    "            a.admin1_code,\n",
    "            a.admin2_code,\n",
    "            a.admin3_code,\n",
    "            a.admin4_code,\n",
    "            a.feature_class,\n",
    "            a.feature_code,\n",
    "            f.name AS feature_name,\n",
    "            a.latitude,\n",
    "            a.longitude,\n",
    "            a.population,\n",
    "            a.elevation,\n",
    "            a.alternatenames,\n",
    "            c.Country AS country_name,\n",
    "            -- More balanced importance scoring\n",
    "            {config[\"base_score\"]} +\n",
    "            (\n",
    "                -- Population component\n",
    "                CASE\n",
    "                    WHEN a.population > 10000000 THEN 0.4\n",
    "                    WHEN a.population > 1000000 THEN 0.35\n",
    "                    WHEN a.population > 100000 THEN 0.3\n",
    "                    WHEN a.population > 10000 THEN 0.25\n",
    "                    WHEN a.population > 1000 THEN 0.2\n",
    "                    WHEN a.population > 100 THEN 0.15\n",
    "                    WHEN a.population > 0 THEN 0.1\n",
    "                    ELSE 0.05\n",
    "                END * {config[\"pop_weight\"]}\n",
    "                +\n",
    "                -- Feature type component\n",
    "                CASE\n",
    "                    -- Capital cities and major landmarks\n",
    "                    WHEN a.feature_code IN ('PPLC', 'CSTL', 'MNMT') THEN 0.4\n",
    "                    -- Major tourist destinations\n",
    "                    WHEN a.feature_code IN ('AIRP', 'TOWR', 'MUS', 'RUIN', 'PAL', 'PGDA') THEN 0.35\n",
    "                    -- Important facilities\n",
    "                    WHEN a.feature_code IN ('UNIV', 'PPLA', 'RSTN', 'MAR', 'HTL') THEN 0.3\n",
    "                    -- Notable natural features\n",
    "                    WHEN a.feature_code IN ('MT', 'PK', 'VLC', 'ISL', 'BCH') THEN 0.25\n",
    "                    -- General infrastructure\n",
    "                    WHEN a.feature_code IN ('CH', 'HSP', 'SCH', 'THTR', 'STDM') THEN 0.2\n",
    "                    -- Other features\n",
    "                    ELSE 0.1\n",
    "                END * {config[\"feature_weight\"]}\n",
    "                +\n",
    "                -- Name recognition bonus (if it has many alternate names)\n",
    "                CASE\n",
    "                    WHEN LENGTH(a.alternatenames) > 1000 THEN 0.2\n",
    "                    WHEN LENGTH(a.alternatenames) > 500 THEN 0.15\n",
    "                    WHEN LENGTH(a.alternatenames) > 100 THEN 0.1\n",
    "                    WHEN LENGTH(a.alternatenames) > 0 THEN 0.05\n",
    "                    ELSE 0\n",
    "                END * 0.2\n",
    "            ) AS importance_score,\n",
    "            -- Calculate tier directly during insert\n",
    "            CASE\n",
    "                WHEN (\n",
    "                    {calculation}\n",
    "\n",
    "                ) >= 0.8 THEN 1  -- Top tier\n",
    "                WHEN ({calculation}) >= 0.6 THEN 2  -- High importance\n",
    "                WHEN ({calculation}) >= 0.4 THEN 3  -- Medium importance\n",
    "                WHEN ({calculation}) >= 0.2 THEN 4  -- Low importance\n",
    "                ELSE 5  -- Minimal importance\n",
    "            END AS importance_tier\n",
    "        FROM\n",
    "            allCountries a\n",
    "        LEFT JOIN\n",
    "            featureCodes f ON a.feature_class || '.' || a.feature_code = f.code\n",
    "        LEFT JOIN\n",
    "            countryInfo c ON a.admin0_code = c.ISO\n",
    "        WHERE\n",
    "            a.feature_code IN ('{feature_codes}')\n",
    "            AND a.population >= {config[\"min_population\"]}\n",
    "            AND a.admin0_code IS NOT NULL\n",
    "            AND NOT EXISTS (\n",
    "                SELECT 1 FROM admin_search\n",
    "                WHERE admin_search.geonameId = a.geonameId\n",
    "            )\n",
    "        \"\"\"\n",
    "        # Execute the query to insert data and get the number of rows added\n",
    "        count = con.execute(insert_query).fetchone()[0]\n",
    "        logger.debug(f\"Added {count} {category} features\")\n",
    "\n",
    "    # Add remaining features\n",
    "    logger.info(\"Adding remaining features with low importance...\")\n",
    "\n",
    "    processed_codes = []\n",
    "    for config in feature_categories.values():\n",
    "        processed_codes.extend(config[\"codes\"])\n",
    "\n",
    "    insert_remaining_query = f\"\"\"\n",
    "    INSERT INTO places_search\n",
    "    SELECT\n",
    "        a.geonameId,\n",
    "        a.name,\n",
    "        a.asciiname,\n",
    "        a.admin0_code,\n",
    "        a.admin1_code,\n",
    "        a.admin2_code,\n",
    "        a.admin3_code,\n",
    "        a.admin4_code,\n",
    "        a.feature_class,\n",
    "        a.feature_code,\n",
    "        f.name AS feature_name,\n",
    "        a.latitude,\n",
    "        a.longitude,\n",
    "        a.population,\n",
    "        a.elevation,\n",
    "        a.alternatenames,\n",
    "        c.Country AS country_name,\n",
    "        -- Base score for remaining features\n",
    "        0.1 +\n",
    "        CASE\n",
    "            WHEN a.population > 0 THEN LOG10(a.population) / 20\n",
    "            ELSE 0\n",
    "        END +\n",
    "        CASE\n",
    "            WHEN LENGTH(a.alternatenames) > 0 THEN 0.05\n",
    "            ELSE 0\n",
    "        END AS importance_score,\n",
    "        -- Calculate tier\n",
    "        CASE\n",
    "            WHEN (0.1 + CASE WHEN a.population > 0 THEN LOG10(a.population) / 20 ELSE 0 END) >= 0.2 THEN 4\n",
    "            ELSE 5\n",
    "        END AS importance_tier\n",
    "    FROM\n",
    "        allCountries a\n",
    "    LEFT JOIN\n",
    "        featureCodes f ON a.feature_class || '.' || a.feature_code = f.code\n",
    "    LEFT JOIN\n",
    "        countryInfo c ON a.admin0_code = c.ISO\n",
    "    WHERE\n",
    "        a.feature_code NOT IN ('{\"', '\".join(processed_codes)}')\n",
    "        AND NOT (a.feature_code LIKE 'ADM%' OR a.feature_code LIKE 'PCL%')\n",
    "        AND a.admin0_code IS NOT NULL\n",
    "        AND a.feature_class IN ('P', 'S', 'T', 'H', 'L', 'V', 'R')\n",
    "        AND a.name IS NOT NULL AND a.name != ''\n",
    "    \"\"\"\n",
    "\n",
    "    count = con.execute(insert_remaining_query).fetchone()[0]\n",
    "    logger.debug(f\"Added {count} remaining features with low importance\")\n",
    "\n",
    "    # Create FTS index\n",
    "    logger.debug(\"Creating FTS index for places_search table...\")\n",
    "    con.execute(\"\"\"\n",
    "    PRAGMA create_fts_index(\n",
    "        places_search,\n",
    "        geonameId,\n",
    "        name, asciiname, alternatenames,\n",
    "        stemmer = 'none',\n",
    "        stopwords = 'none',\n",
    "        ignore = '(\\\\.|[^a-z0-9])+',\n",
    "        overwrite = 1\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    # Update statistics\n",
    "    con.execute(\"VACUUM ANALYZE;\")\n",
    "\n",
    "    # Show tier distribution\n",
    "    tier_dist = con.execute(\"\"\"\n",
    "        SELECT importance_tier, COUNT(*) as count\n",
    "        FROM places_search\n",
    "        GROUP BY importance_tier\n",
    "        ORDER BY importance_tier\n",
    "    \"\"\").pl()\n",
    "\n",
    "    logger.info(\"Importance tier distribution:\")\n",
    "    for row in tier_dist.iter_rows(named=True):\n",
    "        logger.info(f\"  Tier {row['importance_tier']}: {row['count']:,} features\")\n",
    "\n",
    "    logger.debug(\"Writing places_search table to parquet...\")\n",
    "    con.table(\"places_search\").pl().write_parquet(\n",
    "        \"./data/processed/geonames/places_search.parquet\",\n",
    "        partition_by=[\"importance_tier\"],\n",
    "    )\n",
    "    logger.debug(\"Saved places_search table to parquet file\")\n",
    "\n",
    "\n",
    "build_places_search_table(con, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()\n",
    "\n",
    "con = duckdb.connect(database=duck_db_path.as_posix(), read_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The idea here is now we want to have a more flexible search function.\n",
    "# As we have done above we have have created one big admin_search table, where the core idea of that is to allow us to search over multiple admin levels at once.\n",
    "# This will enable us to have two types of searches:\n",
    "# 1. Search for a specific admin level (e.g. admin1, admin2, etc.) and return results for that level.\n",
    "#   - This is useful when we want to find specific entities at a certain level.\n",
    "#   - It will take in a list of exactly length 5 that contains str or None for each admin level.\n",
    "#   - We can search for the exact level we want and return results for that level.\n",
    "# 2. Search for a term that is more flexible where you may not know what the exact level is.\n",
    "#   - This is useful when we want to find entities that match a term but may not know the exact level.\n",
    "#   - It will take in a list of potentially variable sizes (up to 5) that contains str only. The idea is that its essentially a window function and can sort of map it to the structured input of before.\n",
    "#      - Lets say we have a flexible the input of [A, B, C] where we are unsure of the level for each of the inputs. What we get is esentially a window function we are able to search over.\n",
    "#      - That input could be mapped to the structured input of [A, B, C, None, None] or [None, A, B, C, None] or [None, None, A, B, C], [A, None, B, None, C] etc. (and so on).\n",
    "#      - But we know that for 'A' there are three possible levels for it, so we can search over all of these levels (e.g. admin0, admin1, admin2) and return the results for that level. 'B' could be admin1, admin2, admin3 and so on. The idea is that we can use the number of terms that we have / that aren't None to determine the levels we want to search over.\n",
    "#   - This means that we need to be able to search over multiple levels at once and return results for all of them.\n",
    "#   - Once we have the results we can try and filter the next level based on the previous results.\n",
    "#   - Due to the nature of the flexible search it may not filter down nicely as the structured search, but we can try to filter it down as accurately as possible.\n",
    "\n",
    "\n",
    "def get_latest_adjusted_score_level(columns: list[str]) -> int | None:\n",
    "    adjusted_score_columns = [\n",
    "        col for col in columns if col.startswith(\"adjusted_score_\")\n",
    "    ]\n",
    "    if not adjusted_score_columns:\n",
    "        return None\n",
    "    # Extract the level from the column name and find the maximum level\n",
    "    levels = [int(col.rsplit(\"_\", maxsplit=1)[-1]) for col in adjusted_score_columns]\n",
    "    max_level = max(levels)\n",
    "    return max_level\n",
    "\n",
    "\n",
    "def search_score_admin(\n",
    "    df: pl.LazyFrame,\n",
    "    level: int,\n",
    "    text_weight: float = 0.35,\n",
    "    pop_weight: float = 0.35,\n",
    "    feature_weight: float = 0.15,\n",
    "    parent_weight: float = 0.15,\n",
    "    search_term: str | None = None,\n",
    ") -> pl.LazyFrame:\n",
    "    \"\"\"\n",
    "    A scoring function for geographic entities that better prioritizes\n",
    "    significant locations.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame with search results\n",
    "    - level: Admin level (0=country, 1=admin1, etc.)\n",
    "    - text_weight: Weight for text matching score\n",
    "    - pop_weight: Weight for population-based importance\n",
    "    - feature_weight: Weight for feature type significance\n",
    "    - parent_weight: Weight for parent entity scores\n",
    "    - search_term: Original search term (for exact match detection)\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with adjusted scores\n",
    "    \"\"\"\n",
    "    assert level in range(5), \"Level must be between 0 and 4\"\n",
    "    score_col = f\"adjusted_score_{level}\"\n",
    "    columns = df.collect_schema().names()\n",
    "\n",
    "    # ===== 1. Text relevance score =====\n",
    "    fts_column = f\"fts_score_{level}\"\n",
    "    if \"fts_score\" in columns:\n",
    "        df = df.rename({\"fts_score\": fts_column})\n",
    "\n",
    "        df = df.with_columns(\n",
    "            # Calculate z-score\n",
    "            z_score=(\n",
    "                (pl.col(fts_column) - pl.col(fts_column).mean())\n",
    "                / pl.when(pl.col(fts_column).std() > 0)\n",
    "                .then(pl.col(fts_column).std())\n",
    "                .otherwise(1.0)\n",
    "            ),\n",
    "        ).with_columns(\n",
    "            # Apply sigmoid transformation: 1/(1+e^(-z))\n",
    "            text_score=(1 / (1 + pl.col.z_score.mul(-1.5).exp()))\n",
    "        )\n",
    "        if search_term:\n",
    "            df = df.with_columns(\n",
    "                text_score=pl.when(\n",
    "                    pl.col.name.str.to_lowercase() == search_term.lower()\n",
    "                )\n",
    "                .then(1)\n",
    "                .otherwise(pl.col.text_score)\n",
    "                .clip(0, 1)\n",
    "            )\n",
    "    else:\n",
    "        logger.warning(\n",
    "            f\"Column '{fts_column}' not found in DataFrame. Skipping Z-score normalization.\"\n",
    "        )\n",
    "        df = df.with_columns(text_score=pl.lit(0.5))\n",
    "\n",
    "    # ===== 2. Population importance - stronger scaling =====\n",
    "    pop_col = \"population\"\n",
    "    if pop_col in columns:\n",
    "        df = df.with_columns(\n",
    "            # Sigmoid normalized population factor\n",
    "            pop_score=pl.when(pl.col(pop_col) > 0)\n",
    "            .then(\n",
    "                (\n",
    "                    # Stronger population scaling using logarithmic curve\n",
    "                    1 - 1 / (1 + (pl.col(pop_col).log10() / 3))\n",
    "                )\n",
    "            )\n",
    "            .otherwise(0.1)\n",
    "        )\n",
    "    else:\n",
    "        logger.warning(\n",
    "            f\"Column '{pop_col}' not found in DataFrame. Skipping population factor.\"\n",
    "        )\n",
    "        df = df.with_columns(pop_score=pl.lit(0.3))\n",
    "\n",
    "    # ===== 3. Feature type importance =====\n",
    "    feature_col = \"feature_code\"\n",
    "    if feature_col in columns:\n",
    "        df = df.with_columns(\n",
    "            # More nuanced feature type scoring based on importance\n",
    "            feature_score=pl.when(pl.col(feature_col) == \"PCLI\")\n",
    "            .then(1.0)  # Independent countries\n",
    "            .when(pl.col(feature_col).str.starts_with(\"PCL\"))\n",
    "            .then(0.9)  # Other country-like entities\n",
    "            .when(pl.col(feature_col) == \"PPLC\")\n",
    "            .then(0.95)  # Capital cities\n",
    "            .when(pl.col(feature_col).str.starts_with(\"PPL\"))\n",
    "            .then(0.8)  # Major populated places\n",
    "            .when(pl.col(feature_col).str.starts_with(\"ADM1\"))\n",
    "            .then(0.85)  # First-level admin (provinces/states)\n",
    "            .when(pl.col(feature_col).str.starts_with(\"ADM2\"))\n",
    "            .then(0.75)  # Second-level admin (counties)\n",
    "            .when(pl.col(feature_col).str.starts_with(\"ADM3\"))\n",
    "            .then(0.65)  # Third-level admin (districts)\n",
    "            .when(pl.col(feature_col).str.starts_with(\"ADM\"))\n",
    "            .then(0.55)  # Other admin units\n",
    "            .otherwise(0.5)\n",
    "        )\n",
    "    else:\n",
    "        logger.warning(\n",
    "            f\"Column '{feature_col}' not found in DataFrame. Skipping feature factor.\"\n",
    "        )\n",
    "        df = df.with_columns(feature_score=pl.lit(0.5))\n",
    "\n",
    "    # ===== 4. Country/region prominence - prioritize major countries =====\n",
    "    country_col = \"admin0_code\"\n",
    "    if country_col in columns:\n",
    "        # List of major countries to prioritize\n",
    "        major_countries = [\n",
    "            \"US\",\n",
    "            \"GB\",\n",
    "            \"DE\",\n",
    "            \"FR\",\n",
    "            \"JP\",\n",
    "            \"CN\",\n",
    "            \"IN\",\n",
    "            \"BR\",\n",
    "            \"RU\",\n",
    "            \"CA\",\n",
    "            \"AU\",\n",
    "        ]\n",
    "        df = df.with_columns(\n",
    "            country_score=pl.when(pl.col(country_col).is_in(major_countries))\n",
    "            .then(0.8)  # Major countries\n",
    "            .otherwise(0.5)  # Other countries\n",
    "        )\n",
    "    else:\n",
    "        df = df.with_columns(country_score=pl.lit(0.5))\n",
    "\n",
    "    parent_score_cols_exist = any(\n",
    "        col.startswith(\"parent_adjusted_score_\") for col in df.collect_schema().names()\n",
    "    )\n",
    "\n",
    "    if parent_score_cols_exist:\n",
    "        df = df.with_columns(\n",
    "            # Calculate mean of all parent_adjusted_score_ columns for the row.\n",
    "            # fill_null(0.0) handles cases where a row has no matching parent scores\n",
    "            # or a specific linkage didn't yield scores.\n",
    "            average_parent_score=pl.mean_horizontal(cs.starts_with(\"parent_adjusted_score_\")).fill_null(0.0)\n",
    "        )\n",
    "        # Normalize this average_parent_score across the entire DataFrame (current batch)\n",
    "        # Add a small epsilon to avoid division by zero if all average_parent_scores are 0.\n",
    "        # Max is calculated over a dummy literal column to get the max over the whole frame partition.\n",
    "        df = df.with_columns(\n",
    "            parent_max_score_overall = pl.col.average_parent_score.max().over(pl.lit(1)) # Max of averages\n",
    "        ).with_columns(\n",
    "            parent_factor=pl.when(pl.col.parent_max_score_overall > 1e-9)\n",
    "            .then(pl.col.average_parent_score / (pl.col.parent_max_score_overall + 1e-9) )\n",
    "            .otherwise(0.5) # Default if all parent scores are zero or no parent scores\n",
    "            .clip(0.0, 1.0) # Ensure it's strictly within [0,1]\n",
    "        ).drop(\"parent_max_score_overall\")\n",
    "    else:\n",
    "        # This case handles when results_with_potential_parents had no parent_adjusted_score_ columns\n",
    "        # (e.g., no previous_results or no successful joins in the loop)\n",
    "        logger.warning(\"No parent_adjusted_score_ columns found. Skipping parent factor.\")\n",
    "        df = df.with_columns(parent_factor=pl.lit(0.5))\n",
    "\n",
    "#     if get_latest_adjusted_score_level(columns) is not None:\n",
    "#         df = df.with_columns(\n",
    "#             average_parent_score=pl.mean_horizontal(cs.starts_with(\"adjusted_score_\"))\n",
    "#         ).with_columns(\n",
    "#             parent_factor=pl.when(pl.col.average_parent_score > 0)\n",
    "#             .then(pl.col.average_parent_score / pl.col.average_parent_score.max())\n",
    "#             .otherwise(0.5)\n",
    "#         )\n",
    "\n",
    "#     else:\n",
    "#         logger.warning(\"No parent score column found. Skipping parent factor.\")\n",
    "#         df = df.with_columns(parent_factor=pl.lit(0.5))\n",
    "\n",
    "    # ===== 6. Final score calculation =====\n",
    "    # Base score calculation\n",
    "    df = df.with_columns(\n",
    "        (\n",
    "            pl.col(\"text_score\").mul(text_weight)\n",
    "            + pl.col(\"pop_score\").mul(pop_weight)\n",
    "            + pl.col(\"feature_score\").mul(feature_weight)\n",
    "            + pl.col(\"parent_factor\").mul(parent_weight)\n",
    "        ).alias(\"base_score\")\n",
    "    )\n",
    "\n",
    "    # Apply country prominence boost to the final score\n",
    "    df = df.with_columns(\n",
    "        (pl.col(\"base_score\") * (0.7 + (0.3 * pl.col(\"country_score\")))).alias(\n",
    "            score_col\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # For debugging, keep all intermediate scores\n",
    "    return df.sort(score_col, descending=True)\n",
    "\n",
    "\n",
    "def build_path_conditions(df: pl.DataFrame, admin_cols: list[str]) -> str:\n",
    "    \"\"\"\n",
    "    Build SQL conditions by scanning backwards to find the last non-null value.\n",
    "    \"\"\"\n",
    "    if not admin_cols or df.is_empty():\n",
    "        return \"\"\n",
    "\n",
    "    # Extract relevant columns and filter out all-null rows\n",
    "    paths_df = (\n",
    "        df.select(admin_cols).filter(~pl.all_horizontal(pl.all().is_null())).unique()\n",
    "    )\n",
    "\n",
    "    path_conditions = []\n",
    "    for row in paths_df.iter_rows(named=True):\n",
    "        # Scan backward to find the last non-null column\n",
    "        last_non_null_idx = -1\n",
    "        for idx in range(len(admin_cols) - 1, -1, -1):\n",
    "            if row[admin_cols[idx]] is not None:\n",
    "                last_non_null_idx = idx\n",
    "                break\n",
    "\n",
    "        if last_non_null_idx == -1:\n",
    "            continue  # Skip rows with all nulls\n",
    "\n",
    "        # Build conditions up through the last non-null column\n",
    "        conditions = []\n",
    "        for idx in range(last_non_null_idx + 1):\n",
    "            col = admin_cols[idx]\n",
    "            val = row[col]\n",
    "            if val is None:\n",
    "                conditions.append(f\"{col} IS NULL\")\n",
    "            else:\n",
    "                conditions.append(f\"{col} = '{val}'\")\n",
    "\n",
    "        path_conditions.append(f\"({' AND '.join(conditions)})\")\n",
    "\n",
    "    return \" OR \".join(path_conditions)\n",
    "\n",
    "\n",
    "def search_admin(\n",
    "    term: str,\n",
    "    levels: list[int] | int,\n",
    "    con: DuckDBPyConnection,\n",
    "    previous_results: pl.DataFrame | None = None,\n",
    "    limit: int = 100,\n",
    "    all_cols: bool = False,\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Search for admin entities across one or multiple admin levels with path-aware filtering.\n",
    "\n",
    "    Parameters:\n",
    "    - term: The search term to look for\n",
    "    - levels: A list of admin levels to search over (0-4) or a single level\n",
    "    - con: The DuckDB connection object\n",
    "    - previous_results: Previous search results to filter against\n",
    "    - limit: The maximum number of results to return\n",
    "\n",
    "    Returns:\n",
    "    - A DataFrame with the search results\n",
    "    \"\"\"\n",
    "    # Normalize levels to a list\n",
    "    if isinstance(levels, int):\n",
    "        levels = [levels]\n",
    "    elif not isinstance(levels, list):\n",
    "        raise ValueError(\"Levels must be an integer or a list of integers\")\n",
    "\n",
    "    # Validate levels\n",
    "    if not all(0 <= level <= 4 for level in levels):\n",
    "        raise ValueError(\"All levels must be between 0 and 4\")\n",
    "\n",
    "    # Build level constraint\n",
    "    level_conditions = \" OR \".join([f\"admin_level = {level}\" for level in levels])\n",
    "    where_clauses = [f\"({level_conditions})\"]\n",
    "\n",
    "    # Special handling for country (admin_level = 0) exact matches\n",
    "    has_country_level = 0 in levels\n",
    "    country_exact_matches = None\n",
    "\n",
    "    select_cols_list: list[str] = (\n",
    "        [\n",
    "            \"geonameId\",\n",
    "            \"name\",\n",
    "            \"asciiname\",\n",
    "            \"admin0_code\",\n",
    "            \"admin1_code\",\n",
    "            \"admin2_code\",\n",
    "            \"admin3_code\",\n",
    "            \"admin4_code\",\n",
    "            \"feature_class\",\n",
    "            \"feature_code\",\n",
    "            \"population\",\n",
    "            \"latitude\",\n",
    "            \"longitude\",\n",
    "        ]\n",
    "        if not all_cols\n",
    "        else [\"*\"]\n",
    "    )\n",
    "\n",
    "    if has_country_level and len(term) <= 3:\n",
    "        # If the term is short (<= 3 characters), we can assume it's a country code\n",
    "        # First try exact matches for country codes\n",
    "        exact_match_query = f\"\"\"\n",
    "        SELECT {\", \".join(select_cols_list)},\n",
    "        -- High fixed score for exact matches\n",
    "        CASE\n",
    "            WHEN LOWER(ISO) = LOWER($term) THEN 10.0\n",
    "            WHEN LOWER(ISO3) = LOWER($term) THEN 8.0\n",
    "            WHEN LOWER(fips) = LOWER($term) THEN 4.0\n",
    "        END AS fts_score\n",
    "        FROM admin_search\n",
    "        WHERE admin_level = 0 AND (\n",
    "            LOWER(ISO) = LOWER($term) OR\n",
    "            LOWER(ISO3) = LOWER($term) OR\n",
    "            LOWER(fips) = LOWER($term)\n",
    "        )\n",
    "        \"\"\"\n",
    "\n",
    "        country_exact_matches = con.execute(exact_match_query, {\"term\": term}).pl()\n",
    "\n",
    "        # If we found exact matches, exclude these from the FTS search\n",
    "        if not country_exact_matches.is_empty():\n",
    "            country_ids = country_exact_matches[\"geonameId\"].to_list()\n",
    "            where_clauses.append(\n",
    "                f\"(admin_level != 0 OR geonameId NOT IN ({','.join(map(str, country_ids))}))\"\n",
    "            )\n",
    "\n",
    "    admin_cols = []\n",
    "    # Build path filtering from previous results\n",
    "    if previous_results is not None and not previous_results.is_empty():\n",
    "        # Determine which admin code columns to use based on the previous results\n",
    "        for i in range(5):\n",
    "            col = f\"admin{i}_code\"\n",
    "            if (\n",
    "                col in previous_results.columns\n",
    "                and previous_results[col].drop_nulls().shape[0] > 0\n",
    "            ):\n",
    "                admin_cols.append(col)\n",
    "\n",
    "        # Build path conditions using the admin code columns\n",
    "        if admin_cols:\n",
    "            path_conditions = build_path_conditions(previous_results, admin_cols)\n",
    "            if path_conditions:\n",
    "                where_clauses.append(f\"({path_conditions})\")\n",
    "\n",
    "    # Build the WHERE clause\n",
    "    where_clause = \" AND \".join(where_clauses)\n",
    "\n",
    "    # Build and execute the FTS search\n",
    "    fts_query = f\"\"\"\n",
    "\n",
    "    WITH filtered_results AS (\n",
    "        SELECT {\",\".join(select_cols_list)}, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
    "        FROM admin_search\n",
    "        WHERE {where_clause}\n",
    "    )\n",
    "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
    "    SELECT * FROM filtered_results\n",
    "    WHERE fts_score IS NOT NULL\n",
    "    ORDER BY fts_score DESC\n",
    "    LIMIT $limit\n",
    "    \"\"\"\n",
    "    logger.debug(f\"Executing FTS query: {fts_query}\")\n",
    "    fts_results = con.execute(fts_query, {\"term\": term, \"limit\": limit * 2}).pl()\n",
    "\n",
    "    # Combine exact matches with FTS results if we had exact matches\n",
    "    if country_exact_matches is not None and not country_exact_matches.is_empty():\n",
    "        # Ensure both have the same columns\n",
    "        if not fts_results.is_empty():\n",
    "            # Dont need this any more.\n",
    "            # Make sure both have the same columns in the same order\n",
    "            # all_columns = list(\n",
    "            #     set(country_exact_matches.columns).union(set(fts_results.columns))\n",
    "            # )\n",
    "\n",
    "            # Add any missing columns with None values\n",
    "            # for col in all_columns:\n",
    "            #     if col not in country_exact_matches.columns:\n",
    "            #         country_exact_matches = country_exact_matches.with_columns(\n",
    "            #             pl.lit(None).alias(col)\n",
    "            #         )\n",
    "            #     if col not in fts_results.columns:\n",
    "            #         fts_results = fts_results.with_columns(pl.lit(None).alias(col))\n",
    "\n",
    "            # Combine and sort by score\n",
    "            results = pl.concat(\n",
    "                [country_exact_matches.lazy(), fts_results.lazy()],\n",
    "                how=\"vertical_relaxed\",\n",
    "            )\n",
    "            results = results.sort(\"fts_score\", descending=True)\n",
    "        else:\n",
    "            # If no FTS results, just use exact matches\n",
    "            results = country_exact_matches.lazy()\n",
    "    else:\n",
    "        # Just use FTS results\n",
    "        results = fts_results.lazy()\n",
    "\n",
    "    # Trying to get the adjusted scores from the previous results working with the flexible search. The issue is that we need to be able to join the previous results with the current results based on the admin codes. (Tracking the path back is much harder than when doing hierarchical search, as there are potentially multiple paths to the same entity. Unsure how to do this yet. )\n",
    "    logger.info(admin_cols)\n",
    "    if previous_results is not None and not previous_results.is_empty():\n",
    "        previous_scores_df = previous_results.lazy()\n",
    "        # Rename score columns from previous_results to mark them as parent scores\n",
    "        parent_score_renames = {\n",
    "            col: f\"parent_{col}\"\n",
    "            for col in previous_results.collect_schema().names()\n",
    "            if col.startswith(\"adjusted_score_\")\n",
    "        }\n",
    "        previous_scores_df = previous_scores_df.rename(parent_score_renames)\n",
    "\n",
    "        lfs = []\n",
    "        # Iterate through increasingly specific join key sets\n",
    "        for i in range(1, len(admin_cols) + 1):\n",
    "            tmp_cols = admin_cols[:i]  # e.g., [\"admin0_code\"], then [\"admin0_code\", \"admin1_code\"]\n",
    "            # Select join keys and all parent score columns from previous_scores_df\n",
    "            selected_previous = previous_scores_df.select(\n",
    "                cs.by_name(tmp_cols), cs.starts_with(\"parent_adjusted_score_\")\n",
    "            )\n",
    "            # Join current FTS results with these selected parent scores\n",
    "            joined_lf = results.join(\n",
    "                selected_previous,\n",
    "                on=tmp_cols,\n",
    "                how=\"left\"\n",
    "            )\n",
    "            lfs.append(joined_lf)\n",
    "        if lfs:\n",
    "            # Combine all joined versions. Each geonameId might appear multiple times\n",
    "            # if it could be linked via different paths (different tmp_cols).\n",
    "            results_with_potential_parents = pl.concat(lfs, how=\"vertical\")\n",
    "        else:\n",
    "            # Should not happen if admin_cols is populated, but as a fallback\n",
    "            results_with_potential_parents = results\n",
    "            # Ensure results_with_potential_parents has a consistent schema for parent scores,\n",
    "            # even if they are all nulls here.\n",
    "            # This might be needed if search_score_admin expects parent_adjusted_score_ columns.\n",
    "            # However, the modified search_score_admin below handles their absence.\n",
    "\n",
    "    else: # No previous_results\n",
    "        results_with_potential_parents = results\n",
    "\n",
    "    # Original way that works for hierarchical search but not flexible search. Want to try and get this working for flexible search as well.\n",
    "    # For now we will just ignore any previous score when doing the flexible search as it complicates things too much.\n",
    "    # A simple way to work out if we are doing a flexible search is to check the length of the admin_cols and the length of the levels.\n",
    "    # if (\n",
    "    #     previous_results is not None and not previous_results.is_empty()\n",
    "    #     # and 1 == len(levels)\n",
    "    # ):\n",
    "    #     # Join with previous results to get adjusted scores\n",
    "    #     results = results.join(\n",
    "    #         previous_results.lazy().select(\n",
    "    #             cs.by_name(admin_cols), cs.starts_with(\"adjusted_score_\")\n",
    "    #         ),\n",
    "    #         on=admin_cols,\n",
    "    #         how=\"left\",\n",
    "    #     )\n",
    "\n",
    "    return (\n",
    "        results_with_potential_parents.pipe(search_score_admin, min(levels), search_term=term)\n",
    "        .sort(f\"adjusted_score_{min(levels)}\", descending=True)\n",
    "        # Now, for each geonameId, pick the one that got the highest score\n",
    "        # This effectively selects the \"best\" parent linkage.\n",
    "        .unique(\"geonameId\", keep=\"first\", maintain_order=True)\n",
    "        .head(limit)\n",
    "        .select(\n",
    "            # Your existing select logic\n",
    "            (cs.by_name(select_cols_list) if select_cols_list != [\"*\"] else cs.all(), # Ensure 'select' is a list of actual column names\n",
    "             cs.starts_with(\"parent_adjusted_score_\") ,# Optionally keep parent scores for debugging\n",
    "             cs.starts_with(\"adjusted_score_\"),\n",
    "            )\n",
    "            if not all_cols\n",
    "            else cs.all()\n",
    "        )\n",
    "        .collect()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = con.table(\"admin_search\").pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-07 13:56:01.335\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m390\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 0 OR admin_level = 1)\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-07 13:56:01.396\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m426\u001b[0m - \u001b[1m[]\u001b[0m\n",
      "\u001b[32m2025-05-07 13:56:01.397\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_score_admin\u001b[0m:\u001b[36m191\u001b[0m - \u001b[33m\u001b[1mNo parent_adjusted_score_ columns found. Skipping parent factor.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "a = search_admin(\"The united states of america\", [0,1], con, None, limit=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-07 14:12:17.299\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m390\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 1 OR admin_level = 2) AND ((admin0_code = 'AI' AND admin1_code = '11205396') OR (admin0_code = 'US' AND admin1_code = 'GA') OR (admin0_code = 'IN' AND admin1_code = '18') OR (admin0_code = 'IN' AND admin1_code = '39') OR (admin0_code = 'SD') OR (admin0_code = 'BR') OR (admin0_code = 'US' AND admin1_code = 'AR') OR (admin0_code = 'NL') OR (admin0_code = 'CM') OR (admin0_code = 'TZ') OR (admin0_code = 'VE') OR (admin0_code = 'US') OR (admin0_code = 'BS') OR (admin0_code = 'AI' AND admin1_code = '11205444') OR (admin0_code = 'PH') OR (admin0_code = 'AU' AND admin1_code = '04') OR (admin0_code = 'GM') OR (admin0_code = 'IN' AND admin1_code = '21') OR (admin0_code = 'PT' AND admin1_code = '23') OR (admin0_code = 'AI' AND admin1_code = '11205439'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-07 14:12:17.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m426\u001b[0m - \u001b[1m['admin0_code', 'admin1_code']\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 15)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>asciiname</th><th>admin0_code</th><th>admin1_code</th><th>admin2_code</th><th>admin3_code</th><th>admin4_code</th><th>feature_class</th><th>feature_code</th><th>population</th><th>latitude</th><th>longitude</th><th>parent_adjusted_score_0</th><th>adjusted_score_1</th></tr><tr><td>u32</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i32</td><td>f32</td><td>f32</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>5332921</td><td>&quot;California&quot;</td><td>&quot;California&quot;</td><td>&quot;US&quot;</td><td>&quot;CA&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM1&quot;</td><td>39431263</td><td>37.250221</td><td>-119.751259</td><td>0.753021</td><td>0.8257</td></tr><tr><td>6322708</td><td>&quot;Califórnia&quot;</td><td>&quot;California&quot;</td><td>&quot;BR&quot;</td><td>&quot;18&quot;</td><td>&quot;4103503&quot;</td><td>null</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM2&quot;</td><td>8069</td><td>-23.663401</td><td>-51.328239</td><td>0.550401</td><td>0.682443</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 15)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ geonameId ┆ name      ┆ asciiname ┆ admin0_co ┆ … ┆ latitude  ┆ longitude ┆ parent_ad ┆ adjusted │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ de        ┆   ┆ ---       ┆ ---       ┆ justed_sc ┆ _score_1 │\n",
       "│ u32       ┆ str       ┆ str       ┆ ---       ┆   ┆ f32       ┆ f32       ┆ ore_0     ┆ ---      │\n",
       "│           ┆           ┆           ┆ str       ┆   ┆           ┆           ┆ ---       ┆ f64      │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ f64       ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 5332921   ┆ Californi ┆ Californi ┆ US        ┆ … ┆ 37.250221 ┆ -119.7512 ┆ 0.753021  ┆ 0.8257   │\n",
       "│           ┆ a         ┆ a         ┆           ┆   ┆           ┆ 59        ┆           ┆          │\n",
       "│ 6322708   ┆ Califórni ┆ Californi ┆ BR        ┆ … ┆ -23.66340 ┆ -51.32823 ┆ 0.550401  ┆ 0.682443 │\n",
       "│           ┆ a         ┆ a         ┆           ┆   ┆ 1         ┆ 9         ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_admin(\"california\", [1,2], con, a, limit=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3_158, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>admin0_code</th><th>admin1_code</th><th>admin2_code</th></tr><tr><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;US&quot;</td><td>&quot;MT&quot;</td><td>&quot;075&quot;</td></tr><tr><td>&quot;US&quot;</td><td>&quot;MN&quot;</td><td>&quot;129&quot;</td></tr><tr><td>&quot;US&quot;</td><td>&quot;AL&quot;</td><td>&quot;079&quot;</td></tr><tr><td>&quot;US&quot;</td><td>&quot;CT&quot;</td><td>&quot;190&quot;</td></tr><tr><td>&quot;US&quot;</td><td>&quot;AL&quot;</td><td>&quot;125&quot;</td></tr><tr><td>&quot;US&quot;</td><td>&quot;ND&quot;</td><td>&quot;053&quot;</td></tr><tr><td>&quot;US&quot;</td><td>&quot;KY&quot;</td><td>&quot;199&quot;</td></tr><tr><td>&quot;US&quot;</td><td>&quot;AK&quot;</td><td>&quot;201&quot;</td></tr><tr><td>&quot;US&quot;</td><td>&quot;IL&quot;</td><td>&quot;123&quot;</td></tr><tr><td>&quot;US&quot;</td><td>&quot;GA&quot;</td><td>&quot;113&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;US&quot;</td><td>&quot;AR&quot;</td><td>&quot;019&quot;</td></tr><tr><td>&quot;US&quot;</td><td>&quot;VA&quot;</td><td>&quot;049&quot;</td></tr><tr><td>&quot;US&quot;</td><td>&quot;WI&quot;</td><td>&quot;131&quot;</td></tr><tr><td>&quot;US&quot;</td><td>&quot;OK&quot;</td><td>&quot;149&quot;</td></tr><tr><td>&quot;US&quot;</td><td>&quot;TX&quot;</td><td>&quot;337&quot;</td></tr><tr><td>&quot;US&quot;</td><td>&quot;MO&quot;</td><td>&quot;175&quot;</td></tr><tr><td>&quot;US&quot;</td><td>&quot;NC&quot;</td><td>&quot;183&quot;</td></tr><tr><td>&quot;US&quot;</td><td>&quot;TX&quot;</td><td>&quot;141&quot;</td></tr><tr><td>&quot;US&quot;</td><td>&quot;MD&quot;</td><td>&quot;011&quot;</td></tr><tr><td>&quot;US&quot;</td><td>&quot;NY&quot;</td><td>&quot;049&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3_158, 3)\n",
       "┌─────────────┬─────────────┬─────────────┐\n",
       "│ admin0_code ┆ admin1_code ┆ admin2_code │\n",
       "│ ---         ┆ ---         ┆ ---         │\n",
       "│ str         ┆ str         ┆ str         │\n",
       "╞═════════════╪═════════════╪═════════════╡\n",
       "│ US          ┆ MT          ┆ 075         │\n",
       "│ US          ┆ MN          ┆ 129         │\n",
       "│ US          ┆ AL          ┆ 079         │\n",
       "│ US          ┆ CT          ┆ 190         │\n",
       "│ US          ┆ AL          ┆ 125         │\n",
       "│ US          ┆ ND          ┆ 053         │\n",
       "│ US          ┆ KY          ┆ 199         │\n",
       "│ US          ┆ AK          ┆ 201         │\n",
       "│ US          ┆ IL          ┆ 123         │\n",
       "│ US          ┆ GA          ┆ 113         │\n",
       "│ …           ┆ …           ┆ …           │\n",
       "│ US          ┆ AR          ┆ 019         │\n",
       "│ US          ┆ VA          ┆ 049         │\n",
       "│ US          ┆ WI          ┆ 131         │\n",
       "│ US          ┆ OK          ┆ 149         │\n",
       "│ US          ┆ TX          ┆ 337         │\n",
       "│ US          ┆ MO          ┆ 175         │\n",
       "│ US          ┆ NC          ┆ 183         │\n",
       "│ US          ┆ TX          ┆ 141         │\n",
       "│ US          ┆ MD          ┆ 011         │\n",
       "│ US          ┆ NY          ┆ 049         │\n",
       "└─────────────┴─────────────┴─────────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (\n",
    "    df.filter(pl.col(\"admin_level\") == 2)\n",
    "    .filter(pl.col.admin0_code.is_in([\"US\", \"UK\"]))\n",
    "    .select(cs.exclude(\"admin_level\"))\n",
    "    .select(cs.starts_with(\"admin\"))\n",
    "    .unique()\n",
    ")\n",
    "a[[s.name for s in a if not (s.null_count() == a.height)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_score_place(\n",
    "    df: pl.LazyFrame,\n",
    "    text_weight: float = 0.35,\n",
    "    importance_weight: float = 0.30,\n",
    "    feature_weight: float = 0.15,\n",
    "    distance_weight: float = 0.1,\n",
    "    parent_admin_score_weight: float = 0.1,\n",
    "    search_term: str | None = None,\n",
    "    center_lat: float | None = None,\n",
    "    center_lon: float | None = None,\n",
    ") -> pl.LazyFrame:\n",
    "    \"\"\"\n",
    "    Score places based on multiple factors.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame with search results\n",
    "    - text_weight: Weight for text matching score\n",
    "    - importance_weight: Weight for pre-calculated importance\n",
    "    - feature_weight: Weight for feature type relevance\n",
    "    - distance_weight: Weight for geographic proximity\n",
    "    - parent_admin_score_weight: Weight for scores from parent admin entities\n",
    "    - search_term: Original search term for exact matching\n",
    "    - center_lat/lon: Center point for distance calculation\n",
    "    \"\"\"\n",
    "    score_col = \"place_score\"\n",
    "    columns = df.collect_schema().names()\n",
    "\n",
    "    # Text relevance score (FTS)\n",
    "    fts_column = \"fts_score\"\n",
    "    if fts_column in columns:\n",
    "        # Normalize FTS score\n",
    "        df = df.with_columns(\n",
    "            z_score=(\n",
    "                (pl.col(fts_column) - pl.col(fts_column).mean())\n",
    "                / pl.when(pl.col(fts_column).std() > 0)\n",
    "                .then(pl.col(fts_column).std())\n",
    "                .otherwise(1.0)\n",
    "            ),\n",
    "        ).with_columns(text_score=(1 / (1 + pl.col.z_score.mul(-1.5).exp())))\n",
    "\n",
    "        # Exact match bonus\n",
    "        if search_term:\n",
    "            df = df.with_columns(\n",
    "                text_score=pl.when(\n",
    "                    pl.col.name.str.to_lowercase() == search_term.lower()\n",
    "                )\n",
    "                .then(1)\n",
    "                .when(pl.col.name.str.to_lowercase().str.contains(search_term.lower()))\n",
    "                .then(pl.col.text_score + 0.25)\n",
    "                .otherwise(pl.col.text_score)\n",
    "                .clip(0, 1)\n",
    "            )\n",
    "    else:\n",
    "        df = df.with_columns(text_score=pl.lit(0.5))\n",
    "\n",
    "    # 2. Importance score (already normalized between 0-1)\n",
    "    if \"importance_score\" in columns:\n",
    "        df = df.with_columns(importance_norm=pl.col(\"importance_score\").clip(0, 1))\n",
    "    else:\n",
    "        df = df.with_columns(importance_norm=pl.lit(0.5))\n",
    "\n",
    "    # Feature type scoring for places\n",
    "    if \"feature_code\" in columns:\n",
    "        df = df.with_columns(\n",
    "            # Capital/admin centers\n",
    "            feature_score=pl.when(\n",
    "                pl.col(\"feature_code\").is_in(\n",
    "                    [\"PPLC\", \"PPLA\", \"PPLA2\", \"PPLA3\", \"PPLA4\"]\n",
    "                )\n",
    "            )\n",
    "            .then(1.0)\n",
    "            # Major landmarks\n",
    "            .when(pl.col(\"feature_code\").is_in([\"CSTL\", \"MNMT\", \"RUIN\", \"TOWR\"]))\n",
    "            .then(0.95)\n",
    "            # Cultural venues\n",
    "            .when(pl.col(\"feature_code\").is_in([\"MUS\", \"THTR\", \"AMTH\", \"LIBR\", \"OPRA\"]))\n",
    "            .then(0.9)\n",
    "            # Populated places\n",
    "            .when(pl.col(\"feature_code\").is_in([\"PPL\", \"PPLF\", \"PPLS\", \"PPLX\"]))\n",
    "            .then(0.85)\n",
    "            # Transportation hubs\n",
    "            .when(pl.col(\"feature_code\").is_in([\"AIRP\", \"RSTN\", \"PRT\", \"MAR\"]))\n",
    "            .then(0.8)\n",
    "            # Educational/medical/institutions\n",
    "            .when(pl.col(\"feature_code\").is_in([\"UNIV\", \"SCH\", \"HSP\", \"HTL\", \"RSRT\"]))\n",
    "            .then(0.75)\n",
    "            # Commercial\n",
    "            .when(pl.col(\"feature_code\").is_in([\"MALL\", \"MKT\"]))\n",
    "            .then(0.7)\n",
    "            # Religious sites\n",
    "            .when(pl.col(\"feature_code\").is_in([\"CH\", \"MSQE\", \"TMPL\", \"SHRN\"]))\n",
    "            .then(0.65)\n",
    "            # Natural features\n",
    "            .when(\n",
    "                pl.col(\"feature_code\").is_in(\n",
    "                    [\"MT\", \"PK\", \"VLC\", \"ISL\", \"BCH\", \"LK\", \"BAY\"]\n",
    "                )\n",
    "            )\n",
    "            .then(0.6)\n",
    "            .otherwise(0.3)\n",
    "        )\n",
    "    else:\n",
    "        df = df.with_columns(feature_score=pl.lit(0.5))\n",
    "\n",
    "        # 4. Distance score (if center point provided)\n",
    "    if (\n",
    "        center_lat is not None\n",
    "        and center_lon is not None\n",
    "        and \"latitude\" in columns\n",
    "        and \"longitude\" in columns\n",
    "    ):\n",
    "        # Haversine distance calculation\n",
    "        df = (\n",
    "            df.with_columns(\n",
    "                x=pl.struct(latitude=\"latitude\", longitude=\"longitude\"),\n",
    "                y=pl.struct(\n",
    "                    latitude=center_lat,\n",
    "                    longitude=center_lon,\n",
    "                    schema={\n",
    "                        \"latitude\": pl.Float32,\n",
    "                        \"longitude\": pl.Float32,\n",
    "                    },\n",
    "                ),\n",
    "            )\n",
    "            .with_columns(distance_km=pld.col(\"x\").dist.haversine(\"y\", unit=\"km\"))\n",
    "            .drop(\"x\", \"y\")\n",
    "            .with_columns(\n",
    "                # Convert distance to score (closer = higher score)\n",
    "                # Using exponential decay: score = e^(-distance/50)\n",
    "                distance_score=(-pl.col(\"distance_km\") / 50).exp()\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        df = df.with_columns(distance_score=pl.lit(0.5))\n",
    "\n",
    "    # 5. Parent Admin Score Factor\n",
    "    parent_score_cols_exist = any(\n",
    "        col.startswith(\"parent_adjusted_score_\") for col in df.collect_schema().names()\n",
    "    )\n",
    "    if parent_score_cols_exist:\n",
    "        df = df.with_columns(\n",
    "            # Calculate mean of all parent_adjusted_score_ columns for the row.\n",
    "            # Assumes parent scores are already normalized (0-1).\n",
    "            parent_admin_factor=pl.mean_horizontal(cs.starts_with(\"parent_adjusted_score_\")).fill_null(0.5).clip(0.0, 1.0)\n",
    "        )\n",
    "    else:\n",
    "        df = df.with_columns(parent_admin_factor=pl.lit(0.5))\n",
    "\n",
    "    df = df.with_columns(\n",
    "        (\n",
    "            pl.col(\"text_score\").mul(text_weight)\n",
    "            + pl.col(\"importance_norm\").mul(importance_weight)\n",
    "            + pl.col(\"feature_score\").mul(feature_weight)\n",
    "            + pl.col(\"distance_score\").mul(distance_weight)\n",
    "            + pl.col(\"parent_admin_factor\").mul(parent_admin_score_weight) # Added parent admin score\n",
    "        ).alias(score_col)\n",
    "    )\n",
    "    # 6. Apply tier boost (prioritize higher importance tiers)\n",
    "    if \"importance_tier\" in columns:\n",
    "        df = df.with_columns(\n",
    "            pl.col(score_col)\n",
    "            * pl.when(pl.col(\"importance_tier\") == 1)\n",
    "            .then(1.2)\n",
    "            .when(pl.col(\"importance_tier\") == 2)\n",
    "            .then(1.1)\n",
    "            .when(pl.col(\"importance_tier\") == 3)\n",
    "            .then(1.0)\n",
    "            .when(pl.col(\"importance_tier\") == 4)\n",
    "            .then(0.9)\n",
    "            .otherwise(0.8)\n",
    "            .alias(score_col)\n",
    "        )\n",
    "\n",
    "    return df.sort(score_col, descending=True)\n",
    "\n",
    "\n",
    "def search_place(\n",
    "    term: str,\n",
    "    con: DuckDBPyConnection,\n",
    "    previous_results: pl.DataFrame | None = None,\n",
    "    limit: int = 100,\n",
    "    min_importance_tier: int = 5,\n",
    "    center_lat: float | None = None,\n",
    "    center_lon: float | None = None,\n",
    "    all_cols: bool = False,\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Search for places within the places_search table.\n",
    "\n",
    "    Parameters:\n",
    "    - term: The search term for the place\n",
    "    - con: Database connection\n",
    "    - previous_results: Previous admin search results to filter by\n",
    "    - limit: Maximum number of results\n",
    "    - min_importance_tier: Minimum importance tier to include\n",
    "    - progressive_search: Whether to start with high-importance places first\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with search results\n",
    "    \"\"\"\n",
    "    logger.debug(f\"Searching for places with term: {term}\")\n",
    "\n",
    "    select_cols_place: list[str] = (\n",
    "        [\n",
    "            \"geonameId\",\n",
    "            \"name\",\n",
    "            \"asciiname\",\n",
    "            \"admin0_code\",\n",
    "            \"admin1_code\",\n",
    "            \"admin2_code\",\n",
    "            \"admin3_code\",\n",
    "            \"admin4_code\",\n",
    "            \"feature_class\",\n",
    "            \"feature_code\",\n",
    "            \"population\",\n",
    "            \"latitude\",\n",
    "            \"longitude\",\n",
    "            \"importance_score\",\n",
    "            \"importance_tier\",\n",
    "        ]\n",
    "        if not all_cols\n",
    "        else [\"*\"]\n",
    "    )\n",
    "\n",
    "    where_clauses = []\n",
    "    join_on_admin_cols = []\n",
    "    # Build path filtering from previous results\n",
    "    if previous_results is not None and not previous_results.is_empty():\n",
    "        # Determine which admin code columns to use based on the previous results\n",
    "        for i in range(5):\n",
    "            col = f\"admin{i}_code\"\n",
    "            if (\n",
    "                col in previous_results.columns\n",
    "                and previous_results[col].drop_nulls().shape[0] > 0\n",
    "            ):\n",
    "                join_on_admin_cols.append(col)\n",
    "\n",
    "        # Build path conditions using the admin code columns\n",
    "        if join_on_admin_cols:\n",
    "            path_conditions = build_path_conditions(previous_results, join_on_admin_cols)\n",
    "            if path_conditions:\n",
    "                where_clauses.append(f\"({path_conditions})\")\n",
    "    # Add importance tier condition\n",
    "    where_clauses.append(f\"importance_tier <= {min_importance_tier}\")\n",
    "\n",
    "    # Build the WHERE clause\n",
    "    where_clause = \" AND \".join(where_clauses)\n",
    "\n",
    "    # Extract center point from previous results if not provided\n",
    "    if center_lat is None and center_lon is None and previous_results is not None:\n",
    "        if (\n",
    "            \"latitude\" in previous_results.columns\n",
    "            and \"longitude\" in previous_results.columns\n",
    "            and not previous_results.select([\"latitude\", \"longitude\"]).is_empty()\n",
    "        ):\n",
    "            center_data = previous_results.select(\n",
    "                [\n",
    "                    pl.mean(\"latitude\").alias(\"center_lat\"),\n",
    "                    pl.mean(\"longitude\").alias(\"center_lon\"),\n",
    "                ]\n",
    "            ).row(0, named=True)\n",
    "            if center_data[\"center_lat\"] is not None and center_data[\"center_lon\"] is not None:\n",
    "                center_lat, center_lon = center_data[\"center_lat\"], center_data[\"center_lon\"]\n",
    "                logger.debug(\n",
    "                    f\"Using center point from previous admin results: ({center_lat}, {center_lon})\"\n",
    "                )\n",
    "\n",
    "    query = f\"\"\"\n",
    "    WITH filtered_results AS (\n",
    "        SELECT {\",\".join(select_cols_place)},\n",
    "            fts_main_places_search.match_bm25(geonameId, $term) AS fts_score\n",
    "        FROM places_search\n",
    "        WHERE {where_clause}\n",
    "    )\n",
    "    SELECT * FROM filtered_results\n",
    "    WHERE fts_score IS NOT NULL\n",
    "    ORDER BY fts_score DESC,\n",
    "        importance_score DESC\n",
    "    LIMIT $limit\n",
    "    \"\"\"\n",
    "    logger.debug(f\"Executing FTS query: {query}\")\n",
    "    results_df = con.execute(\n",
    "        query,\n",
    "        {\n",
    "            \"term\": term,\n",
    "            \"limit\": limit * 3,\n",
    "        },\n",
    "    ).pl()\n",
    "    logger.debug(f\"Found {results_df.shape[0]} results\")\n",
    "    # Return empty frame if no results\n",
    "    if results_df.is_empty():\n",
    "        return results_df\n",
    "\n",
    "    # Join with parent admin scores if available\n",
    "    if previous_results is not None and not previous_results.is_empty() and join_on_admin_cols:\n",
    "        previous_scores_df = previous_results.lazy()\n",
    "\n",
    "        parent_score_renames = {\n",
    "            col: f\"parent_{col}\"\n",
    "            for col in previous_results.collect_schema().names()\n",
    "            if col.startswith(\"adjusted_score_\")\n",
    "        }\n",
    "\n",
    "        # Select only join keys and score columns to be renamed\n",
    "        cols_to_select_from_previous = join_on_admin_cols + list(parent_score_renames.keys())\n",
    "        previous_scores_df = previous_scores_df.select(cols_to_select_from_previous).rename(parent_score_renames)\n",
    "\n",
    "        # Ensure unique admin paths from previous results before join\n",
    "        previous_scores_df = previous_scores_df.unique(subset=join_on_admin_cols, keep='first', maintain_order=False)\n",
    "\n",
    "        logger.debug(f\"Joining place results with parent admin scores on: {join_on_admin_cols}\")\n",
    "        results_df = results_df.lazy().join(\n",
    "            previous_scores_df,\n",
    "            on=join_on_admin_cols,\n",
    "            how=\"left\"\n",
    "        ).collect()\n",
    "        logger.debug(f\"Shape after joining with parent scores: {results_df.shape}\")\n",
    "    # Score and sort results\n",
    "    final_results = (\n",
    "        results_df.lazy()\n",
    "        .pipe(\n",
    "            search_score_place,\n",
    "            search_term=term,\n",
    "            center_lat=center_lat,\n",
    "            center_lon=center_lon,\n",
    "        )\n",
    "        .sort(\"place_score\", descending=True)\n",
    "        .head(limit)\n",
    "    )\n",
    "\n",
    "    # Define final columns to select\n",
    "    if not all_cols:\n",
    "        # Start with the basic place select columns\n",
    "        final_select_expressions = [cs.by_name(select_cols_place)]\n",
    "        # Add the main place_score\n",
    "        final_select_expressions.append(cs.by_name(\"place_score\"))\n",
    "        # Optionally add parent admin scores for debugging/inspection\n",
    "        final_select_expressions.append(cs.starts_with(\"parent_adjusted_score_\"))\n",
    "        # Add any intermediate scoring factors if desired (e.g., text_score, distance_score etc.)\n",
    "        # final_select_expressions.append(cs.by_name([\"text_score\", \"importance_norm\", \"feature_score\", \"distance_score\", \"parent_admin_factor\"]))\n",
    "\n",
    "        final_results = final_results.select(final_select_expressions)\n",
    "    else:\n",
    "        # If all_cols is True, select everything that has been computed\n",
    "        final_results = final_results.select(cs.all())\n",
    "\n",
    "    return final_results.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdminHierarchy(NamedTuple):\n",
    "    admin0: str | None = None\n",
    "    admin1: str | None = None\n",
    "    admin2: str | None = None\n",
    "    admin3: str | None = None\n",
    "    admin4: str | None = None\n",
    "    place: str | None = None\n",
    "\n",
    "    @classmethod\n",
    "    def from_list(cls, search_terms: list[str | None]) -> Self:\n",
    "        if len(search_terms) not in [5, 6]:\n",
    "            raise ValueError(\"Search terms must be a list of length 5 or 6\")\n",
    "        terms = search_terms + [None] if len(search_terms) == 5 else search_terms\n",
    "        return cls(*terms)\n",
    "\n",
    "    def get_admin_values(self) -> list[str | None]:\n",
    "        return [self.admin0, self.admin1, self.admin2, self.admin3, self.admin4]\n",
    "\n",
    "    def find_last_non_null_admin_index(self) -> int:\n",
    "        admin_values = self.get_admin_values()\n",
    "        return max(\n",
    "            (i for i, term in enumerate(admin_values) if term is not None), default=-1\n",
    "        )\n",
    "\n",
    "    # Removed move_last_admin_to_place as its logic is now integrated into hierarchical_search\n",
    "\n",
    "class SearchResult(TypedDict, total=False):\n",
    "    admin0: pl.DataFrame\n",
    "    admin1: pl.DataFrame\n",
    "    admin2: pl.DataFrame\n",
    "    admin3: pl.DataFrame\n",
    "    admin4: pl.DataFrame\n",
    "    place: pl.DataFrame\n",
    "\n",
    "def search_admin_hierarchy(\n",
    "    search_terms: AdminHierarchy,\n",
    "    con: DuckDBPyConnection,\n",
    "    limit: int,\n",
    "    all_cols: bool,\n",
    ") -> tuple[SearchResult, pl.DataFrame | None]:\n",
    "    \"\"\"\n",
    "    Search through the admin hierarchy levels.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (results dictionary, last successful results DataFrame)\n",
    "    \"\"\"\n",
    "    results: SearchResult = {}\n",
    "    last_results: pl.DataFrame | None = None\n",
    "\n",
    "    for admin_level, term in enumerate(search_terms.get_admin_values()):\n",
    "        if term is None:\n",
    "            continue\n",
    "\n",
    "        logger.debug(f\"Searching for term '{term}' at admin level {admin_level}\")\n",
    "\n",
    "        search_results = search_admin(\n",
    "            term, admin_level, con, last_results, limit, all_cols\n",
    "        )\n",
    "\n",
    "        if not search_results.is_empty():\n",
    "            results[f\"admin{admin_level}\"] = search_results\n",
    "            last_results = search_results\n",
    "        else:\n",
    "            logger.debug(\n",
    "                f\"No results found for term '{term}' at admin level {admin_level}\"\n",
    "            )\n",
    "\n",
    "    return results, last_results\n",
    "\n",
    "\n",
    "def place_as_admin(\n",
    "    place_term: str,\n",
    "    admin_level: int,\n",
    "    con: DuckDBPyConnection,\n",
    "    last_results: pl.DataFrame | None,\n",
    "    limit: int,\n",
    "    all_cols: bool,\n",
    ") -> pl.DataFrame | None:\n",
    "    \"\"\"\n",
    "    Try searching a place term as an admin level.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame of results if successful, None otherwise\n",
    "    \"\"\"\n",
    "    logger.debug(f\"Trying place term '{place_term}' as admin level {admin_level}\")\n",
    "\n",
    "    results = search_admin(place_term, admin_level, con, last_results, limit, all_cols)\n",
    "\n",
    "    if not results.is_empty():\n",
    "        return results\n",
    "    else:\n",
    "        logger.debug(\n",
    "            f\"No results found for place term '{place_term}' at admin level {admin_level}\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "\n",
    "def search_place_with_context(\n",
    "    place_term: str,\n",
    "    con: DuckDBPyConnection,\n",
    "    last_results: pl.DataFrame | None,\n",
    "    limit: int,\n",
    "    all_cols: bool = False,\n",
    ") -> pl.DataFrame | None:\n",
    "    \"\"\"\n",
    "    Search for a place with optional context from previous results.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame of results if successful, None otherwise\n",
    "    \"\"\"\n",
    "    logger.debug(f\"Searching for place: '{place_term}'\")\n",
    "\n",
    "    place_results = search_place(\n",
    "        place_term,\n",
    "        con,\n",
    "        previous_results=last_results,\n",
    "        limit=limit,\n",
    "        all_cols=all_cols,\n",
    "    )\n",
    "\n",
    "    if not place_results.is_empty():\n",
    "        return place_results\n",
    "    else:\n",
    "        logger.debug(f\"No place results found for '{place_term}'\")\n",
    "        return None\n",
    "\n",
    "def find_next_null_admin_level(\n",
    "    search_terms: AdminHierarchy | list[str | None],\n",
    ") -> int | None:\n",
    "    \"\"\"\n",
    "    Find the position of the first null admin level after the last non-null admin level.\n",
    "\n",
    "    Args:\n",
    "        search_terms: Either an AdminHierarchy or a list of search terms where the last element\n",
    "                     is the place term (optional in list form)\n",
    "\n",
    "    Returns:\n",
    "        The index of the first null after the last non-null admin level,\n",
    "        0 if all admin levels are null, or\n",
    "        None if there is no null position available\n",
    "\n",
    "    Examples:\n",
    "        [None, None, A, None, B, Place] -> None (no null after B)\n",
    "        [None, None, None, None, None, Place] -> 0 (all admin levels null)\n",
    "        [A, None, None, None, None, Place] -> 1 (next null after A)\n",
    "        [A, B, C, None, None, Place] -> 3 (next null after C)\n",
    "    \"\"\"\n",
    "    # Handle AdminHierarchy object\n",
    "    if isinstance(search_terms, AdminHierarchy):\n",
    "        admin_terms = [\n",
    "            search_terms.admin0,\n",
    "            search_terms.admin1,\n",
    "            search_terms.admin2,\n",
    "            search_terms.admin3,\n",
    "            search_terms.admin4,\n",
    "        ]\n",
    "    else:\n",
    "        # For list input, consider all but the last element if length is 6\n",
    "        admin_terms = search_terms[:-1] if len(search_terms) == 6 else search_terms\n",
    "    # If all admin terms are None, return 0\n",
    "    if all(term is None for term in admin_terms):\n",
    "        return 0\n",
    "    # Find the index of the last non-null admin term\n",
    "    last_non_null_idx = max(\n",
    "        (i for i, term in enumerate(admin_terms) if term is not None), default=-1\n",
    "    )\n",
    "    # Find the first null after the last non-null\n",
    "    for i in range(last_non_null_idx + 1, len(admin_terms)):\n",
    "        if admin_terms[i] is None:\n",
    "            return i\n",
    "    # If there's no null after the last non-null, return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def hierarchical_search(\n",
    "    search_terms_input: AdminHierarchy,\n",
    "    con: DuckDBPyConnection,\n",
    "    limit: int = 20,\n",
    "    all_cols: bool = False,\n",
    "    use_last_admin_as_implicit_place_if_none_given: bool = True,\n",
    "    try_place_candidate_as_admin_in_gap: bool = True,\n",
    ") -> SearchResult:\n",
    "    \"\"\"\n",
    "    Perform hierarchical geographic search across admin levels.\n",
    "\n",
    "    Args:\n",
    "        search_terms_input: AdminHierarchy containing search terms.\n",
    "        con: Database connection.\n",
    "        limit: Maximum results to return per level.\n",
    "        all_cols: Return all columns.\n",
    "        use_last_admin_as_implicit_place_if_none_given: If True and no explicit place term is given,\n",
    "            the last non-null admin term will be used as the candidate for place search and admin fallback.\n",
    "        try_place_candidate_as_admin_in_gap: If True, the place candidate term (explicit or implicit)\n",
    "            will be searched as an admin entity in the first available null admin slot\n",
    "            after the explicitly specified admin terms.\n",
    "    Returns:\n",
    "        Dictionary mapping level names to search results.\n",
    "    \"\"\"\n",
    "\n",
    "    results: SearchResult = {}\n",
    "    last_results: pl.DataFrame | None = None\n",
    "        # --- Step 1: Perform searches for explicitly provided admin terms ---\n",
    "    admin_terms_from_input = list(search_terms_input.get_admin_values())\n",
    "\n",
    "    # Create a temporary AdminHierarchy for search_admin_hierarchy, ensuring its .place is None\n",
    "    # so it only processes the adminX fields from the input.\n",
    "    temp_hierarchy_for_admin_search = AdminHierarchy(\n",
    "        admin0=admin_terms_from_input[0],\n",
    "        admin1=admin_terms_from_input[1],\n",
    "        admin2=admin_terms_from_input[2],\n",
    "        admin3=admin_terms_from_input[3],\n",
    "        admin4=admin_terms_from_input[4],\n",
    "        place=None  # Explicitly None for this stage\n",
    "    )\n",
    "\n",
    "    # search_admin_hierarchy processes admin0-admin4 from temp_hierarchy_for_admin_search\n",
    "    results, last_results_context = search_admin_hierarchy(\n",
    "        temp_hierarchy_for_admin_search, con, limit, all_cols\n",
    "    )\n",
    "\n",
    "\n",
    "    # --- Step 2: Determine the term to be used for place-related searches (place_candidate_term) ---\n",
    "    place_candidate_term = search_terms_input.place  # The explicitly provided place term\n",
    "\n",
    "    if place_candidate_term is None and use_last_admin_as_implicit_place_if_none_given:\n",
    "        # Find the last non-null term from the *input* admin levels\n",
    "        last_admin_idx = search_terms_input.find_last_non_null_admin_index()\n",
    "\n",
    "        if last_admin_idx != -1:\n",
    "            place_candidate_term = admin_terms_from_input[last_admin_idx]\n",
    "            logger.debug(\n",
    "                f\"No explicit place term. Using last admin term '{place_candidate_term}' \"\n",
    "                f\"(from input level admin{last_admin_idx}) as the place candidate.\"\n",
    "            )\n",
    "            # Note: The search for this term as an admin entity (at admin{last_admin_idx})\n",
    "            # has already been performed in Step 1.\n",
    "\n",
    "    # --- Step 3: If a place_candidate_term exists, optionally try it as an admin entity in a \"gap\" ---\n",
    "    if place_candidate_term is not None and try_place_candidate_as_admin_in_gap:\n",
    "        # A \"gap\" is a null admin level in the *original input `search_terms_input`* that occurs\n",
    "        # after the last non-null admin term specified in that input.\n",
    "        # `find_next_null_admin_level` correctly identifies this.\n",
    "        gap_admin_level = find_next_null_admin_level(search_terms_input)\n",
    "\n",
    "        if gap_admin_level is not None and gap_admin_level < 5:\n",
    "            # We try `place_candidate_term` at `gap_admin_level`.\n",
    "            # The context for this search is `last_results_context` from Step 1 (or updated if Step 1 had results).\n",
    "            logger.debug(\n",
    "                f\"Attempting to search place candidate '{place_candidate_term}' \"\n",
    "                f\"as admin level {gap_admin_level} (fallback in gap).\"\n",
    "            )\n",
    "            fallback_admin_results = place_as_admin(\n",
    "                place_candidate_term, gap_admin_level, con, last_results_context, limit, all_cols\n",
    "            )\n",
    "            if fallback_admin_results is not None and not fallback_admin_results.is_empty():\n",
    "                # This result is for the `gap_admin_level`.\n",
    "                results[f\"admin{gap_admin_level}\"] = fallback_admin_results\n",
    "                # This fallback search now becomes the latest context for the final place search.\n",
    "                last_results_context = fallback_admin_results\n",
    "\n",
    "    # --- Step 4: Perform the final search for place_candidate_term as a place ---\n",
    "    if place_candidate_term is not None:\n",
    "        logger.debug(f\"Searching for '{place_candidate_term}' as a place entity.\")\n",
    "        final_place_results = search_place_with_context(\n",
    "            place_candidate_term, con, last_results_context, limit, all_cols\n",
    "        )\n",
    "        if final_place_results is not None and not final_place_results.is_empty():\n",
    "            results[\"place\"] = final_place_results\n",
    "            # Optionally update context if further steps needed it:\n",
    "            #last_results_context = final_place_results\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "def flexible_search(\n",
    "    search_terms_raw: list[str],\n",
    "    con: DuckDBPyConnection,\n",
    "    limit: int = 20,\n",
    "    all_cols: bool = False,\n",
    "    try_place_candidate_as_admin_fallback_on_fail: bool = True,\n",
    ") -> list[pl.DataFrame]:\n",
    "    \"\"\"\n",
    "    Perform flexible geographic search across admin levels.\n",
    "\n",
    "    Args:\n",
    "        search_terms_raw: List of search terms.\n",
    "        con: Database connection.\n",
    "        limit: Maximum results to return per level.\n",
    "        all_cols: Return all columns.\n",
    "        try_place_candidate_as_admin_fallback_on_fail: If True and the place candidate term\n",
    "            search (as a place) fails, try searching it as an admin entity in subsequent levels.\n",
    "    Returns:\n",
    "        List of DataFrames with search results.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Input Cleaning & Term Definition ---\n",
    "    cleaned_terms = [term for term in search_terms_raw if term is not None and term.strip()]\n",
    "    if not cleaned_terms:\n",
    "        # Return empty list or raise error based on desired behavior for no valid terms\n",
    "        logger.warning(\"No valid search terms provided after cleaning.\")\n",
    "        return []\n",
    "    if len(cleaned_terms) > 6:\n",
    "        raise ValueError(\"Search terms must be a list of length <= 6 after cleaning.\")\n",
    "\n",
    "    admin_terms_for_flex_search: list[str]\n",
    "    place_candidate_term: str\n",
    "    # is_place_term_exclusive: True if the place_candidate_term was *only* for place search (input had 6 terms).\n",
    "    is_place_term_exclusive: bool\n",
    "\n",
    "    if len(cleaned_terms) == 6:\n",
    "        admin_terms_for_flex_search = cleaned_terms[:-1]\n",
    "        place_candidate_term = cleaned_terms[-1]\n",
    "        is_place_term_exclusive = True\n",
    "    else:  # 1 to 5 terms\n",
    "        admin_terms_for_flex_search = list(cleaned_terms) # All terms are part of admin sequence\n",
    "        place_candidate_term = cleaned_terms[-1]      # The last of these is also the place candidate\n",
    "        is_place_term_exclusive = False\n",
    "\n",
    "    logger.debug(f\"Flexible search: Admin terms: {admin_terms_for_flex_search}\")\n",
    "    logger.debug(f\"Flexible search: Place candidate: '{place_candidate_term}', Exclusive: {is_place_term_exclusive}\")\n",
    "\n",
    "    all_found_results_list: list[pl.DataFrame] = []\n",
    "    last_successful_admin_context: pl.DataFrame | None = None\n",
    "\n",
    "    # --- Step 1: Iterative Flexible Admin Search ---\n",
    "    num_actual_admin_terms = len(admin_terms_for_flex_search)\n",
    "    # empty_admin_slots determines how many levels a term can \"slide\" over.\n",
    "    # If 1 admin term, it can be level 0-4 (empty_admin_slots = 4).\n",
    "    # If 5 admin terms, each term maps to one level (empty_admin_slots = 0).\n",
    "    empty_admin_slots = 5 - num_actual_admin_terms\n",
    "\n",
    "    for i, term_to_search in enumerate(admin_terms_for_flex_search):\n",
    "        start_level = i\n",
    "        # The term at index `i` can occupy levels from `i` up to `i + empty_admin_slots`.\n",
    "        # Max admin level is 4.\n",
    "        end_level = min(4, i + empty_admin_slots)\n",
    "\n",
    "        current_search_levels = list(range(start_level, end_level + 1))\n",
    "\n",
    "        if not current_search_levels: # Should ideally not happen with correct logic\n",
    "            logger.warning(f\"Term '{term_to_search}': No valid admin levels to search (calculated range: {start_level}-{end_level}). Skipping.\")\n",
    "            continue\n",
    "\n",
    "        logger.debug(f\"Flex-searching admin term '{term_to_search}' for levels {current_search_levels}.\")\n",
    "\n",
    "        term_admin_results = search_admin(\n",
    "            term_to_search, current_search_levels, con,\n",
    "            last_successful_admin_context, limit, all_cols\n",
    "        )\n",
    "\n",
    "        if not term_admin_results.is_empty():\n",
    "            all_found_results_list.append(term_admin_results)\n",
    "            last_successful_admin_context = term_admin_results\n",
    "        else:\n",
    "            logger.debug(f\"No admin results for term '{term_to_search}' in levels {current_search_levels}.\")\n",
    "            # Context (last_successful_admin_context) remains from the previous successful search.\n",
    "\n",
    "    # --- Step 2: Search for Place Candidate as a Place ---\n",
    "    logger.debug(f\"Searching for '{place_candidate_term}' as a place entity.\")\n",
    "    place_search_results = search_place_with_context(\n",
    "        place_candidate_term, con, last_successful_admin_context, limit, all_cols\n",
    "    )\n",
    "\n",
    "    place_found_successfully = (place_search_results is not None and not place_search_results.is_empty())\n",
    "\n",
    "    if place_found_successfully:\n",
    "        all_found_results_list.append(place_search_results) # type: ignore[arg-type]\n",
    "    else:\n",
    "        logger.debug(f\"No place results for '{place_candidate_term}'.\")\n",
    "\n",
    "        # --- Step 3: Fallback - Try Place Candidate as Admin if Place Search Failed ---\n",
    "        if try_place_candidate_as_admin_fallback_on_fail:\n",
    "            # Determine levels for this fallback. These should be levels *after* those\n",
    "            # notionally covered by `admin_terms_for_flex_search`.\n",
    "            # `num_actual_admin_terms` is the count of terms in `admin_terms_for_flex_search`.\n",
    "            # So, the next available admin slot starts at index `num_actual_admin_terms`.\n",
    "            fallback_start_level = num_actual_admin_terms\n",
    "\n",
    "            if fallback_start_level < 5: # Max admin level is 4. If fallback_start_level is 5, no slots.\n",
    "                admin_fallback_levels = list(range(fallback_start_level, 5)) # e.g., if 3 admin terms, try levels 3, 4.\n",
    "\n",
    "                if admin_fallback_levels:\n",
    "                    logger.debug(\n",
    "                        f\"Fallback: Trying place candidate '{place_candidate_term}' as admin \"\n",
    "                        f\"at levels {admin_fallback_levels}.\"\n",
    "                    )\n",
    "                    # Context for this fallback is still `last_successful_admin_context` from Step 1.\n",
    "                    admin_fallback_data = place_as_admin(\n",
    "                        place_candidate_term, admin_fallback_levels, con,\n",
    "                        last_successful_admin_context, limit, all_cols,\n",
    "                    )\n",
    "                    if admin_fallback_data is not None and not admin_fallback_data.is_empty():\n",
    "\n",
    "                        all_found_results_list.append(admin_fallback_data)\n",
    "\n",
    "    return all_found_results_list\n",
    "\n",
    "def backfill_hierarchy(row: dict, con: DuckDBPyConnection) -> dict:\n",
    "    def get_where_clause(codes: list[str | None]) -> str:\n",
    "        return \"WHERE \" + \" AND \".join(\n",
    "            [\n",
    "                f\"admin{i}_code = '{code}'\"\n",
    "                if code is not None\n",
    "                else f\"admin{i}_code IS NULL\"\n",
    "                for i, code in enumerate(codes)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    hierarchy = {}\n",
    "    codes = []\n",
    "    for i in range(5):\n",
    "        print(i)\n",
    "        code = row.get(f\"admin{i}_code\")\n",
    "        codes.append(code)\n",
    "        if code is not None:\n",
    "            df = con.execute(\n",
    "                f\"SELECT geonameId, name FROM admin{i} {get_where_clause(codes)} LIMIT 1\"\n",
    "            ).pl()\n",
    "            if not df.is_empty():\n",
    "                hierarchy[f\"admin{i}\"] = df.to_dicts()[0]\n",
    "    return hierarchy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-07 13:44:55.327\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin_hierarchy\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mSearching for term 'US' at admin level 0\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:55.450\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m390\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 0) AND (admin_level != 0 OR geonameId NOT IN (6252001))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:55.518\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m426\u001b[0m - \u001b[1m[]\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:55.520\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_score_admin\u001b[0m:\u001b[36m191\u001b[0m - \u001b[33m\u001b[1mNo parent_adjusted_score_ columns found. Skipping parent factor.\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:55.522\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin_hierarchy\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mSearching for term 'CA' at admin level 1\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:55.524\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m390\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 1) AND ((admin0_code = 'UZ') OR (admin0_code = 'VI') OR (admin0_code = 'US') OR (admin0_code = 'GU') OR (admin0_code = 'UM'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:55.543\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m426\u001b[0m - \u001b[1m['admin0_code']\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:55.547\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin_hierarchy\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mSearching for term 'Los Angeles County' at admin level 2\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:55.549\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m390\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 2) AND ((admin0_code = 'US' AND admin1_code = 'CA'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:55.577\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m426\u001b[0m - \u001b[1m['admin0_code', 'admin1_code']\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:55.580\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin_hierarchy\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mSearching for term 'Beverly Hills' at admin level 3\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:55.581\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m390\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 3) AND ((admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '113') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '027') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '031') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '067') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '059') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '085') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '047') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '097') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '093') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '019') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '111') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '061') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '037') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '029') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '075') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '041') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '107') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '011') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '087') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '095'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:55.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m426\u001b[0m - \u001b[1m['admin0_code', 'admin1_code', 'admin2_code']\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:55.607\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mhierarchical_search\u001b[0m:\u001b[36m231\u001b[0m - \u001b[34m\u001b[1mNo explicit place term. Using last admin term 'Beverly Hills' (from input level admin3) as the place candidate.\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:55.607\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mhierarchical_search\u001b[0m:\u001b[36m248\u001b[0m - \u001b[34m\u001b[1mAttempting to search place candidate 'Beverly Hills' as admin level 4 (fallback in gap).\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:55.608\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mplace_as_admin\u001b[0m:\u001b[36m85\u001b[0m - \u001b[34m\u001b[1mTrying place term 'Beverly Hills' as admin level 4\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:55.609\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m390\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 4) AND ((admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '037' AND admin3_code = '11788500') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '037' AND admin3_code = '11789027') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '037' AND admin3_code = '11788576'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:55.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m426\u001b[0m - \u001b[1m['admin0_code', 'admin1_code', 'admin2_code', 'admin3_code']\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:55.635\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mplace_as_admin\u001b[0m:\u001b[36m92\u001b[0m - \u001b[34m\u001b[1mNo results found for place term 'Beverly Hills' at admin level 4\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:55.635\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mhierarchical_search\u001b[0m:\u001b[36m263\u001b[0m - \u001b[34m\u001b[1mSearching for 'Beverly Hills' as a place entity.\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:55.636\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place_with_context\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1mSearching for place: 'Beverly Hills'\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:55.636\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m201\u001b[0m - \u001b[34m\u001b[1mSearching for places with term: Beverly Hills\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:55.637\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m264\u001b[0m - \u001b[34m\u001b[1mUsing center point from previous admin results: (34.131099700927734, -118.60806274414062)\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:55.638\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m281\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude,importance_score,importance_tier,\n",
      "            fts_main_places_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM places_search\n",
      "        WHERE ((admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '037' AND admin3_code = '11788500') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '037' AND admin3_code = '11789027') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '037' AND admin3_code = '11788576')) AND importance_tier <= 5\n",
      "    )\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC,\n",
      "        importance_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:55.953\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m289\u001b[0m - \u001b[34m\u001b[1mFound 0 results\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:55.953\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place_with_context\u001b[0m:\u001b[36m124\u001b[0m - \u001b[34m\u001b[1mNo place results found for 'Beverly Hills'\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 17)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>asciiname</th><th>admin0_code</th><th>admin1_code</th><th>admin2_code</th><th>admin3_code</th><th>admin4_code</th><th>feature_class</th><th>feature_code</th><th>population</th><th>latitude</th><th>longitude</th><th>parent_adjusted_score_0</th><th>parent_adjusted_score_1</th><th>parent_adjusted_score_2</th><th>adjusted_score_3</th></tr><tr><td>u32</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i32</td><td>f32</td><td>f32</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>11788500</td><td>&quot;City of Beverly Hills&quot;</td><td>&quot;City of Beverly Hills&quot;</td><td>&quot;US&quot;</td><td>&quot;CA&quot;</td><td>&quot;037&quot;</td><td>&quot;11788500&quot;</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM3&quot;</td><td>0</td><td>34.07856</td><td>-118.402107</td><td>0.76254</td><td>0.6612</td><td>0.805971</td><td>0.559061</td></tr><tr><td>11789027</td><td>&quot;City of Hidden Hills&quot;</td><td>&quot;City of Hidden Hills&quot;</td><td>&quot;US&quot;</td><td>&quot;CA&quot;</td><td>&quot;037&quot;</td><td>&quot;11789027&quot;</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM3&quot;</td><td>0</td><td>34.163738</td><td>-118.661201</td><td>0.76254</td><td>0.6612</td><td>0.805971</td><td>0.350435</td></tr><tr><td>11788576</td><td>&quot;City of Agoura Hills&quot;</td><td>&quot;City of Agoura Hills&quot;</td><td>&quot;US&quot;</td><td>&quot;CA&quot;</td><td>&quot;037&quot;</td><td>&quot;11788576&quot;</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM3&quot;</td><td>0</td><td>34.151001</td><td>-118.76088</td><td>0.76254</td><td>0.6612</td><td>0.805971</td><td>0.350435</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 17)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ geonameId ┆ name      ┆ asciiname ┆ admin0_co ┆ … ┆ parent_ad ┆ parent_ad ┆ parent_ad ┆ adjusted │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ de        ┆   ┆ justed_sc ┆ justed_sc ┆ justed_sc ┆ _score_3 │\n",
       "│ u32       ┆ str       ┆ str       ┆ ---       ┆   ┆ ore_0     ┆ ore_1     ┆ ore_2     ┆ ---      │\n",
       "│           ┆           ┆           ┆ str       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ f64      │\n",
       "│           ┆           ┆           ┆           ┆   ┆ f64       ┆ f64       ┆ f64       ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 11788500  ┆ City of   ┆ City of   ┆ US        ┆ … ┆ 0.76254   ┆ 0.6612    ┆ 0.805971  ┆ 0.559061 │\n",
       "│           ┆ Beverly   ┆ Beverly   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Hills     ┆ Hills     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 11789027  ┆ City of   ┆ City of   ┆ US        ┆ … ┆ 0.76254   ┆ 0.6612    ┆ 0.805971  ┆ 0.350435 │\n",
       "│           ┆ Hidden    ┆ Hidden    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Hills     ┆ Hills     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 11788576  ┆ City of   ┆ City of   ┆ US        ┆ … ┆ 0.76254   ┆ 0.6612    ┆ 0.805971  ┆ 0.350435 │\n",
       "│           ┆ Agoura    ┆ Agoura    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Hills     ┆ Hills     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hierarchical search with place\n",
    "st = [\"US\", \"CA\", \"Los Angeles County\", \"Beverly Hills\", None, None]\n",
    "search_terms = AdminHierarchy.from_list(st)\n",
    "results = hierarchical_search(search_terms, con)\n",
    "results.get(\"admin3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-07 13:44:59.900\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m320\u001b[0m - \u001b[34m\u001b[1mFlexible search: Admin terms: ['US', 'Los Angeles County', 'Beverly Hills']\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:59.901\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m321\u001b[0m - \u001b[34m\u001b[1mFlexible search: Place candidate: 'Beverly Hills', Exclusive: False\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:59.901\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m345\u001b[0m - \u001b[34m\u001b[1mFlex-searching admin term 'US' for levels [0, 1, 2].\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:59.905\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m390\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 0 OR admin_level = 1 OR admin_level = 2) AND (admin_level != 0 OR geonameId NOT IN (6252001))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:59.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m426\u001b[0m - \u001b[1m[]\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:59.933\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_score_admin\u001b[0m:\u001b[36m191\u001b[0m - \u001b[33m\u001b[1mNo parent_adjusted_score_ columns found. Skipping parent factor.\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:59.934\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m345\u001b[0m - \u001b[34m\u001b[1mFlex-searching admin term 'Los Angeles County' for levels [1, 2, 3].\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:59.936\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m390\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 1 OR admin_level = 2 OR admin_level = 3) AND ((admin0_code = 'VI') OR (admin0_code = 'GE' AND admin1_code = '71' AND admin2_code = '615141') OR (admin0_code = 'AS' AND admin1_code = '040') OR (admin0_code = 'MN' AND admin1_code = '15' AND admin2_code = '6619052') OR (admin0_code = 'GU') OR (admin0_code = 'UZ') OR (admin0_code = 'AF' AND admin1_code = '40' AND admin2_code = '302') OR (admin0_code = 'FR' AND admin1_code = '44' AND admin2_code = '55') OR (admin0_code = 'NO' AND admin1_code = '34' AND admin2_code = '3430') OR (admin0_code = 'UM') OR (admin0_code = 'US'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:59.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m426\u001b[0m - \u001b[1m['admin0_code', 'admin1_code', 'admin2_code']\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:59.970\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m345\u001b[0m - \u001b[34m\u001b[1mFlex-searching admin term 'Beverly Hills' for levels [2, 3, 4].\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:59.971\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m390\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 2 OR admin_level = 3 OR admin_level = 4) AND ((admin0_code = 'US' AND admin1_code = 'IN' AND admin2_code = '087') OR (admin0_code = 'US' AND admin1_code = 'CO' AND admin2_code = '014') OR (admin0_code = 'US' AND admin1_code = 'IN' AND admin2_code = '141') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '037') OR (admin0_code = 'US' AND admin1_code = 'IL' AND admin2_code = '039') OR (admin0_code = 'US' AND admin1_code = 'SC' AND admin2_code = '075') OR (admin0_code = 'US' AND admin1_code = 'NY' AND admin2_code = '071') OR (admin0_code = 'US' AND admin1_code = 'NY' AND admin2_code = '081') OR (admin0_code = 'US' AND admin1_code = 'FL' AND admin2_code = '057') OR (admin0_code = 'US' AND admin1_code = 'TX' AND admin2_code = '061' AND admin3_code = '7173701') OR (admin0_code = 'US' AND admin1_code = 'NM' AND admin2_code = '028') OR (admin0_code = 'US' AND admin1_code = 'WA' AND admin2_code = '009' AND admin3_code = '7174112') OR (admin0_code = 'US' AND admin1_code = 'NY' AND admin2_code = '047') OR (admin0_code = 'US' AND admin1_code = 'NY' AND admin2_code = '061') OR (admin0_code = 'US' AND admin1_code = 'MD' AND admin2_code = '037') OR (admin0_code = 'US' AND admin1_code = 'NH' AND admin2_code = '011') OR (admin0_code = 'US' AND admin1_code = 'WV' AND admin2_code = '061') OR (admin0_code = 'US' AND admin1_code = 'FL' AND admin2_code = '095') OR (admin0_code = 'US' AND admin1_code = 'TX' AND admin2_code = '061' AND admin3_code = '7175328') OR (admin0_code = 'US' AND admin1_code = 'NC' AND admin2_code = '135'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:59.994\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m426\u001b[0m - \u001b[1m['admin0_code', 'admin1_code', 'admin2_code', 'admin3_code']\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:59.997\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m360\u001b[0m - \u001b[34m\u001b[1mSearching for 'Beverly Hills' as a place entity.\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:59.997\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place_with_context\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1mSearching for place: 'Beverly Hills'\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:59.998\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m201\u001b[0m - \u001b[34m\u001b[1mSearching for places with term: Beverly Hills\u001b[0m\n",
      "\u001b[32m2025-05-07 13:44:59.999\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m264\u001b[0m - \u001b[34m\u001b[1mUsing center point from previous admin results: (36.368614196777344, -106.886474609375)\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:00.000\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m281\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude,importance_score,importance_tier,\n",
      "            fts_main_places_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM places_search\n",
      "        WHERE ((admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '037' AND admin3_code = '11789027') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '037' AND admin3_code = '11788576') OR (admin0_code = 'US' AND admin1_code = 'NH' AND admin2_code = '011' AND admin3_code = '79780') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '037' AND admin3_code = '11788500')) AND importance_tier <= 5\n",
      "    )\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC,\n",
      "        importance_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:00.299\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m289\u001b[0m - \u001b[34m\u001b[1mFound 0 results\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:00.299\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place_with_context\u001b[0m:\u001b[36m124\u001b[0m - \u001b[34m\u001b[1mNo place results found for 'Beverly Hills'\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:00.299\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m370\u001b[0m - \u001b[34m\u001b[1mNo place results for 'Beverly Hills'.\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:00.300\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m384\u001b[0m - \u001b[34m\u001b[1mFallback: Trying place candidate 'Beverly Hills' as admin at levels [3, 4].\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:00.300\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mplace_as_admin\u001b[0m:\u001b[36m85\u001b[0m - \u001b[34m\u001b[1mTrying place term 'Beverly Hills' as admin level [3, 4]\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:00.302\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m390\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 3 OR admin_level = 4) AND ((admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '037' AND admin3_code = '11789027') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '037' AND admin3_code = '11788576') OR (admin0_code = 'US' AND admin1_code = 'CA' AND admin2_code = '037' AND admin3_code = '11788500') OR (admin0_code = 'US' AND admin1_code = 'NH' AND admin2_code = '011' AND admin3_code = '79780'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:00.330\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m426\u001b[0m - \u001b[1m['admin0_code', 'admin1_code', 'admin2_code', 'admin3_code']\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[shape: (11, 14)\n",
       " ┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       " │ geonameId ┆ name      ┆ asciiname ┆ admin0_co ┆ … ┆ populatio ┆ latitude  ┆ longitude ┆ adjusted │\n",
       " │ ---       ┆ ---       ┆ ---       ┆ de        ┆   ┆ n         ┆ ---       ┆ ---       ┆ _score_0 │\n",
       " │ u32       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ f32       ┆ f32       ┆ ---      │\n",
       " │           ┆           ┆           ┆ str       ┆   ┆ i32       ┆           ┆           ┆ f64      │\n",
       " ╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       " │ 6252001   ┆ United    ┆ United    ┆ US        ┆ … ┆ 327167434 ┆ 39.759998 ┆ -98.5     ┆ 0.768901 │\n",
       " │           ┆ States    ┆ States    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 2994106   ┆ Meuse     ┆ Meuse     ┆ FR        ┆ … ┆ 200417    ┆ 48.97176  ┆ 5.36371   ┆ 0.47306  │\n",
       " │ 1512440   ┆ Republic  ┆ Republic  ┆ UZ        ┆ … ┆ 32955400  ┆ 41.666672 ┆ 63.833328 ┆ 0.466216 │\n",
       " │           ┆ of Uzbeki ┆ of Uzbeki ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │           ┆ stan      ┆ stan      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 4043988   ┆ Guam      ┆ Guam      ┆ GU        ┆ … ┆ 165768    ┆ 13.47861  ┆ 144.81834 ┆ 0.447696 │\n",
       " │           ┆           ┆           ┆           ┆   ┆           ┆           ┆ 4         ┆          │\n",
       " │ 6619052   ┆ Guchin-Us ┆ Guchin-Us ┆ MN        ┆ … ┆ 0         ┆ 45.458321 ┆ 102.42089 ┆ 0.442675 │\n",
       " │           ┆           ┆           ┆           ┆   ┆           ┆           ┆ 8         ┆          │\n",
       " │ 6453342   ┆ Os        ┆ Os        ┆ NO        ┆ … ┆ 1870      ┆ 62.495361 ┆ 11.22807  ┆ 0.428154 │\n",
       " │ 7054038   ┆ Jabal us  ┆ Jabal us  ┆ AF        ┆ … ┆ 0         ┆ 35.11628  ┆ 69.18412  ┆ 0.425565 │\n",
       " │           ┆ Sarāj     ┆ Saraj     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 4796775   ┆ United    ┆ United    ┆ VI        ┆ … ┆ 106977    ┆ 18.348289 ┆ -64.98348 ┆ 0.423905 │\n",
       " │           ┆ States    ┆ States    ┆           ┆   ┆           ┆           ┆ 2         ┆          │\n",
       " │           ┆ Virgin    ┆ Virgin    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │           ┆ Islands   ┆ Islands   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 5881199   ┆ Swains    ┆ Swains    ┆ AS        ┆ … ┆ 37        ┆ -11.056   ┆ -171.0820 ┆ 0.417198 │\n",
       " │           ┆ Island    ┆ Island    ┆           ┆   ┆           ┆           ┆ 01        ┆          │\n",
       " │ 615141    ┆ Chkhorots ┆ Chkhorots ┆ GE        ┆ … ┆ 0         ┆ 42.61235  ┆ 42.21553  ┆ 0.378476 │\n",
       " │           ┆ ’q’us Mun ┆ 'q'us Mun ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │           ┆ itsip’ali ┆ itsip'ali ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │           ┆ t’e…      ┆ t'e…      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 5854968   ┆ United    ┆ United    ┆ UM        ┆ … ┆ 0         ┆ 5.875     ┆ -162.0570 ┆ 0.266668 │\n",
       " │           ┆ States    ┆ States    ┆           ┆   ┆           ┆           ┆ 07        ┆          │\n",
       " │           ┆ Minor     ┆ Minor     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │           ┆ Outlying  ┆ Outlying  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │           ┆ I…        ┆ I…        ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " └───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘,\n",
       " shape: (20, 15)\n",
       " ┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       " │ geonameId ┆ name      ┆ asciiname ┆ admin0_co ┆ … ┆ latitude  ┆ longitude ┆ parent_ad ┆ adjusted │\n",
       " │ ---       ┆ ---       ┆ ---       ┆ de        ┆   ┆ ---       ┆ ---       ┆ justed_sc ┆ _score_1 │\n",
       " │ u32       ┆ str       ┆ str       ┆ ---       ┆   ┆ f32       ┆ f32       ┆ ore_0     ┆ ---      │\n",
       " │           ┆           ┆           ┆ str       ┆   ┆           ┆           ┆ ---       ┆ f64      │\n",
       " │           ┆           ┆           ┆           ┆   ┆           ┆           ┆ f64       ┆          │\n",
       " ╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       " │ 5368381   ┆ Los       ┆ Los       ┆ US        ┆ … ┆ 34.198009 ┆ -118.2610 ┆ 0.768901  ┆ 0.805971 │\n",
       " │           ┆ Angeles   ┆ Angeles   ┆           ┆   ┆           ┆ 17        ┆           ┆          │\n",
       " │           ┆ County    ┆ County    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 7174112   ┆ City of   ┆ City of   ┆ US        ┆ … ┆ 48.11739  ┆ -123.4494 ┆ 0.768901  ┆ 0.734919 │\n",
       " │           ┆ Port      ┆ Port      ┆           ┆   ┆           ┆ 78        ┆           ┆          │\n",
       " │           ┆ Angeles   ┆ Angeles   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 5476834   ┆ Los       ┆ Los       ┆ US        ┆ … ┆ 35.86937  ┆ -106.3072 ┆ 0.768901  ┆ 0.728241 │\n",
       " │           ┆ Alamos    ┆ Alamos    ┆           ┆   ┆           ┆ 89        ┆           ┆          │\n",
       " │           ┆ County    ┆ County    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 7173701   ┆ City of   ┆ City of   ┆ US        ┆ … ┆ 26.072689 ┆ -97.47554 ┆ 0.768901  ┆ 0.64993  │\n",
       " │           ┆ Los       ┆ Los       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │           ┆ Fresnos   ┆ Fresnos   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 6941775   ┆ Kings     ┆ Kings     ┆ US        ┆ … ┆ 40.634392 ┆ -73.95027 ┆ 0.768901  ┆ 0.64683  │\n",
       " │           ┆ County    ┆ County    ┆           ┆   ┆           ┆ 2         ┆           ┆          │\n",
       " │ 7175328   ┆ Town of   ┆ Town of   ┆ US        ┆ … ┆ 26.049311 ┆ -97.73513 ┆ 0.768901  ┆ 0.632734 │\n",
       " │           ┆ Los       ┆ Los       ┆           ┆   ┆           ┆ 8         ┆           ┆          │\n",
       " │           ┆ Indios    ┆ Indios    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 4158712   ┆ Hillsboro ┆ Hillsboro ┆ US        ┆ … ┆ 27.906231 ┆ -82.34691 ┆ 0.768901  ┆ 0.614931 │\n",
       " │           ┆ ugh       ┆ ugh       ┆           ┆   ┆           ┆ 6         ┆           ┆          │\n",
       " │           ┆ County    ┆ County    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 5087463   ┆ Hillsboro ┆ Hillsboro ┆ US        ┆ … ┆ 42.91531  ┆ -71.71601 ┆ 0.768901  ┆ 0.608214 │\n",
       " │           ┆ ugh       ┆ ugh       ┆           ┆   ┆           ┆ 1         ┆           ┆          │\n",
       " │           ┆ County    ┆ County    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 5133268   ┆ Queens    ┆ Queens    ┆ US        ┆ … ┆ 40.65749  ┆ -73.83875 ┆ 0.768901  ┆ 0.603761 │\n",
       " │           ┆ County    ┆ County    ┆           ┆   ┆           ┆ 3         ┆           ┆          │\n",
       " │ 4922458   ┆ LaGrange  ┆ LaGrange  ┆ US        ┆ … ┆ 41.642609 ┆ -85.42649 ┆ 0.768901  ┆ 0.592881 │\n",
       " │           ┆ County    ┆ County    ┆           ┆   ┆           ┆ 8         ┆           ┆          │\n",
       " │ 4889548   ┆ DeWitt    ┆ DeWitt    ┆ US        ┆ … ┆ 40.174629 ┆ -88.90409 ┆ 0.768901  ┆ 0.585911 │\n",
       " │           ┆ County    ┆ County    ┆           ┆   ┆           ┆ 1         ┆           ┆          │\n",
       " │ 5128594   ┆ New York  ┆ New York  ┆ US        ┆ … ┆ 40.774269 ┆ -73.96981 ┆ 0.768901  ┆ 0.583033 │\n",
       " │           ┆ County    ┆ County    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 4368320   ┆ Saint     ┆ Saint     ┆ US        ┆ … ┆ 38.215858 ┆ -76.52906 ┆ 0.768901  ┆ 0.582542 │\n",
       " │           ┆ Mary's    ┆ Mary's    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │           ┆ County    ┆ County    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 4167060   ┆ Orange    ┆ Orange    ┆ US        ┆ … ┆ 28.51442  ┆ -81.32347 ┆ 0.768901  ┆ 0.579927 │\n",
       " │           ┆ County    ┆ County    ┆           ┆   ┆           ┆ 9         ┆           ┆          │\n",
       " │ 4590186   ┆ Orangebur ┆ Orangebur ┆ US        ┆ … ┆ 33.438992 ┆ -80.80030 ┆ 0.768901  ┆ 0.575967 │\n",
       " │           ┆ g County  ┆ g County  ┆           ┆   ┆           ┆ 1         ┆           ┆          │\n",
       " │ 4925848   ┆ Saint     ┆ Saint     ┆ US        ┆ … ┆ 41.616718 ┆ -86.28986 ┆ 0.768901  ┆ 0.573181 │\n",
       " │           ┆ Joseph    ┆ Joseph    ┆           ┆   ┆           ┆ 4         ┆           ┆          │\n",
       " │           ┆ County    ┆ County    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 5129915   ┆ Orange    ┆ Orange    ┆ US        ┆ … ┆ 41.402142 ┆ -74.30557 ┆ 0.768901  ┆ 0.572585 │\n",
       " │           ┆ County    ┆ County    ┆           ┆   ┆           ┆ 3         ┆           ┆          │\n",
       " │ 4815207   ┆ Monongali ┆ Monongali ┆ US        ┆ … ┆ 39.63028  ┆ -80.04653 ┆ 0.768901  ┆ 0.570887 │\n",
       " │           ┆ a County  ┆ a County  ┆           ┆   ┆           ┆ 9         ┆           ┆          │\n",
       " │ 5415040   ┆ Broomfiel ┆ Broomfiel ┆ US        ┆ … ┆ 39.954128 ┆ -105.0526 ┆ 0.768901  ┆ 0.570103 │\n",
       " │           ┆ d County  ┆ d County  ┆           ┆   ┆           ┆ 58        ┆           ┆          │\n",
       " │ 4483525   ┆ Orange    ┆ Orange    ┆ US        ┆ … ┆ 36.061298 ┆ -79.12059 ┆ 0.768901  ┆ 0.566279 │\n",
       " │           ┆ County    ┆ County    ┆           ┆   ┆           ┆ 8         ┆           ┆          │\n",
       " └───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘,\n",
       " shape: (4, 16)\n",
       " ┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       " │ geonameId ┆ name      ┆ asciiname ┆ admin0_co ┆ … ┆ longitude ┆ parent_ad ┆ parent_ad ┆ adjusted │\n",
       " │ ---       ┆ ---       ┆ ---       ┆ de        ┆   ┆ ---       ┆ justed_sc ┆ justed_sc ┆ _score_2 │\n",
       " │ u32       ┆ str       ┆ str       ┆ ---       ┆   ┆ f32       ┆ ore_0     ┆ ore_1     ┆ ---      │\n",
       " │           ┆           ┆           ┆ str       ┆   ┆           ┆ ---       ┆ ---       ┆ f64      │\n",
       " │           ┆           ┆           ┆           ┆   ┆           ┆ f64       ┆ f64       ┆          │\n",
       " ╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       " │ 11788500  ┆ City of   ┆ City of   ┆ US        ┆ … ┆ -118.4021 ┆ 0.768901  ┆ 0.805971  ┆ 0.57064  │\n",
       " │           ┆ Beverly   ┆ Beverly   ┆           ┆   ┆ 07        ┆           ┆           ┆          │\n",
       " │           ┆ Hills     ┆ Hills     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 5094337   ┆ Town of   ┆ Town of   ┆ US        ┆ … ┆ -71.72171 ┆ 0.768901  ┆ 0.805971  ┆ 0.492178 │\n",
       " │           ┆ Weare     ┆ Weare     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 11789027  ┆ City of   ┆ City of   ┆ US        ┆ … ┆ -118.6612 ┆ 0.768901  ┆ 0.805971  ┆ 0.379005 │\n",
       " │           ┆ Hidden    ┆ Hidden    ┆           ┆   ┆ 01        ┆           ┆           ┆          │\n",
       " │           ┆ Hills     ┆ Hills     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 11788576  ┆ City of   ┆ City of   ┆ US        ┆ … ┆ -118.7608 ┆ 0.768901  ┆ 0.805971  ┆ 0.379005 │\n",
       " │           ┆ Agoura    ┆ Agoura    ┆           ┆   ┆ 8         ┆           ┆           ┆          │\n",
       " │           ┆ Hills     ┆ Hills     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " └───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘,\n",
       " shape: (4, 17)\n",
       " ┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       " │ geonameId ┆ name      ┆ asciiname ┆ admin0_co ┆ … ┆ parent_ad ┆ parent_ad ┆ parent_ad ┆ adjusted │\n",
       " │ ---       ┆ ---       ┆ ---       ┆ de        ┆   ┆ justed_sc ┆ justed_sc ┆ justed_sc ┆ _score_3 │\n",
       " │ u32       ┆ str       ┆ str       ┆ ---       ┆   ┆ ore_0     ┆ ore_1     ┆ ore_2     ┆ ---      │\n",
       " │           ┆           ┆           ┆ str       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ f64      │\n",
       " │           ┆           ┆           ┆           ┆   ┆ f64       ┆ f64       ┆ f64       ┆          │\n",
       " ╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       " │ 11788500  ┆ City of   ┆ City of   ┆ US        ┆ … ┆ 0.768901  ┆ 0.805971  ┆ 0.57064   ┆ 0.56662  │\n",
       " │           ┆ Beverly   ┆ Beverly   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │           ┆ Hills     ┆ Hills     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 5094337   ┆ Town of   ┆ Town of   ┆ US        ┆ … ┆ 0.768901  ┆ 0.805971  ┆ 0.57064   ┆ 0.486577 │\n",
       " │           ┆ Weare     ┆ Weare     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 11788576  ┆ City of   ┆ City of   ┆ US        ┆ … ┆ 0.768901  ┆ 0.805971  ┆ 0.57064   ┆ 0.370772 │\n",
       " │           ┆ Agoura    ┆ Agoura    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │           ┆ Hills     ┆ Hills     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │ 11789027  ┆ City of   ┆ City of   ┆ US        ┆ … ┆ 0.768901  ┆ 0.805971  ┆ 0.57064   ┆ 0.370772 │\n",
       " │           ┆ Hidden    ┆ Hidden    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " │           ┆ Hills     ┆ Hills     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       " └───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = flexible_search([\"US\",  \"Los Angeles County\", \"Beverly Hills\"], con)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 17)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>asciiname</th><th>admin0_code</th><th>admin1_code</th><th>admin2_code</th><th>admin3_code</th><th>admin4_code</th><th>feature_class</th><th>feature_code</th><th>population</th><th>latitude</th><th>longitude</th><th>parent_adjusted_score_0</th><th>parent_adjusted_score_1</th><th>parent_adjusted_score_2</th><th>adjusted_score_3</th></tr><tr><td>u32</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i32</td><td>f32</td><td>f32</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>11788500</td><td>&quot;City of Beverly Hills&quot;</td><td>&quot;City of Beverly Hills&quot;</td><td>&quot;US&quot;</td><td>&quot;CA&quot;</td><td>&quot;037&quot;</td><td>&quot;11788500&quot;</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM3&quot;</td><td>0</td><td>34.07856</td><td>-118.402107</td><td>0.768901</td><td>0.805971</td><td>0.57064</td><td>0.56662</td></tr><tr><td>5094337</td><td>&quot;Town of Weare&quot;</td><td>&quot;Town of Weare&quot;</td><td>&quot;US&quot;</td><td>&quot;NH&quot;</td><td>&quot;011&quot;</td><td>&quot;79780&quot;</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM3&quot;</td><td>8913</td><td>43.08115</td><td>-71.72171</td><td>0.768901</td><td>0.805971</td><td>0.57064</td><td>0.486577</td></tr><tr><td>11788576</td><td>&quot;City of Agoura Hills&quot;</td><td>&quot;City of Agoura Hills&quot;</td><td>&quot;US&quot;</td><td>&quot;CA&quot;</td><td>&quot;037&quot;</td><td>&quot;11788576&quot;</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM3&quot;</td><td>0</td><td>34.151001</td><td>-118.76088</td><td>0.768901</td><td>0.805971</td><td>0.57064</td><td>0.370772</td></tr><tr><td>11789027</td><td>&quot;City of Hidden Hills&quot;</td><td>&quot;City of Hidden Hills&quot;</td><td>&quot;US&quot;</td><td>&quot;CA&quot;</td><td>&quot;037&quot;</td><td>&quot;11789027&quot;</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM3&quot;</td><td>0</td><td>34.163738</td><td>-118.661201</td><td>0.768901</td><td>0.805971</td><td>0.57064</td><td>0.370772</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 17)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ geonameId ┆ name      ┆ asciiname ┆ admin0_co ┆ … ┆ parent_ad ┆ parent_ad ┆ parent_ad ┆ adjusted │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ de        ┆   ┆ justed_sc ┆ justed_sc ┆ justed_sc ┆ _score_3 │\n",
       "│ u32       ┆ str       ┆ str       ┆ ---       ┆   ┆ ore_0     ┆ ore_1     ┆ ore_2     ┆ ---      │\n",
       "│           ┆           ┆           ┆ str       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ f64      │\n",
       "│           ┆           ┆           ┆           ┆   ┆ f64       ┆ f64       ┆ f64       ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 11788500  ┆ City of   ┆ City of   ┆ US        ┆ … ┆ 0.768901  ┆ 0.805971  ┆ 0.57064   ┆ 0.56662  │\n",
       "│           ┆ Beverly   ┆ Beverly   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Hills     ┆ Hills     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 5094337   ┆ Town of   ┆ Town of   ┆ US        ┆ … ┆ 0.768901  ┆ 0.805971  ┆ 0.57064   ┆ 0.486577 │\n",
       "│           ┆ Weare     ┆ Weare     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 11788576  ┆ City of   ┆ City of   ┆ US        ┆ … ┆ 0.768901  ┆ 0.805971  ┆ 0.57064   ┆ 0.370772 │\n",
       "│           ┆ Agoura    ┆ Agoura    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Hills     ┆ Hills     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 11789027  ┆ City of   ┆ City of   ┆ US        ┆ … ┆ 0.768901  ┆ 0.805971  ┆ 0.57064   ┆ 0.370772 │\n",
       "│           ┆ Hidden    ┆ Hidden    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Hills     ┆ Hills     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admin0_code', 'admin1_code', 'admin2_code', 'admin3_code']\n"
     ]
    }
   ],
   "source": [
    "a = results[2].select(cs.exclude(\"admin_level\")).select(cs.starts_with(\"admin\")).unique()\n",
    "join_cols = a[[s.name for s in a if not (s.null_count() == a.height)]].columns\n",
    "print(join_cols)\n",
    "b= con.table(\"admin_search\").pl().lazy().join(\n",
    "    results[2].lazy().select(join_cols), on=join_cols\n",
    ").filter(\n",
    "    # These terms are esentially the same thing\n",
    "    pl.col(\"admin_level\").is_in([3, 4])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-07 13:45:15.499\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m320\u001b[0m - \u001b[34m\u001b[1mFlexible search: Admin terms: ['United Kingdom', 'London', 'Westminster', 'Parlement']\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:15.500\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m321\u001b[0m - \u001b[34m\u001b[1mFlexible search: Place candidate: 'Parlement', Exclusive: False\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:15.500\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m345\u001b[0m - \u001b[34m\u001b[1mFlex-searching admin term 'United Kingdom' for levels [0, 1].\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:15.500\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m390\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 0 OR admin_level = 1)\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:15.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m426\u001b[0m - \u001b[1m[]\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:15.535\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_score_admin\u001b[0m:\u001b[36m191\u001b[0m - \u001b[33m\u001b[1mNo parent_adjusted_score_ columns found. Skipping parent factor.\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:15.536\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m345\u001b[0m - \u001b[34m\u001b[1mFlex-searching admin term 'London' for levels [1, 2].\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:15.538\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m390\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 1 OR admin_level = 2) AND ((admin0_code = 'US' AND admin1_code = 'HI') OR (admin0_code = 'TO') OR (admin0_code = 'WF' AND admin1_code = '98611') OR (admin0_code = 'LS') OR (admin0_code = 'SE') OR (admin0_code = 'DK') OR (admin0_code = 'NO') OR (admin0_code = 'MA') OR (admin0_code = 'BT') OR (admin0_code = 'US') OR (admin0_code = 'TH') OR (admin0_code = 'KH') OR (admin0_code = 'GB') OR (admin0_code = 'TZ') OR (admin0_code = 'JO') OR (admin0_code = 'BH') OR (admin0_code = 'IN' AND admin1_code = '36') OR (admin0_code = 'ES') OR (admin0_code = 'IN' AND admin1_code = '29') OR (admin0_code = 'BE'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:15.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m426\u001b[0m - \u001b[1m['admin0_code', 'admin1_code']\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:15.685\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m345\u001b[0m - \u001b[34m\u001b[1mFlex-searching admin term 'Westminster' for levels [2, 3].\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:15.686\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m390\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 2 OR admin_level = 3) AND ((admin0_code = 'US' AND admin1_code = 'CT' AND admin2_code = '011') OR (admin0_code = 'GB' AND admin1_code = 'ENG' AND admin2_code = 'GLA'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:15.728\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m426\u001b[0m - \u001b[1m['admin0_code', 'admin1_code', 'admin2_code']\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:15.732\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m345\u001b[0m - \u001b[34m\u001b[1mFlex-searching admin term 'Parlement' for levels [3, 4].\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:15.733\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m390\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 3 OR admin_level = 4) AND ((admin0_code = 'GB' AND admin1_code = 'ENG' AND admin2_code = 'GLA' AND admin3_code = 'P5'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:15.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m426\u001b[0m - \u001b[1m['admin0_code', 'admin1_code', 'admin2_code', 'admin3_code']\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:15.751\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m356\u001b[0m - \u001b[34m\u001b[1mNo admin results for term 'Parlement' in levels [3, 4].\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:15.752\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m360\u001b[0m - \u001b[34m\u001b[1mSearching for 'Parlement' as a place entity.\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:15.752\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place_with_context\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1mSearching for place: 'Parlement'\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:15.752\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m201\u001b[0m - \u001b[34m\u001b[1mSearching for places with term: Parlement\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:15.755\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m264\u001b[0m - \u001b[34m\u001b[1mUsing center point from previous admin results: (51.512908935546875, -0.15895000100135803)\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:15.755\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m281\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude,importance_score,importance_tier,\n",
      "            fts_main_places_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM places_search\n",
      "        WHERE ((admin0_code = 'GB' AND admin1_code = 'ENG' AND admin2_code = 'GLA' AND admin3_code = 'P5')) AND importance_tier <= 5\n",
      "    )\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC,\n",
      "        importance_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:15.906\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m289\u001b[0m - \u001b[34m\u001b[1mFound 1 results\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:15.907\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m311\u001b[0m - \u001b[34m\u001b[1mJoining place results with parent admin scores on: ['admin0_code', 'admin1_code', 'admin2_code', 'admin3_code']\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:15.909\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m317\u001b[0m - \u001b[34m\u001b[1mShape after joining with parent scores: (1, 17)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 16)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>asciiname</th><th>admin0_code</th><th>admin1_code</th><th>admin2_code</th><th>admin3_code</th><th>admin4_code</th><th>feature_class</th><th>feature_code</th><th>population</th><th>latitude</th><th>longitude</th><th>parent_adjusted_score_0</th><th>parent_adjusted_score_1</th><th>adjusted_score_2</th></tr><tr><td>u32</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i32</td><td>f32</td><td>f32</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>3333218</td><td>&quot;City of Westminster&quot;</td><td>&quot;City of Westminster&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;GLA&quot;</td><td>&quot;P5&quot;</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM3&quot;</td><td>247614</td><td>51.512909</td><td>-0.15895</td><td>0.64437</td><td>0.752222</td><td>0.608563</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 16)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ geonameId ┆ name      ┆ asciiname ┆ admin0_co ┆ … ┆ longitude ┆ parent_ad ┆ parent_ad ┆ adjusted │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ de        ┆   ┆ ---       ┆ justed_sc ┆ justed_sc ┆ _score_2 │\n",
       "│ u32       ┆ str       ┆ str       ┆ ---       ┆   ┆ f32       ┆ ore_0     ┆ ore_1     ┆ ---      │\n",
       "│           ┆           ┆           ┆ str       ┆   ┆           ┆ ---       ┆ ---       ┆ f64      │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ f64       ┆ f64       ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 3333218   ┆ City of   ┆ City of   ┆ GB        ┆ … ┆ -0.15895  ┆ 0.64437   ┆ 0.752222  ┆ 0.608563 │\n",
       "│           ┆ Westminst ┆ Westminst ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ er        ┆ er        ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flexible search with potential place\n",
    "flex_terms = [\"United Kingdom\", \"London\", \"Westminster\", \"Parlement\"]\n",
    "flex_results = flexible_search(flex_terms, con)\n",
    "\n",
    "flex_results[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-07 13:45:21.312\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin_hierarchy\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mSearching for term 'FR' at admin level 0\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:21.319\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m390\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT *, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 0) AND (admin_level != 0 OR geonameId NOT IN (3017382))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:21.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m426\u001b[0m - \u001b[1m[]\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:21.347\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_score_admin\u001b[0m:\u001b[36m191\u001b[0m - \u001b[33m\u001b[1mNo parent_adjusted_score_ columns found. Skipping parent factor.\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:21.349\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin_hierarchy\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mSearching for term 'Provence-Alpes-Côte d'Azur' at admin level 1\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:21.351\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m390\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT *, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 1) AND ((admin0_code = 'FR') OR (admin0_code = 'PF') OR (admin0_code = 'GF') OR (admin0_code = 'MF'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:21.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m426\u001b[0m - \u001b[1m['admin0_code']\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:21.392\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin_hierarchy\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mSearching for term 'Le Lavandou' at admin level 4\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:21.394\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m390\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT *, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 4) AND ((admin0_code = 'FR' AND admin1_code = 'B4') OR (admin0_code = 'FR' AND admin1_code = '24') OR (admin0_code = 'FR' AND admin1_code = '32') OR (admin0_code = 'FR' AND admin1_code = '11') OR (admin0_code = 'FR' AND admin1_code = '84') OR (admin0_code = 'FR' AND admin1_code = 'B9') OR (admin0_code = 'FR' AND admin1_code = '52') OR (admin0_code = 'FR' AND admin1_code = '93'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:21.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m426\u001b[0m - \u001b[1m['admin0_code', 'admin1_code']\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:21.433\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mhierarchical_search\u001b[0m:\u001b[36m231\u001b[0m - \u001b[34m\u001b[1mNo explicit place term. Using last admin term 'Le Lavandou' (from input level admin4) as the place candidate.\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:21.434\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mhierarchical_search\u001b[0m:\u001b[36m263\u001b[0m - \u001b[34m\u001b[1mSearching for 'Le Lavandou' as a place entity.\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:21.434\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place_with_context\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1mSearching for place: 'Le Lavandou'\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:21.434\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m201\u001b[0m - \u001b[34m\u001b[1mSearching for places with term: Le Lavandou\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:21.436\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m264\u001b[0m - \u001b[34m\u001b[1mUsing center point from previous admin results: (46.86593246459961, 2.3935935497283936)\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:21.437\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m281\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "    WITH filtered_results AS (\n",
      "        SELECT *,\n",
      "            fts_main_places_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM places_search\n",
      "        WHERE ((admin0_code = 'FR' AND admin1_code = '11' AND admin2_code = '77' AND admin3_code = '771' AND admin4_code = '77363') OR (admin0_code = 'FR' AND admin1_code = '24' AND admin2_code = '36' AND admin3_code = '362' AND admin4_code = '36159') OR (admin0_code = 'FR' AND admin1_code = '32' AND admin2_code = '62' AND admin3_code = '624' AND admin4_code = '62647') OR (admin0_code = 'FR' AND admin1_code = '84' AND admin2_code = '07' AND admin3_code = '072' AND admin4_code = '07181') OR (admin0_code = 'FR' AND admin1_code = '52' AND admin2_code = '85' AND admin3_code = '851' AND admin4_code = '85031') OR (admin0_code = 'FR' AND admin1_code = '24' AND admin2_code = '36' AND admin3_code = '362' AND admin4_code = '36154') OR (admin0_code = 'FR' AND admin1_code = '52' AND admin2_code = '44' AND admin3_code = '445' AND admin4_code = '44062') OR (admin0_code = 'FR' AND admin1_code = '84' AND admin2_code = '69' AND admin3_code = '692' AND admin4_code = '69151') OR (admin0_code = 'FR' AND admin1_code = '84' AND admin2_code = '07' AND admin3_code = '072' AND admin4_code = '07319') OR (admin0_code = 'FR' AND admin1_code = '32' AND admin2_code = '62' AND admin3_code = '623' AND admin4_code = '62667') OR (admin0_code = 'FR' AND admin1_code = '84' AND admin2_code = '15' AND admin3_code = '152' AND admin4_code = '15261') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '832' AND admin4_code = '83070') OR (admin0_code = 'FR' AND admin1_code = '84' AND admin2_code = '38' AND admin3_code = '381' AND admin4_code = '38511') OR (admin0_code = 'FR' AND admin1_code = '84' AND admin2_code = '07' AND admin3_code = '073' AND admin4_code = '07064') OR (admin0_code = 'FR' AND admin1_code = '84' AND admin2_code = '43' AND admin3_code = '432' AND admin4_code = '43140') OR (admin0_code = 'FR' AND admin1_code = '52' AND admin2_code = '44' AND admin3_code = '445' AND admin4_code = '44028') OR (admin0_code = 'FR' AND admin1_code = '11' AND admin2_code = '78' AND admin3_code = '783' AND admin4_code = '78396') OR (admin0_code = 'FR' AND admin1_code = '11' AND admin2_code = '78' AND admin3_code = '783' AND admin4_code = '78650') OR (admin0_code = 'FR' AND admin1_code = '11' AND admin2_code = '77' AND admin3_code = '774' AND admin4_code = '77485') OR (admin0_code = 'FR' AND admin1_code = '52' AND admin2_code = '44' AND admin3_code = '442' AND admin4_code = '44014')) AND importance_tier <= 5\n",
      "    )\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC,\n",
      "        importance_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:21.727\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m289\u001b[0m - \u001b[34m\u001b[1mFound 54 results\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:21.727\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m311\u001b[0m - \u001b[34m\u001b[1mJoining place results with parent admin scores on: ['admin0_code', 'admin1_code', 'admin2_code', 'admin3_code', 'admin4_code']\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:21.728\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m317\u001b[0m - \u001b[34m\u001b[1mShape after joining with parent scores: (54, 21)\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:21.731\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m15\u001b[0m - \u001b[34m\u001b[1mAdmin1 results:\u001b[0m\n",
      "\u001b[32m2025-05-07 13:45:21.732\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m28\u001b[0m - \u001b[34m\u001b[1mAdmin4 results:\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (10, 33)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ geonameId ┆ name      ┆ asciiname ┆ admin_lev ┆ … ┆ average_p ┆ parent_fa ┆ base_scor ┆ adjusted │\n",
      "│ ---       ┆ ---       ┆ ---       ┆ el        ┆   ┆ arent_sco ┆ ctor      ┆ e         ┆ _score_1 │\n",
      "│ u32       ┆ str       ┆ str       ┆ ---       ┆   ┆ re        ┆ ---       ┆ ---       ┆ ---      │\n",
      "│           ┆           ┆           ┆ u8        ┆   ┆ ---       ┆ f64       ┆ f64       ┆ f64      │\n",
      "│           ┆           ┆           ┆           ┆   ┆ f64       ┆           ┆           ┆          │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ 2985244   ┆ Provence- ┆ Provence- ┆ 1         ┆ … ┆ 0.746891  ┆ 1.0       ┆ 0.869319  ┆ 0.81716  │\n",
      "│           ┆ Alpes-Côt ┆ Alpes-Cot ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ e d'Azur  ┆ e d'Azur  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 2983751   ┆ Rhône-Alp ┆ Rhone-Alp ┆ 1         ┆ … ┆ 0.746891  ┆ 1.0       ┆ 0.73502   ┆ 0.690918 │\n",
      "│           ┆ es        ┆ es        ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 11071625  ┆ Auvergne- ┆ Auvergne- ┆ 1         ┆ … ┆ 0.746891  ┆ 1.0       ┆ 0.708504  ┆ 0.665994 │\n",
      "│           ┆ Rhône-Alp ┆ Rhone-Alp ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ es        ┆ es        ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 11071624  ┆ Hauts-de- ┆ Hauts-de- ┆ 1         ┆ … ┆ 0.746891  ┆ 1.0       ┆ 0.607866  ┆ 0.571394 │\n",
      "│           ┆ France    ┆ France    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 3012874   ┆ Île-de-Fr ┆ Ile-de-Fr ┆ 1         ┆ … ┆ 0.746891  ┆ 1.0       ┆ 0.605335  ┆ 0.569015 │\n",
      "│           ┆ ance      ┆ ance      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 2988289   ┆ Pays de   ┆ Pays de   ┆ 1         ┆ … ┆ 0.746891  ┆ 1.0       ┆ 0.605125  ┆ 0.568817 │\n",
      "│           ┆ la Loire  ┆ la Loire  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 3027939   ┆ Centre-Va ┆ Centre-Va ┆ 1         ┆ … ┆ 0.746891  ┆ 1.0       ┆ 0.604934  ┆ 0.568638 │\n",
      "│           ┆ l de      ┆ l de      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ Loire     ┆ Loire     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 2990119   ┆ Nord-Pas- ┆ Nord-Pas- ┆ 1         ┆ … ┆ 0.746891  ┆ 1.0       ┆ 0.599649  ┆ 0.563671 │\n",
      "│           ┆ de-Calais ┆ de-Calais ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 8378478   ┆ Alpes     ┆ Alpes     ┆ 1         ┆ … ┆ 0.746891  ┆ 1.0       ┆ 0.55539   ┆ 0.522067 │\n",
      "│           ┆ Maritimae ┆ Maritimae ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 8378477   ┆ Alpes     ┆ Alpes     ┆ 1         ┆ … ┆ 0.746891  ┆ 1.0       ┆ 0.546637  ┆ 0.513839 │\n",
      "│           ┆ Graiae    ┆ Graiae    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n",
      "shape: (20, 34)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ geonameId ┆ name      ┆ asciiname ┆ admin_lev ┆ … ┆ average_p ┆ parent_fa ┆ base_scor ┆ adjusted │\n",
      "│ ---       ┆ ---       ┆ ---       ┆ el        ┆   ┆ arent_sco ┆ ctor      ┆ e         ┆ _score_4 │\n",
      "│ u32       ┆ str       ┆ str       ┆ ---       ┆   ┆ re        ┆ ---       ┆ ---       ┆ ---      │\n",
      "│           ┆           ┆           ┆ u8        ┆   ┆ ---       ┆ f64       ┆ f64       ┆ f64      │\n",
      "│           ┆           ┆           ┆           ┆   ┆ f64       ┆           ┆           ┆          │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ 6615009   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.777183  ┆ 0.730552 │\n",
      "│           ┆ Lavandou  ┆ Lavandou  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 6456500   ┆ Le Mesnil ┆ Le Mesnil ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.596345  ┆ 0.560564 │\n",
      "│           ┆ -le-Roi   ┆ -le-Roi   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 6455417   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.596114  ┆ 0.560347 │\n",
      "│           ┆ Vésinet   ┆ Vesinet   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 6455917   ┆ Le Poinço ┆ Le Poinco ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.586711  ┆ 0.551508 │\n",
      "│           ┆ nnet      ┆ nnet      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 6618343   ┆ Le Portel ┆ Le Portel ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.582675  ┆ 0.547714 │\n",
      "│ 6618158   ┆ Le Teil   ┆ Le Teil   ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.581927  ┆ 0.547012 │\n",
      "│ 6457137   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.580175  ┆ 0.545364 │\n",
      "│           ┆ Boupère   ┆ Boupere   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 6456350   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.57766   ┆ 0.543001 │\n",
      "│           ┆ Perréon   ┆ Perreon   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 6455915   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.574354  ┆ 0.539893 │\n",
      "│           ┆ Pêchereau ┆ Pechereau ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 6456917   ┆ Le Gâvre  ┆ Le Gavre  ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.573856  ┆ 0.539424 │\n",
      "│ 6616805   ┆ Le Bignon ┆ Le Bignon ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.573582  ┆ 0.539167 │\n",
      "│ 6614417   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.573525  ┆ 0.539113 │\n",
      "│           ┆ Cellier   ┆ Cellier   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 6455958   ┆ Le Touvet ┆ Le Touvet ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.572168  ┆ 0.537838 │\n",
      "│ 6456682   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.570826  ┆ 0.536577 │\n",
      "│           ┆ Cheylard  ┆ Cheylard  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 6613182   ┆ Le Pouzin ┆ Le Pouzin ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.570765  ┆ 0.53652  │\n",
      "│ 6456485   ┆ Le Pin    ┆ Le Pin    ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.564502  ┆ 0.530632 │\n",
      "│ 6456492   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.563099  ┆ 0.529313 │\n",
      "│           ┆ Vaudoué   ┆ Vaudoue   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 6455608   ┆ Le Vigean ┆ Le Vigean ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.555921  ┆ 0.522565 │\n",
      "│ 6618346   ┆ Le Parcq  ┆ Le Parcq  ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.555371  ┆ 0.522048 │\n",
      "│ 6616793   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.553067  ┆ 0.519883 │\n",
      "│           ┆ Monteil   ┆ Monteil   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (20, 34)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>asciiname</th><th>admin_level</th><th>admin0_code</th><th>admin1_code</th><th>admin2_code</th><th>admin3_code</th><th>admin4_code</th><th>feature_class</th><th>feature_code</th><th>ISO</th><th>ISO3</th><th>ISO_Numeric</th><th>official_name</th><th>fips</th><th>latitude</th><th>longitude</th><th>population</th><th>area</th><th>alternatenames</th><th>country_name</th><th>fts_score_4</th><th>parent_adjusted_score_0</th><th>parent_adjusted_score_1</th><th>z_score</th><th>text_score</th><th>pop_score</th><th>feature_score</th><th>country_score</th><th>average_parent_score</th><th>parent_factor</th><th>base_score</th><th>adjusted_score_4</th></tr><tr><td>u32</td><td>str</td><td>str</td><td>u8</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>u16</td><td>str</td><td>str</td><td>f32</td><td>f32</td><td>i32</td><td>f32</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>6615009</td><td>&quot;Le Lavandou&quot;</td><td>&quot;Le Lavandou&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;832&quot;</td><td>&quot;83070&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>43.137779</td><td>6.36778</td><td>5759</td><td>null</td><td>&quot;83070,Le Lavandou&quot;</td><td>&quot;Republic of France&quot;</td><td>12.610318</td><td>0.746891</td><td>0.81716</td><td>6.086062</td><td>1.0</td><td>0.556236</td><td>0.55</td><td>0.8</td><td>0.782025</td><td>1.0</td><td>0.777183</td><td>0.730552</td></tr><tr><td>6456500</td><td>&quot;Le Mesnil-le-Roi&quot;</td><td>&quot;Le Mesnil-le-Roi&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;11&quot;</td><td>&quot;78&quot;</td><td>&quot;783&quot;</td><td>&quot;78396&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>48.936668</td><td>2.12667</td><td>6276</td><td>null</td><td>&quot;78396,Le Mesnil-le-Roi&quot;</td><td>&quot;Republic of France&quot;</td><td>3.822629</td><td>0.746891</td><td>0.81716</td><td>-0.051004</td><td>0.480883</td><td>0.558673</td><td>0.55</td><td>0.8</td><td>0.782025</td><td>1.0</td><td>0.596345</td><td>0.560564</td></tr><tr><td>6455417</td><td>&quot;Le Vésinet&quot;</td><td>&quot;Le Vesinet&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;11&quot;</td><td>&quot;78&quot;</td><td>&quot;783&quot;</td><td>&quot;78650&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>48.89389</td><td>2.13222</td><td>16047</td><td>null</td><td>&quot;78650,Le Vesinet,Le Vésinet&quot;</td><td>&quot;Republic of France&quot;</td><td>3.724332</td><td>0.746891</td><td>0.81716</td><td>-0.119651</td><td>0.455251</td><td>0.583645</td><td>0.55</td><td>0.8</td><td>0.782025</td><td>1.0</td><td>0.596114</td><td>0.560347</td></tr><tr><td>6455917</td><td>&quot;Le Poinçonnet&quot;</td><td>&quot;Le Poinconnet&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;24&quot;</td><td>&quot;36&quot;</td><td>&quot;362&quot;</td><td>&quot;36159&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>46.763889</td><td>1.71889</td><td>5870</td><td>null</td><td>&quot;36159,Le Poinconnet,Le Poinçon…</td><td>&quot;Republic of France&quot;</td><td>3.724332</td><td>0.746891</td><td>0.81716</td><td>-0.119651</td><td>0.455251</td><td>0.556779</td><td>0.55</td><td>0.8</td><td>0.782025</td><td>1.0</td><td>0.586711</td><td>0.551508</td></tr><tr><td>6618343</td><td>&quot;Le Portel&quot;</td><td>&quot;Le Portel&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;32&quot;</td><td>&quot;62&quot;</td><td>&quot;623&quot;</td><td>&quot;62667&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>50.706902</td><td>1.574</td><td>9262</td><td>null</td><td>&quot;62667,Le Portel&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.81716</td><td>-0.184857</td><td>0.431119</td><td>0.56938</td><td>0.55</td><td>0.8</td><td>0.782025</td><td>1.0</td><td>0.582675</td><td>0.547714</td></tr><tr><td>6618158</td><td>&quot;Le Teil&quot;</td><td>&quot;Le Teil&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;84&quot;</td><td>&quot;07&quot;</td><td>&quot;072&quot;</td><td>&quot;07319&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>44.545502</td><td>4.6826</td><td>8557</td><td>null</td><td>&quot;07319,Le Teil&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.81716</td><td>-0.184857</td><td>0.431119</td><td>0.567245</td><td>0.55</td><td>0.8</td><td>0.782025</td><td>1.0</td><td>0.581927</td><td>0.547012</td></tr><tr><td>6457137</td><td>&quot;Le Boupère&quot;</td><td>&quot;Le Boupere&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;52&quot;</td><td>&quot;85&quot;</td><td>&quot;851&quot;</td><td>&quot;85031&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>46.79472</td><td>-0.92639</td><td>3126</td><td>null</td><td>&quot;85031,Le Boupere,Le Boupère&quot;</td><td>&quot;Republic of France&quot;</td><td>3.724332</td><td>0.746891</td><td>0.81716</td><td>-0.119651</td><td>0.455251</td><td>0.538105</td><td>0.55</td><td>0.8</td><td>0.782025</td><td>1.0</td><td>0.580175</td><td>0.545364</td></tr><tr><td>6456350</td><td>&quot;Le Perréon&quot;</td><td>&quot;Le Perreon&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;84&quot;</td><td>&quot;69&quot;</td><td>&quot;692&quot;</td><td>&quot;69151&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>46.063061</td><td>4.60056</td><td>1566</td><td>null</td><td>&quot;69151,Le Perreyon,Le Pèrreyon,…</td><td>&quot;Republic of France&quot;</td><td>3.782694</td><td>0.746891</td><td>0.81716</td><td>-0.078893</td><td>0.47045</td><td>0.515722</td><td>0.55</td><td>0.8</td><td>0.782025</td><td>1.0</td><td>0.57766</td><td>0.543001</td></tr><tr><td>6455915</td><td>&quot;Le Pêchereau&quot;</td><td>&quot;Le Pechereau&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;24&quot;</td><td>&quot;36&quot;</td><td>&quot;362&quot;</td><td>&quot;36154&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>46.57806</td><td>1.5475</td><td>1859</td><td>null</td><td>&quot;36154,Le Pechereau,Le Pêcherea…</td><td>&quot;Republic of France&quot;</td><td>3.724332</td><td>0.746891</td><td>0.81716</td><td>-0.119651</td><td>0.455251</td><td>0.521476</td><td>0.55</td><td>0.8</td><td>0.782025</td><td>1.0</td><td>0.574354</td><td>0.539893</td></tr><tr><td>6456917</td><td>&quot;Le Gâvre&quot;</td><td>&quot;Le Gavre&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;52&quot;</td><td>&quot;44&quot;</td><td>&quot;445&quot;</td><td>&quot;44062&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>47.520561</td><td>-1.74861</td><td>1781</td><td>null</td><td>&quot;44062,Le Gavre,Le Gâvre&quot;</td><td>&quot;Republic of France&quot;</td><td>3.724332</td><td>0.746891</td><td>0.81716</td><td>-0.119651</td><td>0.455251</td><td>0.520051</td><td>0.55</td><td>0.8</td><td>0.782025</td><td>1.0</td><td>0.573856</td><td>0.539424</td></tr><tr><td>6616805</td><td>&quot;Le Bignon&quot;</td><td>&quot;Le Bignon&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;52&quot;</td><td>&quot;44&quot;</td><td>&quot;442&quot;</td><td>&quot;44014&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>47.098801</td><td>-1.4896</td><td>3718</td><td>null</td><td>&quot;44014,Le Bignon&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.81716</td><td>-0.184857</td><td>0.431119</td><td>0.5434</td><td>0.55</td><td>0.8</td><td>0.782025</td><td>1.0</td><td>0.573582</td><td>0.539167</td></tr><tr><td>6614417</td><td>&quot;Le Cellier&quot;</td><td>&quot;Le Cellier&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;52&quot;</td><td>&quot;44&quot;</td><td>&quot;445&quot;</td><td>&quot;44028&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>47.319439</td><td>-1.34639</td><td>3698</td><td>null</td><td>&quot;44028,Le Cellier&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.81716</td><td>-0.184857</td><td>0.431119</td><td>0.543238</td><td>0.55</td><td>0.8</td><td>0.782025</td><td>1.0</td><td>0.573525</td><td>0.539113</td></tr><tr><td>6455958</td><td>&quot;Le Touvet&quot;</td><td>&quot;Le Touvet&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;84&quot;</td><td>&quot;38&quot;</td><td>&quot;381&quot;</td><td>&quot;38511&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>45.357498</td><td>5.94806</td><td>3256</td><td>null</td><td>&quot;38511,Le Touvet&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.81716</td><td>-0.184857</td><td>0.431119</td><td>0.53936</td><td>0.55</td><td>0.8</td><td>0.782025</td><td>1.0</td><td>0.572168</td><td>0.537838</td></tr><tr><td>6456682</td><td>&quot;Le Cheylard&quot;</td><td>&quot;Le Cheylard&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;84&quot;</td><td>&quot;07&quot;</td><td>&quot;073&quot;</td><td>&quot;07064&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>44.905281</td><td>4.42222</td><td>2877</td><td>null</td><td>&quot;07064,Le Cheylard&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.81716</td><td>-0.184857</td><td>0.431119</td><td>0.535527</td><td>0.55</td><td>0.8</td><td>0.782025</td><td>1.0</td><td>0.570826</td><td>0.536577</td></tr><tr><td>6613182</td><td>&quot;Le Pouzin&quot;</td><td>&quot;Le Pouzin&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;84&quot;</td><td>&quot;07&quot;</td><td>&quot;072&quot;</td><td>&quot;07181&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>44.75333</td><td>4.74778</td><td>2861</td><td>null</td><td>&quot;07181,Le Pouzin&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.81716</td><td>-0.184857</td><td>0.431119</td><td>0.535353</td><td>0.55</td><td>0.8</td><td>0.782025</td><td>1.0</td><td>0.570765</td><td>0.53652</td></tr><tr><td>6456485</td><td>&quot;Le Pin&quot;</td><td>&quot;Le Pin&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;11&quot;</td><td>&quot;77&quot;</td><td>&quot;771&quot;</td><td>&quot;77363&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>48.91444</td><td>2.62917</td><td>1407</td><td>null</td><td>&quot;77363,Le Pin,Le-Pen,Pin,Ле-Пен&quot;</td><td>&quot;Republic of France&quot;</td><td>3.651942</td><td>0.746891</td><td>0.81716</td><td>-0.170206</td><td>0.436517</td><td>0.51206</td><td>0.55</td><td>0.8</td><td>0.782025</td><td>1.0</td><td>0.564502</td><td>0.530632</td></tr><tr><td>6456492</td><td>&quot;Le Vaudoué&quot;</td><td>&quot;Le Vaudoue&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;11&quot;</td><td>&quot;77&quot;</td><td>&quot;774&quot;</td><td>&quot;77485&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>48.356941</td><td>2.51889</td><td>749</td><td>null</td><td>&quot;77485,Le Vaudoue,Le Vaudoué&quot;</td><td>&quot;Republic of France&quot;</td><td>3.724332</td><td>0.746891</td><td>0.81716</td><td>-0.119651</td><td>0.455251</td><td>0.489317</td><td>0.55</td><td>0.8</td><td>0.782025</td><td>1.0</td><td>0.563099</td><td>0.529313</td></tr><tr><td>6455608</td><td>&quot;Le Vigean&quot;</td><td>&quot;Le Vigean&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;84&quot;</td><td>&quot;15&quot;</td><td>&quot;152&quot;</td><td>&quot;15261&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>45.227089</td><td>2.35245</td><td>825</td><td>null</td><td>&quot;15261,Le Vigean&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.81716</td><td>-0.184857</td><td>0.431119</td><td>0.49294</td><td>0.55</td><td>0.8</td><td>0.782025</td><td>1.0</td><td>0.555921</td><td>0.522565</td></tr><tr><td>6618346</td><td>&quot;Le Parcq&quot;</td><td>&quot;Le Parcq&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;32&quot;</td><td>&quot;62&quot;</td><td>&quot;624&quot;</td><td>&quot;62647&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>50.379299</td><td>2.1005</td><td>791</td><td>null</td><td>&quot;62647,Le Parcq&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.81716</td><td>-0.184857</td><td>0.431119</td><td>0.491368</td><td>0.55</td><td>0.8</td><td>0.782025</td><td>1.0</td><td>0.555371</td><td>0.522048</td></tr><tr><td>6616793</td><td>&quot;Le Monteil&quot;</td><td>&quot;Le Monteil&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;84&quot;</td><td>&quot;43&quot;</td><td>&quot;432&quot;</td><td>&quot;43140&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>45.065479</td><td>3.91357</td><td>665</td><td>null</td><td>&quot;43140,Le Monteil&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.81716</td><td>-0.184857</td><td>0.431119</td><td>0.484786</td><td>0.55</td><td>0.8</td><td>0.782025</td><td>1.0</td><td>0.553067</td><td>0.519883</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (20, 34)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ geonameId ┆ name      ┆ asciiname ┆ admin_lev ┆ … ┆ average_p ┆ parent_fa ┆ base_scor ┆ adjusted │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ el        ┆   ┆ arent_sco ┆ ctor      ┆ e         ┆ _score_4 │\n",
       "│ u32       ┆ str       ┆ str       ┆ ---       ┆   ┆ re        ┆ ---       ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆           ┆ u8        ┆   ┆ ---       ┆ f64       ┆ f64       ┆ f64      │\n",
       "│           ┆           ┆           ┆           ┆   ┆ f64       ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 6615009   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.777183  ┆ 0.730552 │\n",
       "│           ┆ Lavandou  ┆ Lavandou  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6456500   ┆ Le Mesnil ┆ Le Mesnil ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.596345  ┆ 0.560564 │\n",
       "│           ┆ -le-Roi   ┆ -le-Roi   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6455417   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.596114  ┆ 0.560347 │\n",
       "│           ┆ Vésinet   ┆ Vesinet   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6455917   ┆ Le Poinço ┆ Le Poinco ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.586711  ┆ 0.551508 │\n",
       "│           ┆ nnet      ┆ nnet      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6618343   ┆ Le Portel ┆ Le Portel ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.582675  ┆ 0.547714 │\n",
       "│ 6618158   ┆ Le Teil   ┆ Le Teil   ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.581927  ┆ 0.547012 │\n",
       "│ 6457137   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.580175  ┆ 0.545364 │\n",
       "│           ┆ Boupère   ┆ Boupere   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6456350   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.57766   ┆ 0.543001 │\n",
       "│           ┆ Perréon   ┆ Perreon   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6455915   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.574354  ┆ 0.539893 │\n",
       "│           ┆ Pêchereau ┆ Pechereau ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6456917   ┆ Le Gâvre  ┆ Le Gavre  ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.573856  ┆ 0.539424 │\n",
       "│ 6616805   ┆ Le Bignon ┆ Le Bignon ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.573582  ┆ 0.539167 │\n",
       "│ 6614417   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.573525  ┆ 0.539113 │\n",
       "│           ┆ Cellier   ┆ Cellier   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6455958   ┆ Le Touvet ┆ Le Touvet ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.572168  ┆ 0.537838 │\n",
       "│ 6456682   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.570826  ┆ 0.536577 │\n",
       "│           ┆ Cheylard  ┆ Cheylard  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6613182   ┆ Le Pouzin ┆ Le Pouzin ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.570765  ┆ 0.53652  │\n",
       "│ 6456485   ┆ Le Pin    ┆ Le Pin    ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.564502  ┆ 0.530632 │\n",
       "│ 6456492   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.563099  ┆ 0.529313 │\n",
       "│           ┆ Vaudoué   ┆ Vaudoue   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6455608   ┆ Le Vigean ┆ Le Vigean ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.555921  ┆ 0.522565 │\n",
       "│ 6618346   ┆ Le Parcq  ┆ Le Parcq  ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.555371  ┆ 0.522048 │\n",
       "│ 6616793   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.553067  ┆ 0.519883 │\n",
       "│           ┆ Monteil   ┆ Monteil   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = [\"FR\", \"Provence-Alpes-Côte d'Azur\", None, None, \"Le Lavandou\", None]\n",
    "search_terms = AdminHierarchy.from_list(st)\n",
    "# Search through the admin hierarchy\n",
    "results = hierarchical_search(\n",
    "    search_terms,\n",
    "    con=con,\n",
    "    all_cols=True,\n",
    ")\n",
    "\n",
    "# Access results for each level\n",
    "if \"country\" in results:\n",
    "    logger.debug(\"Country results:\")\n",
    "    print(results[\"country\"])\n",
    "if \"admin1\" in results:\n",
    "    logger.debug(\"Admin1 results:\")\n",
    "    print(results[\"admin1\"])\n",
    "if \"admin2\" in results:\n",
    "    logger.debug(\n",
    "        \"Admin2 results:\",\n",
    "    )\n",
    "    print(results[\"admin2\"])\n",
    "if \"admin3\" in results:\n",
    "    logger.debug(\n",
    "        \"Admin3 results:\",\n",
    "    )\n",
    "    print(results[\"admin3\"])\n",
    "if \"admin4\" in results:\n",
    "    logger.debug(\n",
    "        \"Admin4 results:\",\n",
    "    )\n",
    "    print(results[\"admin4\"])\n",
    "results[\"admin4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (20, 29)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>asciiname</th><th>admin0_code</th><th>admin1_code</th><th>admin2_code</th><th>admin3_code</th><th>admin4_code</th><th>feature_class</th><th>feature_code</th><th>feature_name</th><th>latitude</th><th>longitude</th><th>population</th><th>elevation</th><th>alternatenames</th><th>country_name</th><th>importance_score</th><th>importance_tier</th><th>fts_score</th><th>parent_adjusted_score_4</th><th>z_score</th><th>text_score</th><th>importance_norm</th><th>feature_score</th><th>distance_km</th><th>distance_score</th><th>parent_admin_factor</th><th>place_score</th></tr><tr><td>u32</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f32</td><td>f32</td><td>i32</td><td>i16</td><td>str</td><td>str</td><td>f32</td><td>u8</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f32</td><td>f64</td><td>f32</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>11101524</td><td>&quot;Port du Lavandou&quot;</td><td>&quot;Port du Lavandou&quot;</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;832&quot;</td><td>&quot;83070&quot;</td><td>&quot;L&quot;</td><td>&quot;PRT&quot;</td><td>&quot;port&quot;</td><td>43.137039</td><td>6.37447</td><td>0</td><td>null</td><td>null</td><td>&quot;France&quot;</td><td>0.485</td><td>3</td><td>9.058121</td><td>0.730552</td><td>3.210655</td><td>0.991966</td><td>0.485</td><td>0.8</td><td>519.354553</td><td>0.000031</td><td>0.730552</td><td>0.685746</td></tr><tr><td>3003713</td><td>&quot;Le Lavandou&quot;</td><td>&quot;Le Lavandou&quot;</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;832&quot;</td><td>&quot;83070&quot;</td><td>&quot;P&quot;</td><td>&quot;PPL&quot;</td><td>&quot;populated place&quot;</td><td>43.137001</td><td>6.366</td><td>5902</td><td>0</td><td>&quot;Le-Lavandu,Lo Lavandor,lai la …</td><td>&quot;France&quot;</td><td>0.33855</td><td>4</td><td>10.777037</td><td>0.730552</td><td>4.295851</td><td>1.0</td><td>0.33855</td><td>0.85</td><td>518.957642</td><td>0.000031</td><td>0.730552</td><td>0.586911</td></tr><tr><td>8286976</td><td>&quot;Le Cellier Railway Station&quot;</td><td>&quot;Le Cellier Railway Station&quot;</td><td>&quot;FR&quot;</td><td>&quot;52&quot;</td><td>&quot;44&quot;</td><td>&quot;445&quot;</td><td>&quot;44028&quot;</td><td>&quot;S&quot;</td><td>&quot;RSTN&quot;</td><td>&quot;railroad station&quot;</td><td>47.313099</td><td>-1.35116</td><td>0</td><td>null</td><td>&quot;87481168&quot;</td><td>&quot;France&quot;</td><td>0.635</td><td>2</td><td>3.357349</td><td>0.539113</td><td>-0.388389</td><td>0.358338</td><td>0.635</td><td>0.8</td><td>287.803772</td><td>0.003164</td><td>0.539113</td><td>0.539161</td></tr><tr><td>8288376</td><td>&quot;Le Teil (Ardèche) Railway Stat…</td><td>&quot;Le Teil (Ardeche) Railway Stat…</td><td>&quot;FR&quot;</td><td>&quot;84&quot;</td><td>&quot;07&quot;</td><td>&quot;072&quot;</td><td>&quot;07319&quot;</td><td>&quot;S&quot;</td><td>&quot;RSTN&quot;</td><td>&quot;railroad station&quot;</td><td>44.553188</td><td>4.68665</td><td>0</td><td>null</td><td>&quot;87764472&quot;</td><td>&quot;France&quot;</td><td>0.635</td><td>2</td><td>3.116837</td><td>0.547012</td><td>-0.540231</td><td>0.307817</td><td>0.635</td><td>0.8</td><td>312.754517</td><td>0.001921</td><td>0.547012</td><td>0.520442</td></tr><tr><td>8297160</td><td>&quot;Bureau de Poste de Le Lavandou&quot;</td><td>&quot;Bureau de Poste de Le Lavandou&quot;</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;832&quot;</td><td>&quot;83070&quot;</td><td>&quot;S&quot;</td><td>&quot;PO&quot;</td><td>&quot;post office&quot;</td><td>43.138111</td><td>6.36815</td><td>0</td><td>null</td><td>null</td><td>&quot;France&quot;</td><td>0.33</td><td>4</td><td>10.18779</td><td>0.730552</td><td>3.923844</td><td>1.0</td><td>0.33</td><td>0.3</td><td>518.958862</td><td>0.000031</td><td>0.730552</td><td>0.510352</td></tr><tr><td>2998854</td><td>&quot;Le Vésinet&quot;</td><td>&quot;Le Vesinet&quot;</td><td>&quot;FR&quot;</td><td>&quot;11&quot;</td><td>&quot;78&quot;</td><td>&quot;783&quot;</td><td>&quot;78650&quot;</td><td>&quot;P&quot;</td><td>&quot;PPL&quot;</td><td>&quot;populated place&quot;</td><td>48.892811</td><td>2.13308</td><td>16740</td><td>null</td><td>&quot;Le Vesinet,Le Vésinet,Le-Vezin…</td><td>&quot;France&quot;</td><td>0.361188</td><td>4</td><td>4.352088</td><td>0.560347</td><td>0.239615</td><td>0.588901</td><td>0.361188</td><td>0.85</td><td>226.214035</td><td>0.010843</td><td>0.560347</td><td>0.449181</td></tr><tr><td>3002626</td><td>&quot;Le Poinçonnet&quot;</td><td>&quot;Le Poinconnet&quot;</td><td>&quot;FR&quot;</td><td>&quot;24&quot;</td><td>&quot;36&quot;</td><td>&quot;362&quot;</td><td>&quot;36159&quot;</td><td>&quot;P&quot;</td><td>&quot;PPL&quot;</td><td>&quot;populated place&quot;</td><td>46.764099</td><td>1.7179</td><td>5120</td><td>null</td><td>&quot;Le Poinconnet,Le Poinçonnet,Le…</td><td>&quot;France&quot;</td><td>0.335463</td><td>4</td><td>3.995173</td><td>0.551508</td><td>0.014286</td><td>0.505357</td><td>0.335463</td><td>0.85</td><td>52.650066</td><td>0.348889</td><td>0.551508</td><td>0.445548</td></tr><tr><td>3003375</td><td>&quot;Le Mesnil-le-Roi&quot;</td><td>&quot;Le Mesnil-le-Roi&quot;</td><td>&quot;FR&quot;</td><td>&quot;11&quot;</td><td>&quot;78&quot;</td><td>&quot;783&quot;</td><td>&quot;78396&quot;</td><td>&quot;P&quot;</td><td>&quot;PPL&quot;</td><td>&quot;populated place&quot;</td><td>48.938251</td><td>2.12554</td><td>6515</td><td>null</td><td>&quot;Le Mesnil,Le Mesnil-le-Roi,Le-…</td><td>&quot;France&quot;</td><td>0.340696</td><td>4</td><td>4.331167</td><td>0.560564</td><td>0.226407</td><td>0.584096</td><td>0.340696</td><td>0.85</td><td>231.295685</td><td>0.009795</td><td>0.560564</td><td>0.44206</td></tr><tr><td>3002966</td><td>&quot;Le Perréon&quot;</td><td>&quot;Le Perreon&quot;</td><td>&quot;FR&quot;</td><td>&quot;84&quot;</td><td>&quot;69&quot;</td><td>&quot;692&quot;</td><td>&quot;69151&quot;</td><td>&quot;P&quot;</td><td>&quot;PPL&quot;</td><td>&quot;populated place&quot;</td><td>46.06316</td><td>4.60045</td><td>1085</td><td>null</td><td>&quot;Le Perreon,Le Perréon&quot;</td><td>&quot;France&quot;</td><td>0.301771</td><td>4</td><td>4.391475</td><td>0.543001</td><td>0.264481</td><td>0.5979</td><td>0.301771</td><td>0.85</td><td>191.138992</td><td>0.021867</td><td>0.543001</td><td>0.435405</td></tr><tr><td>2998934</td><td>&quot;Le Vaudoué&quot;</td><td>&quot;Le Vaudoue&quot;</td><td>&quot;FR&quot;</td><td>&quot;11&quot;</td><td>&quot;77&quot;</td><td>&quot;774&quot;</td><td>&quot;77485&quot;</td><td>&quot;P&quot;</td><td>&quot;PPL&quot;</td><td>&quot;populated place&quot;</td><td>48.356991</td><td>2.51838</td><td>787</td><td>null</td><td>&quot;Le Vaudoue,Le Vaudoué&quot;</td><td>&quot;France&quot;</td><td>0.294799</td><td>4</td><td>4.391475</td><td>0.529313</td><td>0.264481</td><td>0.5979</td><td>0.294799</td><td>0.85</td><td>166.061737</td><td>0.036108</td><td>0.529313</td><td>0.433572</td></tr><tr><td>3002808</td><td>&quot;Le Pin&quot;</td><td>&quot;Le Pin&quot;</td><td>&quot;FR&quot;</td><td>&quot;11&quot;</td><td>&quot;77&quot;</td><td>&quot;771&quot;</td><td>&quot;77363&quot;</td><td>&quot;P&quot;</td><td>&quot;PPL&quot;</td><td>&quot;populated place&quot;</td><td>48.91523</td><td>2.62841</td><td>1137</td><td>null</td><td>&quot;Le Pin&quot;</td><td>&quot;France&quot;</td><td>0.302788</td><td>4</td><td>4.311449</td><td>0.530632</td><td>0.213959</td><td>0.579553</td><td>0.302788</td><td>0.85</td><td>228.54277</td><td>0.010349</td><td>0.530632</td><td>0.42775</td></tr><tr><td>2998809</td><td>&quot;Le Vigean&quot;</td><td>&quot;Le Vigean&quot;</td><td>&quot;FR&quot;</td><td>&quot;84&quot;</td><td>&quot;15&quot;</td><td>&quot;152&quot;</td><td>&quot;15261&quot;</td><td>&quot;P&quot;</td><td>&quot;PPL&quot;</td><td>&quot;populated place&quot;</td><td>45.22691</td><td>2.35356</td><td>893</td><td>null</td><td>&quot;Le Vigean&quot;</td><td>&quot;France&quot;</td><td>0.297543</td><td>4</td><td>4.311449</td><td>0.522565</td><td>0.213959</td><td>0.579553</td><td>0.297543</td><td>0.85</td><td>182.277191</td><td>0.026107</td><td>0.522565</td><td>0.427026</td></tr><tr><td>3002986</td><td>&quot;Le Pêchereau&quot;</td><td>&quot;Le Pechereau&quot;</td><td>&quot;FR&quot;</td><td>&quot;24&quot;</td><td>&quot;36&quot;</td><td>&quot;362&quot;</td><td>&quot;36154&quot;</td><td>&quot;P&quot;</td><td>&quot;PPL&quot;</td><td>&quot;populated place&quot;</td><td>46.576771</td><td>1.54743</td><td>1906</td><td>null</td><td>&quot;Le Pechereau,Le Pêchereau,Le-P…</td><td>&quot;France&quot;</td><td>0.314006</td><td>4</td><td>3.956341</td><td>0.539893</td><td>-0.01023</td><td>0.496164</td><td>0.314006</td><td>0.85</td><td>72.071701</td><td>0.236588</td><td>0.539893</td><td>0.425707</td></tr><tr><td>2999259</td><td>&quot;Le Teil&quot;</td><td>&quot;Le Teil&quot;</td><td>&quot;FR&quot;</td><td>&quot;84&quot;</td><td>&quot;07&quot;</td><td>&quot;072&quot;</td><td>&quot;07319&quot;</td><td>&quot;P&quot;</td><td>&quot;PPL&quot;</td><td>&quot;populated place&quot;</td><td>44.545311</td><td>4.68223</td><td>8620</td><td>null</td><td>&quot;Le Teil,Le-Tej,Lo Telh,lei tai…</td><td>&quot;France&quot;</td><td>0.346775</td><td>4</td><td>3.988863</td><td>0.547012</td><td>0.010302</td><td>0.503863</td><td>0.346775</td><td>0.85</td><td>313.287415</td><td>0.0019</td><td>0.547012</td><td>0.416498</td></tr><tr><td>2999131</td><td>&quot;Le Touvet&quot;</td><td>&quot;Le Touvet&quot;</td><td>&quot;FR&quot;</td><td>&quot;84&quot;</td><td>&quot;38&quot;</td><td>&quot;381&quot;</td><td>&quot;38511&quot;</td><td>&quot;P&quot;</td><td>&quot;PPL&quot;</td><td>&quot;populated place&quot;</td><td>45.359089</td><td>5.95283</td><td>2955</td><td>null</td><td>&quot;Le Touvet,Le-Tuve,Touvet,lei t…</td><td>&quot;France&quot;</td><td>0.323528</td><td>4</td><td>3.988863</td><td>0.537838</td><td>0.010302</td><td>0.503863</td><td>0.323528</td><td>0.85</td><td>321.432922</td><td>0.001615</td><td>0.537838</td><td>0.40937</td></tr><tr><td>3005099</td><td>&quot;Le Boupère&quot;</td><td>&quot;Le Boupere&quot;</td><td>&quot;FR&quot;</td><td>&quot;52&quot;</td><td>&quot;85&quot;</td><td>&quot;851&quot;</td><td>&quot;85031&quot;</td><td>&quot;P&quot;</td><td>&quot;PPL&quot;</td><td>&quot;populated place&quot;</td><td>46.7957</td><td>-0.92641</td><td>2985</td><td>null</td><td>&quot;Boupere,Boupère,Buper,Le Boupe…</td><td>&quot;France&quot;</td><td>0.323747</td><td>4</td><td>3.885674</td><td>0.545364</td><td>-0.054844</td><td>0.479445</td><td>0.323747</td><td>0.85</td><td>252.669632</td><td>0.006388</td><td>0.545364</td><td>0.402845</td></tr><tr><td>3002520</td><td>&quot;Le Pouzin&quot;</td><td>&quot;Le Pouzin&quot;</td><td>&quot;FR&quot;</td><td>&quot;84&quot;</td><td>&quot;07&quot;</td><td>&quot;072&quot;</td><td>&quot;07181&quot;</td><td>&quot;P&quot;</td><td>&quot;PPL&quot;</td><td>&quot;populated place&quot;</td><td>44.751732</td><td>4.74798</td><td>2849</td><td>null</td><td>&quot;Le Pouzin,Le-Puzen,Lo Polzin,l…</td><td>&quot;France&quot;</td><td>0.322735</td><td>4</td><td>3.899487</td><td>0.53652</td><td>-0.046124</td><td>0.48271</td><td>0.322735</td><td>0.85</td><td>297.572662</td><td>0.002602</td><td>0.53652</td><td>0.402463</td></tr><tr><td>3004609</td><td>&quot;Le Cheylard&quot;</td><td>&quot;Le Cheylard&quot;</td><td>&quot;FR&quot;</td><td>&quot;84&quot;</td><td>&quot;07&quot;</td><td>&quot;073&quot;</td><td>&quot;07064&quot;</td><td>&quot;P&quot;</td><td>&quot;PPL&quot;</td><td>&quot;populated place&quot;</td><td>44.906231</td><td>4.42406</td><td>3774</td><td>null</td><td>&quot;Cheylard,Le Cheylard,Le-Shejla…</td><td>&quot;France&quot;</td><td>0.32884</td><td>4</td><td>3.817487</td><td>0.536577</td><td>-0.097892</td><td>0.463356</td><td>0.32884</td><td>0.85</td><td>268.6492</td><td>0.00464</td><td>0.536577</td><td>0.398204</td></tr><tr><td>3004119</td><td>&quot;Le Gâvre&quot;</td><td>&quot;Le Gavre&quot;</td><td>&quot;FR&quot;</td><td>&quot;52&quot;</td><td>&quot;44&quot;</td><td>&quot;445&quot;</td><td>&quot;44062&quot;</td><td>&quot;P&quot;</td><td>&quot;PPL&quot;</td><td>&quot;populated place&quot;</td><td>47.520611</td><td>-1.74815</td><td>1026</td><td>null</td><td>&quot;Ar Chavr,Gavr,Gavre,Gâvre,Le G…</td><td>&quot;France&quot;</td><td>0.300557</td><td>4</td><td>3.751652</td><td>0.539424</td><td>-0.139456</td><td>0.447894</td><td>0.300557</td><td>0.85</td><td>321.262268</td><td>0.00162</td><td>0.539424</td><td>0.385681</td></tr><tr><td>3005282</td><td>&quot;Le Bignon&quot;</td><td>&quot;Le Bignon&quot;</td><td>&quot;FR&quot;</td><td>&quot;52&quot;</td><td>&quot;44&quot;</td><td>&quot;442&quot;</td><td>&quot;44014&quot;</td><td>&quot;P&quot;</td><td>&quot;PPL&quot;</td><td>&quot;populated place&quot;</td><td>47.098541</td><td>-1.49103</td><td>2793</td><td>null</td><td>&quot;Bignon,Binon,Bugnonium,Le Bign…</td><td>&quot;France&quot;</td><td>0.322304</td><td>4</td><td>3.653875</td><td>0.539167</td><td>-0.201185</td><td>0.425123</td><td>0.322304</td><td>0.85</td><td>295.789368</td><td>0.002697</td><td>0.539167</td><td>0.384453</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (20, 29)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ geonameId ┆ name      ┆ asciiname ┆ admin0_co ┆ … ┆ distance_ ┆ distance_ ┆ parent_ad ┆ place_sc │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ de        ┆   ┆ km        ┆ score     ┆ min_facto ┆ ore      │\n",
       "│ u32       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ r         ┆ ---      │\n",
       "│           ┆           ┆           ┆ str       ┆   ┆ f32       ┆ f64       ┆ ---       ┆ f64      │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ f64       ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 11101524  ┆ Port du   ┆ Port du   ┆ FR        ┆ … ┆ 519.35455 ┆ 0.000031  ┆ 0.730552  ┆ 0.685746 │\n",
       "│           ┆ Lavandou  ┆ Lavandou  ┆           ┆   ┆ 3         ┆           ┆           ┆          │\n",
       "│ 3003713   ┆ Le        ┆ Le        ┆ FR        ┆ … ┆ 518.95764 ┆ 0.000031  ┆ 0.730552  ┆ 0.586911 │\n",
       "│           ┆ Lavandou  ┆ Lavandou  ┆           ┆   ┆ 2         ┆           ┆           ┆          │\n",
       "│ 8286976   ┆ Le        ┆ Le        ┆ FR        ┆ … ┆ 287.80377 ┆ 0.003164  ┆ 0.539113  ┆ 0.539161 │\n",
       "│           ┆ Cellier   ┆ Cellier   ┆           ┆   ┆ 2         ┆           ┆           ┆          │\n",
       "│           ┆ Railway   ┆ Railway   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Station   ┆ Station   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 8288376   ┆ Le Teil   ┆ Le Teil   ┆ FR        ┆ … ┆ 312.75451 ┆ 0.001921  ┆ 0.547012  ┆ 0.520442 │\n",
       "│           ┆ (Ardèche) ┆ (Ardeche) ┆           ┆   ┆ 7         ┆           ┆           ┆          │\n",
       "│           ┆ Railway   ┆ Railway   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Stat…     ┆ Stat…     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 8297160   ┆ Bureau de ┆ Bureau de ┆ FR        ┆ … ┆ 518.95886 ┆ 0.000031  ┆ 0.730552  ┆ 0.510352 │\n",
       "│           ┆ Poste de  ┆ Poste de  ┆           ┆   ┆ 2         ┆           ┆           ┆          │\n",
       "│           ┆ Le        ┆ Le        ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Lavandou  ┆ Lavandou  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 2998854   ┆ Le        ┆ Le        ┆ FR        ┆ … ┆ 226.21403 ┆ 0.010843  ┆ 0.560347  ┆ 0.449181 │\n",
       "│           ┆ Vésinet   ┆ Vesinet   ┆           ┆   ┆ 5         ┆           ┆           ┆          │\n",
       "│ 3002626   ┆ Le Poinço ┆ Le Poinco ┆ FR        ┆ … ┆ 52.650066 ┆ 0.348889  ┆ 0.551508  ┆ 0.445548 │\n",
       "│           ┆ nnet      ┆ nnet      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3003375   ┆ Le Mesnil ┆ Le Mesnil ┆ FR        ┆ … ┆ 231.29568 ┆ 0.009795  ┆ 0.560564  ┆ 0.44206  │\n",
       "│           ┆ -le-Roi   ┆ -le-Roi   ┆           ┆   ┆ 5         ┆           ┆           ┆          │\n",
       "│ 3002966   ┆ Le        ┆ Le        ┆ FR        ┆ … ┆ 191.13899 ┆ 0.021867  ┆ 0.543001  ┆ 0.435405 │\n",
       "│           ┆ Perréon   ┆ Perreon   ┆           ┆   ┆ 2         ┆           ┆           ┆          │\n",
       "│ 2998934   ┆ Le        ┆ Le        ┆ FR        ┆ … ┆ 166.06173 ┆ 0.036108  ┆ 0.529313  ┆ 0.433572 │\n",
       "│           ┆ Vaudoué   ┆ Vaudoue   ┆           ┆   ┆ 7         ┆           ┆           ┆          │\n",
       "│ 3002808   ┆ Le Pin    ┆ Le Pin    ┆ FR        ┆ … ┆ 228.54277 ┆ 0.010349  ┆ 0.530632  ┆ 0.42775  │\n",
       "│ 2998809   ┆ Le Vigean ┆ Le Vigean ┆ FR        ┆ … ┆ 182.27719 ┆ 0.026107  ┆ 0.522565  ┆ 0.427026 │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 1         ┆           ┆           ┆          │\n",
       "│ 3002986   ┆ Le        ┆ Le        ┆ FR        ┆ … ┆ 72.071701 ┆ 0.236588  ┆ 0.539893  ┆ 0.425707 │\n",
       "│           ┆ Pêchereau ┆ Pechereau ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 2999259   ┆ Le Teil   ┆ Le Teil   ┆ FR        ┆ … ┆ 313.28741 ┆ 0.0019    ┆ 0.547012  ┆ 0.416498 │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 5         ┆           ┆           ┆          │\n",
       "│ 2999131   ┆ Le Touvet ┆ Le Touvet ┆ FR        ┆ … ┆ 321.43292 ┆ 0.001615  ┆ 0.537838  ┆ 0.40937  │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 2         ┆           ┆           ┆          │\n",
       "│ 3005099   ┆ Le        ┆ Le        ┆ FR        ┆ … ┆ 252.66963 ┆ 0.006388  ┆ 0.545364  ┆ 0.402845 │\n",
       "│           ┆ Boupère   ┆ Boupere   ┆           ┆   ┆ 2         ┆           ┆           ┆          │\n",
       "│ 3002520   ┆ Le Pouzin ┆ Le Pouzin ┆ FR        ┆ … ┆ 297.57266 ┆ 0.002602  ┆ 0.53652   ┆ 0.402463 │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 2         ┆           ┆           ┆          │\n",
       "│ 3004609   ┆ Le        ┆ Le        ┆ FR        ┆ … ┆ 268.6492  ┆ 0.00464   ┆ 0.536577  ┆ 0.398204 │\n",
       "│           ┆ Cheylard  ┆ Cheylard  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3004119   ┆ Le Gâvre  ┆ Le Gavre  ┆ FR        ┆ … ┆ 321.26226 ┆ 0.00162   ┆ 0.539424  ┆ 0.385681 │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 8         ┆           ┆           ┆          │\n",
       "│ 3005282   ┆ Le Bignon ┆ Le Bignon ┆ FR        ┆ … ┆ 295.78936 ┆ 0.002697  ┆ 0.539167  ┆ 0.384453 │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 8         ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"place\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-07 13:46:05.272\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m320\u001b[0m - \u001b[34m\u001b[1mFlexible search: Admin terms: ['FR', \"Provence-Alpes-Côte d'Azur\", 'Le Lavandou']\u001b[0m\n",
      "\u001b[32m2025-05-07 13:46:05.275\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m321\u001b[0m - \u001b[34m\u001b[1mFlexible search: Place candidate: 'Le Lavandou', Exclusive: False\u001b[0m\n",
      "\u001b[32m2025-05-07 13:46:05.295\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m345\u001b[0m - \u001b[34m\u001b[1mFlex-searching admin term 'FR' for levels [0, 1, 2].\u001b[0m\n",
      "\u001b[32m2025-05-07 13:46:05.435\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m390\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 0 OR admin_level = 1 OR admin_level = 2) AND (admin_level != 0 OR geonameId NOT IN (3017382))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-07 13:46:05.498\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m426\u001b[0m - \u001b[1m[]\u001b[0m\n",
      "\u001b[32m2025-05-07 13:46:05.505\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_score_admin\u001b[0m:\u001b[36m191\u001b[0m - \u001b[33m\u001b[1mNo parent_adjusted_score_ columns found. Skipping parent factor.\u001b[0m\n",
      "\u001b[32m2025-05-07 13:46:05.514\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m345\u001b[0m - \u001b[34m\u001b[1mFlex-searching admin term 'Provence-Alpes-Côte d'Azur' for levels [1, 2, 3].\u001b[0m\n",
      "\u001b[32m2025-05-07 13:46:05.522\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m390\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 1 OR admin_level = 2 OR admin_level = 3) AND ((admin0_code = 'EG' AND admin1_code = '21') OR (admin0_code = 'NL' AND admin1_code = '02') OR (admin0_code = 'NO' AND admin1_code = '08' AND admin2_code = '1548') OR (admin0_code = 'FR' AND admin1_code = '11' AND admin2_code = '93') OR (admin0_code = 'NO' AND admin1_code = '21' AND admin2_code = '5014') OR (admin0_code = 'FR') OR (admin0_code = 'PF') OR (admin0_code = 'CH' AND admin1_code = 'FR') OR (admin0_code = 'MF') OR (admin0_code = 'IT' AND admin1_code = '07' AND admin2_code = 'FR'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-07 13:46:05.567\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m426\u001b[0m - \u001b[1m['admin0_code', 'admin1_code', 'admin2_code']\u001b[0m\n",
      "\u001b[32m2025-05-07 13:46:05.570\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m345\u001b[0m - \u001b[34m\u001b[1mFlex-searching admin term 'Le Lavandou' for levels [2, 3, 4].\u001b[0m\n",
      "\u001b[32m2025-05-07 13:46:05.571\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m390\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 2 OR admin_level = 3 OR admin_level = 4) AND ((admin0_code = 'FR' AND admin1_code = '84') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '05') OR (admin0_code = 'FR' AND admin1_code = '93') OR (admin0_code = 'FR' AND admin1_code = '28' AND admin2_code = '61' AND admin3_code = '612') OR (admin0_code = 'FR' AND admin1_code = '27' AND admin2_code = '21') OR (admin0_code = 'FR' AND admin1_code = '52' AND admin2_code = '44' AND admin3_code = '444') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '04') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '13' AND admin3_code = '131') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '06') OR (admin0_code = 'FR' AND admin1_code = 'B9'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-07 13:46:05.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m426\u001b[0m - \u001b[1m['admin0_code', 'admin1_code', 'admin2_code', 'admin3_code']\u001b[0m\n",
      "\u001b[32m2025-05-07 13:46:05.610\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m360\u001b[0m - \u001b[34m\u001b[1mSearching for 'Le Lavandou' as a place entity.\u001b[0m\n",
      "\u001b[32m2025-05-07 13:46:05.610\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place_with_context\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1mSearching for place: 'Le Lavandou'\u001b[0m\n",
      "\u001b[32m2025-05-07 13:46:05.610\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m201\u001b[0m - \u001b[34m\u001b[1mSearching for places with term: Le Lavandou\u001b[0m\n",
      "\u001b[32m2025-05-07 13:46:05.612\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m264\u001b[0m - \u001b[34m\u001b[1mUsing center point from previous admin results: (44.852264404296875, 5.49148416519165)\u001b[0m\n",
      "\u001b[32m2025-05-07 13:46:05.612\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m281\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude,importance_score,importance_tier,\n",
      "            fts_main_places_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM places_search\n",
      "        WHERE ((admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '832' AND admin4_code = '83070') OR (admin0_code = 'FR' AND admin1_code = '84' AND admin2_code = '07' AND admin3_code = '072' AND admin4_code = '07181') OR (admin0_code = 'FR' AND admin1_code = '84' AND admin2_code = '38' AND admin3_code = '381' AND admin4_code = '38511') OR (admin0_code = 'FR' AND admin1_code = '84' AND admin2_code = '07' AND admin3_code = '071' AND admin4_code = '07026') OR (admin0_code = 'FR' AND admin1_code = '84' AND admin2_code = '69' AND admin3_code = '692' AND admin4_code = '69151') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '06' AND admin3_code = '061' AND admin4_code = '06112') OR (admin0_code = 'FR' AND admin1_code = '84' AND admin2_code = '74' AND admin3_code = '743' AND admin4_code = '74259') OR (admin0_code = 'FR' AND admin1_code = '84' AND admin2_code = '74' AND admin3_code = '742' AND admin4_code = '74221') OR (admin0_code = 'FR' AND admin1_code = '84' AND admin2_code = '43' AND admin3_code = '432' AND admin4_code = '43140') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '13' AND admin3_code = '131' AND admin4_code = '13109')) AND importance_tier <= 5\n",
      "    )\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC,\n",
      "        importance_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-07 13:46:05.838\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m289\u001b[0m - \u001b[34m\u001b[1mFound 27 results\u001b[0m\n",
      "\u001b[32m2025-05-07 13:46:05.838\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m311\u001b[0m - \u001b[34m\u001b[1mJoining place results with parent admin scores on: ['admin0_code', 'admin1_code', 'admin2_code', 'admin3_code', 'admin4_code']\u001b[0m\n",
      "\u001b[32m2025-05-07 13:46:05.839\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m317\u001b[0m - \u001b[34m\u001b[1mShape after joining with parent scores: (27, 17)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['admin0_code', 'admin1_code', 'admin2_code', 'admin3_code', 'admin4_code']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = flexible_search(st, con=con, limit=10)\n",
    "\n",
    "d = s[1]\n",
    "\n",
    "admin_cols = sorted(\n",
    "    [c for c in d.columns if c.startswith(\"admin\") and c.endswith(\"_code\")]\n",
    ")\n",
    "admin_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-07 13:46:12.704\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m390\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 0 OR admin_level = 1)\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-07 13:46:12.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m426\u001b[0m - \u001b[1m[]\u001b[0m\n",
      "\u001b[32m2025-05-07 13:46:12.873\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_score_admin\u001b[0m:\u001b[36m191\u001b[0m - \u001b[33m\u001b[1mNo parent_adjusted_score_ columns found. Skipping parent factor.\u001b[0m\n",
      "\u001b[32m2025-05-07 13:46:12.875\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m390\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 3 OR admin_level = 4) AND ((admin0_code = 'GB' AND admin1_code = 'ENG'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-07 13:46:12.916\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m426\u001b[0m - \u001b[1m['admin0_code', 'admin1_code']\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 15)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>asciiname</th><th>admin0_code</th><th>admin1_code</th><th>admin2_code</th><th>admin3_code</th><th>admin4_code</th><th>feature_class</th><th>feature_code</th><th>population</th><th>latitude</th><th>longitude</th><th>parent_adjusted_score_0</th><th>adjusted_score_3</th></tr><tr><td>u32</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i32</td><td>f32</td><td>f32</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>7296052</td><td>&quot;Dover&quot;</td><td>&quot;Dover&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE033&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>0</td><td>51.126282</td><td>1.30099</td><td>0.756593</td><td>0.58045</td></tr><tr><td>2651049</td><td>&quot;Dover District&quot;</td><td>&quot;Dover District&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM3&quot;</td><td>114227</td><td>51.150002</td><td>1.23333</td><td>0.756593</td><td>0.509673</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 15)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ geonameId ┆ name      ┆ asciiname ┆ admin0_co ┆ … ┆ latitude  ┆ longitude ┆ parent_ad ┆ adjusted │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ de        ┆   ┆ ---       ┆ ---       ┆ justed_sc ┆ _score_3 │\n",
       "│ u32       ┆ str       ┆ str       ┆ ---       ┆   ┆ f32       ┆ f32       ┆ ore_0     ┆ ---      │\n",
       "│           ┆           ┆           ┆ str       ┆   ┆           ┆           ┆ ---       ┆ f64      │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ f64       ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 7296052   ┆ Dover     ┆ Dover     ┆ GB        ┆ … ┆ 51.126282 ┆ 1.30099   ┆ 0.756593  ┆ 0.58045  │\n",
       "│ 2651049   ┆ Dover     ┆ Dover     ┆ GB        ┆ … ┆ 51.150002 ┆ 1.23333   ┆ 0.756593  ┆ 0.509673 │\n",
       "│           ┆ District  ┆ District  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = search_admin(\"England\", [0, 1], con)\n",
    "# First find the administrative region\n",
    "admin_results = search_admin(\"Dover\", [3, 4], con, r)\n",
    "admin_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-07 13:46:15.856\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m201\u001b[0m - \u001b[34m\u001b[1mSearching for places with term: Dover Ferry Terminal\u001b[0m\n",
      "\u001b[32m2025-05-07 13:46:15.858\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m264\u001b[0m - \u001b[34m\u001b[1mUsing center point from previous admin results: (51.13814163208008, 1.2671599388122559)\u001b[0m\n",
      "\u001b[32m2025-05-07 13:46:15.859\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m281\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude,importance_score,importance_tier,\n",
      "            fts_main_places_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM places_search\n",
      "        WHERE ((admin0_code = 'GB' AND admin1_code = 'ENG' AND admin2_code = 'G5' AND admin3_code = '29UE' AND admin4_code = '29UE033') OR (admin0_code = 'GB' AND admin1_code = 'ENG' AND admin2_code = 'G5' AND admin3_code = '29UE')) AND importance_tier <= 5\n",
      "    )\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC,\n",
      "        importance_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-07 13:46:16.135\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m289\u001b[0m - \u001b[34m\u001b[1mFound 12 results\u001b[0m\n",
      "\u001b[32m2025-05-07 13:46:16.136\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m311\u001b[0m - \u001b[34m\u001b[1mJoining place results with parent admin scores on: ['admin0_code', 'admin1_code', 'admin2_code', 'admin3_code', 'admin4_code']\u001b[0m\n",
      "\u001b[32m2025-05-07 13:46:16.136\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m317\u001b[0m - \u001b[34m\u001b[1mShape after joining with parent scores: (12, 17)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (12, 17)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>asciiname</th><th>admin0_code</th><th>admin1_code</th><th>admin2_code</th><th>admin3_code</th><th>admin4_code</th><th>feature_class</th><th>feature_code</th><th>population</th><th>latitude</th><th>longitude</th><th>importance_score</th><th>importance_tier</th><th>place_score</th><th>parent_adjusted_score_3</th></tr><tr><td>u32</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i32</td><td>f32</td><td>f32</td><td>f32</td><td>u8</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>9253020</td><td>&quot;Dover Port&quot;</td><td>&quot;Dover Port&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE033&quot;</td><td>&quot;L&quot;</td><td>&quot;PRT&quot;</td><td>0</td><td>51.126041</td><td>1.32795</td><td>0.495</td><td>3</td><td>0.764527</td><td>0.58045</td></tr><tr><td>7284378</td><td>&quot;Dover Transmitting Station&quot;</td><td>&quot;Dover Transmitting Station&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE010&quot;</td><td>&quot;S&quot;</td><td>&quot;TOWR&quot;</td><td>0</td><td>51.111698</td><td>1.24746</td><td>0.66</td><td>2</td><td>0.726239</td><td>null</td></tr><tr><td>6287214</td><td>&quot;Dover Castle&quot;</td><td>&quot;Dover Castle&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE033&quot;</td><td>&quot;S&quot;</td><td>&quot;CSTL&quot;</td><td>0</td><td>51.129581</td><td>1.32142</td><td>0.715</td><td>2</td><td>0.71439</td><td>0.58045</td></tr><tr><td>6945262</td><td>&quot;Dover Priory Railway Station&quot;</td><td>&quot;Dover Priory Railway Station&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE033&quot;</td><td>&quot;S&quot;</td><td>&quot;RSTN&quot;</td><td>0</td><td>51.12582</td><td>1.30501</td><td>0.645</td><td>2</td><td>0.68776</td><td>0.58045</td></tr><tr><td>6944960</td><td>&quot;Ramada Dover&quot;</td><td>&quot;Ramada Dover&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE021&quot;</td><td>&quot;S&quot;</td><td>&quot;HTL&quot;</td><td>0</td><td>51.167702</td><td>1.26965</td><td>0.375</td><td>4</td><td>0.517756</td><td>null</td></tr><tr><td>9885608</td><td>&quot;Best Western Dover Marina&quot;</td><td>&quot;Best Western Dover Marina&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE033&quot;</td><td>&quot;S&quot;</td><td>&quot;HTL&quot;</td><td>0</td><td>51.12212</td><td>1.31425</td><td>0.375</td><td>4</td><td>0.473388</td><td>0.58045</td></tr><tr><td>10281873</td><td>&quot;Dover Marina Hotel and Spa&quot;</td><td>&quot;Dover Marina Hotel and Spa&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE033&quot;</td><td>&quot;S&quot;</td><td>&quot;HTL&quot;</td><td>0</td><td>51.127998</td><td>1.3132</td><td>0.375</td><td>4</td><td>0.45485</td><td>0.58045</td></tr><tr><td>2651048</td><td>&quot;Dover&quot;</td><td>&quot;Dover&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE033&quot;</td><td>&quot;P&quot;</td><td>&quot;PPL&quot;</td><td>41709</td><td>51.12598</td><td>1.31257</td><td>0.381011</td><td>4</td><td>0.435201</td><td>0.58045</td></tr><tr><td>10107778</td><td>&quot;Best Western Plus Dover Marina…</td><td>&quot;Best Western Plus Dover Marina…</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE033&quot;</td><td>&quot;S&quot;</td><td>&quot;HTL&quot;</td><td>0</td><td>51.121799</td><td>1.31413</td><td>0.375</td><td>4</td><td>0.426251</td><td>0.58045</td></tr><tr><td>11810602</td><td>&quot;Dover Admiralty Pier Lighthous…</td><td>&quot;Dover Admiralty Pier Lighthous…</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE033&quot;</td><td>&quot;S&quot;</td><td>&quot;LTHSE&quot;</td><td>0</td><td>51.111408</td><td>1.32779</td><td>0.235</td><td>4</td><td>0.372478</td><td>0.58045</td></tr><tr><td>11810600</td><td>&quot;Dover Breakwater West End Ligh…</td><td>&quot;Dover Breakwater West End Ligh…</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>null</td><td>&quot;S&quot;</td><td>&quot;LTHSE&quot;</td><td>0</td><td>51.113152</td><td>1.32989</td><td>0.235</td><td>4</td><td>0.346119</td><td>null</td></tr><tr><td>11810601</td><td>&quot;Dover Prince of Wales Pier Lig…</td><td>&quot;Dover Prince of Wales Pier Lig…</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE033&quot;</td><td>&quot;S&quot;</td><td>&quot;LTHSE&quot;</td><td>0</td><td>51.114101</td><td>1.323</td><td>0.235</td><td>4</td><td>0.338621</td><td>0.58045</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (12, 17)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ geonameId ┆ name      ┆ asciiname ┆ admin0_co ┆ … ┆ importanc ┆ importanc ┆ place_sco ┆ parent_a │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ de        ┆   ┆ e_score   ┆ e_tier    ┆ re        ┆ djusted_ │\n",
       "│ u32       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ score_3  │\n",
       "│           ┆           ┆           ┆ str       ┆   ┆ f32       ┆ u8        ┆ f64       ┆ ---      │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 9253020   ┆ Dover     ┆ Dover     ┆ GB        ┆ … ┆ 0.495     ┆ 3         ┆ 0.764527  ┆ 0.58045  │\n",
       "│           ┆ Port      ┆ Port      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 7284378   ┆ Dover Tra ┆ Dover Tra ┆ GB        ┆ … ┆ 0.66      ┆ 2         ┆ 0.726239  ┆ null     │\n",
       "│           ┆ nsmitting ┆ nsmitting ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Station   ┆ Station   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6287214   ┆ Dover     ┆ Dover     ┆ GB        ┆ … ┆ 0.715     ┆ 2         ┆ 0.71439   ┆ 0.58045  │\n",
       "│           ┆ Castle    ┆ Castle    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6945262   ┆ Dover     ┆ Dover     ┆ GB        ┆ … ┆ 0.645     ┆ 2         ┆ 0.68776   ┆ 0.58045  │\n",
       "│           ┆ Priory    ┆ Priory    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Railway   ┆ Railway   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Station   ┆ Station   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6944960   ┆ Ramada    ┆ Ramada    ┆ GB        ┆ … ┆ 0.375     ┆ 4         ┆ 0.517756  ┆ null     │\n",
       "│           ┆ Dover     ┆ Dover     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 9885608   ┆ Best      ┆ Best      ┆ GB        ┆ … ┆ 0.375     ┆ 4         ┆ 0.473388  ┆ 0.58045  │\n",
       "│           ┆ Western   ┆ Western   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Dover     ┆ Dover     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Marina    ┆ Marina    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 10281873  ┆ Dover     ┆ Dover     ┆ GB        ┆ … ┆ 0.375     ┆ 4         ┆ 0.45485   ┆ 0.58045  │\n",
       "│           ┆ Marina    ┆ Marina    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Hotel and ┆ Hotel and ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Spa       ┆ Spa       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 2651048   ┆ Dover     ┆ Dover     ┆ GB        ┆ … ┆ 0.381011  ┆ 4         ┆ 0.435201  ┆ 0.58045  │\n",
       "│ 10107778  ┆ Best      ┆ Best      ┆ GB        ┆ … ┆ 0.375     ┆ 4         ┆ 0.426251  ┆ 0.58045  │\n",
       "│           ┆ Western   ┆ Western   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Plus      ┆ Plus      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Dover     ┆ Dover     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Marina…   ┆ Marina…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 11810602  ┆ Dover     ┆ Dover     ┆ GB        ┆ … ┆ 0.235     ┆ 4         ┆ 0.372478  ┆ 0.58045  │\n",
       "│           ┆ Admiralty ┆ Admiralty ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Pier Ligh ┆ Pier Ligh ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ thous…    ┆ thous…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 11810600  ┆ Dover Bre ┆ Dover Bre ┆ GB        ┆ … ┆ 0.235     ┆ 4         ┆ 0.346119  ┆ null     │\n",
       "│           ┆ akwater   ┆ akwater   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ West End  ┆ West End  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Ligh…     ┆ Ligh…     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 11810601  ┆ Dover     ┆ Dover     ┆ GB        ┆ … ┆ 0.235     ┆ 4         ┆ 0.338621  ┆ 0.58045  │\n",
       "│           ┆ Prince of ┆ Prince of ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Wales     ┆ Wales     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Pier Lig… ┆ Pier Lig… ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then search for places within that region\n",
    "place_results = search_place(\n",
    "    \"Dover Ferry Terminal\",\n",
    "    con,\n",
    "    previous_results=admin_results,\n",
    "    limit=50,\n",
    ")\n",
    "\n",
    "place_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 15:17:17.170\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 0 OR admin_level = 1)\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 15:17:17.224\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_score_admin\u001b[0m:\u001b[36m178\u001b[0m - \u001b[33m\u001b[1mNo parent score column found. Skipping parent factor.\u001b[0m\n",
      "\u001b[32m2025-05-04 15:17:17.226\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 1 OR admin_level = 2 OR admin_level = 3) AND ((admin0_code = 'GB' AND admin1_code = 'ENG'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 15:17:17.255\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m182\u001b[0m - \u001b[34m\u001b[1mSearching for places with term: Caledonian Road\u001b[0m\n",
      "\u001b[32m2025-05-04 15:17:17.257\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m234\u001b[0m - \u001b[34m\u001b[1mNo center point provided. Using centroid of previous results.\u001b[0m\n",
      "\u001b[32m2025-05-04 15:17:17.257\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m245\u001b[0m - \u001b[34m\u001b[1mUsing center point from previous results: (51.547019958496094, -0.10943999886512756)\u001b[0m\n",
      "\u001b[32m2025-05-04 15:17:17.257\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m264\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude,importance_score,importance_tier,\n",
      "            fts_main_places_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM places_search\n",
      "        WHERE ((admin0_code = 'GB' AND admin1_code = 'ENG' AND admin2_code = 'GLA' AND admin3_code = 'G3'))\n",
      "            AND importance_tier <= 5\n",
      "    )\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC,\n",
      "        importance_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 15:17:17.490\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m272\u001b[0m - \u001b[34m\u001b[1mFound 10 results\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 16)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>asciiname</th><th>admin0_code</th><th>admin1_code</th><th>admin2_code</th><th>admin3_code</th><th>admin4_code</th><th>feature_class</th><th>feature_code</th><th>population</th><th>latitude</th><th>longitude</th><th>importance_score</th><th>importance_tier</th><th>place_score</th></tr><tr><td>u32</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i32</td><td>f32</td><td>f32</td><td>f32</td><td>u8</td><td>f64</td></tr></thead><tbody><tr><td>6952211</td><td>&quot;Caledonian Road &amp; Barnsbury Ra…</td><td>&quot;Caledonian Road &amp; Barnsbury Ra…</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;GLA&quot;</td><td>&quot;G3&quot;</td><td>null</td><td>&quot;S&quot;</td><td>&quot;RSTN&quot;</td><td>0</td><td>51.543449</td><td>-0.11492</td><td>0.635</td><td>2</td><td>0.925274</td></tr><tr><td>6954652</td><td>&quot;Caledonian Road Underground St…</td><td>&quot;Caledonian Road Underground St…</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;GLA&quot;</td><td>&quot;G3&quot;</td><td>null</td><td>&quot;S&quot;</td><td>&quot;MTRO&quot;</td><td>0</td><td>51.548538</td><td>-0.11823</td><td>0.485</td><td>3</td><td>0.713496</td></tr><tr><td>10115056</td><td>&quot;Caledonian Road Apartments&quot;</td><td>&quot;Caledonian Road Apartments&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;GLA&quot;</td><td>&quot;G3&quot;</td><td>null</td><td>&quot;S&quot;</td><td>&quot;HTL&quot;</td><td>0</td><td>51.542461</td><td>-0.11744</td><td>0.375</td><td>4</td><td>0.668034</td></tr><tr><td>6952558</td><td>&quot;Essex Road Railway Station&quot;</td><td>&quot;Essex Road Railway Station&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;GLA&quot;</td><td>&quot;G3&quot;</td><td>null</td><td>&quot;S&quot;</td><td>&quot;RSTN&quot;</td><td>0</td><td>51.5406</td><td>-0.0963</td><td>0.645</td><td>2</td><td>0.594382</td></tr><tr><td>12048395</td><td>&quot;Caledonian&quot;</td><td>&quot;Caledonian&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;GLA&quot;</td><td>&quot;G3&quot;</td><td>null</td><td>&quot;P&quot;</td><td>&quot;PPLX&quot;</td><td>0</td><td>51.540482</td><td>-0.11897</td><td>0.1</td><td>5</td><td>0.450015</td></tr><tr><td>9259001</td><td>&quot;Caledoninan Road&quot;</td><td>&quot;Caledoninan Road&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;GLA&quot;</td><td>&quot;G3&quot;</td><td>null</td><td>&quot;S&quot;</td><td>&quot;HTL&quot;</td><td>0</td><td>51.54245</td><td>-0.11744</td><td>0.375</td><td>4</td><td>0.418297</td></tr><tr><td>2646740</td><td>&quot;Holloway Road Underground Stat…</td><td>&quot;Holloway Road Underground Stat…</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;GLA&quot;</td><td>&quot;G3&quot;</td><td>null</td><td>&quot;S&quot;</td><td>&quot;MTRO&quot;</td><td>0</td><td>51.552792</td><td>-0.11282</td><td>0.485</td><td>3</td><td>0.409473</td></tr><tr><td>9259906</td><td>&quot;Travelodge Central City Road&quot;</td><td>&quot;Travelodge Central City Road&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;GLA&quot;</td><td>&quot;G3&quot;</td><td>null</td><td>&quot;S&quot;</td><td>&quot;HTL&quot;</td><td>0</td><td>51.52282</td><td>-0.08719</td><td>0.375</td><td>4</td><td>0.390436</td></tr><tr><td>6954632</td><td>&quot;Arsenal Underground Station&quot;</td><td>&quot;Arsenal Underground Station&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;GLA&quot;</td><td>&quot;G3&quot;</td><td>null</td><td>&quot;S&quot;</td><td>&quot;MTRO&quot;</td><td>0</td><td>51.558441</td><td>-0.10572</td><td>0.495</td><td>3</td><td>0.379636</td></tr><tr><td>12519726</td><td>&quot;City Road&quot;</td><td>&quot;City Road&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;GLA&quot;</td><td>&quot;G3&quot;</td><td>null</td><td>&quot;R&quot;</td><td>&quot;ST&quot;</td><td>0</td><td>51.53056</td><td>-0.10073</td><td>0.1</td><td>5</td><td>0.238988</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 16)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ geonameId ┆ name      ┆ asciiname ┆ admin0_co ┆ … ┆ longitude ┆ importanc ┆ importanc ┆ place_sc │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ de        ┆   ┆ ---       ┆ e_score   ┆ e_tier    ┆ ore      │\n",
       "│ u32       ┆ str       ┆ str       ┆ ---       ┆   ┆ f32       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆           ┆ str       ┆   ┆           ┆ f32       ┆ u8        ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 6952211   ┆ Caledonia ┆ Caledonia ┆ GB        ┆ … ┆ -0.11492  ┆ 0.635     ┆ 2         ┆ 0.925274 │\n",
       "│           ┆ n Road &  ┆ n Road &  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Barnsbury ┆ Barnsbury ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Ra…       ┆ Ra…       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6954652   ┆ Caledonia ┆ Caledonia ┆ GB        ┆ … ┆ -0.11823  ┆ 0.485     ┆ 3         ┆ 0.713496 │\n",
       "│           ┆ n Road    ┆ n Road    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Undergrou ┆ Undergrou ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ nd St…    ┆ nd St…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 10115056  ┆ Caledonia ┆ Caledonia ┆ GB        ┆ … ┆ -0.11744  ┆ 0.375     ┆ 4         ┆ 0.668034 │\n",
       "│           ┆ n Road    ┆ n Road    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Apartment ┆ Apartment ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ s         ┆ s         ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6952558   ┆ Essex     ┆ Essex     ┆ GB        ┆ … ┆ -0.0963   ┆ 0.645     ┆ 2         ┆ 0.594382 │\n",
       "│           ┆ Road      ┆ Road      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Railway   ┆ Railway   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Station   ┆ Station   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 12048395  ┆ Caledonia ┆ Caledonia ┆ GB        ┆ … ┆ -0.11897  ┆ 0.1       ┆ 5         ┆ 0.450015 │\n",
       "│           ┆ n         ┆ n         ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 9259001   ┆ Caledonin ┆ Caledonin ┆ GB        ┆ … ┆ -0.11744  ┆ 0.375     ┆ 4         ┆ 0.418297 │\n",
       "│           ┆ an Road   ┆ an Road   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 2646740   ┆ Holloway  ┆ Holloway  ┆ GB        ┆ … ┆ -0.11282  ┆ 0.485     ┆ 3         ┆ 0.409473 │\n",
       "│           ┆ Road Unde ┆ Road Unde ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ rground   ┆ rground   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Stat…     ┆ Stat…     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 9259906   ┆ Travelodg ┆ Travelodg ┆ GB        ┆ … ┆ -0.08719  ┆ 0.375     ┆ 4         ┆ 0.390436 │\n",
       "│           ┆ e Central ┆ e Central ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ City Road ┆ City Road ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6954632   ┆ Arsenal   ┆ Arsenal   ┆ GB        ┆ … ┆ -0.10572  ┆ 0.495     ┆ 3         ┆ 0.379636 │\n",
       "│           ┆ Undergrou ┆ Undergrou ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ nd        ┆ nd        ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Station   ┆ Station   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 12519726  ┆ City Road ┆ City Road ┆ GB        ┆ … ┆ -0.10073  ┆ 0.1       ┆ 5         ┆ 0.238988 │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = search_admin(\"England\", [0, 1], con)\n",
    "a = search_admin(\"Islington\", [1, 2, 3], con, r)\n",
    "b = search_place(\n",
    "    \"Caledonian Road\",\n",
    "    con,\n",
    "    previous_results=a,\n",
    "    limit=50,\n",
    ")\n",
    "b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'admin0': {'geonameId': 2635167,\n",
       "  'name': 'United Kingdom of Great Britain and Northern Ireland'},\n",
       " 'admin1': {'geonameId': 2634259, 'name': 'West Suffolk'},\n",
       " 'admin2': {'geonameId': 2648110, 'name': 'Greater London'},\n",
       " 'admin3': {'geonameId': 3333156, 'name': 'Islington'}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backfill_hierarchy(\n",
    "    {\n",
    "        \"admin0_code\": \"GB\",\n",
    "        \"admin1_code\": \"ENG\",\n",
    "        \"admin2_code\": \"GLA\",\n",
    "        \"admin3_code\": \"G3\",\n",
    "        \"geonameId\": 13269818,\n",
    "    },\n",
    "    con,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 21:41:13.161\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin_hierarchy\u001b[0m:\u001b[36m127\u001b[0m - \u001b[34m\u001b[1mSearching for term 'FL' at admin level 1\u001b[0m\n",
      "\u001b[32m2025-05-04 21:41:13.162\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 1)\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 21:41:13.183\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_score_admin\u001b[0m:\u001b[36m178\u001b[0m - \u001b[33m\u001b[1mNo parent score column found. Skipping parent factor.\u001b[0m\n",
      "\u001b[32m2025-05-04 21:41:13.184\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin_hierarchy\u001b[0m:\u001b[36m127\u001b[0m - \u001b[34m\u001b[1mSearching for term 'Lakeland' at admin level 3\u001b[0m\n",
      "\u001b[32m2025-05-04 21:41:13.186\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 3) AND ((admin0_code = 'NL' AND admin1_code = '16') OR (admin0_code = 'US' AND admin1_code = 'FL'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'adjusted_score_1': 0.6674183738082736,\n",
      " 'adjusted_score_3': 0.6025998219254551,\n",
      " 'admin0_code': 'US',\n",
      " 'admin1_code': 'FL',\n",
      " 'admin2_code': '105',\n",
      " 'admin3_code': '7170309',\n",
      " 'admin4_code': None,\n",
      " 'asciiname': 'City of Lakeland',\n",
      " 'feature_class': 'A',\n",
      " 'feature_code': 'ADM3',\n",
      " 'geonameId': 7170309,\n",
      " 'latitude': 28.05565071105957,\n",
      " 'longitude': -81.95420837402344,\n",
      " 'name': 'City of Lakeland',\n",
      " 'population': 97422}\n"
     ]
    },
    {
     "ename": "ParserException",
     "evalue": "Parser Error: syntax error at or near \"WHERE\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mParserException\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[96]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      5\u001b[39m row = results[\u001b[33m\"\u001b[39m\u001b[33madmin3\u001b[39m\u001b[33m\"\u001b[39m].row(\u001b[32m0\u001b[39m, named=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      8\u001b[39m pprint(row)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m pprint(\u001b[43mbackfill_hierarchy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[92]\u001b[39m\u001b[32m, line 408\u001b[39m, in \u001b[36mbackfill_hierarchy\u001b[39m\u001b[34m(row, con)\u001b[39m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m code \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    407\u001b[39m     query = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSELECT geonameId, name FROM admin_search WHERE admin_level = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m AND \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mget_where_clause(codes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m LIMIT 1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m408\u001b[39m     df = \u001b[43mcon\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m.pl()\n\u001b[32m    410\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m df.is_empty():\n\u001b[32m    411\u001b[39m         hierarchy[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33madmin\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m] = df.to_dicts()[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mParserException\u001b[39m: Parser Error: syntax error at or near \"WHERE\""
     ]
    }
   ],
   "source": [
    "results = hierarchical_search(\n",
    "    search_terms=AdminHierarchy.from_list([None, \"FL\", None, \"Lakeland\", None, None]),\n",
    "    con=con,\n",
    "    try_place_as_admin=False,\n",
    ")\n",
    "row = results[\"admin3\"].row(0, named=True)\n",
    "\n",
    "\n",
    "pprint(row)\n",
    "\n",
    "pprint(backfill_hierarchy(row, con))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 21:40:52.486\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mhierarchical_search\u001b[0m:\u001b[36m232\u001b[0m - \u001b[34m\u001b[1mMoved last non-null admin level 'Le Lavandou' to place term\u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.487\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin_hierarchy\u001b[0m:\u001b[36m127\u001b[0m - \u001b[34m\u001b[1mSearching for term 'FR' at admin level 0\u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.495\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 0) AND (admin_level != 0 OR geonameId NOT IN (3017382))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.564\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_score_admin\u001b[0m:\u001b[36m178\u001b[0m - \u001b[33m\u001b[1mNo parent score column found. Skipping parent factor.\u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.571\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin_hierarchy\u001b[0m:\u001b[36m127\u001b[0m - \u001b[34m\u001b[1mSearching for term 'Provence-Alpes-Côte d'Azur' at admin level 1\u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.575\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 1) AND ((admin0_code = 'PF') OR (admin0_code = 'FR') OR (admin0_code = 'MF') OR (admin0_code = 'GF'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.618\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin_hierarchy\u001b[0m:\u001b[36m127\u001b[0m - \u001b[34m\u001b[1mSearching for term 'Var' at admin level 2\u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.619\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 2) AND ((admin0_code = 'FR' AND admin1_code = '24') OR (admin0_code = 'FR' AND admin1_code = '11') OR (admin0_code = 'FR' AND admin1_code = 'B4') OR (admin0_code = 'FR' AND admin1_code = 'B9') OR (admin0_code = 'FR' AND admin1_code = '52') OR (admin0_code = 'FR' AND admin1_code = '93') OR (admin0_code = 'FR' AND admin1_code = '32') OR (admin0_code = 'FR' AND admin1_code = '84'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.653\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin_hierarchy\u001b[0m:\u001b[36m127\u001b[0m - \u001b[34m\u001b[1mSearching for term 'Arrondissement de Toulon' at admin level 3\u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.655\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 3) AND ((admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.689\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mplace_as_admin\u001b[0m:\u001b[36m158\u001b[0m - \u001b[34m\u001b[1mTrying place term 'Le Lavandou' as admin level 4\u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.690\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 4) AND ((admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '833') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '831') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '832'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.719\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place_with_context\u001b[0m:\u001b[36m191\u001b[0m - \u001b[34m\u001b[1mSearching for place: 'Le Lavandou'\u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.719\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m186\u001b[0m - \u001b[34m\u001b[1mSearching for places with term: Le Lavandou\u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.721\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m238\u001b[0m - \u001b[34m\u001b[1mNo center point provided. Using centroid of previous results.\u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.721\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m249\u001b[0m - \u001b[34m\u001b[1mUsing center point from previous results: (43.32274627685547, 6.215458869934082)\u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.721\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m268\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "    WITH filtered_results AS (\n",
      "        SELECT geonameId,name,asciiname,admin0_code,admin1_code,admin2_code,admin3_code,admin4_code,feature_class,feature_code,population,latitude,longitude,importance_score,importance_tier,\n",
      "            fts_main_places_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM places_search\n",
      "        WHERE ((admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '833' AND admin4_code = '83073') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '833' AND admin4_code = '83075') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '832' AND admin4_code = '83098') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '832' AND admin4_code = '83019') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '831' AND admin4_code = '83086') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '831' AND admin4_code = '83020') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '832' AND admin4_code = '83103') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '833' AND admin4_code = '83143') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '831' AND admin4_code = '83094') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '833' AND admin4_code = '83077') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '833' AND admin4_code = '83031') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '832' AND admin4_code = '83016') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '832' AND admin4_code = '83035') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '833' AND admin4_code = '83136') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '832' AND admin4_code = '83070'))\n",
      "            AND importance_tier <= 5\n",
      "    )\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC,\n",
      "        importance_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.938\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m276\u001b[0m - \u001b[34m\u001b[1mFound 42 results\u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.941\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mAdmin1 results:\u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.942\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m20\u001b[0m - \u001b[34m\u001b[1mAdmin2 results:\u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.942\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m22\u001b[0m - \u001b[34m\u001b[1mAdmin3 results:\u001b[0m\n",
      "\u001b[32m2025-05-04 21:40:52.942\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m24\u001b[0m - \u001b[34m\u001b[1mAdmin4 results:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (15, 18)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>asciiname</th><th>admin0_code</th><th>admin1_code</th><th>admin2_code</th><th>admin3_code</th><th>admin4_code</th><th>feature_class</th><th>feature_code</th><th>population</th><th>latitude</th><th>longitude</th><th>adjusted_score_0</th><th>adjusted_score_1</th><th>adjusted_score_2</th><th>adjusted_score_3</th><th>adjusted_score_4</th></tr><tr><td>u32</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i32</td><td>f32</td><td>f32</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>6615009</td><td>&quot;Le Lavandou&quot;</td><td>&quot;Le Lavandou&quot;</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;832&quot;</td><td>&quot;83070&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>5759</td><td>43.137779</td><td>6.36778</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.777905</td><td>0.730552</td></tr><tr><td>6457128</td><td>&quot;Le Pradet&quot;</td><td>&quot;Le Pradet&quot;</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;832&quot;</td><td>&quot;83098&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>10027</td><td>43.10556</td><td>6.02333</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.777905</td><td>0.568234</td></tr><tr><td>6457113</td><td>&quot;Le Beausset&quot;</td><td>&quot;Le Beausset&quot;</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;832&quot;</td><td>&quot;83016&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>9637</td><td>43.19833</td><td>5.80278</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.777905</td><td>0.559563</td></tr><tr><td>6457122</td><td>&quot;Le Luc&quot;</td><td>&quot;Le Luc&quot;</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;833&quot;</td><td>&quot;83073&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>10952</td><td>43.394402</td><td>6.3134</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.542154</td><td>0.558407</td></tr><tr><td>6457127</td><td>&quot;Le Muy&quot;</td><td>&quot;Le Muy&quot;</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;831&quot;</td><td>&quot;83086&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>9248</td><td>43.4725</td><td>6.56639</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.540235</td><td>0.556842</td></tr><tr><td>6456550</td><td>&quot;Le Val&quot;</td><td>&quot;Le Val&quot;</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;833&quot;</td><td>&quot;83143&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>4297</td><td>43.439442</td><td>6.07306</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.542154</td><td>0.549818</td></tr><tr><td>6456549</td><td>&quot;Le Thoronet&quot;</td><td>&quot;Le Thoronet&quot;</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;833&quot;</td><td>&quot;83136&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>2449</td><td>43.451939</td><td>6.30389</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.542154</td><td>0.544131</td></tr><tr><td>6456545</td><td>&quot;Le Revest-les-Eaux&quot;</td><td>&quot;Le Revest-les-Eaux&quot;</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;832&quot;</td><td>&quot;83103&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>3812</td><td>43.176601</td><td>5.9273</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.777905</td><td>0.529966</td></tr><tr><td>6617824</td><td>&quot;Le Castellet&quot;</td><td>&quot;Le Castellet&quot;</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;832&quot;</td><td>&quot;83035&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>3875</td><td>43.202702</td><td>5.777</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.777905</td><td>0.527065</td></tr><tr><td>6457115</td><td>&quot;Le Cannet-des-Maures&quot;</td><td>&quot;Le Cannet-des-Maures&quot;</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;833&quot;</td><td>&quot;83031&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>4328</td><td>43.39167</td><td>6.34083</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.542154</td><td>0.526716</td></tr><tr><td>6451513</td><td>&quot;Le Plan-de-la-Tour&quot;</td><td>&quot;Le Plan-de-la-Tour&quot;</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;831&quot;</td><td>&quot;83094&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>2714</td><td>43.340561</td><td>6.54639</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.540235</td><td>0.512782</td></tr><tr><td>6451462</td><td>&quot;Bormes-les-Mimosas&quot;</td><td>&quot;Bormes-les-Mimosas&quot;</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;832&quot;</td><td>&quot;83019&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>7982</td><td>43.151669</td><td>6.34306</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.777905</td><td>0.485188</td></tr><tr><td>6614863</td><td>&quot;Le Bourguet&quot;</td><td>&quot;Le Bourguet&quot;</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;831&quot;</td><td>&quot;83020&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>31</td><td>43.784168</td><td>6.51861</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.540235</td><td>0.478774</td></tr><tr><td>6451500</td><td>&quot;Méounes-lès-Montrieux&quot;</td><td>&quot;Meounes-les-Montrieux&quot;</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;833&quot;</td><td>&quot;83077&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>2165</td><td>43.281109</td><td>5.97</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.542154</td><td>0.464287</td></tr><tr><td>6457124</td><td>&quot;Les Mayons&quot;</td><td>&quot;Les Mayons&quot;</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;833&quot;</td><td>&quot;83075&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>641</td><td>43.312778</td><td>6.35806</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.542154</td><td>0.450247</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (15, 18)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ geonameId ┆ name      ┆ asciiname ┆ admin0_co ┆ … ┆ adjusted_ ┆ adjusted_ ┆ adjusted_ ┆ adjusted │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ de        ┆   ┆ score_1   ┆ score_2   ┆ score_3   ┆ _score_4 │\n",
       "│ u32       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆           ┆ str       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 6615009   ┆ Le        ┆ Le        ┆ FR        ┆ … ┆ 0.81716   ┆ 0.795429  ┆ 0.777905  ┆ 0.730552 │\n",
       "│           ┆ Lavandou  ┆ Lavandou  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6457128   ┆ Le Pradet ┆ Le Pradet ┆ FR        ┆ … ┆ 0.81716   ┆ 0.795429  ┆ 0.777905  ┆ 0.568234 │\n",
       "│ 6457113   ┆ Le        ┆ Le        ┆ FR        ┆ … ┆ 0.81716   ┆ 0.795429  ┆ 0.777905  ┆ 0.559563 │\n",
       "│           ┆ Beausset  ┆ Beausset  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6457122   ┆ Le Luc    ┆ Le Luc    ┆ FR        ┆ … ┆ 0.81716   ┆ 0.795429  ┆ 0.542154  ┆ 0.558407 │\n",
       "│ 6457127   ┆ Le Muy    ┆ Le Muy    ┆ FR        ┆ … ┆ 0.81716   ┆ 0.795429  ┆ 0.540235  ┆ 0.556842 │\n",
       "│ 6456550   ┆ Le Val    ┆ Le Val    ┆ FR        ┆ … ┆ 0.81716   ┆ 0.795429  ┆ 0.542154  ┆ 0.549818 │\n",
       "│ 6456549   ┆ Le        ┆ Le        ┆ FR        ┆ … ┆ 0.81716   ┆ 0.795429  ┆ 0.542154  ┆ 0.544131 │\n",
       "│           ┆ Thoronet  ┆ Thoronet  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6456545   ┆ Le Revest ┆ Le Revest ┆ FR        ┆ … ┆ 0.81716   ┆ 0.795429  ┆ 0.777905  ┆ 0.529966 │\n",
       "│           ┆ -les-Eaux ┆ -les-Eaux ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6617824   ┆ Le        ┆ Le        ┆ FR        ┆ … ┆ 0.81716   ┆ 0.795429  ┆ 0.777905  ┆ 0.527065 │\n",
       "│           ┆ Castellet ┆ Castellet ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6457115   ┆ Le Cannet ┆ Le Cannet ┆ FR        ┆ … ┆ 0.81716   ┆ 0.795429  ┆ 0.542154  ┆ 0.526716 │\n",
       "│           ┆ -des-Maur ┆ -des-Maur ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ es        ┆ es        ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6451513   ┆ Le Plan-d ┆ Le Plan-d ┆ FR        ┆ … ┆ 0.81716   ┆ 0.795429  ┆ 0.540235  ┆ 0.512782 │\n",
       "│           ┆ e-la-Tour ┆ e-la-Tour ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6451462   ┆ Bormes-le ┆ Bormes-le ┆ FR        ┆ … ┆ 0.81716   ┆ 0.795429  ┆ 0.777905  ┆ 0.485188 │\n",
       "│           ┆ s-Mimosas ┆ s-Mimosas ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6614863   ┆ Le        ┆ Le        ┆ FR        ┆ … ┆ 0.81716   ┆ 0.795429  ┆ 0.540235  ┆ 0.478774 │\n",
       "│           ┆ Bourguet  ┆ Bourguet  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6451500   ┆ Méounes-l ┆ Meounes-l ┆ FR        ┆ … ┆ 0.81716   ┆ 0.795429  ┆ 0.542154  ┆ 0.464287 │\n",
       "│           ┆ ès-Montri ┆ es-Montri ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ eux       ┆ eux       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6457124   ┆ Les       ┆ Les       ┆ FR        ┆ … ┆ 0.81716   ┆ 0.795429  ┆ 0.542154  ┆ 0.450247 │\n",
       "│           ┆ Mayons    ┆ Mayons    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search through the admin hierarchy\n",
    "results = hierarchical_search(\n",
    "    search_terms=AdminHierarchy.from_list(\n",
    "        [\n",
    "            \"FR\",\n",
    "            \"Provence-Alpes-Côte d'Azur\",\n",
    "            \"Var\",\n",
    "            \"Arrondissement de Toulon\",\n",
    "            \"Le Lavandou\",\n",
    "            None,\n",
    "        ]\n",
    "    ),\n",
    "    con=con,\n",
    ")\n",
    "\n",
    "# Access results for each level\n",
    "if \"country\" in results:\n",
    "    logger.debug(\"Country results:\", results[\"country\"])\n",
    "if \"admin1\" in results:\n",
    "    logger.debug(\"Admin1 results:\", results[\"admin1\"])\n",
    "if \"admin2\" in results:\n",
    "    logger.debug(\"Admin2 results:\", results[\"admin2\"])\n",
    "if \"admin3\" in results:\n",
    "    logger.debug(\"Admin3 results:\", results[\"admin3\"])\n",
    "if \"admin4\" in results:\n",
    "    logger.debug(\"Admin4 results:\", results[\"admin4\"])\n",
    "results[\"admin4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    con.execute(\"SELECT geonameId, latitude, longitude FROM allCountries\")\n",
    "    .pl()\n",
    "    .select(\n",
    "        pl.col(\"geonameId\"),\n",
    "        pl.concat_list(pl.col(\"latitude\"), pl.col(\"longitude\"))\n",
    "        .cast(pl.Array(pl.Float32, 2))\n",
    "        .alias(\"vectors\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_coordinates1 = np.array([51.549902, -0.121696], dtype=np.float32)\n",
    "my_coordinates2 = np.array([37.77493, -122.41942], dtype=np.float32)\n",
    "\n",
    "vidx = VectorIndex(\"latlon\", data, metric=\"haversine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (path := Path(\"./data/processed/latlon.index\")).exists():\n",
    "    logger.debug(\"Loading index...\")\n",
    "    index = Index.restore(path, view=True)\n",
    "    if index is None:\n",
    "        raise ValueError(\"Failed to load index\")\n",
    "else:\n",
    "    logger.debug(\"Creating index...\")\n",
    "    coordinates = df.select([\"latitude\", \"longitude\"]).to_numpy(order=\"c\")\n",
    "    labels = df[\"geonameId\"].to_numpy()\n",
    "    index: Index = Index(ndim=2, metric=\"haversine\", dtype=\"f32\")\n",
    "    index.add(keys=labels, vectors=coordinates, log=True)\n",
    "    index.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example function to search and return results with distances\n",
    "def search_with_distances(\n",
    "    index: Index,\n",
    "    my_coordinates: NDArray[np.float32],\n",
    "    original_df: pl.LazyFrame,\n",
    "    k=10,\n",
    "    exact=False,\n",
    "):\n",
    "    # Perform the search\n",
    "    output = index.search(vectors=my_coordinates, count=k, log=True, exact=exact)\n",
    "\n",
    "    logger.debug(f\"Visited members: {output.visited_members}\")\n",
    "    logger.debug(f\"Computed distances: {output.computed_distances}\")\n",
    "\n",
    "    # Extract keys (geonameids) and distances\n",
    "    keys = output.keys\n",
    "    distances = output.distances\n",
    "\n",
    "    # Create a DataFrame from the search results\n",
    "    results_df = pl.LazyFrame(\n",
    "        data={\"geonameId\": keys, \"distance\": distances},\n",
    "        schema={\"geonameId\": pl.UInt32, \"distance\": pl.Float32},\n",
    "    ).with_columns(pl.col(\"distance\") * 6371.0)\n",
    "\n",
    "    # Join the results with the original DataFrame to get detailed information\n",
    "    detailed_results_df = results_df.join(original_df, on=\"geonameId\", how=\"left\")\n",
    "\n",
    "    # Sort by distance\n",
    "    sorted_results_df = detailed_results_df.sort(\"distance\")\n",
    "\n",
    "    return sorted_results_df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_with_distances(index, my_coordinates2, df.lazy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output: Matches = index.search(vectors=my_coordinates1, count=10, log=True)\n",
    "logger.debug(f\"{output.computed_distances=}\")\n",
    "logger.debug(f\"{output.visited_members=}\")\n",
    "df.filter(pl.col(\"geonameId\").is_in(output.keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# con.execute(sql_file(\"create_view_*_NODES.sql\", table=\"admin0\"))\n",
    "\n",
    "# con.execute(sql_file(\"create_view_*_FTS.sql\", table=\"admin0\"))\n",
    "\n",
    "# # if (path := Path(\"./data/processed/latlon.index\")).exists():\n",
    "# #     logger.debug(\"Loading index...\")\n",
    "# #     index = Index.restore(path, view=True) or raise ValueError(\"Failed to load index\")\n",
    "# # else:\n",
    "# #     logger.debug(\"Creating index...\")\n",
    "# #     coordinates = df.select([\"latitude\", \"longitude\"]).to_numpy(order=\"c\")\n",
    "# #     labels = df[\"geonameid\"].to_numpy()\n",
    "# #     index: Index = Index(ndim=2, metric=\"haversine\", dtype=\"f32\")\n",
    "# #     index.add(keys=labels, vectors=coordinates, log=True)\n",
    "# #     index.save(path)\n",
    "\n",
    "\n",
    "# class VectorIndex:\n",
    "#     default_index_path = Path(\"./data/indexes/vector\")\n",
    "\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         index_name: str,\n",
    "#         data: pl.DataFrame | None = None,\n",
    "#         id_column: str = \"geonameId\",\n",
    "#         main_column: str = \"vectors\",\n",
    "#         metric: str = \"L2\",\n",
    "#         embedder: SentenceTransformer | None = None,\n",
    "#     ):\n",
    "#         self._index_path = self.default_index_path / f\"{index_name}.index\"\n",
    "#         self._id_column = id_column\n",
    "#         self._main_column = main_column\n",
    "#         self._metric = metric\n",
    "#         index = self.get_or_build_index(data, metric)\n",
    "#         if isinstance(index, Err):\n",
    "#             logger.debug(\n",
    "#                 f\"Index does not exist at '{self.index_path}', build index with 'build_index' method.\"\n",
    "#             )\n",
    "#             self._index = None  # type: ignore\n",
    "#         else:\n",
    "#             self._index: Index = index.ok_value\n",
    "\n",
    "#     @property\n",
    "#     def index(self) -> Index:\n",
    "#         return self._index\n",
    "\n",
    "#     @property\n",
    "#     def id_column(self) -> str:\n",
    "#         return self._id_column\n",
    "\n",
    "#     @property\n",
    "#     def main_column(self) -> str:\n",
    "#         return self._main_column\n",
    "\n",
    "#     @property\n",
    "#     def index_path(self) -> Path:\n",
    "#         return self._index_path\n",
    "\n",
    "#     @property\n",
    "#     def ndims(self) -> int:\n",
    "#         return self._ndims\n",
    "\n",
    "#     @property\n",
    "#     def metric(self) -> str:\n",
    "#         return self._metric\n",
    "\n",
    "#     def _build_index(\n",
    "#         self,\n",
    "#         df: pl.DataFrame,\n",
    "#         metric: str = \"L2\",  # TODO: Metric like\n",
    "#     ) -> Result[Index, str]:\n",
    "#         \"\"\"Data passed should be an Id and a vector.\"\"\"\n",
    "#         logger.debug(\"Creating index...\")\n",
    "#         vectors = df[self.main_column].to_numpy()\n",
    "#         labels = df[self.id_column].to_numpy()\n",
    "#         ndims = vectors.shape[1]  # Find n dims\n",
    "#         index: Index = Index(ndim=ndims, metric=metric, dtype=\"f32\")\n",
    "#         index.add(keys=labels, vectors=vectors, log=True)\n",
    "#         index.save(self.index_path)\n",
    "#         return Ok(index)\n",
    "\n",
    "#     def get_index(self) -> Result[Index, str]:\n",
    "#         if (path := self.index_path).exists():\n",
    "#             logger.debug(f\"Opening index at '{self.index_path}'\")\n",
    "#             index = Index.restore(path, view=True)\n",
    "#             if index is not None:\n",
    "#                 return Ok(index)\n",
    "#         return Err(f\"Index does not exist at '{self.index_path}'\")\n",
    "\n",
    "#     def get_or_build_index(\n",
    "#         self,\n",
    "#         df: pl.DataFrame | None = None,\n",
    "#         metric: str = \"L2\",  # TODO: as above\n",
    "#     ) -> Result[Index, str]:\n",
    "#         self.index_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#         if not self.index_path.exists():\n",
    "#             if df is None:\n",
    "#                 return Err(\n",
    "#                     \"Index does not exist. DataFrame is required to create index\"\n",
    "#                 )\n",
    "#             match self._build_index(df, metric):\n",
    "#                 case Ok(index):\n",
    "#                     ...\n",
    "#                 case Err(e):\n",
    "#                     return Err(e)\n",
    "#         else:\n",
    "#             match self.get_index():\n",
    "#                 case Ok(index):\n",
    "#                     ...\n",
    "#                 case Err(e):\n",
    "#                     return Err(e)\n",
    "\n",
    "#         self._ndims = index.ndim\n",
    "#         logger.debug(\"Opening index\")\n",
    "#         return Ok(index)\n",
    "\n",
    "#     def search(\n",
    "#         self,\n",
    "#         query: NDArray[np.float32],\n",
    "#         limit: int = 10,\n",
    "#         include: list[int] | None = None,\n",
    "#         exclude: list[int] | None = None,\n",
    "#     ) -> Result[pl.DataFrame, str]:\n",
    "#         return self.vector_search(query, limit, include, exclude)\n",
    "\n",
    "#     def vector_search(\n",
    "#         self,\n",
    "#         query: NDArray[np.float32],\n",
    "#         limit: int = 10,\n",
    "#         include: list[int] | None = None,\n",
    "#         exclude: list[int] | None = None,\n",
    "#         exact: bool = False,\n",
    "#     ) -> Result[pl.DataFrame, str]:\n",
    "#         output = self.index.search(vectors=query, count=limit, log=True, exact=exact)\n",
    "\n",
    "#         logger.debug(f\"Visited members: {output.visited_members}\")\n",
    "#         logger.debug(f\"Computed distances: {output.computed_distances}\")\n",
    "\n",
    "#         # Extract keys (geonameids) and distances\n",
    "#         keys = output.keys\n",
    "#         distances = output.distances\n",
    "\n",
    "#         # Create a DataFrame from the search results\n",
    "#         results_df = pl.LazyFrame(\n",
    "#             data={self.id_column: keys, \"score\": distances},\n",
    "#             schema={self.id_column: pl.UInt32, \"score\": pl.Float32},\n",
    "#         )\n",
    "#         if self.metric == \"haversine\":\n",
    "#             results_df = results_df.with_columns(pl.col(\"score\") * 6371.0)\n",
    "\n",
    "#         results_df = results_df.sort(\n",
    "#             \"score\"\n",
    "#         )  # TODO: ascending descending depending on metric.\n",
    "\n",
    "#         return Ok(results_df.collect())\n",
    "\n",
    "\n",
    "# class FTSIndex:\n",
    "#     default_index_path = Path(\"./data/indexes/fts\")\n",
    "\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         index_name: str,\n",
    "#         data: pl.DataFrame | None = None,\n",
    "#         id_column: str = \"geonameId\",\n",
    "#         main_column: str = \"name\",\n",
    "#     ):\n",
    "#         self._index_path = self.default_index_path / index_name\n",
    "#         self._column_types = {}\n",
    "#         self._id_column = id_column\n",
    "#         self._main_column = main_column\n",
    "#         index = self.get_or_build_index(data)\n",
    "#         if isinstance(index, Err):\n",
    "#             logger.debug(\n",
    "#                 f\"Index does not exist at '{self.index_path}', build index with 'build_index' method.\"\n",
    "#             )\n",
    "#             self._index = None  # type: ignore\n",
    "#         else:\n",
    "#             self._index: tantivy.Index = index.ok_value\n",
    "\n",
    "#     @property\n",
    "#     def index(self) -> tantivy.Index:\n",
    "#         self._index.reload()\n",
    "#         return self._index\n",
    "\n",
    "#     @property\n",
    "#     def column_types(self) -> dict[str, str]:\n",
    "#         return self._column_types\n",
    "\n",
    "#     @property\n",
    "#     def id_column(self) -> str:\n",
    "#         return self._id_column\n",
    "\n",
    "#     @property\n",
    "#     def main_column(self) -> str:\n",
    "#         return self._main_column\n",
    "\n",
    "#     @property\n",
    "#     def index_path(self) -> Path:\n",
    "#         return self._index_path\n",
    "\n",
    "#     @property\n",
    "#     def columns_not_id(self) -> list[str]:\n",
    "#         return [col for col in self.column_types if col != self.id_column]\n",
    "\n",
    "#     def _build_index(\n",
    "#         self,\n",
    "#         df: pl.DataFrame,\n",
    "#         split_field: dict[str, list[str] | str] | None = None,\n",
    "#     ) -> Result[tantivy.Index, str]:\n",
    "#         \"\"\"Only pass in data which you wish to build the ftx index with. split_field is a dictionary of fields to split by a delimiter. eg {\",\": [\"field1\", \"field2\"]} will split field1 and field2 by comma.\"\"\"\n",
    "#         # TODO: this programmatically into tantivy schema\n",
    "#         schema_builder = tantivy.SchemaBuilder()\n",
    "\n",
    "#         if self.id_column not in df.columns:\n",
    "#             return Err(f\"'{self.id_column}' column not found in DataFrame\")\n",
    "\n",
    "#         col_types = {}\n",
    "#         for col in df.columns:\n",
    "#             if col == self.id_column:\n",
    "#                 schema_builder.add_integer_field(\n",
    "#                     self.id_column, stored=True, indexed=True, fast=True\n",
    "#                 )\n",
    "#             # TODO: ADD support for other types\n",
    "#             else:\n",
    "#                 schema_builder.add_text_field(col)\n",
    "#             col_types[col] = df[col].dtype._string_repr()\n",
    "\n",
    "#         self._column_types = col_types\n",
    "\n",
    "#         schema = schema_builder.build()\n",
    "#         logger.debug(f\"Creating index with columns:\\n{json.dumps(col_types, indent=2)}\")\n",
    "\n",
    "#         index = tantivy.Index(schema, path=self.index_path.as_posix(), reuse=False)\n",
    "#         writer = index.writer()\n",
    "#         for row in df.rows(named=True):\n",
    "#             if split_field:\n",
    "#                 for splitter, fields in split_field.items():\n",
    "#                     if isinstance(fields, str):\n",
    "#                         fields = [fields]\n",
    "#                     for field in fields:\n",
    "#                         logger.debug(f\"Splitting {field} by {splitter}...\")\n",
    "#                         row[field] = row[field].split(splitter)\n",
    "#             writer.add_document(tantivy.Document(**row))\n",
    "#         writer.commit()\n",
    "#         writer.wait_merging_threads()\n",
    "#         return Ok(index)\n",
    "\n",
    "#     def get_index(self) -> Result[tantivy.Index, str]:\n",
    "#         if tantivy.Index.exists(self.index_path.as_posix()):\n",
    "#             logger.debug(f\"Opening index at '{self.index_path}'\")\n",
    "#             return Ok(tantivy.Index.open(self.index_path.as_posix()))\n",
    "#         return Err(f\"Index does not exist at '{self.index_path}'\")\n",
    "\n",
    "#     def get_or_build_index(\n",
    "#         self, df: pl.DataFrame | None = None\n",
    "#     ) -> Result[tantivy.Index, str]:\n",
    "#         if not self.index_path.exists() and df is None:\n",
    "#             return Err(\"Index does not exist. DataFrame is required to create index\")\n",
    "\n",
    "#         self.index_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#         if not tantivy.Index.exists(self.index_path.as_posix()):\n",
    "#             if df is None:\n",
    "#                 return Err(\"DataFrame is required to create index\")\n",
    "#             match self._build_index(df):\n",
    "#                 case Ok(index):\n",
    "#                     ...\n",
    "#                 case Err(e):\n",
    "#                     return Err(e)\n",
    "#         else:\n",
    "#             match self.get_index():\n",
    "#                 case Ok(index):\n",
    "#                     ...\n",
    "#                 case Err(e):\n",
    "#                     return Err(e)\n",
    "#         schema = json.loads((self.index_path / \"meta.json\").read_text())[\"schema\"]\n",
    "#         sc = {}\n",
    "#         for v in schema:\n",
    "#             type_ = v[\"type\"]\n",
    "#             if type_ == \"text\":\n",
    "#                 type_ = pl.Utf8\n",
    "#             elif type_ == \"i64\":\n",
    "#                 type_ = pl.UInt32\n",
    "#             sc[v[\"name\"]] = type_\n",
    "\n",
    "#         self._column_types = sc\n",
    "#         logger.debug(\"Schema Loaded\")\n",
    "#         logger.debug(\"Opening country index\")\n",
    "#         return Ok(index)\n",
    "\n",
    "#     def convert_fts_results(\n",
    "#         self, hits: tantivy.SearchResult, searcher: tantivy.Searcher\n",
    "#     ) -> pl.DataFrame:\n",
    "#         logger.debug(f\"FTS hits from search: {hits.count}\")  # type: ignore\n",
    "\n",
    "#         scores, gids = zip(\n",
    "#             *[\n",
    "#                 (score, searcher.doc(doc).get_first(self.id_column))\n",
    "#                 for score, doc in hits.hits\n",
    "#             ]\n",
    "#         )\n",
    "\n",
    "#         return (\n",
    "#             pl.LazyFrame(\n",
    "#                 {\"geonameId\": list(gids), \"score\": list(scores)},\n",
    "#                 schema={\"geonameId\": pl.UInt32, \"score\": pl.Float32},\n",
    "#             )\n",
    "#             .sort(\"score\", descending=True, maintain_order=True)\n",
    "#             .collect()\n",
    "#         )\n",
    "\n",
    "#     def search(\n",
    "#         self,\n",
    "#         query: str,\n",
    "#         limit: int = 10,\n",
    "#         include: list[int] | None = None,\n",
    "#         exclude: list[int] | None = None,\n",
    "#     ) -> Result[pl.DataFrame, str]:\n",
    "#         return self.fts_search(\n",
    "#             query,\n",
    "#             limit=limit,\n",
    "#             include=include,\n",
    "#             exclude=exclude,\n",
    "#         )\n",
    "\n",
    "#     def fts_search(\n",
    "#         self,\n",
    "#         query: str,\n",
    "#         limit: int = 10,\n",
    "#         include: list[int] | None = None,\n",
    "#         exclude: list[int] | None = None,\n",
    "#         main_term_query_boost: float = 3.0,\n",
    "#         fuzzy_term_query_boost: float = 2.0,\n",
    "#         max_fuzzy_distance: int = 2,\n",
    "#         phrase: bool = True,\n",
    "#     ) -> Result[pl.DataFrame, str]:\n",
    "#         # Create for list of queries (batch search)\n",
    "#         if phrase:\n",
    "#             query = f\"'{query}'\"\n",
    "#         else:\n",
    "#             query = query.strip(\"\\\"'\")\n",
    "#         query = query.strip()\n",
    "#         index = self.index\n",
    "\n",
    "#         searcher = index.searcher()\n",
    "\n",
    "#         bool_query_list: list[tuple[tantivy.Occur, tantivy.Query]] = []\n",
    "\n",
    "#         # Calculate fuzzy distance based on query length\n",
    "#         fuzzy_distance = min(max(0, len(query) - 2), max_fuzzy_distance)\n",
    "\n",
    "#         if self.main_column in self.columns_not_id:\n",
    "#             main_term_query = tantivy.Query.term_query(\n",
    "#                 index.schema, self.main_column, query\n",
    "#             )\n",
    "#             bool_query_list.append(\n",
    "#                 (\n",
    "#                     tantivy.Occur.Should,\n",
    "#                     tantivy.Query.boost_query(main_term_query, main_term_query_boost),\n",
    "#                 )\n",
    "#             )\n",
    "\n",
    "#             if fuzzy_distance > 0:\n",
    "#                 main_fuzzy_query = tantivy.Query.fuzzy_term_query(\n",
    "#                     index.schema, self.main_column, query, distance=fuzzy_distance\n",
    "#                 )\n",
    "\n",
    "#                 bool_query_list.append(\n",
    "#                     (\n",
    "#                         tantivy.Occur.Should,\n",
    "#                         tantivy.Query.boost_query(\n",
    "#                             main_fuzzy_query, fuzzy_term_query_boost\n",
    "#                         ),\n",
    "#                     )\n",
    "#                 )\n",
    "\n",
    "#             rest_of_query = index.parse_query(\n",
    "#                 query, list(set(self.columns_not_id) - {self.main_column})\n",
    "#             )\n",
    "#             bool_query_list.append((tantivy.Occur.Should, rest_of_query))\n",
    "\n",
    "#         if include:\n",
    "#             bool_query_list.append(\n",
    "#                 (\n",
    "#                     tantivy.Occur.Must,\n",
    "#                     tantivy.Query.term_set_query(index.schema, self.id_column, include),\n",
    "#                 )\n",
    "#             )\n",
    "#         if exclude:\n",
    "#             bool_query_list.append(\n",
    "#                 (\n",
    "#                     tantivy.Occur.MustNot,\n",
    "#                     tantivy.Query.term_set_query(index.schema, self.id_column, exclude),\n",
    "#                 )\n",
    "#             )\n",
    "#         if bool_query_list:\n",
    "#             final_query = tantivy.Query.boolean_query(bool_query_list)\n",
    "\n",
    "#         else:\n",
    "#             final_query: tantivy.Query = index.parse_query(\n",
    "#                 query, default_field_names=self.columns_not_id\n",
    "#             )\n",
    "\n",
    "#         logger.debug(final_query)\n",
    "\n",
    "#         hits: tantivy.SearchResult = searcher.search(final_query, limit=limit)\n",
    "\n",
    "#         if hits.count == 0:  # type: ignore\n",
    "#             if phrase:\n",
    "#                 logger.debug(\"No results found, retrying without phrase search...\")\n",
    "#                 return self.fts_search(\n",
    "#                     query,\n",
    "#                     limit,\n",
    "#                     include,\n",
    "#                     exclude,\n",
    "#                     main_term_query_boost,\n",
    "#                     fuzzy_term_query_boost,\n",
    "#                     max_fuzzy_distance,\n",
    "#                     phrase=False,\n",
    "#                 )\n",
    "#             return Err(\"No results found\")\n",
    "\n",
    "#         return Ok(self.convert_fts_results(hits, searcher))\n",
    "\n",
    "\n",
    "# class HybridIndex:\n",
    "#     def __init__(self, fts_idx: FTSIndex, vidx: VectorIndex):\n",
    "#         self._fts_idx = fts_idx\n",
    "#         self._vidx = vidx\n",
    "\n",
    "#     @property\n",
    "#     def vector_index(self) -> VectorIndex:\n",
    "#         return self._vidx\n",
    "\n",
    "#     @property\n",
    "#     def fts_index(self) -> FTSIndex:\n",
    "#         return self._fts_idx\n",
    "\n",
    "#     def search(\n",
    "#         self,\n",
    "#         query: str,\n",
    "#         limit: int = 10,\n",
    "#         include: list[int] | None = None,\n",
    "#         exclude: list[int] | None = None,\n",
    "#         main_term_query_boost: float = 3.0,\n",
    "#         fuzzy_term_query_boost: float = 2.0,\n",
    "#         max_fuzzy_distance: int = 2,\n",
    "#         phrase: bool = True,\n",
    "#     ) -> Result[pl.DataFrame, str]:\n",
    "#         v_search = self.vector_index.vector_search\n",
    "\n",
    "\n",
    "# country_index = FTSIndex(\"admin0\", con.table(\"admin0_FTS\").pl())\n",
    "# country_index.fts_search(\"An Danmhairg\").unwrap().join(\n",
    "#     con.table(\"admin0\").pl(), \"geonameId\", \"left\"\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
