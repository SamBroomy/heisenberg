{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "import polars_distance as pld\n",
    "from pprint import pprint\n",
    "from loguru import logger\n",
    "import polars.selectors as cs\n",
    "import kuzu as kz\n",
    "from pathlib import Path\n",
    "from typing import Type, Callable\n",
    "from usearch.index import Index, Matches\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from numpy.typing import NDArray\n",
    "import duckdb\n",
    "from duckdb import DuckDBPyConnection\n",
    "from time import time\n",
    "\n",
    "pl.Config.set_tbl_rows(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x107cf1cb0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duck_db_path = Path(\"./data/db/duck_db/data.db\")\n",
    "duck_db_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "con = duckdb.connect(database=duck_db_path.as_posix())\n",
    "\n",
    "con.execute(\"SET enable_progress_bar = false;\")\n",
    "con.install_extension(\"spatial\")\n",
    "con.load_extension(\"spatial\")\n",
    "\n",
    "# Set DuckDB optimizations\n",
    "con.execute(\"PRAGMA memory_limit='16GB'\")  # Adjust based on your system\n",
    "con.execute(\"PRAGMA threads=8\")  # Adjust based on your CPU cores\n",
    "con.execute(\"PRAGMA enable_object_cache=true\")  # Improve query caching\n",
    "con.execute(\"PRAGMA profiling_mode = 'standard'\")  # Set profiling mode\n",
    "con.execute(\"PRAGMA enable_profiling = 'json'\")  # Enable profiling\n",
    "con.execute(\"PRAGMA profiling_output = './profile.json'\")  # Set profiling output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_FOLDER = Path(\"./sql\")\n",
    "\n",
    "\n",
    "def sql_file(sql_path: Path | str, **kwargs) -> str:\n",
    "    if isinstance(sql_path, str):\n",
    "        sql_path = Path(sql_path)\n",
    "    if not sql_path.exists():\n",
    "        sql_path = SQL_FOLDER / sql_path\n",
    "        if not sql_path.exists():\n",
    "            raise FileNotFoundError(f\"SQL file {sql_path} not found\")\n",
    "    sql = sql_path.read_text()\n",
    "    if kwargs:\n",
    "        sql = sql.format(**kwargs)\n",
    "\n",
    "    # Validate no {kwarg} left in string (regex)\n",
    "    # if uninit_kwargs := re.findall(r\"\\{.*\\}\", sql):\n",
    "    #     raise ValueError(\n",
    "    #         f\"SQL file {sql_path} still has unprocessed kwargs: {list(set(uninit_kwargs))} in:\\n\\n{sql}\"\n",
    "    #     )\n",
    "\n",
    "    return sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 13:25:46.487\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_file\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mTable 'allCountries' already exists\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:46.490\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_file\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mTable 'allPostCodes' already exists\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:46.494\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_file\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mTable 'admin1CodesASCII' already exists\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:46.497\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_file\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mTable 'admin2Codes' already exists\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:46.501\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_file\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mTable 'adminCode5' already exists\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:46.504\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_file\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mTable 'alternateNamesV2' already exists\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:46.507\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_file\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mTable 'countryInfo' already exists\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:46.511\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_file\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mTable 'featureCodes' already exists\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:46.514\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_file\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mTable 'hierarchy' already exists\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:46.518\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_file\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mTable 'iso_languagecodes' already exists\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:46.522\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_file\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mTable 'timeZones' already exists\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x107cf1cb0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GID = \"geonameId\"\n",
    "\n",
    "\n",
    "def table_exists(con: DuckDBPyConnection, table_name: str) -> bool:\n",
    "    return table_name in con.execute(\"SHOW TABLES\").pl()[\"name\"]\n",
    "\n",
    "\n",
    "# Read and load 'allCountries.txt'\n",
    "# Function to read and load other files with different schemas\n",
    "def load_file(\n",
    "    # con: DuckDBPyConnection,\n",
    "    file_path: str,\n",
    "    schema: dict[str, Type[pl.DataType]],\n",
    "    table_name: str,\n",
    "    table_definition: str | None = None,\n",
    "    pipe: Callable[[pl.LazyFrame], pl.LazyFrame] | None = None,\n",
    "    has_header: bool = False,\n",
    "    skip_rows: int = 0,\n",
    "    overwrite: bool = False,\n",
    "    extra_expr: pl.Expr | None = None,\n",
    "):\n",
    "    if table_exists(con, table_name):\n",
    "        logger.debug(f\"Table '{table_name}' already exists\")\n",
    "        if not overwrite:\n",
    "            return\n",
    "        logger.debug(f\"Overwriting table '{table_name}'\")\n",
    "        con.execute(f\"DROP TABLE {table_name} CASCADE\")\n",
    "        logger.debug(f\"Table '{table_name}' dropped\")\n",
    "    time_start = time()\n",
    "    load = con.begin()\n",
    "    try:\n",
    "        logger.info(f\"Loading '{file_path}'...\")\n",
    "        # Time scan\n",
    "        time_scan = time()\n",
    "        q = pl.scan_csv(\n",
    "            file_path,\n",
    "            separator=\"\\t\",\n",
    "            has_header=has_header,\n",
    "            schema=schema,\n",
    "            skip_rows=skip_rows,\n",
    "        )\n",
    "        q = q.with_columns(\n",
    "            pl.col(pl.Utf8).str.strip_chars().str.strip_chars(\"\\\"':\").str.strip_chars()\n",
    "        )\n",
    "        if extra_expr is not None:\n",
    "            q = q.with_columns(extra_expr)\n",
    "        if pipe is not None:\n",
    "            q = q.pipe(pipe)\n",
    "        if GID in schema:\n",
    "            q = q.sort(GID, nulls_last=True)\n",
    "        logger.debug(f\"Scan time: {time() - time_scan:.6f}s\")\n",
    "\n",
    "        q = q.with_columns(cs.by_dtype(pl.String).str.strip_chars().replace(\"\", None))\n",
    "\n",
    "        # Time collect\n",
    "        time_collect = time()\n",
    "        df = q.collect()\n",
    "        logger.debug(f\"Collect time: {time() - time_collect:.6f}s\")\n",
    "\n",
    "        # Time write\n",
    "        time_write = time()\n",
    "        save_path = Path(f\"./data/processed/geonames/{table_name}.parquet\")\n",
    "        save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df.write_parquet(save_path.as_posix())\n",
    "        logger.debug(f\"Write time: {time() - time_write:.6f}s\")\n",
    "\n",
    "        # Time create\n",
    "        time_create = time()\n",
    "        # Create table with predefined schema if provided\n",
    "        time_create = time()\n",
    "        if table_definition:\n",
    "            # Create the table with specified schema\n",
    "            load.execute(table_definition)\n",
    "            load.from_arrow(df.to_arrow()).insert_into(table_name)\n",
    "        else:\n",
    "            # Use automatic schema derivation (your current approach)\n",
    "            load.from_arrow(df.to_arrow()).create(table_name)\n",
    "\n",
    "        logger.debug(f\"Create time: {time() - time_create:.6f}s\")\n",
    "\n",
    "        time_commit = time()\n",
    "        load.commit()\n",
    "        logger.debug(f\"Commit time: {time() - time_commit:.6f}s\")\n",
    "        analyze_time = time()\n",
    "        con.execute(\"VACUUM ANALYZE;\")\n",
    "        logger.debug(f\"Analyze time: {time() - analyze_time:.6f}s\")\n",
    "    except Exception as e:\n",
    "        logger.exception(\"Error loading '{file_path}'\")\n",
    "        logger.debug(e.with_traceback(None))\n",
    "        # Time rollback\n",
    "        time_rollback = time()\n",
    "        load.rollback()\n",
    "        logger.warning(f\"Rollback time: {time() - time_rollback:.6f}s\")\n",
    "        raise e\n",
    "    finally:\n",
    "        logger.info(f\"Total time: {time() - time_start:.6f}s\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def drop_duplicates(df: pl.LazyFrame) -> pl.LazyFrame:\n",
    "    cols = [\n",
    "        \"name\",\n",
    "        \"asciiname\",\n",
    "        \"feature_class\",\n",
    "        \"feature_code\",\n",
    "        \"admin0_code\",\n",
    "        \"admin1_code\",\n",
    "        \"admin2_code\",\n",
    "        \"admin3_code\",\n",
    "        \"admin4_code\",\n",
    "        \"timezone\",\n",
    "    ]\n",
    "    return (\n",
    "        df.sort(\"modification_date\", descending=True)\n",
    "        .unique(cols, keep=\"first\")\n",
    "        .filter(~pl.all_horizontal(pl.col(cols).is_null()))\n",
    "        .sort(\"geonameId\")\n",
    "    )\n",
    "\n",
    "\n",
    "schema_all_countries = {\n",
    "    GID: pl.UInt32,\n",
    "    \"name\": pl.Utf8,\n",
    "    \"asciiname\": pl.Utf8,\n",
    "    \"alternatenames\": pl.Utf8,\n",
    "    \"latitude\": pl.Float32,\n",
    "    \"longitude\": pl.Float32,\n",
    "    \"feature_class\": pl.Categorical,\n",
    "    \"feature_code\": pl.Categorical,\n",
    "    \"admin0_code\": pl.Categorical,\n",
    "    \"cc2\": pl.Utf8,\n",
    "    \"admin1_code\": pl.Utf8,\n",
    "    \"admin2_code\": pl.Utf8,\n",
    "    \"admin3_code\": pl.Utf8,\n",
    "    \"admin4_code\": pl.Utf8,\n",
    "    \"population\": pl.Int64,\n",
    "    \"elevation\": pl.Int32,\n",
    "    \"dem\": pl.Int32,\n",
    "    \"timezone\": pl.Categorical,\n",
    "    \"modification_date\": pl.Date,\n",
    "}\n",
    "\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/allCountries.txt\",\n",
    "    schema_all_countries,\n",
    "    \"allCountries\",\n",
    "    table_definition=sql_file(\"create_table_allCountries.sql\"),\n",
    "    pipe=drop_duplicates,\n",
    ")\n",
    "\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/allCountriesPostCode.txt\",\n",
    "    {\n",
    "        \"admin_code0\": pl.Categorical,\n",
    "        \"postal_code\": pl.Utf8,\n",
    "        \"place_name\": pl.Utf8,\n",
    "        \"admin_name1\": pl.Utf8,\n",
    "        \"admin_code1\": pl.Utf8,\n",
    "        \"admin_name2\": pl.Utf8,\n",
    "        \"admin_code2\": pl.Utf8,\n",
    "        \"admin_name3\": pl.Utf8,\n",
    "        \"admin_code3\": pl.Utf8,\n",
    "        \"latitude\": pl.Float32,\n",
    "        \"longitude\": pl.Float32,\n",
    "        \"accuracy\": pl.Int32,\n",
    "    },\n",
    "    \"allPostCodes\",\n",
    ")\n",
    "\n",
    "\n",
    "# Load other files with respective schemas\n",
    "load_file(\n",
    "    \"./data/raw/geonames/admin1CodesASCII.txt\",\n",
    "    {\n",
    "        \"code\": pl.Utf8,\n",
    "        \"name\": pl.Utf8,\n",
    "        \"name_ascii\": pl.Utf8,\n",
    "        GID: pl.UInt32,\n",
    "    },\n",
    "    \"admin1CodesASCII\",\n",
    "    table_definition=sql_file(\"create_table_admin1CodesASCII.sql\"),\n",
    ")\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/admin2Codes.txt\",\n",
    "    {\n",
    "        \"code\": pl.Utf8,\n",
    "        \"name\": pl.Utf8,\n",
    "        \"asciiname\": pl.Utf8,\n",
    "        GID: pl.UInt32,\n",
    "    },\n",
    "    \"admin2Codes\",\n",
    "    table_definition=sql_file(\"create_table_admin2Codes.sql\"),\n",
    ")\n",
    "\n",
    "\n",
    "def drop_invalid_gids(df: pl.LazyFrame, con: DuckDBPyConnection) -> pl.LazyFrame:\n",
    "    ids = con.execute(\"SELECT geonameId FROM allCountries\").pl().unique().to_series()\n",
    "    return df.filter(pl.col(GID).is_in(ids))\n",
    "\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/adminCode5.txt\",\n",
    "    {\n",
    "        GID: pl.UInt32,\n",
    "        \"adm5code\": pl.Utf8,\n",
    "    },\n",
    "    \"adminCode5\",\n",
    "    table_definition=sql_file(\"create_table_adminCode5.sql\"),\n",
    "    pipe=partial(drop_invalid_gids, con=con),\n",
    ")\n",
    "\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/alternateNamesV2.txt\",\n",
    "    {\n",
    "        \"alternateNameId\": pl.Int32,\n",
    "        GID: pl.UInt32,\n",
    "        \"isolanguage\": pl.Utf8,\n",
    "        \"alternate_name\": pl.Utf8,\n",
    "        \"isPreferredName\": pl.Int8,\n",
    "        \"isShortName\": pl.Int8,\n",
    "        \"isColloquial\": pl.Int8,\n",
    "        \"isHistoric\": pl.Int8,\n",
    "        \"from\": pl.Utf8,\n",
    "        \"to\": pl.Utf8,\n",
    "    },\n",
    "    \"alternateNamesV2\",\n",
    "    table_definition=sql_file(\"create_table_alternateNamesV2.sql\"),\n",
    "    extra_expr=cs.by_dtype(pl.Int8).cast(pl.Boolean).fill_null(False),\n",
    "    pipe=partial(drop_invalid_gids, con=con),\n",
    ")\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/countryInfo.txt\",\n",
    "    {\n",
    "        \"ISO\": pl.Categorical,\n",
    "        \"ISO3\": pl.Categorical,\n",
    "        \"ISO_Numeric\": pl.Int32,\n",
    "        \"fips\": pl.Categorical,\n",
    "        \"Country\": pl.Utf8,\n",
    "        \"Capital\": pl.Utf8,\n",
    "        \"Area\": pl.Float32,\n",
    "        \"Population\": pl.Int32,\n",
    "        \"Continent\": pl.Categorical,\n",
    "        \"tld\": pl.Utf8,\n",
    "        \"CurrencyCode\": pl.Utf8,\n",
    "        \"CurrencyName\": pl.Utf8,\n",
    "        \"Phone\": pl.Utf8,\n",
    "        \"Postal_Code_Format\": pl.Utf8,\n",
    "        \"Postal_Code_Regex\": pl.Utf8,\n",
    "        \"Languages\": pl.Utf8,\n",
    "        GID: pl.UInt32,\n",
    "        \"neighbours\": pl.Utf8,\n",
    "        \"EquivalentFipsCode\": pl.Utf8,\n",
    "    },\n",
    "    \"countryInfo\",\n",
    "    table_definition=sql_file(\"create_table_countryInfo.sql\"),\n",
    "    skip_rows=51,\n",
    ")\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/featureCodes_en.txt\",\n",
    "    {\n",
    "        \"code\": pl.Categorical,\n",
    "        \"name\": pl.Utf8,\n",
    "        \"description\": pl.Utf8,\n",
    "    },\n",
    "    \"featureCodes\",\n",
    "    table_definition=sql_file(\"create_table_featureCodes.sql\"),\n",
    ")\n",
    "\n",
    "\n",
    "def remove_old_ids(df: pl.LazyFrame, con: DuckDBPyConnection) -> pl.LazyFrame:\n",
    "    ids = con.execute(\"SELECT geonameId FROM allCountries\").pl().unique().to_series()\n",
    "    return (\n",
    "        df.filter(pl.col(\"parentId\").is_in(ids) & pl.col(\"childId\").is_in(ids))\n",
    "        .with_columns(\n",
    "            pl.when(pl.col(\"type\").str.contains(\"adm\", literal=True))\n",
    "            .then(pl.col(\"type\").str.to_uppercase())\n",
    "            .otherwise(pl.col(\"type\"))\n",
    "        )\n",
    "        .unique([\"parentId\", \"childId\"])\n",
    "    )\n",
    "\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/hierarchy.txt\",\n",
    "    {\n",
    "        \"parentId\": pl.UInt32,\n",
    "        \"childId\": pl.UInt32,\n",
    "        \"type\": pl.Utf8,\n",
    "    },\n",
    "    \"hierarchy\",\n",
    "    table_definition=sql_file(\"create_table_hierarchy.sql\"),\n",
    "    pipe=partial(remove_old_ids, con=con),\n",
    ")\n",
    "con.execute(sql_file(\"create_table_unique_ids.sql\"))\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/iso-languagecodes.txt\",\n",
    "    {\n",
    "        \"ISO_639_3\": pl.Utf8,\n",
    "        \"ISO_639_2\": pl.Utf8,\n",
    "        \"ISO_639_1\": pl.Utf8,\n",
    "        \"Language_Name\": pl.Utf8,\n",
    "    },\n",
    "    \"iso_languagecodes\",\n",
    "    table_definition=sql_file(\"create_table_iso_languagecodes.sql\"),\n",
    ")\n",
    "\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/timeZones.txt\",\n",
    "    {\n",
    "        \"CountryCode\": pl.Utf8,\n",
    "        \"TimeZoneId\": pl.Utf8,\n",
    "        \"GMT_offset_1_Jan_2024\": pl.Float32,\n",
    "        \"DST_offset_1_Jul_2024\": pl.Float32,\n",
    "        \"rawOffset\": pl.Float32,\n",
    "    },\n",
    "    \"timeZones\",\n",
    "    table_definition=sql_file(\"create_table_timeZones.sql\"),\n",
    "    skip_rows=1,\n",
    ")\n",
    "# # Ignore loading the geo data for now\n",
    "if not table_exists(con, \"shapes\"):\n",
    "    con.execute(sql_file(\"create_table_shapes.sql\"))\n",
    "    logger.debug(\"Table 'shapes' created\")\n",
    "\n",
    "# # File is corupted atm\n",
    "# load_file(\n",
    "#     \"./data/raw/geonames/userTags.txt\",\n",
    "#     {\n",
    "#         GID: pl.Int32,\n",
    "#         \"tag\": pl.Utf8,\n",
    "#     },\n",
    "#     \"userTags\",\n",
    "# )\n",
    "con.execute(sql_file(\"create_table_equivalent.sql\"))\n",
    "con.execute(sql_file(\"create_view_cities.sql\"))\n",
    "con.execute(sql_file(\"create_view_locations_full.sql\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create country table\n",
    "# con.execute(sql_file(\"create_table_equivalent.sql\")).pl()\n",
    "# con.execute(sql_file(\"create_table_admin0.sql\")).execute(\"\"\"PRAGMA create_fts_index(\n",
    "#     admin0,\n",
    "#     geonameId,\n",
    "#     name,\n",
    "#     asciiname,\n",
    "#     official_name,\n",
    "#     alternatenames,\n",
    "#     admin0_code,\n",
    "#     ISO3,\n",
    "#     ISO_Numeric,\n",
    "#     fips,\n",
    "#     stemmer = 'none',\n",
    "#     stopwords = 'none',\n",
    "#     ignore = '(\\\\.|[^a-z0-9])+',\n",
    "#     overwrite = 1\n",
    "# );\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 13:25:47.433\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[34m\u001b[1mLoaded 534106 entities and 508066 hierarchical relationships\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:47.433\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[34m\u001b[1mEntity columns:\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:47.434\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m14\u001b[0m - \u001b[34m\u001b[1mHierarchy columns:\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "entities_df = con.execute(f\"\"\"\n",
    "    SELECT {GID}, name, feature_class, feature_code\n",
    "    FROM unique_ids\n",
    "\"\"\").pl()\n",
    "\n",
    "hierarchy_df = con.execute(\"\"\"\n",
    "    SELECT parentId, childId, type\n",
    "    FROM hierarchy\n",
    "\"\"\").pl()\n",
    "logger.debug(\n",
    "    f\"Loaded {len(entities_df)} entities and {len(hierarchy_df)} hierarchical relationships\"\n",
    ")\n",
    "logger.debug(\"Entity columns:\", entities_df.columns)\n",
    "logger.debug(\"Hierarchy columns:\", hierarchy_df.columns)\n",
    "\n",
    "# 2. Setup Kuzu database connection\n",
    "gdb_path = Path(\"./data/db/graph_db\")\n",
    "gdb_path.mkdir(parents=True, exist_ok=True)\n",
    "gdb = kz.Database(gdb_path.as_posix())\n",
    "conn = kz.Connection(gdb)\n",
    "\n",
    "# 3. Create the schema in Kuzu if needed\n",
    "if \"Entity\" not in conn.execute(\"CALL SHOW_TABLES() RETURN *;\").get_as_pl().get_column(\n",
    "    \"name\"\n",
    "):\n",
    "    conn.execute(sql_file(\"create_node_entity.sql\"))\n",
    "    logger.debug(\"Created Entity table\")\n",
    "\n",
    "if \"IsIn\" not in conn.execute(\"CALL SHOW_TABLES() RETURN *;\").get_as_pl().get_column(\n",
    "    \"name\"\n",
    "):\n",
    "    conn.execute(sql_file(\"create_relation_IsIn.sql\"))\n",
    "    logger.debug(\"Created IsIn table\")\n",
    "\n",
    "    # 4. Check if tables already have data\n",
    "are_nodes = (\n",
    "    conn.execute(\"MATCH (e:Entity) RETURN count(e) > 0 AS HasData\")\n",
    "    .get_as_pl()\n",
    "    .get_column(\"HasData\")[0]\n",
    ")\n",
    "are_edges = (\n",
    "    conn.execute(\"MATCH ()-[r:IsIn]->() RETURN count(r) > 0 AS HasData\")\n",
    "    .get_as_pl()\n",
    "    .get_column(\"HasData\")[0]\n",
    ")\n",
    "\n",
    "if not are_nodes:\n",
    "    conn.execute(\n",
    "        f\"COPY Entity FROM (LOAD FROM entities_df RETURN {GID}, name, feature_class, feature_code)\"\n",
    "    )\n",
    "    logger.debug(\"Loaded Entity\")\n",
    "\n",
    "if not are_edges:\n",
    "    conn.execute(\n",
    "        \"COPY IsIn FROM (LOAD FROM hierarchy_df RETURN parentId, childId, type)\"\n",
    "    )\n",
    "    logger.debug(\"Loaded IsIn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>feature_class</th><th>feature_code</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>6255146</td><td>&quot;Africa&quot;</td><td>&quot;L&quot;</td><td>&quot;CONT&quot;</td></tr><tr><td>7729889</td><td>&quot;Eastern Africa&quot;</td><td>&quot;L&quot;</td><td>&quot;RGN&quot;</td></tr><tr><td>11812257</td><td>&quot;Commonwealth of Nations&quot;</td><td>&quot;A&quot;</td><td>&quot;ZN&quot;</td></tr><tr><td>11820342</td><td>&quot;Horn of Africa&quot;</td><td>&quot;L&quot;</td><td>&quot;RGN&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 4)\n",
       "┌───────────┬─────────────────────────┬───────────────┬──────────────┐\n",
       "│ geonameId ┆ name                    ┆ feature_class ┆ feature_code │\n",
       "│ ---       ┆ ---                     ┆ ---           ┆ ---          │\n",
       "│ i32       ┆ str                     ┆ str           ┆ str          │\n",
       "╞═══════════╪═════════════════════════╪═══════════════╪══════════════╡\n",
       "│ 6255146   ┆ Africa                  ┆ L             ┆ CONT         │\n",
       "│ 7729889   ┆ Eastern Africa          ┆ L             ┆ RGN          │\n",
       "│ 11812257  ┆ Commonwealth of Nations ┆ A             ┆ ZN           │\n",
       "│ 11820342  ┆ Horn of Africa          ┆ L             ┆ RGN          │\n",
       "└───────────┴─────────────────────────┴───────────────┴──────────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_children_query(geoname_id: int) -> str:\n",
    "    query = f\"\"\"MATCH (p:Entity {{geonameId: {geoname_id}}})-[:IsIn]->(c:Entity)\n",
    "    RETURN c.{GID} AS {GID}, c.name AS name, c.feature_class AS feature_class, c.feature_code AS feature_code;\"\"\"\n",
    "    return query\n",
    "\n",
    "\n",
    "def get_parents_query(geoname_id):\n",
    "    query = f\"\"\"MATCH (c:Entity {{geonameId: {geoname_id}}})<-[:IsIn]-(p:Entity)\n",
    "    RETURN p.{GID} AS {GID}, p.name AS name, p.feature_class AS feature_class, p.feature_code AS feature_code;\"\"\"\n",
    "    return query\n",
    "\n",
    "\n",
    "# MATCH (c:Entity) WHERE CAST(c.geonameId, \"INT64\") IN list_creation({formatted_ids}) RETURN *;\n",
    "def get_children_querys(\n",
    "    geoname_ids: list[int] | pl.Series, traverse: bool = False\n",
    ") -> str:\n",
    "    query = f\"\"\"MATCH (p:Entity)-[:IsIn{\"*\" if traverse else \"\"}]->(c:Entity)\n",
    "    WHERE p.geonameId IN CAST({geoname_ids}, \"UINT32[]\")\n",
    "    RETURN DISTINCT c.{GID} AS {GID}, c.name AS name, c.feature_class AS feature_class, c.feature_code AS feature_code;\"\"\"\n",
    "    return query\n",
    "\n",
    "\n",
    "def get_parents_querys(\n",
    "    geoname_ids: list[int] | pl.Series, traverse: bool = False\n",
    ") -> str:\n",
    "    query = f\"\"\"MATCH (c:Entity)<-[:IsIn{\"*\" if traverse else \"\"}]-(p:Entity)\n",
    "    WHERE c.geonameId IN CAST({geoname_ids}, \"UINT32[]\")\n",
    "    RETURN DISTINCT p.{GID} AS {GID}, p.name AS name, p.feature_class AS feature_class, p.feature_code AS feature_code;\"\"\"\n",
    "    return query\n",
    "\n",
    "\n",
    "def get_highest_parent_query():\n",
    "    query = f\"\"\"\n",
    "    MATCH (entity:Entity)\n",
    "    WHERE NOT (entity)<-[:IsIn]-(:Entity)\n",
    "    RETURN entity.{GID} AS {GID}, entity.name AS name, entity.feature_class AS feature_class, entity.feature_code AS feature_code;\"\"\"\n",
    "    return query\n",
    "\n",
    "\n",
    "conn.execute(get_parents_query(49518)).get_as_pl()\n",
    "conn.execute(get_children_query(6252001)).get_as_pl()\n",
    "conn.execute(get_children_querys([49518, 51537])).get_as_pl()\n",
    "conn.execute(get_parents_querys([49518, 51537])).get_as_pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unified_admin_table(con, conn=None, overwrite=True):\n",
    "    \"\"\"Build a simplified admin_search table focusing on admin codes for hierarchy.\"\"\"\n",
    "\n",
    "    logger.debug(\"Starting simplified admin search table construction...\")\n",
    "\n",
    "    # Check if table exists\n",
    "    if table_exists(con, \"admin_search\") and not overwrite:\n",
    "        logger.debug(\"Table admin_search already exists. Skipping.\")\n",
    "        con.execute(\"VACUUM ANALYZE;\")\n",
    "        return\n",
    "\n",
    "    # Create the table with proper schema\n",
    "    con.execute(sql_file(\"create_unified_admin_table.sql\"))\n",
    "\n",
    "    # Define admin level feature code patterns\n",
    "    level_codes = {\n",
    "        0: [\"PCL\", \"PCLI\", \"PCLD\", \"PCLF\", \"PCLS\", \"TERR\"],\n",
    "        1: [\"ADM1\", \"ADM1H\"],\n",
    "        2: [\"ADM2\", \"ADM2H\"],\n",
    "        3: [\"ADM3\", \"ADM3H\"],\n",
    "        4: [\"ADM4\", \"ADM4H\"],\n",
    "    }\n",
    "\n",
    "    # Process each admin level\n",
    "    for level in range(0, 5):\n",
    "        logger.info(f\"Processing admin level {level} entities...\")\n",
    "\n",
    "        # Identify entities of this admin level by feature code\n",
    "        feature_patterns = \"', '\".join([code for code in level_codes[level]])\n",
    "\n",
    "        # Direct insert of entities with the matching feature codes\n",
    "        if level == 0:  # Countries (admin0)\n",
    "            insert_query = f\"\"\"\n",
    "            INSERT INTO admin_search\n",
    "            SELECT\n",
    "                a.geonameId,\n",
    "                a.name,\n",
    "                a.asciiname,\n",
    "                0 AS admin_level,\n",
    "                a.admin0_code,\n",
    "                NULL AS admin1_code,\n",
    "                NULL AS admin2_code,\n",
    "                NULL AS admin3_code,\n",
    "                NULL AS admin4_code,\n",
    "                a.feature_class,\n",
    "                a.feature_code,\n",
    "                c.ISO,\n",
    "                c.ISO3,\n",
    "                c.ISO_Numeric,\n",
    "                c.Country AS official_name,\n",
    "                c.fips,\n",
    "                a.latitude,\n",
    "                a.longitude,\n",
    "                c.population,\n",
    "                c.area,\n",
    "                a.alternatenames,\n",
    "                c.Country AS country_name\n",
    "            FROM\n",
    "                allCountries a\n",
    "            LEFT JOIN\n",
    "                countryInfo c ON a.geonameId = c.geonameId\n",
    "            WHERE\n",
    "                a.feature_code IN ('{feature_patterns}')\n",
    "                OR a.feature_code LIKE '{level_codes[level][0]}%'\n",
    "            \"\"\"\n",
    "        else:\n",
    "            # For admin levels 1-4\n",
    "            insert_query = f\"\"\"\n",
    "            INSERT INTO admin_search\n",
    "            SELECT\n",
    "                a.geonameId,\n",
    "                a.name,\n",
    "                a.asciiname,\n",
    "                {level} AS admin_level,\n",
    "                a.admin0_code,\n",
    "                {(\"a.admin1_code\" if level >= 1 else \"NULL::VARCHAR AS admin1_code\")},\n",
    "                {(\"a.admin2_code\" if level >= 2 else \"NULL::VARCHAR AS admin2_code\")},\n",
    "                {(\"a.admin3_code\" if level >= 3 else \"NULL::VARCHAR AS admin3_code\")},\n",
    "                {(\"a.admin4_code\" if level >= 4 else \"NULL::VARCHAR AS admin4_code\")},\n",
    "                a.feature_class,\n",
    "                a.feature_code,\n",
    "                NULL AS ISO,\n",
    "                NULL AS ISO3,\n",
    "                NULL AS ISO_Numeric,\n",
    "                NULL AS official_name,\n",
    "                NULL AS fips,\n",
    "                a.latitude,\n",
    "                a.longitude,\n",
    "                a.population,\n",
    "                NULL AS area,\n",
    "                a.alternatenames,\n",
    "                c.name AS country_name\n",
    "            FROM\n",
    "                allCountries a\n",
    "            LEFT JOIN\n",
    "                allCountries c ON a.admin0_code = c.admin0_code AND c.feature_code = 'PCLI'\n",
    "            WHERE\n",
    "                (a.feature_code IN ('{feature_patterns}')\n",
    "                OR a.feature_code LIKE '{level_codes[level][0]}%')\n",
    "                AND a.admin0_code IS NOT NULL\n",
    "            \"\"\"\n",
    "\n",
    "        # Execute the query to insert data\n",
    "        con.execute(insert_query)\n",
    "\n",
    "        # Report count\n",
    "        count = con.execute(\n",
    "            f\"SELECT COUNT(*) FROM admin_search WHERE admin_level = {level}\"\n",
    "        ).fetchone()[0]\n",
    "        logger.debug(f\"Added {count} entities for admin level {level}\")\n",
    "\n",
    "    # Create FTS index for the unified table\n",
    "    logger.debug(\"Creating FTS index for admin_search table...\")\n",
    "    con.execute(\"\"\"\n",
    "    PRAGMA create_fts_index(\n",
    "        admin_search,\n",
    "        geonameId,\n",
    "        name, asciiname, alternatenames, official_name, ISO, ISO3,\n",
    "        stemmer = 'none',\n",
    "        stopwords = 'none',\n",
    "        ignore = '(\\\\.|[^a-z0-9])+',\n",
    "        overwrite = 1\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    # Final optimization\n",
    "    logger.debug(\"Running VACUUM ANALYZE to optimize the database...\")\n",
    "    con.execute(\"VACUUM ANALYZE;\")\n",
    "\n",
    "    logger.debug(\"Admin search table construction complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 13:25:47.564\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbuild_unified_admin_table\u001b[0m:\u001b[36m4\u001b[0m - \u001b[34m\u001b[1mStarting simplified admin search table construction...\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:47.568\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbuild_unified_admin_table\u001b[0m:\u001b[36m8\u001b[0m - \u001b[34m\u001b[1mTable admin_search already exists. Skipping.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "build_unified_admin_table(con, conn, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 13:25:47.580\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbuild_places_search_table\u001b[0m:\u001b[36m4\u001b[0m - \u001b[34m\u001b[1mStarting places search table construction...\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:47.585\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbuild_places_search_table\u001b[0m:\u001b[36m7\u001b[0m - \u001b[34m\u001b[1mTable places_search already exists. Skipping.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def build_places_search_table(con, overwrite=True):\n",
    "    \"\"\"Build places_search table with balanced importance scoring.\"\"\"\n",
    "\n",
    "    logger.debug(\"Starting places search table construction...\")\n",
    "\n",
    "    if table_exists(con, \"places_search\") and not overwrite:\n",
    "        logger.debug(\"Table places_search already exists. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # Create the table with physical importance_tier column\n",
    "    con.execute(sql_file(\"create_places_search_table.sql\"))\n",
    "\n",
    "    # Define feature categories with more nuanced scoring\n",
    "    feature_categories = {\n",
    "        \"major_populated\": {\n",
    "            \"codes\": [\n",
    "                \"PPLA\",\n",
    "                \"PPLA2\",\n",
    "                \"PPLA3\",\n",
    "                \"PPLA4\",\n",
    "                \"PPLC\",\n",
    "                \"PPLF\",\n",
    "                \"PPLG\",\n",
    "                \"PPLR\",\n",
    "                \"PPLS\",\n",
    "            ],\n",
    "            \"min_population\": 0,\n",
    "            \"base_score\": 0.6,\n",
    "            \"pop_weight\": 0.7,\n",
    "            \"feature_weight\": 0.3,\n",
    "        },\n",
    "        \"landmarks\": {\n",
    "            \"codes\": [\n",
    "                \"CSTL\",\n",
    "                \"MNMT\",\n",
    "                \"RUIN\",\n",
    "                \"TOWR\",\n",
    "                \"ARCH\",\n",
    "                \"INSM\",\n",
    "                \"HSTS\",\n",
    "                \"CAVE\",\n",
    "                \"ANS\",\n",
    "                \"THTR\",\n",
    "                \"AMTH\",\n",
    "                \"MUS\",\n",
    "                \"LIBR\",\n",
    "                \"OPRA\",\n",
    "                \"PAL\",\n",
    "                \"PGDA\",\n",
    "                \"TMPL\",\n",
    "                \"SHRN\",\n",
    "                \"CH\",\n",
    "                \"MSQE\",\n",
    "                \"SYG\",\n",
    "                \"CVNT\",\n",
    "                \"MTRO\",\n",
    "                \"AIRP\",\n",
    "                \"PRT\",\n",
    "                \"RSTN\",\n",
    "                \"BUSTN\",\n",
    "                \"MAR\",\n",
    "            ],\n",
    "            \"min_population\": 0,\n",
    "            \"base_score\": 0.4,\n",
    "            \"pop_weight\": 0.3,\n",
    "            \"feature_weight\": 0.7,\n",
    "        },\n",
    "        \"natural_features\": {\n",
    "            \"codes\": [\n",
    "                \"MT\",\n",
    "                \"PK\",\n",
    "                \"PASS\",\n",
    "                \"VLC\",\n",
    "                \"ISL\",\n",
    "                \"BCH\",\n",
    "                \"BAY\",\n",
    "                \"CAPE\",\n",
    "                \"LK\",\n",
    "                \"FLLS\",\n",
    "                \"CNYN\",\n",
    "                \"VAL\",\n",
    "                \"DSRT\",\n",
    "                \"GLCR\",\n",
    "                \"RSV\",\n",
    "            ],\n",
    "            \"min_population\": 0,\n",
    "            \"base_score\": 0.3,\n",
    "            \"pop_weight\": 0.2,\n",
    "            \"feature_weight\": 0.8,\n",
    "        },\n",
    "        \"facilities\": {\n",
    "            \"codes\": [\n",
    "                \"HTL\",\n",
    "                \"RSRT\",\n",
    "                \"MALL\",\n",
    "                \"MKT\",\n",
    "                \"SCH\",\n",
    "                \"UNIV\",\n",
    "                \"HSP\",\n",
    "                \"ZOO\",\n",
    "                \"STDM\",\n",
    "                \"PRK\",\n",
    "                \"RECG\",\n",
    "                \"RECR\",\n",
    "                \"SPA\",\n",
    "                \"ATHF\",\n",
    "                \"ASYL\",\n",
    "            ],\n",
    "            \"min_population\": 0,\n",
    "            \"base_score\": 0.2,\n",
    "            \"pop_weight\": 0.5,\n",
    "            \"feature_weight\": 0.5,\n",
    "        },\n",
    "        \"infrastructure\": {\n",
    "            \"codes\": [\n",
    "                \"BDG\",\n",
    "                \"DAM\",\n",
    "                \"LOCK\",\n",
    "                \"LTHSE\",\n",
    "                \"BRKW\",\n",
    "                \"PIER\",\n",
    "                \"QUAY\",\n",
    "                \"PRMN\",\n",
    "                \"OILR\",\n",
    "                \"PS\",\n",
    "                \"PSH\",\n",
    "                \"PSN\",\n",
    "                \"CTRM\",\n",
    "                \"CTRF\",\n",
    "            ],\n",
    "            \"min_population\": 0,\n",
    "            \"base_score\": 0.15,\n",
    "            \"pop_weight\": 0.3,\n",
    "            \"feature_weight\": 0.7,\n",
    "        },\n",
    "        \"government\": {\n",
    "            \"codes\": [\n",
    "                \"ADMF\",\n",
    "                \"GOVL\",\n",
    "                \"CTHSE\",\n",
    "                \"DIP\",\n",
    "                \"BANK\",\n",
    "                \"PO\",\n",
    "                \"PP\",\n",
    "                \"CSTM\",\n",
    "                \"SCHC\",\n",
    "                \"MILB\",\n",
    "                \"INSM\",\n",
    "            ],\n",
    "            \"min_population\": 0,\n",
    "            \"base_score\": 0.25,\n",
    "            \"pop_weight\": 0.4,\n",
    "            \"feature_weight\": 0.6,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Process each category with improved scoring\n",
    "    for category, config in feature_categories.items():\n",
    "        logger.info(f\"Processing {category} features...\")\n",
    "\n",
    "        feature_codes = \"', '\".join(config[\"codes\"])\n",
    "\n",
    "        calculation = f\"\"\"\n",
    "        {config[\"base_score\"]} +\n",
    "                    (\n",
    "                        CASE\n",
    "                            WHEN a.population > 10000000 THEN 0.4\n",
    "                            WHEN a.population > 1000000 THEN 0.35\n",
    "                            WHEN a.population > 100000 THEN 0.3\n",
    "                            WHEN a.population > 10000 THEN 0.25\n",
    "                            WHEN a.population > 1000 THEN 0.2\n",
    "                            WHEN a.population > 100 THEN 0.15\n",
    "                            WHEN a.population > 0 THEN 0.1\n",
    "                            ELSE 0.05\n",
    "                        END * {config[\"pop_weight\"]}\n",
    "                        +\n",
    "                        CASE\n",
    "                            WHEN a.feature_code IN ('PPLC', 'CSTL', 'MNMT') THEN 0.4\n",
    "                            WHEN a.feature_code IN ('AIRP', 'TOWR', 'MUS', 'RUIN', 'PAL', 'PGDA') THEN 0.35\n",
    "                            WHEN a.feature_code IN ('UNIV', 'PPLA', 'RSTN', 'MAR', 'HTL') THEN 0.3\n",
    "                            WHEN a.feature_code IN ('MT', 'PK', 'VLC', 'ISL', 'BCH') THEN 0.25\n",
    "                            WHEN a.feature_code IN ('CH', 'HSP', 'SCH', 'THTR', 'STDM') THEN 0.2\n",
    "                            ELSE 0.1\n",
    "                        END * {config[\"feature_weight\"]}\n",
    "                        +\n",
    "                        CASE\n",
    "                            WHEN LENGTH(a.alternatenames) > 1000 THEN 0.2\n",
    "                            WHEN LENGTH(a.alternatenames) > 500 THEN 0.15\n",
    "                            WHEN LENGTH(a.alternatenames) > 100 THEN 0.1\n",
    "                            WHEN LENGTH(a.alternatenames) > 0 THEN 0.05\n",
    "                            ELSE 0\n",
    "                        END * 0.2\n",
    "                    )\"\"\"\n",
    "\n",
    "        insert_query = f\"\"\"\n",
    "        INSERT INTO places_search\n",
    "        SELECT\n",
    "            a.geonameId,\n",
    "            a.name,\n",
    "            a.asciiname,\n",
    "            a.admin0_code,\n",
    "            a.admin1_code,\n",
    "            a.admin2_code,\n",
    "            a.admin3_code,\n",
    "            a.admin4_code,\n",
    "            a.feature_class,\n",
    "            a.feature_code,\n",
    "            f.name AS feature_name,\n",
    "            a.latitude,\n",
    "            a.longitude,\n",
    "            a.population,\n",
    "            a.elevation,\n",
    "            a.alternatenames,\n",
    "            c.Country AS country_name,\n",
    "            -- More balanced importance scoring\n",
    "            {config[\"base_score\"]} +\n",
    "            (\n",
    "                -- Population component\n",
    "                CASE\n",
    "                    WHEN a.population > 10000000 THEN 0.4\n",
    "                    WHEN a.population > 1000000 THEN 0.35\n",
    "                    WHEN a.population > 100000 THEN 0.3\n",
    "                    WHEN a.population > 10000 THEN 0.25\n",
    "                    WHEN a.population > 1000 THEN 0.2\n",
    "                    WHEN a.population > 100 THEN 0.15\n",
    "                    WHEN a.population > 0 THEN 0.1\n",
    "                    ELSE 0.05\n",
    "                END * {config[\"pop_weight\"]}\n",
    "                +\n",
    "                -- Feature type component\n",
    "                CASE\n",
    "                    -- Capital cities and major landmarks\n",
    "                    WHEN a.feature_code IN ('PPLC', 'CSTL', 'MNMT') THEN 0.4\n",
    "                    -- Major tourist destinations\n",
    "                    WHEN a.feature_code IN ('AIRP', 'TOWR', 'MUS', 'RUIN', 'PAL', 'PGDA') THEN 0.35\n",
    "                    -- Important facilities\n",
    "                    WHEN a.feature_code IN ('UNIV', 'PPLA', 'RSTN', 'MAR', 'HTL') THEN 0.3\n",
    "                    -- Notable natural features\n",
    "                    WHEN a.feature_code IN ('MT', 'PK', 'VLC', 'ISL', 'BCH') THEN 0.25\n",
    "                    -- General infrastructure\n",
    "                    WHEN a.feature_code IN ('CH', 'HSP', 'SCH', 'THTR', 'STDM') THEN 0.2\n",
    "                    -- Other features\n",
    "                    ELSE 0.1\n",
    "                END * {config[\"feature_weight\"]}\n",
    "                +\n",
    "                -- Name recognition bonus (if it has many alternate names)\n",
    "                CASE\n",
    "                    WHEN LENGTH(a.alternatenames) > 1000 THEN 0.2\n",
    "                    WHEN LENGTH(a.alternatenames) > 500 THEN 0.15\n",
    "                    WHEN LENGTH(a.alternatenames) > 100 THEN 0.1\n",
    "                    WHEN LENGTH(a.alternatenames) > 0 THEN 0.05\n",
    "                    ELSE 0\n",
    "                END * 0.2\n",
    "            ) AS importance_score,\n",
    "            -- Calculate tier directly during insert\n",
    "            CASE\n",
    "                WHEN (\n",
    "                    {calculation}\n",
    "\n",
    "                ) >= 0.8 THEN 1  -- Top tier\n",
    "                WHEN ({calculation}) >= 0.6 THEN 2  -- High importance\n",
    "                WHEN ({calculation}) >= 0.4 THEN 3  -- Medium importance\n",
    "                WHEN ({calculation}) >= 0.2 THEN 4  -- Low importance\n",
    "                ELSE 5  -- Minimal importance\n",
    "            END AS importance_tier\n",
    "        FROM\n",
    "            allCountries a\n",
    "        LEFT JOIN\n",
    "            featureCodes f ON a.feature_class || '.' || a.feature_code = f.code\n",
    "        LEFT JOIN\n",
    "            countryInfo c ON a.admin0_code = c.ISO\n",
    "        WHERE\n",
    "            a.feature_code IN ('{feature_codes}')\n",
    "            AND a.population >= {config[\"min_population\"]}\n",
    "            AND a.admin0_code IS NOT NULL\n",
    "            AND NOT EXISTS (\n",
    "                SELECT 1 FROM admin_search\n",
    "                WHERE admin_search.geonameId = a.geonameId\n",
    "            )\n",
    "        \"\"\"\n",
    "        # Execute the query to insert data and get the number of rows added\n",
    "        count = con.execute(insert_query).fetchone()[0]\n",
    "        logger.debug(f\"Added {count} {category} features\")\n",
    "\n",
    "    # Add remaining features\n",
    "    logger.info(\"Adding remaining features with low importance...\")\n",
    "\n",
    "    processed_codes = []\n",
    "    for config in feature_categories.values():\n",
    "        processed_codes.extend(config[\"codes\"])\n",
    "\n",
    "    insert_remaining_query = f\"\"\"\n",
    "    INSERT INTO places_search\n",
    "    SELECT\n",
    "        a.geonameId,\n",
    "        a.name,\n",
    "        a.asciiname,\n",
    "        a.admin0_code,\n",
    "        a.admin1_code,\n",
    "        a.admin2_code,\n",
    "        a.admin3_code,\n",
    "        a.admin4_code,\n",
    "        a.feature_class,\n",
    "        a.feature_code,\n",
    "        f.name AS feature_name,\n",
    "        a.latitude,\n",
    "        a.longitude,\n",
    "        a.population,\n",
    "        a.elevation,\n",
    "        a.alternatenames,\n",
    "        c.Country AS country_name,\n",
    "        -- Base score for remaining features\n",
    "        0.1 +\n",
    "        CASE\n",
    "            WHEN a.population > 0 THEN LOG10(a.population) / 20\n",
    "            ELSE 0\n",
    "        END +\n",
    "        CASE\n",
    "            WHEN LENGTH(a.alternatenames) > 0 THEN 0.05\n",
    "            ELSE 0\n",
    "        END AS importance_score,\n",
    "        -- Calculate tier\n",
    "        CASE\n",
    "            WHEN (0.1 + CASE WHEN a.population > 0 THEN LOG10(a.population) / 20 ELSE 0 END) >= 0.2 THEN 4\n",
    "            ELSE 5\n",
    "        END AS importance_tier\n",
    "    FROM\n",
    "        allCountries a\n",
    "    LEFT JOIN\n",
    "        featureCodes f ON a.feature_class || '.' || a.feature_code = f.code\n",
    "    LEFT JOIN\n",
    "        countryInfo c ON a.admin0_code = c.ISO\n",
    "    WHERE\n",
    "        a.feature_code NOT IN ('{\"', '\".join(processed_codes)}')\n",
    "        AND NOT (a.feature_code LIKE 'ADM%' OR a.feature_code LIKE 'PCL%')\n",
    "        AND a.admin0_code IS NOT NULL\n",
    "        AND a.feature_class IN ('P', 'S', 'T', 'H', 'L', 'V', 'R')\n",
    "        AND a.name IS NOT NULL AND a.name != ''\n",
    "    \"\"\"\n",
    "\n",
    "    count = con.execute(insert_remaining_query).fetchone()[0]\n",
    "    logger.debug(f\"Added {count} remaining features with low importance\")\n",
    "\n",
    "    # Create FTS index\n",
    "    logger.debug(\"Creating FTS index for places_search table...\")\n",
    "    con.execute(\"\"\"\n",
    "    PRAGMA create_fts_index(\n",
    "        places_search,\n",
    "        geonameId,\n",
    "        name, asciiname, alternatenames,\n",
    "        stemmer = 'none',\n",
    "        stopwords = 'none',\n",
    "        ignore = '(\\\\.|[^a-z0-9])+',\n",
    "        overwrite = 1\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    # Update statistics\n",
    "    con.execute(\"VACUUM ANALYZE;\")\n",
    "\n",
    "    # Show tier distribution\n",
    "    tier_dist = con.execute(\"\"\"\n",
    "        SELECT importance_tier, COUNT(*) as count\n",
    "        FROM places_search\n",
    "        GROUP BY importance_tier\n",
    "        ORDER BY importance_tier\n",
    "    \"\"\").pl()\n",
    "\n",
    "    logger.info(\"Importance tier distribution:\")\n",
    "    for row in tier_dist.iter_rows(named=True):\n",
    "        logger.info(f\"  Tier {row['importance_tier']}: {row['count']:,} features\")\n",
    "\n",
    "    logger.info(\"Places search table construction complete!\")\n",
    "\n",
    "\n",
    "a = build_places_search_table(con, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()\n",
    "\n",
    "con = duckdb.connect(database=duck_db_path.as_posix(), read_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The idea here is now we want to have a more flexible search function.\n",
    "# As we have done above we have have created one big admin_search table, where the core idea of that is to allow us to search over multiple admin levels at once.\n",
    "# This will enable us to have two types of searches:\n",
    "# 1. Search for a specific admin level (e.g. admin1, admin2, etc.) and return results for that level.\n",
    "#   - This is useful when we want to find specific entities at a certain level.\n",
    "#   - It will take in a list of exactly length 5 that contains str or None for each admin level.\n",
    "#   - We can search for the exact level we want and return results for that level.\n",
    "# 2. Search for a term that is more flexible where you may not know what the exact level is.\n",
    "#   - This is useful when we want to find entities that match a term but may not know the exact level.\n",
    "#   - It will take in a list of potentially variable sizes (up to 5) that contains str only. The idea is that its essentially a window function and can sort of map it to the structured input of before.\n",
    "#      - Lets say we have a flexible the input of [A, B, C] where we are unsure of the level for each of the inputs. What we get is esentially a window function we are able to search over.\n",
    "#      - That input could be mapped to the structured input of [A, B, C, None, None] or [None, A, B, C, None] or [None, None, A, B, C], [A, None, B, None, C] etc. (and so on).\n",
    "#      - But we know that for 'A' there are three possible levels for it, so we can search over all of these levels (e.g. admin0, admin1, admin2) and return the results for that level. 'B' could be admin1, admin2, admin3 and so on. The idea is that we can use the number of terms that we have / that aren't None to determine the levels we want to search over.\n",
    "#   - This means that we need to be able to search over multiple levels at once and return results for all of them.\n",
    "#   - Once we have the results we can try and filter the next level based on the previous results.\n",
    "#   - Due to the nature of the flexible search it may not filter down nicely as the structured search, but we can try to filter it down as accurately as possible.\n",
    "\n",
    "\n",
    "def get_latest_adjusted_score_level(columns: list[str]) -> int | None:\n",
    "    adjusted_score_columns = [\n",
    "        col for col in columns if col.startswith(\"adjusted_score_\")\n",
    "    ]\n",
    "    if not adjusted_score_columns:\n",
    "        return None\n",
    "    # Extract the level from the column name and find the maximum level\n",
    "    levels = [int(col.rsplit(\"_\", maxsplit=1)[-1]) for col in adjusted_score_columns]\n",
    "    max_level = max(levels)\n",
    "    return max_level\n",
    "\n",
    "\n",
    "def search_score_admin(\n",
    "    df: pl.LazyFrame,\n",
    "    level: int,\n",
    "    text_weight: float = 0.35,\n",
    "    pop_weight: float = 0.35,\n",
    "    feature_weight: float = 0.15,\n",
    "    parent_weight: float = 0.15,\n",
    "    search_term: str | None = None,\n",
    ") -> pl.LazyFrame:\n",
    "    \"\"\"\n",
    "    A scoring function for geographic entities that better prioritizes\n",
    "    significant locations.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame with search results\n",
    "    - level: Admin level (0=country, 1=admin1, etc.)\n",
    "    - text_weight: Weight for text matching score\n",
    "    - pop_weight: Weight for population-based importance\n",
    "    - feature_weight: Weight for feature type significance\n",
    "    - parent_weight: Weight for parent entity scores\n",
    "    - search_term: Original search term (for exact match detection)\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with adjusted scores\n",
    "    \"\"\"\n",
    "    assert level in range(5), \"Level must be between 0 and 4\"\n",
    "    score_col = f\"adjusted_score_{level}\"\n",
    "    columns = df.collect_schema().names()\n",
    "\n",
    "    # ===== 1. Text relevance score =====\n",
    "    fts_column = f\"fts_score_{level}\"\n",
    "    if \"fts_score\" in columns:\n",
    "        df = df.rename({\"fts_score\": fts_column})\n",
    "\n",
    "        df = df.with_columns(\n",
    "            # Calculate z-score\n",
    "            z_score=(\n",
    "                (pl.col(fts_column) - pl.col(fts_column).mean())\n",
    "                / pl.when(pl.col(fts_column).std() > 0)\n",
    "                .then(pl.col(fts_column).std())\n",
    "                .otherwise(1.0)\n",
    "            ),\n",
    "        ).with_columns(\n",
    "            # Apply sigmoid transformation: 1/(1+e^(-z))\n",
    "            text_score=(1 / (1 + pl.col.z_score.mul(-1.5).exp()))\n",
    "        )\n",
    "        if search_term:\n",
    "            df = df.with_columns(\n",
    "                text_score=pl.when(\n",
    "                    pl.col.name.str.to_lowercase() == search_term.lower()\n",
    "                )\n",
    "                .then(1)\n",
    "                .otherwise(pl.col.text_score)\n",
    "                .clip(0, 1)\n",
    "            )\n",
    "    else:\n",
    "        logger.warning(\n",
    "            f\"Column '{fts_column}' not found in DataFrame. Skipping Z-score normalization.\"\n",
    "        )\n",
    "        df = df.with_columns(text_score=pl.lit(0.5))\n",
    "\n",
    "    # ===== 2. Population importance - stronger scaling =====\n",
    "    pop_col = \"population\"\n",
    "    if pop_col in columns:\n",
    "        df = df.with_columns(\n",
    "            # Sigmoid normalized population factor\n",
    "            pop_score=pl.when(pl.col(pop_col) > 0)\n",
    "            .then(\n",
    "                (\n",
    "                    # Stronger population scaling using logarithmic curve\n",
    "                    1 - 1 / (1 + (pl.col(pop_col).log10() / 3))\n",
    "                )\n",
    "            )\n",
    "            .otherwise(0.1)\n",
    "        )\n",
    "    else:\n",
    "        logger.warning(\n",
    "            f\"Column '{pop_col}' not found in DataFrame. Skipping population factor.\"\n",
    "        )\n",
    "        df = df.with_columns(pop_score=pl.lit(0.3))\n",
    "\n",
    "    # ===== 3. Feature type importance =====\n",
    "    feature_col = \"feature_code\"\n",
    "    if feature_col in columns:\n",
    "        df = df.with_columns(\n",
    "            # More nuanced feature type scoring based on importance\n",
    "            feature_score=pl.when(pl.col(feature_col) == \"PCLI\")\n",
    "            .then(1.0)  # Independent countries\n",
    "            .when(pl.col(feature_col).str.starts_with(\"PCL\"))\n",
    "            .then(0.9)  # Other country-like entities\n",
    "            .when(pl.col(feature_col) == \"PPLC\")\n",
    "            .then(0.95)  # Capital cities\n",
    "            .when(pl.col(feature_col).str.starts_with(\"PPL\"))\n",
    "            .then(0.8)  # Major populated places\n",
    "            .when(pl.col(feature_col).str.starts_with(\"ADM1\"))\n",
    "            .then(0.85)  # First-level admin (provinces/states)\n",
    "            .when(pl.col(feature_col).str.starts_with(\"ADM2\"))\n",
    "            .then(0.75)  # Second-level admin (counties)\n",
    "            .when(pl.col(feature_col).str.starts_with(\"ADM3\"))\n",
    "            .then(0.65)  # Third-level admin (districts)\n",
    "            .when(pl.col(feature_col).str.starts_with(\"ADM\"))\n",
    "            .then(0.55)  # Other admin units\n",
    "            .otherwise(0.5)\n",
    "        )\n",
    "    else:\n",
    "        logger.warning(\n",
    "            f\"Column '{feature_col}' not found in DataFrame. Skipping feature factor.\"\n",
    "        )\n",
    "        df = df.with_columns(feature_score=pl.lit(0.5))\n",
    "\n",
    "    # ===== 4. Country/region prominence - prioritize major countries =====\n",
    "    country_col = \"admin0_code\"\n",
    "    if country_col in columns:\n",
    "        # List of major countries to prioritize\n",
    "        major_countries = [\n",
    "            \"US\",\n",
    "            \"GB\",\n",
    "            \"DE\",\n",
    "            \"FR\",\n",
    "            \"JP\",\n",
    "            \"CN\",\n",
    "            \"IN\",\n",
    "            \"BR\",\n",
    "            \"RU\",\n",
    "            \"CA\",\n",
    "            \"AU\",\n",
    "        ]\n",
    "        df = df.with_columns(\n",
    "            country_score=pl.when(pl.col(country_col).is_in(major_countries))\n",
    "            .then(0.8)  # Major countries\n",
    "            .otherwise(0.5)  # Other countries\n",
    "        )\n",
    "    else:\n",
    "        df = df.with_columns(country_score=pl.lit(0.5))\n",
    "\n",
    "    # ===== 5. Parent score influence =====\n",
    "    # TODO: No longer need for the function\n",
    "    if get_latest_adjusted_score_level(columns) is not None:\n",
    "        df = df.with_columns(\n",
    "            average_parent_score=pl.mean_horizontal(cs.starts_with(\"adjusted_score_\"))\n",
    "        ).with_columns(\n",
    "            parent_factor=pl.when(pl.col.average_parent_score > 0)\n",
    "            .then(pl.col.average_parent_score / pl.col.average_parent_score.max())\n",
    "            .otherwise(0.5)\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        logger.warning(\"No parent score column found. Skipping parent factor.\")\n",
    "        df = df.with_columns(parent_factor=pl.lit(0.5))\n",
    "\n",
    "    # ===== 6. Final score calculation =====\n",
    "    # Base score calculation\n",
    "    df = df.with_columns(\n",
    "        (\n",
    "            pl.col(\"text_score\").mul(text_weight)\n",
    "            + pl.col(\"pop_score\").mul(pop_weight)\n",
    "            + pl.col(\"feature_score\").mul(feature_weight)\n",
    "            + pl.col(\"parent_factor\").mul(parent_weight)\n",
    "        ).alias(\"base_score\")\n",
    "    )\n",
    "\n",
    "    # Apply country prominence boost to the final score\n",
    "    df = df.with_columns(\n",
    "        (pl.col(\"base_score\") * (0.7 + (0.3 * pl.col(\"country_score\")))).alias(\n",
    "            score_col\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # For debugging, keep all intermediate scores\n",
    "    return df.sort(score_col, descending=True)\n",
    "\n",
    "\n",
    "def build_path_conditions(df: pl.DataFrame, admin_cols: list[str]) -> str:\n",
    "    \"\"\"\n",
    "    Build SQL conditions by scanning backwards to find the last non-null value.\n",
    "    \"\"\"\n",
    "    if not admin_cols or df.is_empty():\n",
    "        return \"\"\n",
    "\n",
    "    # Extract relevant columns and filter out all-null rows\n",
    "    paths_df = (\n",
    "        df.select(admin_cols).filter(~pl.all_horizontal(pl.all().is_null())).unique()\n",
    "    )\n",
    "\n",
    "    path_conditions = []\n",
    "    for row in paths_df.iter_rows(named=True):\n",
    "        # Scan backward to find the last non-null column\n",
    "        last_non_null_idx = -1\n",
    "        for idx in range(len(admin_cols) - 1, -1, -1):\n",
    "            if row[admin_cols[idx]] is not None:\n",
    "                last_non_null_idx = idx\n",
    "                break\n",
    "\n",
    "        if last_non_null_idx == -1:\n",
    "            continue  # Skip rows with all nulls\n",
    "\n",
    "        # Build conditions up through the last non-null column\n",
    "        conditions = []\n",
    "        for idx in range(last_non_null_idx + 1):\n",
    "            col = admin_cols[idx]\n",
    "            val = row[col]\n",
    "            if val is None:\n",
    "                conditions.append(f\"{col} IS NULL\")\n",
    "            else:\n",
    "                conditions.append(f\"{col} = '{val}'\")\n",
    "\n",
    "        path_conditions.append(f\"({' AND '.join(conditions)})\")\n",
    "\n",
    "    return \" OR \".join(path_conditions)\n",
    "\n",
    "\n",
    "def search_admin(\n",
    "    term: str,\n",
    "    levels: list[int] | int,\n",
    "    con: DuckDBPyConnection,\n",
    "    previous_results: pl.DataFrame | None = None,\n",
    "    limit: int = 100,\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Search for admin entities across one or multiple admin levels with path-aware filtering.\n",
    "\n",
    "    Parameters:\n",
    "    - term: The search term to look for\n",
    "    - levels: A list of admin levels to search over (0-4) or a single level\n",
    "    - con: The DuckDB connection object\n",
    "    - previous_results: Previous search results to filter against\n",
    "    - limit: The maximum number of results to return\n",
    "\n",
    "    Returns:\n",
    "    - A DataFrame with the search results\n",
    "    \"\"\"\n",
    "    # Normalize levels to a list\n",
    "    if isinstance(levels, int):\n",
    "        levels = [levels]\n",
    "    elif not isinstance(levels, list):\n",
    "        raise ValueError(\"Levels must be an integer or a list of integers\")\n",
    "\n",
    "    # Validate levels\n",
    "    if not all(0 <= level <= 4 for level in levels):\n",
    "        raise ValueError(\"All levels must be between 0 and 4\")\n",
    "\n",
    "    # Build level constraint\n",
    "    level_conditions = \" OR \".join([f\"admin_level = {level}\" for level in levels])\n",
    "    where_clauses = [f\"({level_conditions})\"]\n",
    "\n",
    "    # Special handling for country (admin_level = 0) exact matches\n",
    "    has_country_level = 0 in levels\n",
    "    country_exact_matches = None\n",
    "\n",
    "    if has_country_level and len(term) <= 3:\n",
    "        # If the term is short (<= 3 characters), we can assume it's a country code\n",
    "        # First try exact matches for country codes\n",
    "        exact_match_query = \"\"\"\n",
    "        SELECT *,\n",
    "        -- High fixed score for exact matches\n",
    "        CASE\n",
    "            WHEN LOWER(ISO) = LOWER($term) THEN 10.0\n",
    "            WHEN LOWER(ISO3) = LOWER($term) THEN 8.0\n",
    "            WHEN LOWER(fips) = LOWER($term) THEN 4.0\n",
    "        END AS fts_score\n",
    "        FROM admin_search\n",
    "        WHERE admin_level = 0 AND (\n",
    "            LOWER(ISO) = LOWER($term) OR\n",
    "            LOWER(ISO3) = LOWER($term) OR\n",
    "            LOWER(fips) = LOWER($term)\n",
    "        )\n",
    "        \"\"\"\n",
    "\n",
    "        country_exact_matches = con.execute(exact_match_query, {\"term\": term}).pl()\n",
    "\n",
    "        # If we found exact matches, exclude these from the FTS search\n",
    "        if not country_exact_matches.is_empty():\n",
    "            country_ids = country_exact_matches[\"geonameId\"].to_list()\n",
    "            where_clauses.append(\n",
    "                f\"(admin_level != 0 OR geonameId NOT IN ({','.join(map(str, country_ids))}))\"\n",
    "            )\n",
    "\n",
    "    admin_cols = []\n",
    "    # Build path filtering from previous results\n",
    "    if previous_results is not None and not previous_results.is_empty():\n",
    "        # Determine which admin code columns to use based on the previous results\n",
    "        for i in range(5):\n",
    "            col = f\"admin{i}_code\"\n",
    "            if (\n",
    "                col in previous_results.columns\n",
    "                and previous_results[col].drop_nulls().shape[0] > 0\n",
    "            ):\n",
    "                admin_cols.append(col)\n",
    "\n",
    "        # Build path conditions using the admin code columns\n",
    "        if admin_cols:\n",
    "            path_conditions = build_path_conditions(previous_results, admin_cols)\n",
    "            if path_conditions:\n",
    "                where_clauses.append(f\"({path_conditions})\")\n",
    "\n",
    "    # Build the WHERE clause\n",
    "    where_clause = \" AND \".join(where_clauses)\n",
    "\n",
    "    # Build and execute the FTS search\n",
    "    fts_query = f\"\"\"\n",
    "\n",
    "    WITH filtered_results AS (\n",
    "        SELECT *, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
    "        FROM admin_search\n",
    "        WHERE {where_clause}\n",
    "    )\n",
    "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
    "    SELECT * FROM filtered_results\n",
    "    WHERE fts_score IS NOT NULL\n",
    "    ORDER BY fts_score DESC\n",
    "    LIMIT $limit\n",
    "    \"\"\"\n",
    "    logger.debug(f\"Executing FTS query: {fts_query}\")\n",
    "    fts_results = con.execute(fts_query, {\"term\": term, \"limit\": limit * 2}).pl()\n",
    "\n",
    "    # Combine exact matches with FTS results if we had exact matches\n",
    "    if country_exact_matches is not None and not country_exact_matches.is_empty():\n",
    "        # Ensure both have the same columns\n",
    "        if not fts_results.is_empty():\n",
    "            # Dont need this any more.\n",
    "            # Make sure both have the same columns in the same order\n",
    "            # all_columns = list(\n",
    "            #     set(country_exact_matches.columns).union(set(fts_results.columns))\n",
    "            # )\n",
    "\n",
    "            # Add any missing columns with None values\n",
    "            # for col in all_columns:\n",
    "            #     if col not in country_exact_matches.columns:\n",
    "            #         country_exact_matches = country_exact_matches.with_columns(\n",
    "            #             pl.lit(None).alias(col)\n",
    "            #         )\n",
    "            #     if col not in fts_results.columns:\n",
    "            #         fts_results = fts_results.with_columns(pl.lit(None).alias(col))\n",
    "\n",
    "            # Combine and sort by score\n",
    "            results = pl.concat(\n",
    "                [country_exact_matches.lazy(), fts_results.lazy()],\n",
    "                how=\"vertical_relaxed\",\n",
    "            )\n",
    "            results = results.sort(\"fts_score\", descending=True)\n",
    "        else:\n",
    "            # If no FTS results, just use exact matches\n",
    "            results = country_exact_matches.lazy()\n",
    "    else:\n",
    "        # Just use FTS results\n",
    "        results = fts_results.lazy()\n",
    "\n",
    "    # Trying to get the adjusted scores from the previous results working with the flexible search. The issue is that we need to be able to join the previous results with the current results based on the admin codes. (Tracking the path back is much harder than when doing hierarchical search, as there are potentially multiple paths to the same entity. Unsure how to do this yet. )\n",
    "    # logger.info(admin_cols)\n",
    "    # if previous_results is not None and not previous_results.is_empty():\n",
    "    #     for i in range(1, len(admin_cols)+1):\n",
    "    #         logger.info(i)\n",
    "    #         logger.warning(f\"adjusted_score_{min(levels)-1}\")\n",
    "    #         tmp_cols = admin_cols[:i]\n",
    "    #         logger.info(f\"{tmp_cols=}\")\n",
    "    #         logger.info(f\"{results.collect_schema().names()=}\")\n",
    "    #         logger.info(f\"{previous_results.select(\n",
    "    #                 cs.by_name(tmp_cols), cs.starts_with(\"adjusted_score_\")\n",
    "    #             ).collect_schema().names()=}\")\n",
    "\n",
    "    #         results = results.join(\n",
    "    #             previous_results.select(\n",
    "    #                 cs.by_name(tmp_cols), pl.col(f\"adjusted_score_{min(levels)-1}\")\n",
    "    #             ),\n",
    "    #             on=tmp_cols,\n",
    "    #             how=\"left\",\n",
    "    #         )\n",
    "    #         logger.info(results.collect_schema())\n",
    "    #         if f\"adjusted_score_{min(levels)-1}_right\" in results.collect_schema().names():\n",
    "    #             results = results.with_columns(pl.coalesce(cs.starts_with(f\"adjusted_score_{min(levels)-1}\"))).drop(cs.ends_with(\"right\"))\n",
    "\n",
    "    # Original way that works for hierarchical search but not flexible search. Want to try and get this working for flexible search as well.\n",
    "    # For now we will just ignore any previous score when doing the flexible search as it complicates things too much.\n",
    "    # A simple way to work out if we are doing a flexible search is to check the length of the admin_cols and the length of the levels.\n",
    "    if (\n",
    "        previous_results is not None and not previous_results.is_empty()\n",
    "        # and 1 == len(levels)\n",
    "    ):\n",
    "        # Join with previous results to get adjusted scores\n",
    "        results = results.join(\n",
    "            previous_results.lazy().select(\n",
    "                cs.by_name(admin_cols), cs.starts_with(\"adjusted_score_\")\n",
    "            ),\n",
    "            on=admin_cols,\n",
    "            how=\"left\",\n",
    "        )\n",
    "\n",
    "    return (\n",
    "        results.pipe(search_score_admin, min(levels), search_term=term)\n",
    "        .sort(f\"adjusted_score_{min(levels)}\", descending=True)\n",
    "        .unique(\"geonameId\", keep=\"first\", maintain_order=True)\n",
    "        .head(limit)\n",
    "        .collect()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_score_place(\n",
    "    df: pl.LazyFrame,\n",
    "    text_weight: float = 0.4,\n",
    "    importance_weight: float = 0.35,\n",
    "    feature_weight: float = 0.15,\n",
    "    distance_weight: float = 0.1,\n",
    "    search_term: str | None = None,\n",
    "    center_lat: float | None = None,\n",
    "    center_lon: float | None = None,\n",
    ") -> pl.LazyFrame:\n",
    "    \"\"\"\n",
    "    Score places based on multiple factors.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame with search results\n",
    "    - level: Admin level (0=country, 1=admin1, etc.)\n",
    "    - text_weight: Weight for text matching score\n",
    "    - importance_weight: Weight for pre-calculated importance\n",
    "    - feature_weight: Weight for feature type relevance\n",
    "    - distance_weight: Weight for geographic proximity (if center point provided)\n",
    "    - search_term: Original search term for exact matching\n",
    "    - center_lat/lon: Center point for distance calculation (from previous admin results)\n",
    "    \"\"\"\n",
    "    score_col = \"place_score\"\n",
    "    columns = df.collect_schema().names()\n",
    "\n",
    "    # Text relevance score (FTS)\n",
    "    fts_column = \"fts_score\"\n",
    "    if fts_column in columns:\n",
    "        # Normalize FTS score\n",
    "        df = df.with_columns(\n",
    "            z_score=(\n",
    "                (pl.col(fts_column) - pl.col(fts_column).mean())\n",
    "                / pl.when(pl.col(fts_column).std() > 0)\n",
    "                .then(pl.col(fts_column).std())\n",
    "                .otherwise(1.0)\n",
    "            ),\n",
    "        ).with_columns(text_score=(1 / (1 + pl.col.z_score.mul(-1.5).exp())))\n",
    "\n",
    "        # Exact match bonus\n",
    "        if search_term:\n",
    "            df = df.with_columns(\n",
    "                text_score=pl.when(\n",
    "                    pl.col.name.str.to_lowercase() == search_term.lower()\n",
    "                )\n",
    "                .then(1)\n",
    "                .when(pl.col.name.str.to_lowercase().str.contains(search_term.lower()))\n",
    "                .then(pl.col.text_score + 0.25)\n",
    "                .otherwise(pl.col.text_score)\n",
    "                .clip(0, 1)\n",
    "            )\n",
    "    else:\n",
    "        df = df.with_columns(text_score=pl.lit(0.5))\n",
    "\n",
    "    # 2. Importance score (already normalized between 0-1)\n",
    "    if \"importance_score\" in columns:\n",
    "        df = df.with_columns(importance_norm=pl.col(\"importance_score\").clip(0, 1))\n",
    "    else:\n",
    "        df = df.with_columns(importance_norm=pl.lit(0.5))\n",
    "\n",
    "    # Feature type scoring for places\n",
    "    if \"feature_code\" in columns:\n",
    "        df = df.with_columns(\n",
    "            # Capital/admin centers\n",
    "            feature_score=pl.when(\n",
    "                pl.col(\"feature_code\").is_in(\n",
    "                    [\"PPLC\", \"PPLA\", \"PPLA2\", \"PPLA3\", \"PPLA4\"]\n",
    "                )\n",
    "            )\n",
    "            .then(1.0)\n",
    "            # Major landmarks\n",
    "            .when(pl.col(\"feature_code\").is_in([\"CSTL\", \"MNMT\", \"RUIN\", \"TOWR\"]))\n",
    "            .then(0.95)\n",
    "            # Cultural venues\n",
    "            .when(pl.col(\"feature_code\").is_in([\"MUS\", \"THTR\", \"AMTH\", \"LIBR\", \"OPRA\"]))\n",
    "            .then(0.9)\n",
    "            # Populated places\n",
    "            .when(pl.col(\"feature_code\").is_in([\"PPL\", \"PPLF\", \"PPLS\", \"PPLX\"]))\n",
    "            .then(0.85)\n",
    "            # Transportation hubs\n",
    "            .when(pl.col(\"feature_code\").is_in([\"AIRP\", \"RSTN\", \"PRT\", \"MAR\"]))\n",
    "            .then(0.8)\n",
    "            # Educational/medical/institutions\n",
    "            .when(pl.col(\"feature_code\").is_in([\"UNIV\", \"SCH\", \"HSP\", \"HTL\", \"RSRT\"]))\n",
    "            .then(0.75)\n",
    "            # Commercial\n",
    "            .when(pl.col(\"feature_code\").is_in([\"MALL\", \"MKT\"]))\n",
    "            .then(0.7)\n",
    "            # Religious sites\n",
    "            .when(pl.col(\"feature_code\").is_in([\"CH\", \"MSQE\", \"TMPL\", \"SHRN\"]))\n",
    "            .then(0.65)\n",
    "            # Natural features\n",
    "            .when(\n",
    "                pl.col(\"feature_code\").is_in(\n",
    "                    [\"MT\", \"PK\", \"VLC\", \"ISL\", \"BCH\", \"LK\", \"BAY\"]\n",
    "                )\n",
    "            )\n",
    "            .then(0.6)\n",
    "            .otherwise(0.3)\n",
    "        )\n",
    "    else:\n",
    "        df = df.with_columns(feature_score=pl.lit(0.5))\n",
    "\n",
    "        # 4. Distance score (if center point provided)\n",
    "    if (\n",
    "        center_lat is not None\n",
    "        and center_lon is not None\n",
    "        and \"latitude\" in columns\n",
    "        and \"longitude\" in columns\n",
    "    ):\n",
    "        # Haversine distance calculation\n",
    "        df = (\n",
    "            df.with_columns(\n",
    "                x=pl.struct(latitude=\"latitude\", longitude=\"longitude\"),\n",
    "                y=pl.struct(latitude=center_lat, longitude=center_lon),\n",
    "            )\n",
    "            .with_columns(distance_km=pld.col(\"x\").dist.haversine(\"y\", unit=\"km\"))\n",
    "            .drop(\"x\", \"y\")\n",
    "            .with_columns(\n",
    "                # Convert distance to score (closer = higher score)\n",
    "                # Using exponential decay: score = e^(-distance/50)\n",
    "                distance_score=(-pl.col(\"distance_km\") / 50).exp()\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        df = df.with_columns(distance_score=pl.lit(0.5))\n",
    "\n",
    "    df = df.with_columns(\n",
    "        (\n",
    "            pl.col(\"text_score\").mul(text_weight)\n",
    "            + pl.col(\"importance_norm\").mul(importance_weight)\n",
    "            + pl.col(\"feature_score\").mul(feature_weight)\n",
    "            + pl.col(\"distance_score\").mul(distance_weight)\n",
    "        ).alias(score_col)\n",
    "    )\n",
    "    # 6. Apply tier boost (prioritize higher importance tiers)\n",
    "    if \"importance_tier\" in columns:\n",
    "        df = df.with_columns(\n",
    "            pl.col(score_col)\n",
    "            * pl.when(pl.col(\"importance_tier\") == 1)\n",
    "            .then(1.2)\n",
    "            .when(pl.col(\"importance_tier\") == 2)\n",
    "            .then(1.1)\n",
    "            .when(pl.col(\"importance_tier\") == 3)\n",
    "            .then(1.0)\n",
    "            .when(pl.col(\"importance_tier\") == 4)\n",
    "            .then(0.9)\n",
    "            .otherwise(0.8)\n",
    "            .alias(score_col)\n",
    "        )\n",
    "\n",
    "    return df.sort(score_col, descending=True)\n",
    "\n",
    "\n",
    "def search_place(\n",
    "    term: str,\n",
    "    con: DuckDBPyConnection,\n",
    "    previous_results: pl.DataFrame | None = None,\n",
    "    limit: int = 100,\n",
    "    min_importance_tier: int = 5,\n",
    "    center_lat: float | None = None,\n",
    "    center_lon: float | None = None,\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Search for places within the places_search table.\n",
    "\n",
    "    Parameters:\n",
    "    - term: The search term for the place\n",
    "    - con: Database connection\n",
    "    - previous_results: Previous admin search results to filter by\n",
    "    - limit: Maximum number of results\n",
    "    - min_importance_tier: Minimum importance tier to include\n",
    "    - progressive_search: Whether to start with high-importance places first\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with search results\n",
    "    \"\"\"\n",
    "    logger.debug(f\"Searching for places with term: {term}\")\n",
    "\n",
    "    where_clauses = []\n",
    "    admin_cols = []\n",
    "    # Build path filtering from previous results\n",
    "    if previous_results is not None and not previous_results.is_empty():\n",
    "        # Determine which admin code columns to use based on the previous results\n",
    "        for i in range(5):\n",
    "            col = f\"admin{i}_code\"\n",
    "            if (\n",
    "                col in previous_results.columns\n",
    "                and previous_results[col].drop_nulls().shape[0] > 0\n",
    "            ):\n",
    "                admin_cols.append(col)\n",
    "\n",
    "        # Build path conditions using the admin code columns\n",
    "        if admin_cols:\n",
    "            path_conditions = build_path_conditions(previous_results, admin_cols)\n",
    "            if path_conditions:\n",
    "                where_clauses.append(f\"({path_conditions})\")\n",
    "\n",
    "    # Build the WHERE clause\n",
    "    where_clause = \" AND \".join(where_clauses)\n",
    "\n",
    "    # Extract center point from previous results if not provided\n",
    "    if center_lat is None and center_lon is None and previous_results is not None:\n",
    "        if (\n",
    "            \"latitude\" in previous_results.columns\n",
    "            and \"longitude\" in previous_results.columns\n",
    "        ):\n",
    "            logger.debug(\n",
    "                \"No center point provided. Using centroid of previous results.\"\n",
    "            )\n",
    "            # Use the centroid of previous results\n",
    "            center_data = previous_results.select(\n",
    "                [\n",
    "                    pl.mean(\"latitude\").alias(\"center_lat\"),\n",
    "                    pl.mean(\"longitude\").alias(\"center_lon\"),\n",
    "                ]\n",
    "            ).row(0)\n",
    "            center_lat, center_lon = center_data\n",
    "            logger.debug(\n",
    "                f\"Using center point from previous results: ({center_lat}, {center_lon})\"\n",
    "            )\n",
    "\n",
    "        # If progressive search didn't return enough results, or not using progressive search\n",
    "    query = f\"\"\"\n",
    "    WITH filtered_results AS (\n",
    "        SELECT *,\n",
    "            fts_main_places_search.match_bm25(geonameId, $term) AS fts_score\n",
    "        FROM places_search\n",
    "        WHERE {where_clause}\n",
    "            AND importance_tier <= {min_importance_tier}\n",
    "    )\n",
    "    SELECT * FROM filtered_results\n",
    "    WHERE fts_score IS NOT NULL\n",
    "    ORDER BY fts_score DESC,\n",
    "        importance_score DESC\n",
    "    LIMIT $limit\n",
    "    \"\"\"\n",
    "    logger.debug(f\"Executing FTS query: {query}\")\n",
    "    results = con.execute(\n",
    "        query,\n",
    "        {\n",
    "            \"term\": term,\n",
    "            \"limit\": limit * 3,\n",
    "        },\n",
    "    ).pl()\n",
    "    logger.debug(f\"Found {results.shape[0]} results\")\n",
    "    # Return empty frame if no results\n",
    "    if results.is_empty():\n",
    "        return results\n",
    "\n",
    "    # Score and sort results\n",
    "    return (\n",
    "        results.lazy()\n",
    "        .pipe(\n",
    "            search_score_place,\n",
    "            search_term=term,\n",
    "            center_lat=center_lat,\n",
    "            center_lon=center_lon,\n",
    "        )\n",
    "        .sort(\"place_score\", descending=True)\n",
    "        .head(limit)\n",
    "        .collect()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple, Self, TypedDict\n",
    "\n",
    "\n",
    "class AdminHierarchy(NamedTuple):\n",
    "    admin0: str | None = None\n",
    "    admin1: str | None = None\n",
    "    admin2: str | None = None\n",
    "    admin3: str | None = None\n",
    "    admin4: str | None = None\n",
    "\n",
    "    @classmethod\n",
    "    def from_list(cls, search_terms: list[str | None]) -> Self:\n",
    "        if len(search_terms) != 5:\n",
    "            raise ValueError(\"Search terms must be a list of length 5\")\n",
    "        return cls(\n",
    "            admin0=search_terms[0],\n",
    "            admin1=search_terms[1],\n",
    "            admin2=search_terms[2],\n",
    "            admin3=search_terms[3],\n",
    "            admin4=search_terms[4],\n",
    "        )\n",
    "\n",
    "\n",
    "class SearchResult(TypedDict, total=False):\n",
    "    admin0: pl.DataFrame\n",
    "    admin1: pl.DataFrame\n",
    "    admin2: pl.DataFrame\n",
    "    admin3: pl.DataFrame\n",
    "    admin4: pl.DataFrame\n",
    "\n",
    "\n",
    "def hierarchical_search(\n",
    "    search_terms: AdminHierarchy, con: DuckDBPyConnection, limit: int = 20\n",
    ") -> SearchResult:\n",
    "    \"\"\"\n",
    "    Perform hierarchical geographic search across admin levels.\n",
    "\n",
    "    Args:\n",
    "        search_terms: List of search terms, ordered by admin level (admin0 (country), admin1, admin2, etc.)\n",
    "        con: Database connection\n",
    "        limit: Maximum results to return per level\n",
    "\n",
    "    Returns:\n",
    "        Dictionary mapping level names to search results\n",
    "    \"\"\"\n",
    "\n",
    "    results: SearchResult = {}\n",
    "    last_results: pl.DataFrame | None = None\n",
    "\n",
    "    for admin_level, term in enumerate(search_terms):\n",
    "        if term is None:\n",
    "            continue\n",
    "\n",
    "        logger.debug(f\"Searching for term '{term}' at admin level {admin_level}\")\n",
    "\n",
    "        # Perform the search\n",
    "        search_results = search_admin(\n",
    "            term,\n",
    "            admin_level,\n",
    "            con,\n",
    "            last_results,\n",
    "            limit,\n",
    "        )\n",
    "\n",
    "        # If results are found, store them in the results dictionary\n",
    "        if not search_results.is_empty():\n",
    "            results[f\"admin{admin_level}\"] = search_results\n",
    "            last_results = search_results\n",
    "        else:\n",
    "            logger.debug(\n",
    "                f\"No results found for term '{term}' at admin level {admin_level}\"\n",
    "            )\n",
    "\n",
    "    # # Level 0: Country search\n",
    "    # if search_terms.admin0 is not None:\n",
    "    #     logger.debug(f\"Searching for country: '{search_terms.admin0}'\")\n",
    "    #     admin1_results = search_admin(search_terms.admin0, 0, con, None, limit)\n",
    "    #     if not admin1_results.is_empty():\n",
    "    #         results[\"admin0\"] = admin1_results\n",
    "    #         last_results = admin1_results\n",
    "\n",
    "    # # Level 1: Admin1 search\n",
    "    # if search_terms.admin1 is not None:\n",
    "    #     logger.debug(f\"Searching for admin1: '{search_terms.admin1}'\")\n",
    "    #     admin1_results = search_admin(search_terms.admin1, 1, con, last_results, limit)\n",
    "    #     if not admin1_results.is_empty():\n",
    "    #         results[\"admin1\"] = admin1_results\n",
    "    #         last_results = admin1_results\n",
    "\n",
    "    # # Level 2: Admin2 search\n",
    "    # if search_terms.admin2 is not None:\n",
    "    #     logger.debug(f\"Searching for admin2: '{search_terms.admin2}'\")\n",
    "    #     admin2_results = search_admin(search_terms.admin2, 2, con, last_results, limit)\n",
    "    #     if not admin2_results.is_empty():\n",
    "    #         results[\"admin2\"] = admin2_results\n",
    "    #         last_results = admin2_results\n",
    "\n",
    "    # # Level 3: Admin3 search\n",
    "    # if search_terms.admin3 is not None:\n",
    "    #     logger.debug(f\"Searching for admin3: '{search_terms.admin3}'\")\n",
    "    #     admin3_results = search_admin(search_terms.admin3, 3, con, last_results, limit)\n",
    "    #     if not admin3_results.is_empty():\n",
    "    #         results[\"admin3\"] = admin3_results\n",
    "    #         last_results = admin3_results\n",
    "\n",
    "    # # Level 4: Admin4 search\n",
    "    # if search_terms.admin4 is not None:\n",
    "    #     logger.debug(f\"Searching for admin4: '{search_terms.admin4}'\")\n",
    "    #     admin4_results = search_admin(search_terms.admin4, 4, con, last_results, limit)\n",
    "    #     if not admin4_results.is_empty():\n",
    "    #         results[\"admin4\"] = admin4_results\n",
    "    #         last_results = admin4_results\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def flexible_search(\n",
    "    search_terms: list[str],\n",
    "    con: DuckDBPyConnection,\n",
    "    limit: int = 50,\n",
    ") -> list[pl.DataFrame]:\n",
    "    \"\"\"\n",
    "    Perform flexible geographic search across admin levels.\n",
    "\n",
    "    Args:\n",
    "        search_terms: List of search terms, ordered by admin level (admin0 (country), admin1, admin2, etc.)\n",
    "        con: Database connection\n",
    "        limit: Maximum results to return per level\n",
    "\n",
    "    Returns:\n",
    "        Dictionary mapping level names to search results\n",
    "    \"\"\"\n",
    "    assert len(search_terms) <= 5, \"Search terms must be a list of length <= 5\"\n",
    "    search_terms = [term for term in search_terms if term is not None]\n",
    "    if len(search_terms) == 0:\n",
    "        raise ValueError(\"Search terms must not be empty\")\n",
    "    logger.debug(f\"Search terms: {search_terms}\")\n",
    "    empty_terms = 5 - len(search_terms)\n",
    "\n",
    "    previous_results: pl.DataFrame | None = None\n",
    "    results = []\n",
    "\n",
    "    for i, term in enumerate(search_terms):\n",
    "        logger.debug(f\"Searching for term '{term}' at admin level {i}\")\n",
    "        search_range = list(range(i, (empty_terms + i + 1)))\n",
    "        logger.debug(f\"Searching for: '{term}' in range {search_range}\")\n",
    "        search_results = search_admin(\n",
    "            term,\n",
    "            search_range,\n",
    "            con,\n",
    "            previous_results,\n",
    "            limit,\n",
    "        )\n",
    "        if not search_results.is_empty():\n",
    "            results.append(search_results)\n",
    "            previous_results = search_results\n",
    "        else:\n",
    "            logger.debug(f\"No results found for term '{term}' in range {search_range}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def backfill_hierarchy(row: dict, con: DuckDBPyConnection) -> dict:\n",
    "    def get_where_clause(codes: list[str | None]) -> str:\n",
    "        return \"WHERE \" + \" AND \".join(\n",
    "            [\n",
    "                f\"admin{i}_code = '{code}'\"\n",
    "                if code is not None\n",
    "                else f\"admin{i}_code IS NULL\"\n",
    "                for i, code in enumerate(codes)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    hierarchy = {}\n",
    "    codes = []\n",
    "    for i in range(5):\n",
    "        print(i)\n",
    "        code = row.get(f\"admin{i}_code\")\n",
    "        codes.append(code)\n",
    "        if code is not None:\n",
    "            df = con.execute(\n",
    "                f\"SELECT geonameId, name FROM admin{i} {get_where_clause(codes)} LIMIT 1\"\n",
    "            ).pl()\n",
    "            if not df.is_empty():\n",
    "                hierarchy[f\"admin{i}\"] = df.to_dicts()[0]\n",
    "    return hierarchy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 13:25:47.886\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mhierarchical_search\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mSearching for term 'FR' at admin level 0\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:48.155\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m343\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT *, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 0) AND (admin_level != 0 OR geonameId NOT IN (3017382))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:48.189\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_score_admin\u001b[0m:\u001b[36m178\u001b[0m - \u001b[33m\u001b[1mNo parent score column found. Skipping parent factor.\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:48.190\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mhierarchical_search\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mSearching for term 'Provence-Alpes-Côte d'Azur' at admin level 1\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:48.191\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m343\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT *, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 1) AND ((admin0_code = 'GF') OR (admin0_code = 'PF') OR (admin0_code = 'FR') OR (admin0_code = 'MF'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:48.228\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mhierarchical_search\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mSearching for term 'Le Lavandou' at admin level 4\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:48.229\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m343\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT *, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 4) AND ((admin0_code = 'FR' AND admin1_code = 'B4') OR (admin0_code = 'FR' AND admin1_code = '84') OR (admin0_code = 'FR' AND admin1_code = '93') OR (admin0_code = 'FR' AND admin1_code = '32') OR (admin0_code = 'FR' AND admin1_code = '52') OR (admin0_code = 'FR' AND admin1_code = 'B9') OR (admin0_code = 'FR' AND admin1_code = '24') OR (admin0_code = 'FR' AND admin1_code = '11'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:48.265\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m14\u001b[0m - \u001b[34m\u001b[1mAdmin1 results:\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:48.266\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[34m\u001b[1mAdmin4 results:\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (10, 33)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ geonameId ┆ name      ┆ asciiname ┆ admin_lev ┆ … ┆ average_p ┆ parent_fa ┆ base_scor ┆ adjusted │\n",
      "│ ---       ┆ ---       ┆ ---       ┆ el        ┆   ┆ arent_sco ┆ ctor      ┆ e         ┆ _score_1 │\n",
      "│ i32       ┆ str       ┆ str       ┆ ---       ┆   ┆ re        ┆ ---       ┆ ---       ┆ ---      │\n",
      "│           ┆           ┆           ┆ i32       ┆   ┆ ---       ┆ f64       ┆ f64       ┆ f64      │\n",
      "│           ┆           ┆           ┆           ┆   ┆ f64       ┆           ┆           ┆          │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ 2985244   ┆ Provence- ┆ Provence- ┆ 1         ┆ … ┆ 0.746891  ┆ 1.0       ┆ 0.869319  ┆ 0.81716  │\n",
      "│           ┆ Alpes-Côt ┆ Alpes-Cot ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ e d'Azur  ┆ e d'Azur  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 2983751   ┆ Rhône-Alp ┆ Rhone-Alp ┆ 1         ┆ … ┆ 0.746891  ┆ 1.0       ┆ 0.73502   ┆ 0.690918 │\n",
      "│           ┆ es        ┆ es        ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 11071625  ┆ Auvergne- ┆ Auvergne- ┆ 1         ┆ … ┆ 0.746891  ┆ 1.0       ┆ 0.708504  ┆ 0.665994 │\n",
      "│           ┆ Rhône-Alp ┆ Rhone-Alp ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ es        ┆ es        ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 11071624  ┆ Hauts-de- ┆ Hauts-de- ┆ 1         ┆ … ┆ 0.746891  ┆ 1.0       ┆ 0.607866  ┆ 0.571394 │\n",
      "│           ┆ France    ┆ France    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 3012874   ┆ Île-de-Fr ┆ Ile-de-Fr ┆ 1         ┆ … ┆ 0.746891  ┆ 1.0       ┆ 0.605335  ┆ 0.569015 │\n",
      "│           ┆ ance      ┆ ance      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 2988289   ┆ Pays de   ┆ Pays de   ┆ 1         ┆ … ┆ 0.746891  ┆ 1.0       ┆ 0.605125  ┆ 0.568817 │\n",
      "│           ┆ la Loire  ┆ la Loire  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 3027939   ┆ Centre-Va ┆ Centre-Va ┆ 1         ┆ … ┆ 0.746891  ┆ 1.0       ┆ 0.604934  ┆ 0.568638 │\n",
      "│           ┆ l de      ┆ l de      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ Loire     ┆ Loire     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 2990119   ┆ Nord-Pas- ┆ Nord-Pas- ┆ 1         ┆ … ┆ 0.746891  ┆ 1.0       ┆ 0.599649  ┆ 0.563671 │\n",
      "│           ┆ de-Calais ┆ de-Calais ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 8378478   ┆ Alpes     ┆ Alpes     ┆ 1         ┆ … ┆ 0.746891  ┆ 1.0       ┆ 0.55539   ┆ 0.522067 │\n",
      "│           ┆ Maritimae ┆ Maritimae ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 8378477   ┆ Alpes     ┆ Alpes     ┆ 1         ┆ … ┆ 0.746891  ┆ 1.0       ┆ 0.546637  ┆ 0.513839 │\n",
      "│           ┆ Graiae    ┆ Graiae    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n",
      "shape: (20, 34)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ geonameId ┆ name      ┆ asciiname ┆ admin_lev ┆ … ┆ average_p ┆ parent_fa ┆ base_scor ┆ adjusted │\n",
      "│ ---       ┆ ---       ┆ ---       ┆ el        ┆   ┆ arent_sco ┆ ctor      ┆ e         ┆ _score_4 │\n",
      "│ i32       ┆ str       ┆ str       ┆ ---       ┆   ┆ re        ┆ ---       ┆ ---       ┆ ---      │\n",
      "│           ┆           ┆           ┆ i32       ┆   ┆ ---       ┆ f64       ┆ f64       ┆ f64      │\n",
      "│           ┆           ┆           ┆           ┆   ┆ f64       ┆           ┆           ┆          │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ 6615009   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.777183  ┆ 0.730552 │\n",
      "│           ┆ Lavandou  ┆ Lavandou  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 6457128   ┆ Le Pradet ┆ Le Pradet ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.583307  ┆ 0.548308 │\n",
      "│ 6457127   ┆ Le Muy    ┆ Le Muy    ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.582551  ┆ 0.547597 │\n",
      "│ 6456724   ┆ Le Rove   ┆ Le Rove   ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.576784  ┆ 0.542177 │\n",
      "│ 6456550   ┆ Le Val    ┆ Le Val    ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.574986  ┆ 0.540487 │\n",
      "│ 6455473   ┆ Le Rouret ┆ Le Rouret ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.574266  ┆ 0.53981  │\n",
      "│ 6455417   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.657953  ┆ 0.841345  ┆ 0.571741  ┆ 0.537437 │\n",
      "│           ┆ Vésinet   ┆ Vesinet   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 6456500   ┆ Le Mesnil ┆ Le Mesnil ┆ 4         ┆ … ┆ 0.657953  ┆ 0.841345  ┆ 0.571478  ┆ 0.537189 │\n",
      "│           ┆ -le-Roi   ┆ -le-Roi   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 6456549   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.568936  ┆ 0.5348   │\n",
      "│           ┆ Thoronet  ┆ Thoronet  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 6456896   ┆ Le Coteau ┆ Le Coteau ┆ 4         ┆ … ┆ 0.706443  ┆ 0.90335   ┆ 0.565171  ┆ 0.531261 │\n",
      "│ 6457011   ┆ Le Cendre ┆ Le Cendre ┆ 4         ┆ … ┆ 0.706443  ┆ 0.90335   ┆ 0.56269   ┆ 0.528929 │\n",
      "│ 6456673   ┆ Le Broc   ┆ Le Broc   ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.56252   ┆ 0.528768 │\n",
      "│ 6455917   ┆ Le Poinço ┆ Le Poinco ┆ 4         ┆ … ┆ 0.657765  ┆ 0.841104  ┆ 0.562302  ┆ 0.528564 │\n",
      "│           ┆ nnet      ┆ nnet      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 6456350   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.706443  ┆ 0.90335   ┆ 0.562295  ┆ 0.528557 │\n",
      "│           ┆ Perréon   ┆ Perreon   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 6455961   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.706443  ┆ 0.90335   ┆ 0.561621  ┆ 0.527924 │\n",
      "│           ┆ Versoud   ┆ Versoud   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 6456652   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.557723  ┆ 0.52426  │\n",
      "│           ┆ Brusquet  ┆ Brusquet  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 6455958   ┆ Le Touvet ┆ Le Touvet ┆ 4         ┆ … ┆ 0.706443  ┆ 0.90335   ┆ 0.55756   ┆ 0.524107 │\n",
      "│ 6456682   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.706443  ┆ 0.90335   ┆ 0.556219  ┆ 0.522846 │\n",
      "│           ┆ Cheylard  ┆ Cheylard  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 6613182   ┆ Le Pouzin ┆ Le Pouzin ┆ 4         ┆ … ┆ 0.706443  ┆ 0.90335   ┆ 0.556158  ┆ 0.522788 │\n",
      "│ 6457137   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.657854  ┆ 0.841218  ┆ 0.555783  ┆ 0.522436 │\n",
      "│           ┆ Boupère   ┆ Boupere   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (20, 34)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>asciiname</th><th>admin_level</th><th>admin0_code</th><th>admin1_code</th><th>admin2_code</th><th>admin3_code</th><th>admin4_code</th><th>feature_class</th><th>feature_code</th><th>ISO</th><th>ISO3</th><th>ISO_Numeric</th><th>official_name</th><th>fips</th><th>latitude</th><th>longitude</th><th>population</th><th>area</th><th>alternatenames</th><th>country_name</th><th>fts_score_4</th><th>adjusted_score_0</th><th>adjusted_score_1</th><th>z_score</th><th>text_score</th><th>pop_score</th><th>feature_score</th><th>country_score</th><th>average_parent_score</th><th>parent_factor</th><th>base_score</th><th>adjusted_score_4</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>i32</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i32</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>6615009</td><td>&quot;Le Lavandou&quot;</td><td>&quot;Le Lavandou&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;832&quot;</td><td>&quot;83070&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>43.137779</td><td>6.36778</td><td>5759</td><td>null</td><td>&quot;83070,Le Lavandou&quot;</td><td>&quot;Republic of France&quot;</td><td>12.610318</td><td>0.746891</td><td>0.81716</td><td>5.743267</td><td>1.0</td><td>0.556236</td><td>0.55</td><td>0.8</td><td>0.782025</td><td>1.0</td><td>0.777183</td><td>0.730552</td></tr><tr><td>6457128</td><td>&quot;Le Pradet&quot;</td><td>&quot;Le Pradet&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;832&quot;</td><td>&quot;83098&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>43.10556</td><td>6.02333</td><td>10027</td><td>null</td><td>&quot;83098,Le Pradet&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.81716</td><td>-0.185713</td><td>0.430805</td><td>0.5715</td><td>0.55</td><td>0.8</td><td>0.782025</td><td>1.0</td><td>0.583307</td><td>0.548308</td></tr><tr><td>6457127</td><td>&quot;Le Muy&quot;</td><td>&quot;Le Muy&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;831&quot;</td><td>&quot;83086&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>43.4725</td><td>6.56639</td><td>9248</td><td>null</td><td>&quot;83086,Le Muy&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.81716</td><td>-0.185713</td><td>0.430805</td><td>0.56934</td><td>0.55</td><td>0.8</td><td>0.782025</td><td>1.0</td><td>0.582551</td><td>0.547597</td></tr><tr><td>6456724</td><td>&quot;Le Rove&quot;</td><td>&quot;Le Rove&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;13&quot;</td><td>&quot;134&quot;</td><td>&quot;13088&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>43.369171</td><td>5.25028</td><td>5121</td><td>null</td><td>&quot;13088,Le Rove&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.81716</td><td>-0.185713</td><td>0.430805</td><td>0.552863</td><td>0.55</td><td>0.8</td><td>0.782025</td><td>1.0</td><td>0.576784</td><td>0.542177</td></tr><tr><td>6456550</td><td>&quot;Le Val&quot;</td><td>&quot;Le Val&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;833&quot;</td><td>&quot;83143&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>43.439442</td><td>6.07306</td><td>4297</td><td>null</td><td>&quot;83143,Le Val&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.81716</td><td>-0.185713</td><td>0.430805</td><td>0.547727</td><td>0.55</td><td>0.8</td><td>0.782025</td><td>1.0</td><td>0.574986</td><td>0.540487</td></tr><tr><td>6455473</td><td>&quot;Le Rouret&quot;</td><td>&quot;Le Rouret&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;06&quot;</td><td>&quot;061&quot;</td><td>&quot;06112&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>43.674438</td><td>7.00556</td><td>4010</td><td>null</td><td>&quot;06112,Le Rouret&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.81716</td><td>-0.185713</td><td>0.430805</td><td>0.545671</td><td>0.55</td><td>0.8</td><td>0.782025</td><td>1.0</td><td>0.574266</td><td>0.53981</td></tr><tr><td>6455417</td><td>&quot;Le Vésinet&quot;</td><td>&quot;Le Vesinet&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;11&quot;</td><td>&quot;78&quot;</td><td>&quot;783&quot;</td><td>&quot;78650&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>48.89389</td><td>2.13222</td><td>16047</td><td>null</td><td>&quot;78650,Le Vesinet,Le Vésinet&quot;</td><td>&quot;Republic of France&quot;</td><td>3.724332</td><td>0.746891</td><td>0.569015</td><td>-0.124063</td><td>0.45361</td><td>0.583645</td><td>0.55</td><td>0.8</td><td>0.657953</td><td>0.841345</td><td>0.571741</td><td>0.537437</td></tr><tr><td>6456500</td><td>&quot;Le Mesnil-le-Roi&quot;</td><td>&quot;Le Mesnil-le-Roi&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;11&quot;</td><td>&quot;78&quot;</td><td>&quot;783&quot;</td><td>&quot;78396&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>48.936668</td><td>2.12667</td><td>6276</td><td>null</td><td>&quot;78396,Le Mesnil-le-Roi&quot;</td><td>&quot;Republic of France&quot;</td><td>3.822629</td><td>0.746891</td><td>0.569015</td><td>-0.059158</td><td>0.47783</td><td>0.558673</td><td>0.55</td><td>0.8</td><td>0.657953</td><td>0.841345</td><td>0.571478</td><td>0.537189</td></tr><tr><td>6456549</td><td>&quot;Le Thoronet&quot;</td><td>&quot;Le Thoronet&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;833&quot;</td><td>&quot;83136&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>43.451939</td><td>6.30389</td><td>2449</td><td>null</td><td>&quot;83136,Le Thoronet&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.81716</td><td>-0.185713</td><td>0.430805</td><td>0.530442</td><td>0.55</td><td>0.8</td><td>0.782025</td><td>1.0</td><td>0.568936</td><td>0.5348</td></tr><tr><td>6456896</td><td>&quot;Le Coteau&quot;</td><td>&quot;Le Coteau&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;84&quot;</td><td>&quot;42&quot;</td><td>&quot;422&quot;</td><td>&quot;42071&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>46.027222</td><td>4.08667</td><td>6845</td><td>null</td><td>&quot;42071,Le Coteau&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.665994</td><td>-0.185713</td><td>0.430805</td><td>0.561107</td><td>0.55</td><td>0.8</td><td>0.706443</td><td>0.90335</td><td>0.565171</td><td>0.531261</td></tr><tr><td>6457011</td><td>&quot;Le Cendre&quot;</td><td>&quot;Le Cendre&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;84&quot;</td><td>&quot;63&quot;</td><td>&quot;632&quot;</td><td>&quot;63069&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>45.722698</td><td>3.1877</td><td>5330</td><td>null</td><td>&quot;63069,Le Cendre&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.665994</td><td>-0.185713</td><td>0.430805</td><td>0.554018</td><td>0.55</td><td>0.8</td><td>0.706443</td><td>0.90335</td><td>0.56269</td><td>0.528929</td></tr><tr><td>6456673</td><td>&quot;Le Broc&quot;</td><td>&quot;Le Broc&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;06&quot;</td><td>&quot;061&quot;</td><td>&quot;06025&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>43.809441</td><td>7.17</td><td>1409</td><td>null</td><td>&quot;06025,Le Broc&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.81716</td><td>-0.185713</td><td>0.430805</td><td>0.512109</td><td>0.55</td><td>0.8</td><td>0.782025</td><td>1.0</td><td>0.56252</td><td>0.528768</td></tr><tr><td>6455917</td><td>&quot;Le Poinçonnet&quot;</td><td>&quot;Le Poinconnet&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;24&quot;</td><td>&quot;36&quot;</td><td>&quot;362&quot;</td><td>&quot;36159&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>46.763889</td><td>1.71889</td><td>5870</td><td>null</td><td>&quot;36159,Le Poinconnet,Le Poinçon…</td><td>&quot;Republic of France&quot;</td><td>3.724332</td><td>0.746891</td><td>0.568638</td><td>-0.124063</td><td>0.45361</td><td>0.556779</td><td>0.55</td><td>0.8</td><td>0.657765</td><td>0.841104</td><td>0.562302</td><td>0.528564</td></tr><tr><td>6456350</td><td>&quot;Le Perréon&quot;</td><td>&quot;Le Perreon&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;84&quot;</td><td>&quot;69&quot;</td><td>&quot;692&quot;</td><td>&quot;69151&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>46.063061</td><td>4.60056</td><td>1566</td><td>null</td><td>&quot;69151,Le Perreyon,Le Pèrreyon,…</td><td>&quot;Republic of France&quot;</td><td>3.782694</td><td>0.746891</td><td>0.665994</td><td>-0.085527</td><td>0.467971</td><td>0.515722</td><td>0.55</td><td>0.8</td><td>0.706443</td><td>0.90335</td><td>0.562295</td><td>0.528557</td></tr><tr><td>6455961</td><td>&quot;Le Versoud&quot;</td><td>&quot;Le Versoud&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;84&quot;</td><td>&quot;38&quot;</td><td>&quot;381&quot;</td><td>&quot;38538&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>45.216</td><td>5.8625</td><td>4797</td><td>null</td><td>&quot;38538,Le Versoud&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.665994</td><td>-0.185713</td><td>0.430805</td><td>0.550963</td><td>0.55</td><td>0.8</td><td>0.706443</td><td>0.90335</td><td>0.561621</td><td>0.527924</td></tr><tr><td>6456652</td><td>&quot;Le Brusquet&quot;</td><td>&quot;Le Brusquet&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;04&quot;</td><td>&quot;043&quot;</td><td>&quot;04036&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>44.161201</td><td>6.3098</td><td>957</td><td>null</td><td>&quot;04036,Le Brusquet&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.81716</td><td>-0.185713</td><td>0.430805</td><td>0.498404</td><td>0.55</td><td>0.8</td><td>0.782025</td><td>1.0</td><td>0.557723</td><td>0.52426</td></tr><tr><td>6455958</td><td>&quot;Le Touvet&quot;</td><td>&quot;Le Touvet&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;84&quot;</td><td>&quot;38&quot;</td><td>&quot;381&quot;</td><td>&quot;38511&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>45.357498</td><td>5.94806</td><td>3256</td><td>null</td><td>&quot;38511,Le Touvet&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.665994</td><td>-0.185713</td><td>0.430805</td><td>0.53936</td><td>0.55</td><td>0.8</td><td>0.706443</td><td>0.90335</td><td>0.55756</td><td>0.524107</td></tr><tr><td>6456682</td><td>&quot;Le Cheylard&quot;</td><td>&quot;Le Cheylard&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;84&quot;</td><td>&quot;07&quot;</td><td>&quot;073&quot;</td><td>&quot;07064&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>44.905281</td><td>4.42222</td><td>2877</td><td>null</td><td>&quot;07064,Le Cheylard&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.665994</td><td>-0.185713</td><td>0.430805</td><td>0.535527</td><td>0.55</td><td>0.8</td><td>0.706443</td><td>0.90335</td><td>0.556219</td><td>0.522846</td></tr><tr><td>6613182</td><td>&quot;Le Pouzin&quot;</td><td>&quot;Le Pouzin&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;84&quot;</td><td>&quot;07&quot;</td><td>&quot;072&quot;</td><td>&quot;07181&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>44.75333</td><td>4.74778</td><td>2861</td><td>null</td><td>&quot;07181,Le Pouzin&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.665994</td><td>-0.185713</td><td>0.430805</td><td>0.535353</td><td>0.55</td><td>0.8</td><td>0.706443</td><td>0.90335</td><td>0.556158</td><td>0.522788</td></tr><tr><td>6457137</td><td>&quot;Le Boupère&quot;</td><td>&quot;Le Boupere&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;52&quot;</td><td>&quot;85&quot;</td><td>&quot;851&quot;</td><td>&quot;85031&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>46.79472</td><td>-0.92639</td><td>3126</td><td>null</td><td>&quot;85031,Le Boupere,Le Boupère&quot;</td><td>&quot;Republic of France&quot;</td><td>3.724332</td><td>0.746891</td><td>0.568817</td><td>-0.124063</td><td>0.45361</td><td>0.538105</td><td>0.55</td><td>0.8</td><td>0.657854</td><td>0.841218</td><td>0.555783</td><td>0.522436</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (20, 34)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ geonameId ┆ name      ┆ asciiname ┆ admin_lev ┆ … ┆ average_p ┆ parent_fa ┆ base_scor ┆ adjusted │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ el        ┆   ┆ arent_sco ┆ ctor      ┆ e         ┆ _score_4 │\n",
       "│ i32       ┆ str       ┆ str       ┆ ---       ┆   ┆ re        ┆ ---       ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆           ┆ i32       ┆   ┆ ---       ┆ f64       ┆ f64       ┆ f64      │\n",
       "│           ┆           ┆           ┆           ┆   ┆ f64       ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 6615009   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.777183  ┆ 0.730552 │\n",
       "│           ┆ Lavandou  ┆ Lavandou  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6457128   ┆ Le Pradet ┆ Le Pradet ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.583307  ┆ 0.548308 │\n",
       "│ 6457127   ┆ Le Muy    ┆ Le Muy    ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.582551  ┆ 0.547597 │\n",
       "│ 6456724   ┆ Le Rove   ┆ Le Rove   ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.576784  ┆ 0.542177 │\n",
       "│ 6456550   ┆ Le Val    ┆ Le Val    ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.574986  ┆ 0.540487 │\n",
       "│ 6455473   ┆ Le Rouret ┆ Le Rouret ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.574266  ┆ 0.53981  │\n",
       "│ 6455417   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.657953  ┆ 0.841345  ┆ 0.571741  ┆ 0.537437 │\n",
       "│           ┆ Vésinet   ┆ Vesinet   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6456500   ┆ Le Mesnil ┆ Le Mesnil ┆ 4         ┆ … ┆ 0.657953  ┆ 0.841345  ┆ 0.571478  ┆ 0.537189 │\n",
       "│           ┆ -le-Roi   ┆ -le-Roi   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6456549   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.568936  ┆ 0.5348   │\n",
       "│           ┆ Thoronet  ┆ Thoronet  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6456896   ┆ Le Coteau ┆ Le Coteau ┆ 4         ┆ … ┆ 0.706443  ┆ 0.90335   ┆ 0.565171  ┆ 0.531261 │\n",
       "│ 6457011   ┆ Le Cendre ┆ Le Cendre ┆ 4         ┆ … ┆ 0.706443  ┆ 0.90335   ┆ 0.56269   ┆ 0.528929 │\n",
       "│ 6456673   ┆ Le Broc   ┆ Le Broc   ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.56252   ┆ 0.528768 │\n",
       "│ 6455917   ┆ Le Poinço ┆ Le Poinco ┆ 4         ┆ … ┆ 0.657765  ┆ 0.841104  ┆ 0.562302  ┆ 0.528564 │\n",
       "│           ┆ nnet      ┆ nnet      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6456350   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.706443  ┆ 0.90335   ┆ 0.562295  ┆ 0.528557 │\n",
       "│           ┆ Perréon   ┆ Perreon   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6455961   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.706443  ┆ 0.90335   ┆ 0.561621  ┆ 0.527924 │\n",
       "│           ┆ Versoud   ┆ Versoud   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6456652   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.782025  ┆ 1.0       ┆ 0.557723  ┆ 0.52426  │\n",
       "│           ┆ Brusquet  ┆ Brusquet  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6455958   ┆ Le Touvet ┆ Le Touvet ┆ 4         ┆ … ┆ 0.706443  ┆ 0.90335   ┆ 0.55756   ┆ 0.524107 │\n",
       "│ 6456682   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.706443  ┆ 0.90335   ┆ 0.556219  ┆ 0.522846 │\n",
       "│           ┆ Cheylard  ┆ Cheylard  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6613182   ┆ Le Pouzin ┆ Le Pouzin ┆ 4         ┆ … ┆ 0.706443  ┆ 0.90335   ┆ 0.556158  ┆ 0.522788 │\n",
       "│ 6457137   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.657854  ┆ 0.841218  ┆ 0.555783  ┆ 0.522436 │\n",
       "│           ┆ Boupère   ┆ Boupere   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = [\"FR\", \"Provence-Alpes-Côte d'Azur\", None, None, \"Le Lavandou\"]\n",
    "search_terms = AdminHierarchy.from_list(st)\n",
    "# Search through the admin hierarchy\n",
    "results = hierarchical_search(\n",
    "    search_terms,\n",
    "    con=con,\n",
    ")\n",
    "\n",
    "# Access results for each level\n",
    "if \"country\" in results:\n",
    "    logger.debug(\"Country results:\")\n",
    "    print(results[\"country\"])\n",
    "if \"admin1\" in results:\n",
    "    logger.debug(\"Admin1 results:\")\n",
    "    print(results[\"admin1\"])\n",
    "if \"admin2\" in results:\n",
    "    logger.debug(\n",
    "        \"Admin2 results:\",\n",
    "    )\n",
    "    print(results[\"admin2\"])\n",
    "if \"admin3\" in results:\n",
    "    logger.debug(\n",
    "        \"Admin3 results:\",\n",
    "    )\n",
    "    print(results[\"admin3\"])\n",
    "if \"admin4\" in results:\n",
    "    logger.debug(\n",
    "        \"Admin4 results:\",\n",
    "    )\n",
    "    print(results[\"admin4\"])\n",
    "results[\"admin4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 13:25:48.276\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m137\u001b[0m - \u001b[34m\u001b[1mSearch terms: ['FR', \"Provence-Alpes-Côte d'Azur\", 'Le Lavandou']\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:48.277\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m144\u001b[0m - \u001b[34m\u001b[1mSearching for term 'FR' at admin level 0\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:48.277\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m146\u001b[0m - \u001b[34m\u001b[1mSearching for: 'FR' in range [0, 1, 2]\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:48.282\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m343\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT *, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 0 OR admin_level = 1 OR admin_level = 2) AND (admin_level != 0 OR geonameId NOT IN (3017382))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:48.318\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_score_admin\u001b[0m:\u001b[36m178\u001b[0m - \u001b[33m\u001b[1mNo parent score column found. Skipping parent factor.\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:48.319\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m144\u001b[0m - \u001b[34m\u001b[1mSearching for term 'Provence-Alpes-Côte d'Azur' at admin level 1\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:48.320\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m146\u001b[0m - \u001b[34m\u001b[1mSearching for: 'Provence-Alpes-Côte d'Azur' in range [1, 2, 3]\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:48.321\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m343\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT *, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 1 OR admin_level = 2 OR admin_level = 3) AND ((admin0_code = 'NL' AND admin1_code = '02') OR (admin0_code = 'EG' AND admin1_code = '21') OR (admin0_code = 'NO' AND admin1_code = '08' AND admin2_code = '1548') OR (admin0_code = 'PF') OR (admin0_code = 'FR') OR (admin0_code = 'MF') OR (admin0_code = 'FR' AND admin1_code = '11' AND admin2_code = '93') OR (admin0_code = 'IT' AND admin1_code = '07' AND admin2_code = 'FR') OR (admin0_code = 'NO' AND admin1_code = '21' AND admin2_code = '5014') OR (admin0_code = 'CH' AND admin1_code = 'FR'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:48.373\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m144\u001b[0m - \u001b[34m\u001b[1mSearching for term 'Le Lavandou' at admin level 2\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:48.374\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mflexible_search\u001b[0m:\u001b[36m146\u001b[0m - \u001b[34m\u001b[1mSearching for: 'Le Lavandou' in range [2, 3, 4]\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:48.376\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m343\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT *, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 2 OR admin_level = 3 OR admin_level = 4) AND ((admin0_code = 'FR' AND admin1_code = '27' AND admin2_code = '21') OR (admin0_code = 'FR' AND admin1_code = '28' AND admin2_code = '61' AND admin3_code = '612') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '06') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '04') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '13' AND admin3_code = '131') OR (admin0_code = 'FR' AND admin1_code = '93') OR (admin0_code = 'FR' AND admin1_code = '52' AND admin2_code = '44' AND admin3_code = '444') OR (admin0_code = 'FR' AND admin1_code = '84') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '05') OR (admin0_code = 'FR' AND admin1_code = 'B9'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['admin0_code', 'admin1_code', 'admin2_code', 'admin3_code', 'admin4_code']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = flexible_search(st, con=con, limit=10)\n",
    "\n",
    "d =s[1]\n",
    "\n",
    "admin_cols = sorted([c for c in d.columns if c.startswith('admin') and c.endswith('_code')])\n",
    "admin_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 13:25:48.418\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m343\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT *, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 0 OR admin_level = 1)\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:48.444\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_score_admin\u001b[0m:\u001b[36m178\u001b[0m - \u001b[33m\u001b[1mNo parent score column found. Skipping parent factor.\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:48.448\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m343\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT *, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 3 OR admin_level = 4) AND ((admin0_code = 'GB' AND admin1_code = 'ENG'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 33)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>asciiname</th><th>admin_level</th><th>admin0_code</th><th>admin1_code</th><th>admin2_code</th><th>admin3_code</th><th>admin4_code</th><th>feature_class</th><th>feature_code</th><th>ISO</th><th>ISO3</th><th>ISO_Numeric</th><th>official_name</th><th>fips</th><th>latitude</th><th>longitude</th><th>population</th><th>area</th><th>alternatenames</th><th>country_name</th><th>fts_score_3</th><th>adjusted_score_0</th><th>z_score</th><th>text_score</th><th>pop_score</th><th>feature_score</th><th>country_score</th><th>average_parent_score</th><th>parent_factor</th><th>base_score</th><th>adjusted_score_3</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>i32</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i32</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>7296052</td><td>&quot;Dover&quot;</td><td>&quot;Dover&quot;</td><td>4</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE033&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>51.126282</td><td>1.30099</td><td>0</td><td>null</td><td>null</td><td>&quot;United Kingdom of Great Britai…</td><td>7.179517</td><td>0.756593</td><td>0.707107</td><td>1.0</td><td>0.1</td><td>0.55</td><td>0.8</td><td>0.756593</td><td>1.0</td><td>0.6175</td><td>0.58045</td></tr><tr><td>2651049</td><td>&quot;Dover District&quot;</td><td>&quot;Dover District&quot;</td><td>3</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM3&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>51.150002</td><td>1.23333</td><td>114227</td><td>null</td><td>null</td><td>&quot;United Kingdom of Great Britai…</td><td>6.630832</td><td>0.756593</td><td>-0.707107</td><td>0.257183</td><td>0.627688</td><td>0.65</td><td>0.8</td><td>0.756593</td><td>1.0</td><td>0.557205</td><td>0.523773</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 33)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ geonameId ┆ name      ┆ asciiname ┆ admin_lev ┆ … ┆ average_p ┆ parent_fa ┆ base_scor ┆ adjusted │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ el        ┆   ┆ arent_sco ┆ ctor      ┆ e         ┆ _score_3 │\n",
       "│ i32       ┆ str       ┆ str       ┆ ---       ┆   ┆ re        ┆ ---       ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆           ┆ i32       ┆   ┆ ---       ┆ f64       ┆ f64       ┆ f64      │\n",
       "│           ┆           ┆           ┆           ┆   ┆ f64       ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 7296052   ┆ Dover     ┆ Dover     ┆ 4         ┆ … ┆ 0.756593  ┆ 1.0       ┆ 0.6175    ┆ 0.58045  │\n",
       "│ 2651049   ┆ Dover     ┆ Dover     ┆ 3         ┆ … ┆ 0.756593  ┆ 1.0       ┆ 0.557205  ┆ 0.523773 │\n",
       "│           ┆ District  ┆ District  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = search_admin(\"England\", [0, 1], con)\n",
    "# First find the administrative region\n",
    "admin_results = search_admin(\"Dover\", [3, 4], con, r)\n",
    "admin_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 13:25:48.478\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m178\u001b[0m - \u001b[34m\u001b[1mSearching for places with term: Dover Ferry Terminal\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:48.481\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m208\u001b[0m - \u001b[34m\u001b[1mNo center point provided. Using centroid of previous results.\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:48.481\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m219\u001b[0m - \u001b[34m\u001b[1mUsing center point from previous results: (51.13814163208008, 1.2671599984169006)\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:48.481\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m238\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "    WITH filtered_results AS (\n",
      "        SELECT *,\n",
      "            fts_main_places_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM places_search\n",
      "        WHERE ((admin0_code = 'GB' AND admin1_code = 'ENG' AND admin2_code = 'G5' AND admin3_code = '29UE') OR (admin0_code = 'GB' AND admin1_code = 'ENG' AND admin2_code = 'G5' AND admin3_code = '29UE' AND admin4_code = '29UE033'))\n",
      "            AND importance_tier <= 5\n",
      "    )\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC,\n",
      "        importance_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:48.723\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m246\u001b[0m - \u001b[34m\u001b[1mFound 12 results\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (12, 27)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>asciiname</th><th>admin0_code</th><th>admin1_code</th><th>admin2_code</th><th>admin3_code</th><th>admin4_code</th><th>feature_class</th><th>feature_code</th><th>feature_name</th><th>latitude</th><th>longitude</th><th>population</th><th>elevation</th><th>alternatenames</th><th>country_name</th><th>importance_score</th><th>importance_tier</th><th>fts_score</th><th>z_score</th><th>text_score</th><th>importance_norm</th><th>feature_score</th><th>distance_km</th><th>distance_score</th><th>place_score</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>i64</td><td>i32</td><td>str</td><td>str</td><td>f64</td><td>i32</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>9253020</td><td>&quot;Dover Port&quot;</td><td>&quot;Dover Port&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE033&quot;</td><td>&quot;L&quot;</td><td>&quot;PRT&quot;</td><td>&quot;port&quot;</td><td>51.126041</td><td>1.32795</td><td>0</td><td>null</td><td>&quot;Dover Ferry Terminal,Dover Har…</td><td>&quot;United Kingdom&quot;</td><td>0.495</td><td>3</td><td>13.584462</td><td>3.062812</td><td>0.989991</td><td>0.495</td><td>0.8</td><td>4.450072</td><td>0.914844</td><td>0.780731</td></tr><tr><td>7284378</td><td>&quot;Dover Transmitting Station&quot;</td><td>&quot;Dover Transmitting Station&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE010&quot;</td><td>&quot;S&quot;</td><td>&quot;TOWR&quot;</td><td>&quot;tower&quot;</td><td>51.111698</td><td>1.24746</td><td>0</td><td>null</td><td>null</td><td>&quot;United Kingdom&quot;</td><td>0.66</td><td>2</td><td>6.074767</td><td>0.007693</td><td>0.502885</td><td>0.66</td><td>0.95</td><td>3.245923</td><td>0.937144</td><td>0.735205</td></tr><tr><td>6287214</td><td>&quot;Dover Castle&quot;</td><td>&quot;Dover Castle&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE033&quot;</td><td>&quot;S&quot;</td><td>&quot;CSTL&quot;</td><td>&quot;castle&quot;</td><td>51.129581</td><td>1.32142</td><td>0</td><td>null</td><td>&quot;Castello di Dover,Castelo de D…</td><td>&quot;United Kingdom&quot;</td><td>0.715</td><td>2</td><td>5.428692</td><td>-0.255146</td><td>0.405471</td><td>0.715</td><td>0.95</td><td>3.903817</td><td>0.924894</td><td>0.712171</td></tr><tr><td>6945262</td><td>&quot;Dover Priory Railway Station&quot;</td><td>&quot;Dover Priory Railway Station&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE033&quot;</td><td>&quot;S&quot;</td><td>&quot;RSTN&quot;</td><td>&quot;railroad station&quot;</td><td>51.12582</td><td>1.30501</td><td>0</td><td>null</td><td>&quot;Bahnhof Dover Priory,DVP,Dover…</td><td>&quot;United Kingdom&quot;</td><td>0.645</td><td>2</td><td>5.764343</td><td>-0.118595</td><td>0.455644</td><td>0.645</td><td>0.8</td><td>2.975317</td><td>0.94223</td><td>0.684453</td></tr><tr><td>6944960</td><td>&quot;Ramada Dover&quot;</td><td>&quot;Ramada Dover&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE021&quot;</td><td>&quot;S&quot;</td><td>&quot;HTL&quot;</td><td>&quot;hotel&quot;</td><td>51.167702</td><td>1.26965</td><td>0</td><td>null</td><td>null</td><td>&quot;United Kingdom&quot;</td><td>0.375</td><td>4</td><td>6.655505</td><td>0.24395</td><td>0.590474</td><td>0.375</td><td>0.75</td><td>3.291517</td><td>0.93629</td><td>0.516212</td></tr><tr><td>9885608</td><td>&quot;Best Western Dover Marina&quot;</td><td>&quot;Best Western Dover Marina&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE033&quot;</td><td>&quot;S&quot;</td><td>&quot;HTL&quot;</td><td>&quot;hotel&quot;</td><td>51.12212</td><td>1.31425</td><td>0</td><td>null</td><td>null</td><td>&quot;United Kingdom&quot;</td><td>0.375</td><td>4</td><td>5.587242</td><td>-0.190644</td><td>0.428992</td><td>0.375</td><td>0.75</td><td>3.737848</td><td>0.927969</td><td>0.457329</td></tr><tr><td>10281873</td><td>&quot;Dover Marina Hotel and Spa&quot;</td><td>&quot;Dover Marina Hotel and Spa&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE033&quot;</td><td>&quot;S&quot;</td><td>&quot;HTL&quot;</td><td>&quot;hotel&quot;</td><td>51.127998</td><td>1.3132</td><td>0</td><td>null</td><td>null</td><td>&quot;United Kingdom&quot;</td><td>0.375</td><td>4</td><td>5.172156</td><td>-0.359511</td><td>0.368358</td><td>0.375</td><td>0.75</td><td>3.404745</td><td>0.934172</td><td>0.436059</td></tr><tr><td>2651048</td><td>&quot;Dover&quot;</td><td>&quot;Dover&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE033&quot;</td><td>&quot;P&quot;</td><td>&quot;PPL&quot;</td><td>&quot;populated place&quot;</td><td>51.12598</td><td>1.31257</td><td>41709</td><td>null</td><td>&quot;Dofras,Douvres,Dover,Dovero,Du…</td><td>&quot;United Kingdom&quot;</td><td>0.381011</td><td>4</td><td>4.326181</td><td>-0.703673</td><td>0.258168</td><td>0.381011</td><td>0.85</td><td>3.445103</td><td>0.933418</td><td>0.411717</td></tr><tr><td>10107778</td><td>&quot;Best Western Plus Dover Marina…</td><td>&quot;Best Western Plus Dover Marina…</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE033&quot;</td><td>&quot;S&quot;</td><td>&quot;HTL&quot;</td><td>&quot;hotel&quot;</td><td>51.121799</td><td>1.31413</td><td>0</td><td>null</td><td>null</td><td>&quot;United Kingdom&quot;</td><td>0.375</td><td>4</td><td>4.503073</td><td>-0.63171</td><td>0.279375</td><td>0.375</td><td>0.75</td><td>3.747643</td><td>0.927787</td><td>0.403451</td></tr><tr><td>11810602</td><td>&quot;Dover Admiralty Pier Lighthous…</td><td>&quot;Dover Admiralty Pier Lighthous…</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE033&quot;</td><td>&quot;S&quot;</td><td>&quot;LTHSE&quot;</td><td>&quot;lighthouse&quot;</td><td>51.111408</td><td>1.32779</td><td>0</td><td>null</td><td>null</td><td>&quot;United Kingdom&quot;</td><td>0.235</td><td>4</td><td>5.587242</td><td>-0.190644</td><td>0.428992</td><td>0.235</td><td>0.3</td><td>5.171109</td><td>0.901746</td><td>0.350119</td></tr><tr><td>11810600</td><td>&quot;Dover Breakwater West End Ligh…</td><td>&quot;Dover Breakwater West End Ligh…</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>null</td><td>&quot;S&quot;</td><td>&quot;LTHSE&quot;</td><td>&quot;lighthouse&quot;</td><td>51.113152</td><td>1.32989</td><td>0</td><td>null</td><td>null</td><td>&quot;United Kingdom&quot;</td><td>0.235</td><td>4</td><td>5.172156</td><td>-0.359511</td><td>0.368358</td><td>0.235</td><td>0.3</td><td>5.185217</td><td>0.901492</td><td>0.328268</td></tr><tr><td>11810601</td><td>&quot;Dover Prince of Wales Pier Lig…</td><td>&quot;Dover Prince of Wales Pier Lig…</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;G5&quot;</td><td>&quot;29UE&quot;</td><td>&quot;29UE033&quot;</td><td>&quot;S&quot;</td><td>&quot;LTHSE&quot;</td><td>&quot;lighthouse&quot;</td><td>51.114101</td><td>1.323</td><td>0</td><td>null</td><td>null</td><td>&quot;United Kingdom&quot;</td><td>0.235</td><td>4</td><td>4.814479</td><td>-0.505022</td><td>0.319182</td><td>0.235</td><td>0.3</td><td>4.725624</td><td>0.909816</td><td>0.311314</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (12, 27)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ geonameId ┆ name      ┆ asciiname ┆ admin0_co ┆ … ┆ feature_s ┆ distance_ ┆ distance_ ┆ place_sc │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ de        ┆   ┆ core      ┆ km        ┆ score     ┆ ore      │\n",
       "│ i32       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆           ┆ str       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 9253020   ┆ Dover     ┆ Dover     ┆ GB        ┆ … ┆ 0.8       ┆ 4.450072  ┆ 0.914844  ┆ 0.780731 │\n",
       "│           ┆ Port      ┆ Port      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 7284378   ┆ Dover Tra ┆ Dover Tra ┆ GB        ┆ … ┆ 0.95      ┆ 3.245923  ┆ 0.937144  ┆ 0.735205 │\n",
       "│           ┆ nsmitting ┆ nsmitting ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Station   ┆ Station   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6287214   ┆ Dover     ┆ Dover     ┆ GB        ┆ … ┆ 0.95      ┆ 3.903817  ┆ 0.924894  ┆ 0.712171 │\n",
       "│           ┆ Castle    ┆ Castle    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6945262   ┆ Dover     ┆ Dover     ┆ GB        ┆ … ┆ 0.8       ┆ 2.975317  ┆ 0.94223   ┆ 0.684453 │\n",
       "│           ┆ Priory    ┆ Priory    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Railway   ┆ Railway   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Station   ┆ Station   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6944960   ┆ Ramada    ┆ Ramada    ┆ GB        ┆ … ┆ 0.75      ┆ 3.291517  ┆ 0.93629   ┆ 0.516212 │\n",
       "│           ┆ Dover     ┆ Dover     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 9885608   ┆ Best      ┆ Best      ┆ GB        ┆ … ┆ 0.75      ┆ 3.737848  ┆ 0.927969  ┆ 0.457329 │\n",
       "│           ┆ Western   ┆ Western   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Dover     ┆ Dover     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Marina    ┆ Marina    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 10281873  ┆ Dover     ┆ Dover     ┆ GB        ┆ … ┆ 0.75      ┆ 3.404745  ┆ 0.934172  ┆ 0.436059 │\n",
       "│           ┆ Marina    ┆ Marina    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Hotel and ┆ Hotel and ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Spa       ┆ Spa       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 2651048   ┆ Dover     ┆ Dover     ┆ GB        ┆ … ┆ 0.85      ┆ 3.445103  ┆ 0.933418  ┆ 0.411717 │\n",
       "│ 10107778  ┆ Best      ┆ Best      ┆ GB        ┆ … ┆ 0.75      ┆ 3.747643  ┆ 0.927787  ┆ 0.403451 │\n",
       "│           ┆ Western   ┆ Western   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Plus      ┆ Plus      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Dover     ┆ Dover     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Marina…   ┆ Marina…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 11810602  ┆ Dover     ┆ Dover     ┆ GB        ┆ … ┆ 0.3       ┆ 5.171109  ┆ 0.901746  ┆ 0.350119 │\n",
       "│           ┆ Admiralty ┆ Admiralty ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Pier Ligh ┆ Pier Ligh ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ thous…    ┆ thous…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 11810600  ┆ Dover Bre ┆ Dover Bre ┆ GB        ┆ … ┆ 0.3       ┆ 5.185217  ┆ 0.901492  ┆ 0.328268 │\n",
       "│           ┆ akwater   ┆ akwater   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ West End  ┆ West End  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Ligh…     ┆ Ligh…     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 11810601  ┆ Dover     ┆ Dover     ┆ GB        ┆ … ┆ 0.3       ┆ 4.725624  ┆ 0.909816  ┆ 0.311314 │\n",
       "│           ┆ Prince of ┆ Prince of ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Wales     ┆ Wales     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Pier Lig… ┆ Pier Lig… ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then search for places within that region\n",
    "place_results = search_place(\n",
    "    \"Dover Ferry Terminal\",\n",
    "    con,\n",
    "    previous_results=admin_results,\n",
    "    limit=50,\n",
    ")\n",
    "\n",
    "place_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 13:25:48.733\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m343\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT *, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 0 OR admin_level = 1)\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:48.806\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_score_admin\u001b[0m:\u001b[36m178\u001b[0m - \u001b[33m\u001b[1mNo parent score column found. Skipping parent factor.\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:48.809\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m343\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT *, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 1 OR admin_level = 2 OR admin_level = 3) AND ((admin0_code = 'GB' AND admin1_code = 'ENG'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:48.838\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m178\u001b[0m - \u001b[34m\u001b[1mSearching for places with term: Caledonian Road\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:48.839\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m208\u001b[0m - \u001b[34m\u001b[1mNo center point provided. Using centroid of previous results.\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:48.840\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m219\u001b[0m - \u001b[34m\u001b[1mUsing center point from previous results: (51.547019958496094, -0.10943999886512756)\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:48.840\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m238\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "    WITH filtered_results AS (\n",
      "        SELECT *,\n",
      "            fts_main_places_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM places_search\n",
      "        WHERE ((admin0_code = 'GB' AND admin1_code = 'ENG' AND admin2_code = 'GLA' AND admin3_code = 'G3'))\n",
      "            AND importance_tier <= 5\n",
      "    )\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC,\n",
      "        importance_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:49.142\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_place\u001b[0m:\u001b[36m246\u001b[0m - \u001b[34m\u001b[1mFound 10 results\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 27)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>asciiname</th><th>admin0_code</th><th>admin1_code</th><th>admin2_code</th><th>admin3_code</th><th>admin4_code</th><th>feature_class</th><th>feature_code</th><th>feature_name</th><th>latitude</th><th>longitude</th><th>population</th><th>elevation</th><th>alternatenames</th><th>country_name</th><th>importance_score</th><th>importance_tier</th><th>fts_score</th><th>z_score</th><th>text_score</th><th>importance_norm</th><th>feature_score</th><th>distance_km</th><th>distance_score</th><th>place_score</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>i64</td><td>i32</td><td>str</td><td>str</td><td>f64</td><td>i32</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>6952211</td><td>&quot;Caledonian Road &amp; Barnsbury Ra…</td><td>&quot;Caledonian Road &amp; Barnsbury Ra…</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;GLA&quot;</td><td>&quot;G3&quot;</td><td>null</td><td>&quot;S&quot;</td><td>&quot;RSTN&quot;</td><td>&quot;railroad station&quot;</td><td>51.543449</td><td>-0.11492</td><td>0</td><td>null</td><td>&quot;CIR&quot;</td><td>&quot;United Kingdom&quot;</td><td>0.635</td><td>2</td><td>9.99055</td><td>0.924936</td><td>1.0</td><td>0.635</td><td>0.8</td><td>0.548849</td><td>0.989083</td><td>0.925274</td></tr><tr><td>6954652</td><td>&quot;Caledonian Road Underground St…</td><td>&quot;Caledonian Road Underground St…</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;GLA&quot;</td><td>&quot;G3&quot;</td><td>null</td><td>&quot;S&quot;</td><td>&quot;MTRO&quot;</td><td>&quot;metro station&quot;</td><td>51.548538</td><td>-0.11823</td><td>0</td><td>null</td><td>null</td><td>&quot;United Kingdom&quot;</td><td>0.485</td><td>3</td><td>11.193224</td><td>1.26892</td><td>1.0</td><td>0.485</td><td>0.3</td><td>0.63082</td><td>0.987463</td><td>0.713496</td></tr><tr><td>10115056</td><td>&quot;Caledonian Road Apartments&quot;</td><td>&quot;Caledonian Road Apartments&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;GLA&quot;</td><td>&quot;G3&quot;</td><td>null</td><td>&quot;S&quot;</td><td>&quot;HTL&quot;</td><td>&quot;hotel&quot;</td><td>51.542461</td><td>-0.11744</td><td>0</td><td>null</td><td>null</td><td>&quot;United Kingdom&quot;</td><td>0.375</td><td>4</td><td>12.169908</td><td>1.548268</td><td>1.0</td><td>0.375</td><td>0.75</td><td>0.750326</td><td>0.985106</td><td>0.668034</td></tr><tr><td>6952558</td><td>&quot;Essex Road Railway Station&quot;</td><td>&quot;Essex Road Railway Station&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;GLA&quot;</td><td>&quot;G3&quot;</td><td>null</td><td>&quot;S&quot;</td><td>&quot;RSTN&quot;</td><td>&quot;railroad station&quot;</td><td>51.5406</td><td>-0.0963</td><td>0</td><td>null</td><td>&quot;Bahnhof Essex Road,EXR,Essex R…</td><td>&quot;United Kingdom&quot;</td><td>0.645</td><td>2</td><td>4.098034</td><td>-0.76042</td><td>0.242205</td><td>0.645</td><td>0.8</td><td>1.155568</td><td>0.977154</td><td>0.594382</td></tr><tr><td>12048395</td><td>&quot;Caledonian&quot;</td><td>&quot;Caledonian&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;GLA&quot;</td><td>&quot;G3&quot;</td><td>null</td><td>&quot;P&quot;</td><td>&quot;PPLX&quot;</td><td>&quot;section of populated place&quot;</td><td>51.540482</td><td>-0.11897</td><td>0</td><td>null</td><td>null</td><td>&quot;United Kingdom&quot;</td><td>0.1</td><td>5</td><td>9.378785</td><td>0.749961</td><td>0.754904</td><td>0.1</td><td>0.85</td><td>0.981281</td><td>0.980566</td><td>0.450015</td></tr><tr><td>9259001</td><td>&quot;Caledoninan Road&quot;</td><td>&quot;Caledoninan Road&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;GLA&quot;</td><td>&quot;G3&quot;</td><td>null</td><td>&quot;S&quot;</td><td>&quot;HTL&quot;</td><td>&quot;hotel&quot;</td><td>51.54245</td><td>-0.11744</td><td>0</td><td>null</td><td>null</td><td>&quot;United Kingdom&quot;</td><td>0.375</td><td>4</td><td>4.851144</td><td>-0.545018</td><td>0.306289</td><td>0.375</td><td>0.75</td><td>0.751186</td><td>0.985089</td><td>0.418297</td></tr><tr><td>2646740</td><td>&quot;Holloway Road Underground Stat…</td><td>&quot;Holloway Road Underground Stat…</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;GLA&quot;</td><td>&quot;G3&quot;</td><td>null</td><td>&quot;S&quot;</td><td>&quot;MTRO&quot;</td><td>&quot;metro station&quot;</td><td>51.552792</td><td>-0.11282</td><td>0</td><td>null</td><td>null</td><td>&quot;United Kingdom&quot;</td><td>0.485</td><td>3</td><td>4.072496</td><td>-0.767724</td><td>0.240199</td><td>0.485</td><td>0.3</td><td>0.683006</td><td>0.986433</td><td>0.409473</td></tr><tr><td>9259906</td><td>&quot;Travelodge Central City Road&quot;</td><td>&quot;Travelodge Central City Road&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;GLA&quot;</td><td>&quot;G3&quot;</td><td>null</td><td>&quot;S&quot;</td><td>&quot;HTL&quot;</td><td>&quot;hotel&quot;</td><td>51.52282</td><td>-0.08719</td><td>0</td><td>null</td><td>null</td><td>&quot;United Kingdom&quot;</td><td>0.375</td><td>4</td><td>4.072496</td><td>-0.767724</td><td>0.240199</td><td>0.375</td><td>0.75</td><td>3.099958</td><td>0.939884</td><td>0.390436</td></tr><tr><td>6954632</td><td>&quot;Arsenal Underground Station&quot;</td><td>&quot;Arsenal Underground Station&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;GLA&quot;</td><td>&quot;G3&quot;</td><td>null</td><td>&quot;S&quot;</td><td>&quot;MTRO&quot;</td><td>&quot;metro station&quot;</td><td>51.558441</td><td>-0.10572</td><td>0</td><td>null</td><td>&quot;Gillespie Road&quot;</td><td>&quot;United Kingdom&quot;</td><td>0.495</td><td>3</td><td>2.889157</td><td>-1.106179</td><td>0.15986</td><td>0.495</td><td>0.3</td><td>1.295763</td><td>0.974418</td><td>0.379636</td></tr><tr><td>12519726</td><td>&quot;City Road&quot;</td><td>&quot;City Road&quot;</td><td>&quot;GB&quot;</td><td>&quot;ENG&quot;</td><td>&quot;GLA&quot;</td><td>&quot;G3&quot;</td><td>null</td><td>&quot;R&quot;</td><td>&quot;ST&quot;</td><td>&quot;street&quot;</td><td>51.53056</td><td>-0.10073</td><td>0</td><td>null</td><td>null</td><td>&quot;United Kingdom&quot;</td><td>0.1</td><td>5</td><td>4.851144</td><td>-0.545018</td><td>0.306289</td><td>0.1</td><td>0.3</td><td>1.926898</td><td>0.962195</td><td>0.238988</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 27)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ geonameId ┆ name      ┆ asciiname ┆ admin0_co ┆ … ┆ feature_s ┆ distance_ ┆ distance_ ┆ place_sc │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ de        ┆   ┆ core      ┆ km        ┆ score     ┆ ore      │\n",
       "│ i32       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆           ┆ str       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 6952211   ┆ Caledonia ┆ Caledonia ┆ GB        ┆ … ┆ 0.8       ┆ 0.548849  ┆ 0.989083  ┆ 0.925274 │\n",
       "│           ┆ n Road &  ┆ n Road &  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Barnsbury ┆ Barnsbury ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Ra…       ┆ Ra…       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6954652   ┆ Caledonia ┆ Caledonia ┆ GB        ┆ … ┆ 0.3       ┆ 0.63082   ┆ 0.987463  ┆ 0.713496 │\n",
       "│           ┆ n Road    ┆ n Road    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Undergrou ┆ Undergrou ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ nd St…    ┆ nd St…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 10115056  ┆ Caledonia ┆ Caledonia ┆ GB        ┆ … ┆ 0.75      ┆ 0.750326  ┆ 0.985106  ┆ 0.668034 │\n",
       "│           ┆ n Road    ┆ n Road    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Apartment ┆ Apartment ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ s         ┆ s         ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6952558   ┆ Essex     ┆ Essex     ┆ GB        ┆ … ┆ 0.8       ┆ 1.155568  ┆ 0.977154  ┆ 0.594382 │\n",
       "│           ┆ Road      ┆ Road      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Railway   ┆ Railway   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Station   ┆ Station   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 12048395  ┆ Caledonia ┆ Caledonia ┆ GB        ┆ … ┆ 0.85      ┆ 0.981281  ┆ 0.980566  ┆ 0.450015 │\n",
       "│           ┆ n         ┆ n         ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 9259001   ┆ Caledonin ┆ Caledonin ┆ GB        ┆ … ┆ 0.75      ┆ 0.751186  ┆ 0.985089  ┆ 0.418297 │\n",
       "│           ┆ an Road   ┆ an Road   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 2646740   ┆ Holloway  ┆ Holloway  ┆ GB        ┆ … ┆ 0.3       ┆ 0.683006  ┆ 0.986433  ┆ 0.409473 │\n",
       "│           ┆ Road Unde ┆ Road Unde ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ rground   ┆ rground   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Stat…     ┆ Stat…     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 9259906   ┆ Travelodg ┆ Travelodg ┆ GB        ┆ … ┆ 0.75      ┆ 3.099958  ┆ 0.939884  ┆ 0.390436 │\n",
       "│           ┆ e Central ┆ e Central ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ City Road ┆ City Road ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6954632   ┆ Arsenal   ┆ Arsenal   ┆ GB        ┆ … ┆ 0.3       ┆ 1.295763  ┆ 0.974418  ┆ 0.379636 │\n",
       "│           ┆ Undergrou ┆ Undergrou ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ nd        ┆ nd        ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Station   ┆ Station   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 12519726  ┆ City Road ┆ City Road ┆ GB        ┆ … ┆ 0.3       ┆ 1.926898  ┆ 0.962195  ┆ 0.238988 │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = search_admin(\"England\", [0, 1], con)\n",
    "a = search_admin(\"Islington\", [1, 2, 3], con, r)\n",
    "b = search_place(\n",
    "    \"Caledonian Road\",\n",
    "    con,\n",
    "    previous_results=a,\n",
    "    limit=50,\n",
    ")\n",
    "b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'admin0': {'geonameId': 2635167,\n",
       "  'name': 'United Kingdom of Great Britain and Northern Ireland'},\n",
       " 'admin1': {'geonameId': 2634259, 'name': 'West Suffolk'},\n",
       " 'admin2': {'geonameId': 2648110, 'name': 'Greater London'},\n",
       " 'admin3': {'geonameId': 3333156, 'name': 'Islington'}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backfill_hierarchy(\n",
    "    {\n",
    "        \"admin0_code\": \"GB\",\n",
    "        \"admin1_code\": \"ENG\",\n",
    "        \"admin2_code\": \"GLA\",\n",
    "        \"admin3_code\": \"G3\",\n",
    "        \"geonameId\": 13269818,\n",
    "    },\n",
    "    con,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 13:25:49.169\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mhierarchical_search\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mSearching for term 'FL' at admin level 1\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:49.169\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m343\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT *, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 1)\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:49.190\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_score_admin\u001b[0m:\u001b[36m178\u001b[0m - \u001b[33m\u001b[1mNo parent score column found. Skipping parent factor.\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:49.191\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mhierarchical_search\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mSearching for term 'Lakeland' at admin level 3\u001b[0m\n",
      "\u001b[32m2025-05-04 13:25:49.193\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m343\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT *, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 3) AND ((admin0_code = 'US' AND admin1_code = 'FL') OR (admin0_code = 'NL' AND admin1_code = '16'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ISO': None,\n",
      " 'ISO3': None,\n",
      " 'ISO_Numeric': None,\n",
      " 'adjusted_score_1': 0.6674183738082736,\n",
      " 'adjusted_score_3': 0.6025998219254551,\n",
      " 'admin0_code': 'US',\n",
      " 'admin1_code': 'FL',\n",
      " 'admin2_code': '105',\n",
      " 'admin3_code': '7170309',\n",
      " 'admin4_code': None,\n",
      " 'admin_level': 3,\n",
      " 'alternatenames': None,\n",
      " 'area': None,\n",
      " 'asciiname': 'City of Lakeland',\n",
      " 'average_parent_score': 0.6674183738082736,\n",
      " 'base_score': 0.6410636403462289,\n",
      " 'country_name': 'United States',\n",
      " 'country_score': 0.8,\n",
      " 'feature_class': 'A',\n",
      " 'feature_code': 'ADM3',\n",
      " 'feature_score': 0.65,\n",
      " 'fips': None,\n",
      " 'fts_score_3': 7.112898225403302,\n",
      " 'geonameId': 7170309,\n",
      " 'latitude': 28.05565071105957,\n",
      " 'longitude': -81.95420837402344,\n",
      " 'name': 'City of Lakeland',\n",
      " 'official_name': None,\n",
      " 'parent_factor': 1.0,\n",
      " 'pop_score': 0.6244675438463683,\n",
      " 'population': 97422,\n",
      " 'text_score': 0.5,\n",
      " 'z_score': 0.0}\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "{'admin0': {'geonameId': 6252001, 'name': 'United States'},\n",
      " 'admin1': {'geonameId': 4155751, 'name': 'Florida'},\n",
      " 'admin2': {'geonameId': 4168988, 'name': 'Polk County'},\n",
      " 'admin3': {'geonameId': 7170309, 'name': 'City of Lakeland'}}\n"
     ]
    }
   ],
   "source": [
    "results = hierarchical_search(\n",
    "    search_terms=[None, \"FL\", None, \"Lakeland\", None], con=con\n",
    ")\n",
    "row = results[\"admin3\"].row(0, named=True)\n",
    "\n",
    "\n",
    "pprint(row)\n",
    "\n",
    "pprint(backfill_hierarchy(row, con))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 13:27:58.244\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mhierarchical_search\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mSearching for term 'FR' at admin level 0\u001b[0m\n",
      "\u001b[32m2025-05-04 13:27:58.253\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m343\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT *, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 0) AND (admin_level != 0 OR geonameId NOT IN (3017382))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 13:27:58.281\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_score_admin\u001b[0m:\u001b[36m178\u001b[0m - \u001b[33m\u001b[1mNo parent score column found. Skipping parent factor.\u001b[0m\n",
      "\u001b[32m2025-05-04 13:27:58.283\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mhierarchical_search\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mSearching for term 'Provence-Alpes-Côte d'Azur' at admin level 1\u001b[0m\n",
      "\u001b[32m2025-05-04 13:27:58.284\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m343\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT *, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 1) AND ((admin0_code = 'GF') OR (admin0_code = 'FR') OR (admin0_code = 'MF') OR (admin0_code = 'PF'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 13:27:58.316\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mhierarchical_search\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mSearching for term 'Var' at admin level 2\u001b[0m\n",
      "\u001b[32m2025-05-04 13:27:58.318\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m343\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT *, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 2) AND ((admin0_code = 'FR' AND admin1_code = '11') OR (admin0_code = 'FR' AND admin1_code = '32') OR (admin0_code = 'FR' AND admin1_code = '24') OR (admin0_code = 'FR' AND admin1_code = 'B9') OR (admin0_code = 'FR' AND admin1_code = '84') OR (admin0_code = 'FR' AND admin1_code = '93') OR (admin0_code = 'FR' AND admin1_code = '52') OR (admin0_code = 'FR' AND admin1_code = 'B4'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 13:27:58.337\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mhierarchical_search\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mSearching for term 'Arrondissement de Toulon' at admin level 3\u001b[0m\n",
      "\u001b[32m2025-05-04 13:27:58.338\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m343\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT *, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 3) AND ((admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 13:27:58.373\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mhierarchical_search\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mSearching for term 'Le Lavandou' at admin level 4\u001b[0m\n",
      "\u001b[32m2025-05-04 13:27:58.374\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msearch_admin\u001b[0m:\u001b[36m343\u001b[0m - \u001b[34m\u001b[1mExecuting FTS query: \n",
      "\n",
      "    WITH filtered_results AS (\n",
      "        SELECT *, fts_main_admin_search.match_bm25(geonameId, $term) AS fts_score\n",
      "        FROM admin_search\n",
      "        WHERE (admin_level = 4) AND ((admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '831') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '833') OR (admin0_code = 'FR' AND admin1_code = '93' AND admin2_code = '83' AND admin3_code = '832'))\n",
      "    )\n",
      "    -- Using a CTE to ensure we always filter before the FTS score is calculated. Because of the `WHERE fts_score IS NOT NULL` clause, the FTS score will be calculated for all rows, but we only want to keep those that match the search term, hence the subquery first in order to stop the filter push down.\n",
      "    SELECT * FROM filtered_results\n",
      "    WHERE fts_score IS NOT NULL\n",
      "    ORDER BY fts_score DESC\n",
      "    LIMIT $limit\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-04 13:27:58.409\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - \u001b[34m\u001b[1mAdmin1 results:\u001b[0m\n",
      "\u001b[32m2025-05-04 13:27:58.410\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m19\u001b[0m - \u001b[34m\u001b[1mAdmin2 results:\u001b[0m\n",
      "\u001b[32m2025-05-04 13:27:58.410\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m21\u001b[0m - \u001b[34m\u001b[1mAdmin3 results:\u001b[0m\n",
      "\u001b[32m2025-05-04 13:27:58.410\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mAdmin4 results:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (15, 36)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>asciiname</th><th>admin_level</th><th>admin0_code</th><th>admin1_code</th><th>admin2_code</th><th>admin3_code</th><th>admin4_code</th><th>feature_class</th><th>feature_code</th><th>ISO</th><th>ISO3</th><th>ISO_Numeric</th><th>official_name</th><th>fips</th><th>latitude</th><th>longitude</th><th>population</th><th>area</th><th>alternatenames</th><th>country_name</th><th>fts_score_4</th><th>adjusted_score_0</th><th>adjusted_score_1</th><th>adjusted_score_2</th><th>adjusted_score_3</th><th>z_score</th><th>text_score</th><th>pop_score</th><th>feature_score</th><th>country_score</th><th>average_parent_score</th><th>parent_factor</th><th>base_score</th><th>adjusted_score_4</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>i32</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i32</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>6615009</td><td>&quot;Le Lavandou&quot;</td><td>&quot;Le Lavandou&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;832&quot;</td><td>&quot;83070&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>43.137779</td><td>6.36778</td><td>5759</td><td>null</td><td>&quot;83070,Le Lavandou&quot;</td><td>&quot;Republic of France&quot;</td><td>12.610318</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.777905</td><td>3.478571</td><td>1.0</td><td>0.556236</td><td>0.55</td><td>0.8</td><td>0.784346</td><td>1.0</td><td>0.777183</td><td>0.730552</td></tr><tr><td>6457128</td><td>&quot;Le Pradet&quot;</td><td>&quot;Le Pradet&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;832&quot;</td><td>&quot;83098&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>43.10556</td><td>6.02333</td><td>10027</td><td>null</td><td>&quot;83098,Le Pradet&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.777905</td><td>-0.023016</td><td>0.49137</td><td>0.5715</td><td>0.55</td><td>0.8</td><td>0.784346</td><td>1.0</td><td>0.604505</td><td>0.568234</td></tr><tr><td>6457113</td><td>&quot;Le Beausset&quot;</td><td>&quot;Le Beausset&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;832&quot;</td><td>&quot;83016&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>43.19833</td><td>5.80278</td><td>9637</td><td>null</td><td>&quot;83016&quot;</td><td>&quot;Republic of France&quot;</td><td>3.457602</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.777905</td><td>-0.09062</td><td>0.46607</td><td>0.570443</td><td>0.55</td><td>0.8</td><td>0.784346</td><td>1.0</td><td>0.59528</td><td>0.559563</td></tr><tr><td>6457122</td><td>&quot;Le Luc&quot;</td><td>&quot;Le Luc&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;833&quot;</td><td>&quot;83073&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>43.394402</td><td>6.3134</td><td>10952</td><td>null</td><td>&quot;83073,Le Luc&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.542154</td><td>-0.023016</td><td>0.49137</td><td>0.573833</td><td>0.55</td><td>0.8</td><td>0.725408</td><td>0.924857</td><td>0.59405</td><td>0.558407</td></tr><tr><td>6457127</td><td>&quot;Le Muy&quot;</td><td>&quot;Le Muy&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;831&quot;</td><td>&quot;83086&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>43.4725</td><td>6.56639</td><td>9248</td><td>null</td><td>&quot;83086,Le Muy&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.540235</td><td>-0.023016</td><td>0.49137</td><td>0.56934</td><td>0.55</td><td>0.8</td><td>0.724929</td><td>0.924246</td><td>0.592385</td><td>0.556842</td></tr><tr><td>6456550</td><td>&quot;Le Val&quot;</td><td>&quot;Le Val&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;833&quot;</td><td>&quot;83143&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>43.439442</td><td>6.07306</td><td>4297</td><td>null</td><td>&quot;83143,Le Val&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.542154</td><td>-0.023016</td><td>0.49137</td><td>0.547727</td><td>0.55</td><td>0.8</td><td>0.725408</td><td>0.924857</td><td>0.584913</td><td>0.549818</td></tr><tr><td>6456549</td><td>&quot;Le Thoronet&quot;</td><td>&quot;Le Thoronet&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;833&quot;</td><td>&quot;83136&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>43.451939</td><td>6.30389</td><td>2449</td><td>null</td><td>&quot;83136,Le Thoronet&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.542154</td><td>-0.023016</td><td>0.49137</td><td>0.530442</td><td>0.55</td><td>0.8</td><td>0.725408</td><td>0.924857</td><td>0.578863</td><td>0.544131</td></tr><tr><td>6456545</td><td>&quot;Le Revest-les-Eaux&quot;</td><td>&quot;Le Revest-les-Eaux&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;832&quot;</td><td>&quot;83103&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>43.176601</td><td>5.9273</td><td>3812</td><td>null</td><td>&quot;83103&quot;</td><td>&quot;Republic of France&quot;</td><td>3.013891</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.777905</td><td>-0.263649</td><td>0.4024</td><td>0.544153</td><td>0.55</td><td>0.8</td><td>0.784346</td><td>1.0</td><td>0.563794</td><td>0.529966</td></tr><tr><td>6617824</td><td>&quot;Le Castellet&quot;</td><td>&quot;Le Castellet&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;832&quot;</td><td>&quot;83035&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>43.202702</td><td>5.777</td><td>3875</td><td>null</td><td>&quot;83035,Castellet,Kastele,Le-Kas…</td><td>&quot;Republic of France&quot;</td><td>2.947438</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.777905</td><td>-0.289563</td><td>0.393089</td><td>0.544645</td><td>0.55</td><td>0.8</td><td>0.784346</td><td>1.0</td><td>0.560707</td><td>0.527065</td></tr><tr><td>6457115</td><td>&quot;Le Cannet-des-Maures&quot;</td><td>&quot;Le Cannet-des-Maures&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;833&quot;</td><td>&quot;83031&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>43.39167</td><td>6.34083</td><td>4328</td><td>null</td><td>&quot;83031,Le Cannet-des-Maures&quot;</td><td>&quot;Republic of France&quot;</td><td>3.144771</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.542154</td><td>-0.212611</td><td>0.42094</td><td>0.54794</td><td>0.55</td><td>0.8</td><td>0.725408</td><td>0.924857</td><td>0.560337</td><td>0.526716</td></tr><tr><td>6451513</td><td>&quot;Le Plan-de-la-Tour&quot;</td><td>&quot;Le Plan-de-la-Tour&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;831&quot;</td><td>&quot;83094&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>43.340561</td><td>6.54639</td><td>2714</td><td>null</td><td>&quot;83094,Le Plan-de-la-Tour&quot;</td><td>&quot;Republic of France&quot;</td><td>2.947438</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.540235</td><td>-0.289563</td><td>0.393089</td><td>0.533699</td><td>0.55</td><td>0.8</td><td>0.724929</td><td>0.924246</td><td>0.545513</td><td>0.512782</td></tr><tr><td>6451462</td><td>&quot;Bormes-les-Mimosas&quot;</td><td>&quot;Bormes-les-Mimosas&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;832&quot;</td><td>&quot;83019&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>43.151669</td><td>6.34306</td><td>7982</td><td>null</td><td>&quot;83019,Borm le Mimoza,Borm-le-M…</td><td>&quot;Republic of France&quot;</td><td>1.766839</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.777905</td><td>-0.749949</td><td>0.245099</td><td>0.56535</td><td>0.55</td><td>0.8</td><td>0.784346</td><td>1.0</td><td>0.516157</td><td>0.485188</td></tr><tr><td>6614863</td><td>&quot;Le Bourguet&quot;</td><td>&quot;Le Bourguet&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;831&quot;</td><td>&quot;83020&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>43.784168</td><td>6.51861</td><td>31</td><td>null</td><td>&quot;83020,Le Bourguet&quot;</td><td>&quot;Republic of France&quot;</td><td>3.630964</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.540235</td><td>-0.023016</td><td>0.49137</td><td>0.332051</td><td>0.55</td><td>0.8</td><td>0.724929</td><td>0.924246</td><td>0.509334</td><td>0.478774</td></tr><tr><td>6451500</td><td>&quot;Méounes-lès-Montrieux&quot;</td><td>&quot;Meounes-les-Montrieux&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;833&quot;</td><td>&quot;83077&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>43.281109</td><td>5.97</td><td>2165</td><td>null</td><td>&quot;83077,Meojun-le-Monrie,Meonas,…</td><td>&quot;Republic of France&quot;</td><td>1.835897</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.542154</td><td>-0.72302</td><td>0.25265</td><td>0.526475</td><td>0.55</td><td>0.8</td><td>0.725408</td><td>0.924857</td><td>0.493922</td><td>0.464287</td></tr><tr><td>6457124</td><td>&quot;Les Mayons&quot;</td><td>&quot;Les Mayons&quot;</td><td>4</td><td>&quot;FR&quot;</td><td>&quot;93&quot;</td><td>&quot;83&quot;</td><td>&quot;833&quot;</td><td>&quot;83075&quot;</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>43.312778</td><td>6.35806</td><td>641</td><td>null</td><td>&quot;83075,Le-Majon,Lei Maions,lai …</td><td>&quot;Republic of France&quot;</td><td>1.83979</td><td>0.746891</td><td>0.81716</td><td>0.795429</td><td>0.542154</td><td>-0.721501</td><td>0.25308</td><td>0.483369</td><td>0.55</td><td>0.8</td><td>0.725408</td><td>0.924857</td><td>0.478986</td><td>0.450247</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (15, 36)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ geonameId ┆ name      ┆ asciiname ┆ admin_lev ┆ … ┆ average_p ┆ parent_fa ┆ base_scor ┆ adjusted │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ el        ┆   ┆ arent_sco ┆ ctor      ┆ e         ┆ _score_4 │\n",
       "│ i32       ┆ str       ┆ str       ┆ ---       ┆   ┆ re        ┆ ---       ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆           ┆ i32       ┆   ┆ ---       ┆ f64       ┆ f64       ┆ f64      │\n",
       "│           ┆           ┆           ┆           ┆   ┆ f64       ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 6615009   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.784346  ┆ 1.0       ┆ 0.777183  ┆ 0.730552 │\n",
       "│           ┆ Lavandou  ┆ Lavandou  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6457128   ┆ Le Pradet ┆ Le Pradet ┆ 4         ┆ … ┆ 0.784346  ┆ 1.0       ┆ 0.604505  ┆ 0.568234 │\n",
       "│ 6457113   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.784346  ┆ 1.0       ┆ 0.59528   ┆ 0.559563 │\n",
       "│           ┆ Beausset  ┆ Beausset  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6457122   ┆ Le Luc    ┆ Le Luc    ┆ 4         ┆ … ┆ 0.725408  ┆ 0.924857  ┆ 0.59405   ┆ 0.558407 │\n",
       "│ 6457127   ┆ Le Muy    ┆ Le Muy    ┆ 4         ┆ … ┆ 0.724929  ┆ 0.924246  ┆ 0.592385  ┆ 0.556842 │\n",
       "│ 6456550   ┆ Le Val    ┆ Le Val    ┆ 4         ┆ … ┆ 0.725408  ┆ 0.924857  ┆ 0.584913  ┆ 0.549818 │\n",
       "│ 6456549   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.725408  ┆ 0.924857  ┆ 0.578863  ┆ 0.544131 │\n",
       "│           ┆ Thoronet  ┆ Thoronet  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6456545   ┆ Le Revest ┆ Le Revest ┆ 4         ┆ … ┆ 0.784346  ┆ 1.0       ┆ 0.563794  ┆ 0.529966 │\n",
       "│           ┆ -les-Eaux ┆ -les-Eaux ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6617824   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.784346  ┆ 1.0       ┆ 0.560707  ┆ 0.527065 │\n",
       "│           ┆ Castellet ┆ Castellet ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6457115   ┆ Le Cannet ┆ Le Cannet ┆ 4         ┆ … ┆ 0.725408  ┆ 0.924857  ┆ 0.560337  ┆ 0.526716 │\n",
       "│           ┆ -des-Maur ┆ -des-Maur ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ es        ┆ es        ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6451513   ┆ Le Plan-d ┆ Le Plan-d ┆ 4         ┆ … ┆ 0.724929  ┆ 0.924246  ┆ 0.545513  ┆ 0.512782 │\n",
       "│           ┆ e-la-Tour ┆ e-la-Tour ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6451462   ┆ Bormes-le ┆ Bormes-le ┆ 4         ┆ … ┆ 0.784346  ┆ 1.0       ┆ 0.516157  ┆ 0.485188 │\n",
       "│           ┆ s-Mimosas ┆ s-Mimosas ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6614863   ┆ Le        ┆ Le        ┆ 4         ┆ … ┆ 0.724929  ┆ 0.924246  ┆ 0.509334  ┆ 0.478774 │\n",
       "│           ┆ Bourguet  ┆ Bourguet  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6451500   ┆ Méounes-l ┆ Meounes-l ┆ 4         ┆ … ┆ 0.725408  ┆ 0.924857  ┆ 0.493922  ┆ 0.464287 │\n",
       "│           ┆ ès-Montri ┆ es-Montri ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ eux       ┆ eux       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 6457124   ┆ Les       ┆ Les       ┆ 4         ┆ … ┆ 0.725408  ┆ 0.924857  ┆ 0.478986  ┆ 0.450247 │\n",
       "│           ┆ Mayons    ┆ Mayons    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search through the admin hierarchy\n",
    "results = hierarchical_search(\n",
    "    search_terms=[\n",
    "        \"FR\",\n",
    "        \"Provence-Alpes-Côte d'Azur\",\n",
    "        \"Var\",\n",
    "        \"Arrondissement de Toulon\",\n",
    "        \"Le Lavandou\",\n",
    "    ],\n",
    "    con=con,\n",
    ")\n",
    "\n",
    "# Access results for each level\n",
    "if \"country\" in results:\n",
    "    logger.debug(\"Country results:\", results[\"country\"])\n",
    "if \"admin1\" in results:\n",
    "    logger.debug(\"Admin1 results:\", results[\"admin1\"])\n",
    "if \"admin2\" in results:\n",
    "    logger.debug(\"Admin2 results:\", results[\"admin2\"])\n",
    "if \"admin3\" in results:\n",
    "    logger.debug(\"Admin3 results:\", results[\"admin3\"])\n",
    "if \"admin4\" in results:\n",
    "    logger.debug(\"Admin4 results:\", results[\"admin4\"])\n",
    "results[\"admin4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    con.execute(\"SELECT geonameId, latitude, longitude FROM allCountries\")\n",
    "    .pl()\n",
    "    .select(\n",
    "        pl.col(\"geonameId\"),\n",
    "        pl.concat_list(pl.col(\"latitude\"), pl.col(\"longitude\"))\n",
    "        .cast(pl.Array(pl.Float32, 2))\n",
    "        .alias(\"vectors\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_coordinates1 = np.array([51.549902, -0.121696], dtype=np.float32)\n",
    "my_coordinates2 = np.array([37.77493, -122.41942], dtype=np.float32)\n",
    "\n",
    "vidx = VectorIndex(\"latlon\", data, metric=\"haversine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (path := Path(\"./data/processed/latlon.index\")).exists():\n",
    "    logger.debug(\"Loading index...\")\n",
    "    index = Index.restore(path, view=True)\n",
    "    if index is None:\n",
    "        raise ValueError(\"Failed to load index\")\n",
    "else:\n",
    "    logger.debug(\"Creating index...\")\n",
    "    coordinates = df.select([\"latitude\", \"longitude\"]).to_numpy(order=\"c\")\n",
    "    labels = df[\"geonameId\"].to_numpy()\n",
    "    index: Index = Index(ndim=2, metric=\"haversine\", dtype=\"f32\")\n",
    "    index.add(keys=labels, vectors=coordinates, log=True)\n",
    "    index.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example function to search and return results with distances\n",
    "def search_with_distances(\n",
    "    index: Index,\n",
    "    my_coordinates: NDArray[np.float32],\n",
    "    original_df: pl.LazyFrame,\n",
    "    k=10,\n",
    "    exact=False,\n",
    "):\n",
    "    # Perform the search\n",
    "    output = index.search(vectors=my_coordinates, count=k, log=True, exact=exact)\n",
    "\n",
    "    logger.debug(f\"Visited members: {output.visited_members}\")\n",
    "    logger.debug(f\"Computed distances: {output.computed_distances}\")\n",
    "\n",
    "    # Extract keys (geonameids) and distances\n",
    "    keys = output.keys\n",
    "    distances = output.distances\n",
    "\n",
    "    # Create a DataFrame from the search results\n",
    "    results_df = pl.LazyFrame(\n",
    "        data={\"geonameId\": keys, \"distance\": distances},\n",
    "        schema={\"geonameId\": pl.UInt32, \"distance\": pl.Float32},\n",
    "    ).with_columns(pl.col(\"distance\") * 6371.0)\n",
    "\n",
    "    # Join the results with the original DataFrame to get detailed information\n",
    "    detailed_results_df = results_df.join(original_df, on=\"geonameId\", how=\"left\")\n",
    "\n",
    "    # Sort by distance\n",
    "    sorted_results_df = detailed_results_df.sort(\"distance\")\n",
    "\n",
    "    return sorted_results_df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_with_distances(index, my_coordinates2, df.lazy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output: Matches = index.search(vectors=my_coordinates1, count=10, log=True)\n",
    "logger.debug(f\"{output.computed_distances=}\")\n",
    "logger.debug(f\"{output.visited_members=}\")\n",
    "df.filter(pl.col(\"geonameId\").is_in(output.keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# con.execute(sql_file(\"create_view_*_NODES.sql\", table=\"admin0\"))\n",
    "\n",
    "# con.execute(sql_file(\"create_view_*_FTS.sql\", table=\"admin0\"))\n",
    "\n",
    "# # if (path := Path(\"./data/processed/latlon.index\")).exists():\n",
    "# #     logger.debug(\"Loading index...\")\n",
    "# #     index = Index.restore(path, view=True) or raise ValueError(\"Failed to load index\")\n",
    "# # else:\n",
    "# #     logger.debug(\"Creating index...\")\n",
    "# #     coordinates = df.select([\"latitude\", \"longitude\"]).to_numpy(order=\"c\")\n",
    "# #     labels = df[\"geonameid\"].to_numpy()\n",
    "# #     index: Index = Index(ndim=2, metric=\"haversine\", dtype=\"f32\")\n",
    "# #     index.add(keys=labels, vectors=coordinates, log=True)\n",
    "# #     index.save(path)\n",
    "\n",
    "\n",
    "# class VectorIndex:\n",
    "#     default_index_path = Path(\"./data/indexes/vector\")\n",
    "\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         index_name: str,\n",
    "#         data: pl.DataFrame | None = None,\n",
    "#         id_column: str = \"geonameId\",\n",
    "#         main_column: str = \"vectors\",\n",
    "#         metric: str = \"L2\",\n",
    "#         embedder: SentenceTransformer | None = None,\n",
    "#     ):\n",
    "#         self._index_path = self.default_index_path / f\"{index_name}.index\"\n",
    "#         self._id_column = id_column\n",
    "#         self._main_column = main_column\n",
    "#         self._metric = metric\n",
    "#         index = self.get_or_build_index(data, metric)\n",
    "#         if isinstance(index, Err):\n",
    "#             logger.debug(\n",
    "#                 f\"Index does not exist at '{self.index_path}', build index with 'build_index' method.\"\n",
    "#             )\n",
    "#             self._index = None  # type: ignore\n",
    "#         else:\n",
    "#             self._index: Index = index.ok_value\n",
    "\n",
    "#     @property\n",
    "#     def index(self) -> Index:\n",
    "#         return self._index\n",
    "\n",
    "#     @property\n",
    "#     def id_column(self) -> str:\n",
    "#         return self._id_column\n",
    "\n",
    "#     @property\n",
    "#     def main_column(self) -> str:\n",
    "#         return self._main_column\n",
    "\n",
    "#     @property\n",
    "#     def index_path(self) -> Path:\n",
    "#         return self._index_path\n",
    "\n",
    "#     @property\n",
    "#     def ndims(self) -> int:\n",
    "#         return self._ndims\n",
    "\n",
    "#     @property\n",
    "#     def metric(self) -> str:\n",
    "#         return self._metric\n",
    "\n",
    "#     def _build_index(\n",
    "#         self,\n",
    "#         df: pl.DataFrame,\n",
    "#         metric: str = \"L2\",  # TODO: Metric like\n",
    "#     ) -> Result[Index, str]:\n",
    "#         \"\"\"Data passed should be an Id and a vector.\"\"\"\n",
    "#         logger.debug(\"Creating index...\")\n",
    "#         vectors = df[self.main_column].to_numpy()\n",
    "#         labels = df[self.id_column].to_numpy()\n",
    "#         ndims = vectors.shape[1]  # Find n dims\n",
    "#         index: Index = Index(ndim=ndims, metric=metric, dtype=\"f32\")\n",
    "#         index.add(keys=labels, vectors=vectors, log=True)\n",
    "#         index.save(self.index_path)\n",
    "#         return Ok(index)\n",
    "\n",
    "#     def get_index(self) -> Result[Index, str]:\n",
    "#         if (path := self.index_path).exists():\n",
    "#             logger.debug(f\"Opening index at '{self.index_path}'\")\n",
    "#             index = Index.restore(path, view=True)\n",
    "#             if index is not None:\n",
    "#                 return Ok(index)\n",
    "#         return Err(f\"Index does not exist at '{self.index_path}'\")\n",
    "\n",
    "#     def get_or_build_index(\n",
    "#         self,\n",
    "#         df: pl.DataFrame | None = None,\n",
    "#         metric: str = \"L2\",  # TODO: as above\n",
    "#     ) -> Result[Index, str]:\n",
    "#         self.index_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#         if not self.index_path.exists():\n",
    "#             if df is None:\n",
    "#                 return Err(\n",
    "#                     \"Index does not exist. DataFrame is required to create index\"\n",
    "#                 )\n",
    "#             match self._build_index(df, metric):\n",
    "#                 case Ok(index):\n",
    "#                     ...\n",
    "#                 case Err(e):\n",
    "#                     return Err(e)\n",
    "#         else:\n",
    "#             match self.get_index():\n",
    "#                 case Ok(index):\n",
    "#                     ...\n",
    "#                 case Err(e):\n",
    "#                     return Err(e)\n",
    "\n",
    "#         self._ndims = index.ndim\n",
    "#         logger.debug(\"Opening index\")\n",
    "#         return Ok(index)\n",
    "\n",
    "#     def search(\n",
    "#         self,\n",
    "#         query: NDArray[np.float32],\n",
    "#         limit: int = 10,\n",
    "#         include: list[int] | None = None,\n",
    "#         exclude: list[int] | None = None,\n",
    "#     ) -> Result[pl.DataFrame, str]:\n",
    "#         return self.vector_search(query, limit, include, exclude)\n",
    "\n",
    "#     def vector_search(\n",
    "#         self,\n",
    "#         query: NDArray[np.float32],\n",
    "#         limit: int = 10,\n",
    "#         include: list[int] | None = None,\n",
    "#         exclude: list[int] | None = None,\n",
    "#         exact: bool = False,\n",
    "#     ) -> Result[pl.DataFrame, str]:\n",
    "#         output = self.index.search(vectors=query, count=limit, log=True, exact=exact)\n",
    "\n",
    "#         logger.debug(f\"Visited members: {output.visited_members}\")\n",
    "#         logger.debug(f\"Computed distances: {output.computed_distances}\")\n",
    "\n",
    "#         # Extract keys (geonameids) and distances\n",
    "#         keys = output.keys\n",
    "#         distances = output.distances\n",
    "\n",
    "#         # Create a DataFrame from the search results\n",
    "#         results_df = pl.LazyFrame(\n",
    "#             data={self.id_column: keys, \"score\": distances},\n",
    "#             schema={self.id_column: pl.UInt32, \"score\": pl.Float32},\n",
    "#         )\n",
    "#         if self.metric == \"haversine\":\n",
    "#             results_df = results_df.with_columns(pl.col(\"score\") * 6371.0)\n",
    "\n",
    "#         results_df = results_df.sort(\n",
    "#             \"score\"\n",
    "#         )  # TODO: ascending descending depending on metric.\n",
    "\n",
    "#         return Ok(results_df.collect())\n",
    "\n",
    "\n",
    "# class FTSIndex:\n",
    "#     default_index_path = Path(\"./data/indexes/fts\")\n",
    "\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         index_name: str,\n",
    "#         data: pl.DataFrame | None = None,\n",
    "#         id_column: str = \"geonameId\",\n",
    "#         main_column: str = \"name\",\n",
    "#     ):\n",
    "#         self._index_path = self.default_index_path / index_name\n",
    "#         self._column_types = {}\n",
    "#         self._id_column = id_column\n",
    "#         self._main_column = main_column\n",
    "#         index = self.get_or_build_index(data)\n",
    "#         if isinstance(index, Err):\n",
    "#             logger.debug(\n",
    "#                 f\"Index does not exist at '{self.index_path}', build index with 'build_index' method.\"\n",
    "#             )\n",
    "#             self._index = None  # type: ignore\n",
    "#         else:\n",
    "#             self._index: tantivy.Index = index.ok_value\n",
    "\n",
    "#     @property\n",
    "#     def index(self) -> tantivy.Index:\n",
    "#         self._index.reload()\n",
    "#         return self._index\n",
    "\n",
    "#     @property\n",
    "#     def column_types(self) -> dict[str, str]:\n",
    "#         return self._column_types\n",
    "\n",
    "#     @property\n",
    "#     def id_column(self) -> str:\n",
    "#         return self._id_column\n",
    "\n",
    "#     @property\n",
    "#     def main_column(self) -> str:\n",
    "#         return self._main_column\n",
    "\n",
    "#     @property\n",
    "#     def index_path(self) -> Path:\n",
    "#         return self._index_path\n",
    "\n",
    "#     @property\n",
    "#     def columns_not_id(self) -> list[str]:\n",
    "#         return [col for col in self.column_types if col != self.id_column]\n",
    "\n",
    "#     def _build_index(\n",
    "#         self,\n",
    "#         df: pl.DataFrame,\n",
    "#         split_field: dict[str, list[str] | str] | None = None,\n",
    "#     ) -> Result[tantivy.Index, str]:\n",
    "#         \"\"\"Only pass in data which you wish to build the ftx index with. split_field is a dictionary of fields to split by a delimiter. eg {\",\": [\"field1\", \"field2\"]} will split field1 and field2 by comma.\"\"\"\n",
    "#         # TODO: this programmatically into tantivy schema\n",
    "#         schema_builder = tantivy.SchemaBuilder()\n",
    "\n",
    "#         if self.id_column not in df.columns:\n",
    "#             return Err(f\"'{self.id_column}' column not found in DataFrame\")\n",
    "\n",
    "#         col_types = {}\n",
    "#         for col in df.columns:\n",
    "#             if col == self.id_column:\n",
    "#                 schema_builder.add_integer_field(\n",
    "#                     self.id_column, stored=True, indexed=True, fast=True\n",
    "#                 )\n",
    "#             # TODO: ADD support for other types\n",
    "#             else:\n",
    "#                 schema_builder.add_text_field(col)\n",
    "#             col_types[col] = df[col].dtype._string_repr()\n",
    "\n",
    "#         self._column_types = col_types\n",
    "\n",
    "#         schema = schema_builder.build()\n",
    "#         logger.debug(f\"Creating index with columns:\\n{json.dumps(col_types, indent=2)}\")\n",
    "\n",
    "#         index = tantivy.Index(schema, path=self.index_path.as_posix(), reuse=False)\n",
    "#         writer = index.writer()\n",
    "#         for row in df.rows(named=True):\n",
    "#             if split_field:\n",
    "#                 for splitter, fields in split_field.items():\n",
    "#                     if isinstance(fields, str):\n",
    "#                         fields = [fields]\n",
    "#                     for field in fields:\n",
    "#                         logger.debug(f\"Splitting {field} by {splitter}...\")\n",
    "#                         row[field] = row[field].split(splitter)\n",
    "#             writer.add_document(tantivy.Document(**row))\n",
    "#         writer.commit()\n",
    "#         writer.wait_merging_threads()\n",
    "#         return Ok(index)\n",
    "\n",
    "#     def get_index(self) -> Result[tantivy.Index, str]:\n",
    "#         if tantivy.Index.exists(self.index_path.as_posix()):\n",
    "#             logger.debug(f\"Opening index at '{self.index_path}'\")\n",
    "#             return Ok(tantivy.Index.open(self.index_path.as_posix()))\n",
    "#         return Err(f\"Index does not exist at '{self.index_path}'\")\n",
    "\n",
    "#     def get_or_build_index(\n",
    "#         self, df: pl.DataFrame | None = None\n",
    "#     ) -> Result[tantivy.Index, str]:\n",
    "#         if not self.index_path.exists() and df is None:\n",
    "#             return Err(\"Index does not exist. DataFrame is required to create index\")\n",
    "\n",
    "#         self.index_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#         if not tantivy.Index.exists(self.index_path.as_posix()):\n",
    "#             if df is None:\n",
    "#                 return Err(\"DataFrame is required to create index\")\n",
    "#             match self._build_index(df):\n",
    "#                 case Ok(index):\n",
    "#                     ...\n",
    "#                 case Err(e):\n",
    "#                     return Err(e)\n",
    "#         else:\n",
    "#             match self.get_index():\n",
    "#                 case Ok(index):\n",
    "#                     ...\n",
    "#                 case Err(e):\n",
    "#                     return Err(e)\n",
    "#         schema = json.loads((self.index_path / \"meta.json\").read_text())[\"schema\"]\n",
    "#         sc = {}\n",
    "#         for v in schema:\n",
    "#             type_ = v[\"type\"]\n",
    "#             if type_ == \"text\":\n",
    "#                 type_ = pl.Utf8\n",
    "#             elif type_ == \"i64\":\n",
    "#                 type_ = pl.UInt32\n",
    "#             sc[v[\"name\"]] = type_\n",
    "\n",
    "#         self._column_types = sc\n",
    "#         logger.debug(\"Schema Loaded\")\n",
    "#         logger.debug(\"Opening country index\")\n",
    "#         return Ok(index)\n",
    "\n",
    "#     def convert_fts_results(\n",
    "#         self, hits: tantivy.SearchResult, searcher: tantivy.Searcher\n",
    "#     ) -> pl.DataFrame:\n",
    "#         logger.debug(f\"FTS hits from search: {hits.count}\")  # type: ignore\n",
    "\n",
    "#         scores, gids = zip(\n",
    "#             *[\n",
    "#                 (score, searcher.doc(doc).get_first(self.id_column))\n",
    "#                 for score, doc in hits.hits\n",
    "#             ]\n",
    "#         )\n",
    "\n",
    "#         return (\n",
    "#             pl.LazyFrame(\n",
    "#                 {\"geonameId\": list(gids), \"score\": list(scores)},\n",
    "#                 schema={\"geonameId\": pl.UInt32, \"score\": pl.Float32},\n",
    "#             )\n",
    "#             .sort(\"score\", descending=True, maintain_order=True)\n",
    "#             .collect()\n",
    "#         )\n",
    "\n",
    "#     def search(\n",
    "#         self,\n",
    "#         query: str,\n",
    "#         limit: int = 10,\n",
    "#         include: list[int] | None = None,\n",
    "#         exclude: list[int] | None = None,\n",
    "#     ) -> Result[pl.DataFrame, str]:\n",
    "#         return self.fts_search(\n",
    "#             query,\n",
    "#             limit=limit,\n",
    "#             include=include,\n",
    "#             exclude=exclude,\n",
    "#         )\n",
    "\n",
    "#     def fts_search(\n",
    "#         self,\n",
    "#         query: str,\n",
    "#         limit: int = 10,\n",
    "#         include: list[int] | None = None,\n",
    "#         exclude: list[int] | None = None,\n",
    "#         main_term_query_boost: float = 3.0,\n",
    "#         fuzzy_term_query_boost: float = 2.0,\n",
    "#         max_fuzzy_distance: int = 2,\n",
    "#         phrase: bool = True,\n",
    "#     ) -> Result[pl.DataFrame, str]:\n",
    "#         # Create for list of queries (batch search)\n",
    "#         if phrase:\n",
    "#             query = f\"'{query}'\"\n",
    "#         else:\n",
    "#             query = query.strip(\"\\\"'\")\n",
    "#         query = query.strip()\n",
    "#         index = self.index\n",
    "\n",
    "#         searcher = index.searcher()\n",
    "\n",
    "#         bool_query_list: list[tuple[tantivy.Occur, tantivy.Query]] = []\n",
    "\n",
    "#         # Calculate fuzzy distance based on query length\n",
    "#         fuzzy_distance = min(max(0, len(query) - 2), max_fuzzy_distance)\n",
    "\n",
    "#         if self.main_column in self.columns_not_id:\n",
    "#             main_term_query = tantivy.Query.term_query(\n",
    "#                 index.schema, self.main_column, query\n",
    "#             )\n",
    "#             bool_query_list.append(\n",
    "#                 (\n",
    "#                     tantivy.Occur.Should,\n",
    "#                     tantivy.Query.boost_query(main_term_query, main_term_query_boost),\n",
    "#                 )\n",
    "#             )\n",
    "\n",
    "#             if fuzzy_distance > 0:\n",
    "#                 main_fuzzy_query = tantivy.Query.fuzzy_term_query(\n",
    "#                     index.schema, self.main_column, query, distance=fuzzy_distance\n",
    "#                 )\n",
    "\n",
    "#                 bool_query_list.append(\n",
    "#                     (\n",
    "#                         tantivy.Occur.Should,\n",
    "#                         tantivy.Query.boost_query(\n",
    "#                             main_fuzzy_query, fuzzy_term_query_boost\n",
    "#                         ),\n",
    "#                     )\n",
    "#                 )\n",
    "\n",
    "#             rest_of_query = index.parse_query(\n",
    "#                 query, list(set(self.columns_not_id) - {self.main_column})\n",
    "#             )\n",
    "#             bool_query_list.append((tantivy.Occur.Should, rest_of_query))\n",
    "\n",
    "#         if include:\n",
    "#             bool_query_list.append(\n",
    "#                 (\n",
    "#                     tantivy.Occur.Must,\n",
    "#                     tantivy.Query.term_set_query(index.schema, self.id_column, include),\n",
    "#                 )\n",
    "#             )\n",
    "#         if exclude:\n",
    "#             bool_query_list.append(\n",
    "#                 (\n",
    "#                     tantivy.Occur.MustNot,\n",
    "#                     tantivy.Query.term_set_query(index.schema, self.id_column, exclude),\n",
    "#                 )\n",
    "#             )\n",
    "#         if bool_query_list:\n",
    "#             final_query = tantivy.Query.boolean_query(bool_query_list)\n",
    "\n",
    "#         else:\n",
    "#             final_query: tantivy.Query = index.parse_query(\n",
    "#                 query, default_field_names=self.columns_not_id\n",
    "#             )\n",
    "\n",
    "#         logger.debug(final_query)\n",
    "\n",
    "#         hits: tantivy.SearchResult = searcher.search(final_query, limit=limit)\n",
    "\n",
    "#         if hits.count == 0:  # type: ignore\n",
    "#             if phrase:\n",
    "#                 logger.debug(\"No results found, retrying without phrase search...\")\n",
    "#                 return self.fts_search(\n",
    "#                     query,\n",
    "#                     limit,\n",
    "#                     include,\n",
    "#                     exclude,\n",
    "#                     main_term_query_boost,\n",
    "#                     fuzzy_term_query_boost,\n",
    "#                     max_fuzzy_distance,\n",
    "#                     phrase=False,\n",
    "#                 )\n",
    "#             return Err(\"No results found\")\n",
    "\n",
    "#         return Ok(self.convert_fts_results(hits, searcher))\n",
    "\n",
    "\n",
    "# class HybridIndex:\n",
    "#     def __init__(self, fts_idx: FTSIndex, vidx: VectorIndex):\n",
    "#         self._fts_idx = fts_idx\n",
    "#         self._vidx = vidx\n",
    "\n",
    "#     @property\n",
    "#     def vector_index(self) -> VectorIndex:\n",
    "#         return self._vidx\n",
    "\n",
    "#     @property\n",
    "#     def fts_index(self) -> FTSIndex:\n",
    "#         return self._fts_idx\n",
    "\n",
    "#     def search(\n",
    "#         self,\n",
    "#         query: str,\n",
    "#         limit: int = 10,\n",
    "#         include: list[int] | None = None,\n",
    "#         exclude: list[int] | None = None,\n",
    "#         main_term_query_boost: float = 3.0,\n",
    "#         fuzzy_term_query_boost: float = 2.0,\n",
    "#         max_fuzzy_distance: int = 2,\n",
    "#         phrase: bool = True,\n",
    "#     ) -> Result[pl.DataFrame, str]:\n",
    "#         v_search = self.vector_index.vector_search\n",
    "\n",
    "\n",
    "# country_index = FTSIndex(\"admin0\", con.table(\"admin0_FTS\").pl())\n",
    "# country_index.fts_search(\"An Danmhairg\").unwrap().join(\n",
    "#     con.table(\"admin0\").pl(), \"geonameId\", \"left\"\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
