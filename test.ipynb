{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from typing import Literal\n",
    "import polars.selectors as cs\n",
    "import kuzu as kz\n",
    "from pathlib import Path\n",
    "from typing import Type, Callable\n",
    "from usearch.index import Index, Matches\n",
    "import geocoder\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from numpy.typing import NDArray\n",
    "import duckdb\n",
    "from duckdb import DuckDBPyConnection\n",
    "from time import time\n",
    "import tantivy\n",
    "from result import Result, Ok, Err\n",
    "import json\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x10558b370>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duck_db_path = Path(\"./data/db/duck_db/data.db\")\n",
    "duck_db_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "con = duckdb.connect(database=duck_db_path.as_posix())\n",
    "\n",
    "con.execute(\"SET enable_progress_bar = false;\")\n",
    "con.install_extension(\"spatial\")\n",
    "con.load_extension(\"spatial\")\n",
    "\n",
    "# Set DuckDB optimizations\n",
    "con.execute(\"PRAGMA memory_limit='16GB'\")  # Adjust based on your system\n",
    "con.execute(\"PRAGMA threads=8\")  # Adjust based on your CPU cores\n",
    "con.execute(\"PRAGMA enable_object_cache=true\")  # Improve query caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (29, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>name</th></tr><tr><td>str</td></tr></thead><tbody><tr><td>&quot;__duckpgq_internal&quot;</td></tr><tr><td>&quot;admin0&quot;</td></tr><tr><td>&quot;admin0_FTS&quot;</td></tr><tr><td>&quot;admin0_NODES&quot;</td></tr><tr><td>&quot;admin1&quot;</td></tr><tr><td>&hellip;</td></tr><tr><td>&quot;location_hierarchy&quot;</td></tr><tr><td>&quot;locations_full&quot;</td></tr><tr><td>&quot;shapes&quot;</td></tr><tr><td>&quot;timeZones&quot;</td></tr><tr><td>&quot;unique_ids&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (29, 1)\n",
       "┌────────────────────┐\n",
       "│ name               │\n",
       "│ ---                │\n",
       "│ str                │\n",
       "╞════════════════════╡\n",
       "│ __duckpgq_internal │\n",
       "│ admin0             │\n",
       "│ admin0_FTS         │\n",
       "│ admin0_NODES       │\n",
       "│ admin1             │\n",
       "│ …                  │\n",
       "│ location_hierarchy │\n",
       "│ locations_full     │\n",
       "│ shapes             │\n",
       "│ timeZones          │\n",
       "│ unique_ids         │\n",
       "└────────────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"SHOW TABLES\").pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_FOLDER = Path(\"./sql\")\n",
    "\n",
    "\n",
    "def sql_file(sql_path: Path | str, **kwargs) -> str:\n",
    "    if isinstance(sql_path, str):\n",
    "        sql_path = Path(sql_path)\n",
    "    if not sql_path.exists():\n",
    "        sql_path = SQL_FOLDER / sql_path\n",
    "        if not sql_path.exists():\n",
    "            raise FileNotFoundError(f\"SQL file {sql_path} not found\")\n",
    "    sql = sql_path.read_text()\n",
    "    if kwargs:\n",
    "        sql = sql.format(**kwargs)\n",
    "\n",
    "    # Validate no {kwarg} left in string (regex)\n",
    "    # if uninit_kwargs := re.findall(r\"\\{.*\\}\", sql):\n",
    "    #     raise ValueError(\n",
    "    #         f\"SQL file {sql_path} still has unprocessed kwargs: {list(set(uninit_kwargs))} in:\\n\\n{sql}\"\n",
    "    #     )\n",
    "\n",
    "    return sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'allCountries' already exists\n",
      "Table 'allPostCodes' already exists\n",
      "Table 'admin1CodesASCII' already exists\n",
      "Table 'admin2Codes' already exists\n",
      "Table 'adminCode5' already exists\n",
      "Table 'alternateNamesV2' already exists\n",
      "Table 'countryInfo' already exists\n",
      "Table 'featureCodes' already exists\n",
      "Table 'hierarchy' already exists\n",
      "Table 'iso_languagecodes' already exists\n",
      "Table 'timeZones' already exists\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x10558b370>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GID = \"geonameId\"\n",
    "\n",
    "\n",
    "def table_exists(con: DuckDBPyConnection, table_name: str) -> bool:\n",
    "    return table_name in con.execute(\"SHOW TABLES\").pl()[\"name\"]\n",
    "\n",
    "\n",
    "# Read and load 'allCountries.txt'\n",
    "# Function to read and load other files with different schemas\n",
    "def load_file(\n",
    "    # con: DuckDBPyConnection,\n",
    "    file_path: str,\n",
    "    schema: dict[str, Type[pl.DataType]],\n",
    "    table_name: str,\n",
    "    table_definition: str | None = None,\n",
    "    pipe: Callable[[pl.LazyFrame], pl.LazyFrame] | None = None,\n",
    "    has_header: bool = False,\n",
    "    skip_rows: int = 0,\n",
    "    overwrite: bool = False,\n",
    "    extra_expr: pl.Expr | None = None,\n",
    "):\n",
    "    if table_exists(con, table_name):\n",
    "        print(f\"Table '{table_name}' already exists\")\n",
    "        if not overwrite:\n",
    "            return\n",
    "        print(f\"Overwriting table '{table_name}'\")\n",
    "        con.execute(f\"DROP TABLE {table_name} CASCADE\")\n",
    "        print(f\"Table '{table_name}' dropped\")\n",
    "    time_start = time()\n",
    "    load = con.begin()\n",
    "    try:\n",
    "        print(f\"Loading '{file_path}'...\")\n",
    "        # Time scan\n",
    "        time_scan = time()\n",
    "        q = pl.scan_csv(\n",
    "            file_path,\n",
    "            separator=\"\\t\",\n",
    "            has_header=has_header,\n",
    "            schema=schema,\n",
    "            skip_rows=skip_rows,\n",
    "        )\n",
    "        q = q.with_columns(\n",
    "            pl.col(pl.Utf8).str.strip_chars().str.strip_chars(\"\\\"':\").str.strip_chars()\n",
    "        )\n",
    "        if extra_expr is not None:\n",
    "            q = q.with_columns(extra_expr)\n",
    "        if pipe is not None:\n",
    "            q = q.pipe(pipe)\n",
    "        if GID in schema:\n",
    "            q = q.sort(GID, nulls_last=True)\n",
    "        print(f\"Scan time: {time() - time_scan:.6f}s\")\n",
    "\n",
    "        q = q.with_columns(cs.by_dtype(pl.String).str.strip_chars().replace(\"\", None))\n",
    "\n",
    "        # Time collect\n",
    "        time_collect = time()\n",
    "        df = q.collect()\n",
    "        print(f\"Collect time: {time() - time_collect:.6f}s\")\n",
    "\n",
    "        # Time write\n",
    "        time_write = time()\n",
    "        save_path = Path(f\"./data/processed/geonames/{table_name}.parquet\")\n",
    "        save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df.write_parquet(save_path.as_posix())\n",
    "        print(f\"Write time: {time() - time_write:.6f}s\")\n",
    "\n",
    "        # Time create\n",
    "        time_create = time()\n",
    "        # Create table with predefined schema if provided\n",
    "        time_create = time()\n",
    "        if table_definition:\n",
    "            # Create the table with specified schema\n",
    "            load.execute(table_definition)\n",
    "            load.from_arrow(df.to_arrow()).insert_into(table_name)\n",
    "        else:\n",
    "            # Use automatic schema derivation (your current approach)\n",
    "            load.from_arrow(df.to_arrow()).create(table_name)\n",
    "\n",
    "        print(f\"Create time: {time() - time_create:.6f}s\")\n",
    "\n",
    "        time_commit = time()\n",
    "        load.commit()\n",
    "        print(f\"Commit time: {time() - time_commit:.6f}s\")\n",
    "        analyze_time = time()\n",
    "        con.execute(\"VACUUM ANALYZE;\")\n",
    "        print(f\"Analyze time: {time() - analyze_time:.6f}s\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading '{file_path}'\")\n",
    "        print(e.with_traceback(None))\n",
    "        # Time rollback\n",
    "        time_rollback = time()\n",
    "        load.rollback()\n",
    "        print(f\"Rollback time: {time() - time_rollback:.6f}s\")\n",
    "        raise e\n",
    "    finally:\n",
    "        print(f\"Total time: {time() - time_start:.6f}s\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def drop_duplicates(df: pl.LazyFrame) -> pl.LazyFrame:\n",
    "    cols = [\n",
    "        \"name\",\n",
    "        \"asciiname\",\n",
    "        \"feature_class\",\n",
    "        \"feature_code\",\n",
    "        \"admin0_code\",\n",
    "        \"admin1_code\",\n",
    "        \"admin2_code\",\n",
    "        \"admin3_code\",\n",
    "        \"admin4_code\",\n",
    "        \"timezone\",\n",
    "    ]\n",
    "    return (\n",
    "        df.sort(\"modification_date\", descending=True)\n",
    "        .unique(cols, keep=\"first\")\n",
    "        .filter(~pl.all_horizontal(pl.col(cols).is_null()))\n",
    "        .sort(\"geonameId\")\n",
    "    )\n",
    "\n",
    "\n",
    "schema_all_countries = {\n",
    "    GID: pl.UInt32,\n",
    "    \"name\": pl.Utf8,\n",
    "    \"asciiname\": pl.Utf8,\n",
    "    \"alternatenames\": pl.Utf8,\n",
    "    \"latitude\": pl.Float32,\n",
    "    \"longitude\": pl.Float32,\n",
    "    \"feature_class\": pl.Categorical,\n",
    "    \"feature_code\": pl.Categorical,\n",
    "    \"admin0_code\": pl.Categorical,\n",
    "    \"cc2\": pl.Utf8,\n",
    "    \"admin1_code\": pl.Utf8,\n",
    "    \"admin2_code\": pl.Utf8,\n",
    "    \"admin3_code\": pl.Utf8,\n",
    "    \"admin4_code\": pl.Utf8,\n",
    "    \"population\": pl.Int64,\n",
    "    \"elevation\": pl.Int32,\n",
    "    \"dem\": pl.Int32,\n",
    "    \"timezone\": pl.Categorical,\n",
    "    \"modification_date\": pl.Date,\n",
    "}\n",
    "\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/allCountries.txt\",\n",
    "    schema_all_countries,\n",
    "    \"allCountries\",\n",
    "    table_definition=sql_file(\"create_table_allCountries.sql\"),\n",
    "    pipe=drop_duplicates,\n",
    ")\n",
    "\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/allCountriesPostCode.txt\",\n",
    "    {\n",
    "        \"admin_code0\": pl.Categorical,\n",
    "        \"postal_code\": pl.Utf8,\n",
    "        \"place_name\": pl.Utf8,\n",
    "        \"admin_name1\": pl.Utf8,\n",
    "        \"admin_code1\": pl.Utf8,\n",
    "        \"admin_name2\": pl.Utf8,\n",
    "        \"admin_code2\": pl.Utf8,\n",
    "        \"admin_name3\": pl.Utf8,\n",
    "        \"admin_code3\": pl.Utf8,\n",
    "        \"latitude\": pl.Float32,\n",
    "        \"longitude\": pl.Float32,\n",
    "        \"accuracy\": pl.Int32,\n",
    "    },\n",
    "    \"allPostCodes\",\n",
    ")\n",
    "\n",
    "\n",
    "# Load other files with respective schemas\n",
    "load_file(\n",
    "    \"./data/raw/geonames/admin1CodesASCII.txt\",\n",
    "    {\n",
    "        \"code\": pl.Utf8,\n",
    "        \"name\": pl.Utf8,\n",
    "        \"name_ascii\": pl.Utf8,\n",
    "        GID: pl.UInt32,\n",
    "    },\n",
    "    \"admin1CodesASCII\",\n",
    "    table_definition=sql_file(\"create_table_admin1CodesASCII.sql\"),\n",
    ")\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/admin2Codes.txt\",\n",
    "    {\n",
    "        \"code\": pl.Utf8,\n",
    "        \"name\": pl.Utf8,\n",
    "        \"asciiname\": pl.Utf8,\n",
    "        GID: pl.UInt32,\n",
    "    },\n",
    "    \"admin2Codes\",\n",
    "    table_definition=sql_file(\"create_table_admin2Codes.sql\"),\n",
    ")\n",
    "\n",
    "\n",
    "def drop_invalid_gids(df: pl.LazyFrame, con: DuckDBPyConnection) -> pl.LazyFrame:\n",
    "    ids = con.execute(\"SELECT geonameId FROM allCountries\").pl().unique().to_series()\n",
    "    return df.filter(pl.col(GID).is_in(ids))\n",
    "\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/adminCode5.txt\",\n",
    "    {\n",
    "        GID: pl.UInt32,\n",
    "        \"adm5code\": pl.Utf8,\n",
    "    },\n",
    "    \"adminCode5\",\n",
    "    table_definition=sql_file(\"create_table_adminCode5.sql\"),\n",
    "    pipe=partial(drop_invalid_gids, con=con),\n",
    ")\n",
    "\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/alternateNamesV2.txt\",\n",
    "    {\n",
    "        \"alternateNameId\": pl.Int32,\n",
    "        GID: pl.UInt32,\n",
    "        \"isolanguage\": pl.Utf8,\n",
    "        \"alternate_name\": pl.Utf8,\n",
    "        \"isPreferredName\": pl.Int8,\n",
    "        \"isShortName\": pl.Int8,\n",
    "        \"isColloquial\": pl.Int8,\n",
    "        \"isHistoric\": pl.Int8,\n",
    "        \"from\": pl.Utf8,\n",
    "        \"to\": pl.Utf8,\n",
    "    },\n",
    "    \"alternateNamesV2\",\n",
    "    table_definition=sql_file(\"create_table_alternateNamesV2.sql\"),\n",
    "    extra_expr=cs.by_dtype(pl.Int8).cast(pl.Boolean).fill_null(False),\n",
    "    pipe=partial(drop_invalid_gids, con=con),\n",
    ")\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/countryInfo.txt\",\n",
    "    {\n",
    "        \"ISO\": pl.Categorical,\n",
    "        \"ISO3\": pl.Categorical,\n",
    "        \"ISO_Numeric\": pl.Int32,\n",
    "        \"fips\": pl.Categorical,\n",
    "        \"Country\": pl.Utf8,\n",
    "        \"Capital\": pl.Utf8,\n",
    "        \"Area\": pl.Float32,\n",
    "        \"Population\": pl.Int32,\n",
    "        \"Continent\": pl.Categorical,\n",
    "        \"tld\": pl.Utf8,\n",
    "        \"CurrencyCode\": pl.Utf8,\n",
    "        \"CurrencyName\": pl.Utf8,\n",
    "        \"Phone\": pl.Utf8,\n",
    "        \"Postal_Code_Format\": pl.Utf8,\n",
    "        \"Postal_Code_Regex\": pl.Utf8,\n",
    "        \"Languages\": pl.Utf8,\n",
    "        GID: pl.UInt32,\n",
    "        \"neighbours\": pl.Utf8,\n",
    "        \"EquivalentFipsCode\": pl.Utf8,\n",
    "    },\n",
    "    \"countryInfo\",\n",
    "    table_definition=sql_file(\"create_table_countryInfo.sql\"),\n",
    "    skip_rows=51,\n",
    ")\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/featureCodes_en.txt\",\n",
    "    {\n",
    "        \"code\": pl.Categorical,\n",
    "        \"name\": pl.Utf8,\n",
    "        \"description\": pl.Utf8,\n",
    "    },\n",
    "    \"featureCodes\",\n",
    "    table_definition=sql_file(\"create_table_featureCodes.sql\"),\n",
    ")\n",
    "\n",
    "\n",
    "def remove_old_ids(df: pl.LazyFrame, con: DuckDBPyConnection) -> pl.LazyFrame:\n",
    "    ids = con.execute(\"SELECT geonameId FROM allCountries\").pl().unique().to_series()\n",
    "    return (\n",
    "        df.filter(pl.col(\"parentId\").is_in(ids) & pl.col(\"childId\").is_in(ids))\n",
    "        .with_columns(\n",
    "            pl.when(pl.col(\"type\").str.contains(\"adm\", literal=True))\n",
    "            .then(pl.col(\"type\").str.to_uppercase())\n",
    "            .otherwise(pl.col(\"type\"))\n",
    "        )\n",
    "        .unique([\"parentId\", \"childId\"])\n",
    "    )\n",
    "\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/hierarchy.txt\",\n",
    "    {\n",
    "        \"parentId\": pl.UInt32,\n",
    "        \"childId\": pl.UInt32,\n",
    "        \"type\": pl.Utf8,\n",
    "    },\n",
    "    \"hierarchy\",\n",
    "    table_definition=sql_file(\"create_table_hierarchy.sql\"),\n",
    "    pipe=partial(remove_old_ids, con=con),\n",
    ")\n",
    "con.execute(sql_file(\"create_table_unique_ids.sql\"))\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/iso-languagecodes.txt\",\n",
    "    {\n",
    "        \"ISO_639_3\": pl.Utf8,\n",
    "        \"ISO_639_2\": pl.Utf8,\n",
    "        \"ISO_639_1\": pl.Utf8,\n",
    "        \"Language_Name\": pl.Utf8,\n",
    "    },\n",
    "    \"iso_languagecodes\",\n",
    "    table_definition=sql_file(\"create_table_iso_languagecodes.sql\"),\n",
    ")\n",
    "\n",
    "\n",
    "load_file(\n",
    "    \"./data/raw/geonames/timeZones.txt\",\n",
    "    {\n",
    "        \"CountryCode\": pl.Utf8,\n",
    "        \"TimeZoneId\": pl.Utf8,\n",
    "        \"GMT_offset_1_Jan_2024\": pl.Float32,\n",
    "        \"DST_offset_1_Jul_2024\": pl.Float32,\n",
    "        \"rawOffset\": pl.Float32,\n",
    "    },\n",
    "    \"timeZones\",\n",
    "    table_definition=sql_file(\"create_table_timeZones.sql\"),\n",
    "    skip_rows=1,\n",
    ")\n",
    "# # Ignore loading the geo data for now\n",
    "if not table_exists(con, \"shapes\"):\n",
    "    con.execute(sql_file(\"create_table_shapes.sql\"))\n",
    "    print(\"Table 'shapes' created\")\n",
    "\n",
    "# # File is corupted atm\n",
    "# load_file(\n",
    "#     \"./data/raw/geonames/userTags.txt\",\n",
    "#     {\n",
    "#         GID: pl.Int32,\n",
    "#         \"tag\": pl.Utf8,\n",
    "#     },\n",
    "#     \"userTags\",\n",
    "# )\n",
    "con.execute(sql_file(\"create_table_equivalent.sql\"))\n",
    "con.execute(sql_file(\"create_view_cities.sql\"))\n",
    "con.execute(sql_file(\"create_view_locations_full.sql\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (12_320_725, 20)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>asciiname</th><th>feature_class</th><th>feature_code</th><th>feature_name</th><th>feature_description</th><th>admin0_code</th><th>country_name</th><th>admin1_code</th><th>admin1_name</th><th>admin2_code</th><th>admin2_name</th><th>admin3_code</th><th>admin4_code</th><th>latitude</th><th>longitude</th><th>population</th><th>timezone</th><th>timezone_offset</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>i64</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>412252</td><td>&quot;Mbata&quot;</td><td>&quot;Mbata&quot;</td><td>&quot;P&quot;</td><td>&quot;PPL&quot;</td><td>&quot;populated place&quot;</td><td>&quot;a city, town, village, or othe…</td><td>&quot;CF&quot;</td><td>&quot;Central African Republic&quot;</td><td>&quot;11&quot;</td><td>&quot;Ouaka&quot;</td><td>&quot;7732062&quot;</td><td>&quot;Bambari&quot;</td><td>null</td><td>null</td><td>5.74742</td><td>20.625219</td><td>0</td><td>&quot;Africa/Bangui&quot;</td><td>1.0</td></tr><tr><td>412253</td><td>&quot;Mbisiyanba&quot;</td><td>&quot;Mbisiyanba&quot;</td><td>&quot;P&quot;</td><td>&quot;PPL&quot;</td><td>&quot;populated place&quot;</td><td>&quot;a city, town, village, or othe…</td><td>&quot;CF&quot;</td><td>&quot;Central African Republic&quot;</td><td>&quot;11&quot;</td><td>&quot;Ouaka&quot;</td><td>&quot;7732062&quot;</td><td>&quot;Bambari&quot;</td><td>null</td><td>null</td><td>5.74301</td><td>20.621059</td><td>0</td><td>&quot;Africa/Bangui&quot;</td><td>1.0</td></tr><tr><td>412254</td><td>&quot;Boroto&quot;</td><td>&quot;Boroto&quot;</td><td>&quot;P&quot;</td><td>&quot;PPL&quot;</td><td>&quot;populated place&quot;</td><td>&quot;a city, town, village, or othe…</td><td>&quot;CF&quot;</td><td>&quot;Central African Republic&quot;</td><td>&quot;11&quot;</td><td>&quot;Ouaka&quot;</td><td>&quot;7732062&quot;</td><td>&quot;Bambari&quot;</td><td>null</td><td>null</td><td>5.73741</td><td>20.67658</td><td>0</td><td>&quot;Africa/Bangui&quot;</td><td>1.0</td></tr><tr><td>412362</td><td>&quot;Yanbo&quot;</td><td>&quot;Yanbo&quot;</td><td>&quot;P&quot;</td><td>&quot;PPL&quot;</td><td>&quot;populated place&quot;</td><td>&quot;a city, town, village, or othe…</td><td>&quot;CF&quot;</td><td>&quot;Central African Republic&quot;</td><td>&quot;11&quot;</td><td>&quot;Ouaka&quot;</td><td>&quot;7732062&quot;</td><td>&quot;Bambari&quot;</td><td>null</td><td>null</td><td>5.73288</td><td>20.678089</td><td>0</td><td>&quot;Africa/Bangui&quot;</td><td>1.0</td></tr><tr><td>412363</td><td>&quot;Dago&quot;</td><td>&quot;Dago&quot;</td><td>&quot;P&quot;</td><td>&quot;PPL&quot;</td><td>&quot;populated place&quot;</td><td>&quot;a city, town, village, or othe…</td><td>&quot;CF&quot;</td><td>&quot;Central African Republic&quot;</td><td>&quot;11&quot;</td><td>&quot;Ouaka&quot;</td><td>&quot;7732062&quot;</td><td>&quot;Bambari&quot;</td><td>null</td><td>null</td><td>5.73452</td><td>20.603849</td><td>0</td><td>&quot;Africa/Bangui&quot;</td><td>1.0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>13106144</td><td>&quot;Gora Tsagan-Chulut-Ula&quot;</td><td>&quot;Gora Tsagan-Chulut-Ula&quot;</td><td>&quot;T&quot;</td><td>&quot;MT&quot;</td><td>&quot;mountain&quot;</td><td>&quot;an elevation standing high abo…</td><td>&quot;MN&quot;</td><td>&quot;Mongolia&quot;</td><td>&quot;93&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>49.740131</td><td>113.141083</td><td>0</td><td>null</td><td>null</td></tr><tr><td>13106155</td><td>&quot;Gora Tosoktoyskiy Mayak&quot;</td><td>&quot;Gora Tosoktoyskiy Mayak&quot;</td><td>&quot;T&quot;</td><td>&quot;MT&quot;</td><td>&quot;mountain&quot;</td><td>&quot;an elevation standing high abo…</td><td>&quot;MN&quot;</td><td>&quot;Mongolia&quot;</td><td>&quot;93&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>49.836842</td><td>113.217407</td><td>0</td><td>null</td><td>null</td></tr><tr><td>13106160</td><td>&quot;Gora Kharin-Narasunskiy Mayak&quot;</td><td>&quot;Gora Kharin-Narasunskiy Mayak&quot;</td><td>&quot;T&quot;</td><td>&quot;MT&quot;</td><td>&quot;mountain&quot;</td><td>&quot;an elevation standing high abo…</td><td>&quot;MN&quot;</td><td>&quot;Mongolia&quot;</td><td>&quot;93&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>49.972431</td><td>113.485489</td><td>0</td><td>null</td><td>null</td></tr><tr><td>13106171</td><td>&quot;Gora Ukha&quot;</td><td>&quot;Gora Ukha&quot;</td><td>&quot;T&quot;</td><td>&quot;MT&quot;</td><td>&quot;mountain&quot;</td><td>&quot;an elevation standing high abo…</td><td>&quot;MN&quot;</td><td>&quot;Mongolia&quot;</td><td>&quot;93&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>49.889069</td><td>113.342201</td><td>0</td><td>null</td><td>null</td></tr><tr><td>6620255</td><td>&quot;Center&quot;</td><td>&quot;Center&quot;</td><td>&quot;H&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>39.876019</td><td>14.37012</td><td>0</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (12_320_725, 20)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ geonameId ┆ name      ┆ asciiname ┆ feature_c ┆ … ┆ longitude ┆ populatio ┆ timezone  ┆ timezone │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ lass      ┆   ┆ ---       ┆ n         ┆ ---       ┆ _offset  │\n",
       "│ i32       ┆ str       ┆ str       ┆ ---       ┆   ┆ f64       ┆ ---       ┆ str       ┆ ---      │\n",
       "│           ┆           ┆           ┆ str       ┆   ┆           ┆ i64       ┆           ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 412252    ┆ Mbata     ┆ Mbata     ┆ P         ┆ … ┆ 20.625219 ┆ 0         ┆ Africa/Ba ┆ 1.0      │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ ngui      ┆          │\n",
       "│ 412253    ┆ Mbisiyanb ┆ Mbisiyanb ┆ P         ┆ … ┆ 20.621059 ┆ 0         ┆ Africa/Ba ┆ 1.0      │\n",
       "│           ┆ a         ┆ a         ┆           ┆   ┆           ┆           ┆ ngui      ┆          │\n",
       "│ 412254    ┆ Boroto    ┆ Boroto    ┆ P         ┆ … ┆ 20.67658  ┆ 0         ┆ Africa/Ba ┆ 1.0      │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ ngui      ┆          │\n",
       "│ 412362    ┆ Yanbo     ┆ Yanbo     ┆ P         ┆ … ┆ 20.678089 ┆ 0         ┆ Africa/Ba ┆ 1.0      │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ ngui      ┆          │\n",
       "│ 412363    ┆ Dago      ┆ Dago      ┆ P         ┆ … ┆ 20.603849 ┆ 0         ┆ Africa/Ba ┆ 1.0      │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ ngui      ┆          │\n",
       "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
       "│ 13106144  ┆ Gora Tsag ┆ Gora Tsag ┆ T         ┆ … ┆ 113.14108 ┆ 0         ┆ null      ┆ null     │\n",
       "│           ┆ an-Chulut ┆ an-Chulut ┆           ┆   ┆ 3         ┆           ┆           ┆          │\n",
       "│           ┆ -Ula      ┆ -Ula      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 13106155  ┆ Gora Toso ┆ Gora Toso ┆ T         ┆ … ┆ 113.21740 ┆ 0         ┆ null      ┆ null     │\n",
       "│           ┆ ktoyskiy  ┆ ktoyskiy  ┆           ┆   ┆ 7         ┆           ┆           ┆          │\n",
       "│           ┆ Mayak     ┆ Mayak     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 13106160  ┆ Gora Khar ┆ Gora Khar ┆ T         ┆ … ┆ 113.48548 ┆ 0         ┆ null      ┆ null     │\n",
       "│           ┆ in-Narasu ┆ in-Narasu ┆           ┆   ┆ 9         ┆           ┆           ┆          │\n",
       "│           ┆ nskiy     ┆ nskiy     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Mayak     ┆ Mayak     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 13106171  ┆ Gora Ukha ┆ Gora Ukha ┆ T         ┆ … ┆ 113.34220 ┆ 0         ┆ null      ┆ null     │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 1         ┆           ┆           ┆          │\n",
       "│ 6620255   ┆ Center    ┆ Center    ┆ H         ┆ … ┆ 14.37012  ┆ 0         ┆ null      ┆ null     │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.table(\"locations_full\").pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = con.table(\"countryInfo\").pl().join(con.table(\"allCountries\").pl(), on=\"geonameId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (8, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>feature_code</th><th>count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;PCLI&quot;</td><td>192</td></tr><tr><td>&quot;PCLD&quot;</td><td>35</td></tr><tr><td>&quot;PCLIX&quot;</td><td>7</td></tr><tr><td>&quot;PCLS&quot;</td><td>5</td></tr><tr><td>&quot;TERR&quot;</td><td>4</td></tr><tr><td>&quot;PCLF&quot;</td><td>3</td></tr><tr><td>&quot;PCL&quot;</td><td>3</td></tr><tr><td>&quot;PCLH&quot;</td><td>2</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (8, 2)\n",
       "┌──────────────┬───────┐\n",
       "│ feature_code ┆ count │\n",
       "│ ---          ┆ ---   │\n",
       "│ str          ┆ u32   │\n",
       "╞══════════════╪═══════╡\n",
       "│ PCLI         ┆ 192   │\n",
       "│ PCLD         ┆ 35    │\n",
       "│ PCLIX        ┆ 7     │\n",
       "│ PCLS         ┆ 5     │\n",
       "│ TERR         ┆ 4     │\n",
       "│ PCLF         ┆ 3     │\n",
       "│ PCL          ┆ 3     │\n",
       "│ PCLH         ┆ 2     │\n",
       "└──────────────┴───────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.select(pl.col(\"feature_code\").value_counts(sort=True)).unnest(\"feature_code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 37)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ISO</th><th>ISO3</th><th>ISO_Numeric</th><th>fips</th><th>Country</th><th>Capital</th><th>Area</th><th>Population</th><th>Continent</th><th>tld</th><th>CurrencyCode</th><th>CurrencyName</th><th>Phone</th><th>Postal_Code_Format</th><th>Postal_Code_Regex</th><th>Languages</th><th>geonameId</th><th>neighbours</th><th>EquivalentFipsCode</th><th>name</th><th>asciiname</th><th>alternatenames</th><th>latitude</th><th>longitude</th><th>feature_class</th><th>feature_code</th><th>admin0_code</th><th>cc2</th><th>admin1_code</th><th>admin2_code</th><th>admin3_code</th><th>admin4_code</th><th>population</th><th>elevation</th><th>dem</th><th>timezone</th><th>modification_date</th></tr><tr><td>str</td><td>str</td><td>i32</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>i32</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i32</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>i32</td><td>i32</td><td>str</td><td>date</td></tr></thead><tbody><tr><td>&quot;AN&quot;</td><td>&quot;ANT&quot;</td><td>530</td><td>&quot;NT&quot;</td><td>&quot;Netherlands Antilles&quot;</td><td>&quot;Willemstad&quot;</td><td>960.0</td><td>300000</td><td>&quot;NA&quot;</td><td>&quot;.an&quot;</td><td>&quot;ANG&quot;</td><td>&quot;Guilder&quot;</td><td>&quot;599&quot;</td><td>null</td><td>null</td><td>&quot;nl-AN,en,es&quot;</td><td>8505032</td><td>&quot;GP&quot;</td><td>null</td><td>&quot;Netherlands Antilles&quot;</td><td>&quot;Netherlands Antilles&quot;</td><td>&quot;Antia Hulandes,Antias Hulandes…</td><td>12.11721</td><td>-68.91964</td><td>&quot;A&quot;</td><td>&quot;PCLH&quot;</td><td>&quot;AN&quot;</td><td>null</td><td>&quot;00&quot;</td><td>null</td><td>null</td><td>null</td><td>300000</td><td>null</td><td>1</td><td>&quot;America/Curacao&quot;</td><td>2021-08-16</td></tr><tr><td>&quot;CS&quot;</td><td>&quot;SCG&quot;</td><td>891</td><td>&quot;YI&quot;</td><td>&quot;Serbia and Montenegro&quot;</td><td>&quot;Belgrade&quot;</td><td>102350.0</td><td>10829175</td><td>&quot;EU&quot;</td><td>&quot;.cs&quot;</td><td>&quot;RSD&quot;</td><td>&quot;Dinar&quot;</td><td>&quot;381&quot;</td><td>&quot;#####&quot;</td><td>&quot;^(\\d{5})$&quot;</td><td>&quot;cu,hu,sq,sr&quot;</td><td>8505033</td><td>&quot;AL,HU,MK,RO,HR,BA,BG&quot;</td><td>null</td><td>&quot;Serbia and Montenegro&quot;</td><td>&quot;Serbia and Montenegro&quot;</td><td>&quot;Bundesrepublik Jugoslawien,CS,…</td><td>44.817402</td><td>20.463409</td><td>&quot;A&quot;</td><td>&quot;PCLH&quot;</td><td>&quot;CS&quot;</td><td>null</td><td>&quot;00&quot;</td><td>null</td><td>null</td><td>null</td><td>10829175</td><td>null</td><td>110</td><td>&quot;Europe/Belgrade&quot;</td><td>2023-12-04</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 37)\n",
       "┌─────┬──────┬─────────────┬──────┬───┬───────────┬─────┬─────────────────┬───────────────────┐\n",
       "│ ISO ┆ ISO3 ┆ ISO_Numeric ┆ fips ┆ … ┆ elevation ┆ dem ┆ timezone        ┆ modification_date │\n",
       "│ --- ┆ ---  ┆ ---         ┆ ---  ┆   ┆ ---       ┆ --- ┆ ---             ┆ ---               │\n",
       "│ str ┆ str  ┆ i32         ┆ str  ┆   ┆ i32       ┆ i32 ┆ str             ┆ date              │\n",
       "╞═════╪══════╪═════════════╪══════╪═══╪═══════════╪═════╪═════════════════╪═══════════════════╡\n",
       "│ AN  ┆ ANT  ┆ 530         ┆ NT   ┆ … ┆ null      ┆ 1   ┆ America/Curacao ┆ 2021-08-16        │\n",
       "│ CS  ┆ SCG  ┆ 891         ┆ YI   ┆ … ┆ null      ┆ 110 ┆ Europe/Belgrade ┆ 2023-12-04        │\n",
       "└─────┴──────┴─────────────┴──────┴───┴───────────┴─────┴─────────────────┴───────────────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.filter(feature_code=\"PCLH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x10558b370>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create country table\n",
    "con.execute(sql_file(\"create_table_equivalent.sql\")).pl()\n",
    "con.execute(sql_file(\"create_table_admin0.sql\")).execute(\"\"\"PRAGMA create_fts_index(\n",
    "    admin0,\n",
    "    geonameId,\n",
    "    name,\n",
    "    asciiname,\n",
    "    official_name,\n",
    "    alternatenames,\n",
    "    admin0_code,\n",
    "    ISO3,\n",
    "    ISO_Numeric,\n",
    "    fips,\n",
    "    stemmer = 'none',\n",
    "    stopwords = 'none',\n",
    "    ignore = '(\\\\.|[^a-z0-9])+',\n",
    "    overwrite = 1\n",
    ");\"\"\")\n",
    "\n",
    "con.execute(sql_file(\"create_view_*_NODES.sql\", table=\"admin0\"))\n",
    "\n",
    "con.execute(sql_file(\"create_view_*_FTS.sql\", table=\"admin0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening index at 'data/indexes/fts/admin0'\n",
      "Schema Loaded\n",
      "Opening country index\n",
      "Query(BooleanQuery { subqueries: [(Should, Boost(query=TermQuery(Term(field=1, type=Str, \"'An Danmhairg'\")), boost=3)), (Should, Boost(query=FuzzyTermQuery { term: Term(field=1, type=Str, \"'An Danmhairg'\"), distance: 2, transposition_cost_one: true, prefix: false }, boost=2)), (Should, BooleanQuery { subqueries: [(Should, PhraseQuery { field: Field(3), phrase_terms: [(0, Term(field=3, type=Str, \"an\")), (1, Term(field=3, type=Str, \"danmhairg\"))], slop: 0 }), (Should, PhraseQuery { field: Field(4), phrase_terms: [(0, Term(field=4, type=Str, \"an\")), (1, Term(field=4, type=Str, \"danmhairg\"))], slop: 0 }), (Should, PhraseQuery { field: Field(2), phrase_terms: [(0, Term(field=2, type=Str, \"an\")), (1, Term(field=2, type=Str, \"danmhairg\"))], slop: 0 }), (Should, PhraseQuery { field: Field(5), phrase_terms: [(0, Term(field=5, type=Str, \"an\")), (1, Term(field=5, type=Str, \"danmhairg\"))], slop: 0 })] })] })\n",
      "FTS hits from search: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 16)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>score</th><th>name</th><th>asciiname</th><th>admin0_code</th><th>cc2</th><th>ISO</th><th>ISO3</th><th>ISO_Numeric</th><th>official_name</th><th>fips</th><th>Population</th><th>Area</th><th>alternatenames</th><th>feature_class</th><th>feature_code</th></tr><tr><td>u32</td><td>f32</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i32</td><td>str</td><td>str</td><td>i32</td><td>f64</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>2623032</td><td>8.848571</td><td>&quot;Kingdom of Denmark&quot;</td><td>&quot;Kingdom of Denmark&quot;</td><td>&quot;DK&quot;</td><td>null</td><td>&quot;DK&quot;</td><td>&quot;DNK&quot;</td><td>208</td><td>&quot;Denmark&quot;</td><td>&quot;DA&quot;</td><td>5797446</td><td>43094.0</td><td>&quot;An Danmhairg,DK,Daeaenmark,Dae…</td><td>&quot;A&quot;</td><td>&quot;PCLI&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 16)\n",
       "┌───────────┬──────────┬────────────┬────────────┬───┬─────────┬───────────┬───────────┬───────────┐\n",
       "│ geonameId ┆ score    ┆ name       ┆ asciiname  ┆ … ┆ Area    ┆ alternate ┆ feature_c ┆ feature_c │\n",
       "│ ---       ┆ ---      ┆ ---        ┆ ---        ┆   ┆ ---     ┆ names     ┆ lass      ┆ ode       │\n",
       "│ u32       ┆ f32      ┆ str        ┆ str        ┆   ┆ f64     ┆ ---       ┆ ---       ┆ ---       │\n",
       "│           ┆          ┆            ┆            ┆   ┆         ┆ str       ┆ str       ┆ str       │\n",
       "╞═══════════╪══════════╪════════════╪════════════╪═══╪═════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 2623032   ┆ 8.848571 ┆ Kingdom of ┆ Kingdom of ┆ … ┆ 43094.0 ┆ An Danmha ┆ A         ┆ PCLI      │\n",
       "│           ┆          ┆ Denmark    ┆ Denmark    ┆   ┆         ┆ irg,DK,Da ┆           ┆           │\n",
       "│           ┆          ┆            ┆            ┆   ┆         ┆ eaenmark, ┆           ┆           │\n",
       "│           ┆          ┆            ┆            ┆   ┆         ┆ Dae…      ┆           ┆           │\n",
       "└───────────┴──────────┴────────────┴────────────┴───┴─────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if (path := Path(\"./data/processed/latlon.index\")).exists():\n",
    "#     print(\"Loading index...\")\n",
    "#     index = Index.restore(path, view=True) or raise ValueError(\"Failed to load index\")\n",
    "# else:\n",
    "#     print(\"Creating index...\")\n",
    "#     coordinates = df.select([\"latitude\", \"longitude\"]).to_numpy(order=\"c\")\n",
    "#     labels = df[\"geonameid\"].to_numpy()\n",
    "#     index: Index = Index(ndim=2, metric=\"haversine\", dtype=\"f32\")\n",
    "#     index.add(keys=labels, vectors=coordinates, log=True)\n",
    "#     index.save(path)\n",
    "\n",
    "\n",
    "class VectorIndex:\n",
    "    default_index_path = Path(\"./data/indexes/vector\")\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        index_name: str,\n",
    "        data: pl.DataFrame | None = None,\n",
    "        id_column: str = \"geonameId\",\n",
    "        main_column: str = \"vectors\",\n",
    "        metric: str = \"L2\",\n",
    "        embedder: SentenceTransformer | None = None,\n",
    "    ):\n",
    "        self._index_path = self.default_index_path / f\"{index_name}.index\"\n",
    "        self._id_column = id_column\n",
    "        self._main_column = main_column\n",
    "        self._metric = metric\n",
    "        index = self.get_or_build_index(data, metric)\n",
    "        if isinstance(index, Err):\n",
    "            print(\n",
    "                f\"Index does not exist at '{self.index_path}', build index with 'build_index' method.\"\n",
    "            )\n",
    "            self._index = None  # type: ignore\n",
    "        else:\n",
    "            self._index: Index = index.ok_value\n",
    "\n",
    "    @property\n",
    "    def index(self) -> Index:\n",
    "        return self._index\n",
    "\n",
    "    @property\n",
    "    def id_column(self) -> str:\n",
    "        return self._id_column\n",
    "\n",
    "    @property\n",
    "    def main_column(self) -> str:\n",
    "        return self._main_column\n",
    "\n",
    "    @property\n",
    "    def index_path(self) -> Path:\n",
    "        return self._index_path\n",
    "\n",
    "    @property\n",
    "    def ndims(self) -> int:\n",
    "        return self._ndims\n",
    "\n",
    "    @property\n",
    "    def metric(self) -> str:\n",
    "        return self._metric\n",
    "\n",
    "    def _build_index(\n",
    "        self,\n",
    "        df: pl.DataFrame,\n",
    "        metric: str = \"L2\",  # TODO: Metric like\n",
    "    ) -> Result[Index, str]:\n",
    "        \"\"\"Data passed should be an Id and a vector.\"\"\"\n",
    "        print(\"Creating index...\")\n",
    "        vectors = df[self.main_column].to_numpy()\n",
    "        labels = df[self.id_column].to_numpy()\n",
    "        ndims = vectors.shape[1]  # Find n dims\n",
    "        index: Index = Index(ndim=ndims, metric=metric, dtype=\"f32\")\n",
    "        index.add(keys=labels, vectors=vectors, log=True)\n",
    "        index.save(self.index_path)\n",
    "        return Ok(index)\n",
    "\n",
    "    def get_index(self) -> Result[Index, str]:\n",
    "        if (path := self.index_path).exists():\n",
    "            print(f\"Opening index at '{self.index_path}'\")\n",
    "            index = Index.restore(path, view=True)\n",
    "            if index is not None:\n",
    "                return Ok(index)\n",
    "        return Err(f\"Index does not exist at '{self.index_path}'\")\n",
    "\n",
    "    def get_or_build_index(\n",
    "        self,\n",
    "        df: pl.DataFrame | None = None,\n",
    "        metric: str = \"L2\",  # TODO: as above\n",
    "    ) -> Result[Index, str]:\n",
    "        self.index_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        if not self.index_path.exists():\n",
    "            if df is None:\n",
    "                return Err(\n",
    "                    \"Index does not exist. DataFrame is required to create index\"\n",
    "                )\n",
    "            match self._build_index(df, metric):\n",
    "                case Ok(index):\n",
    "                    ...\n",
    "                case Err(e):\n",
    "                    return Err(e)\n",
    "        else:\n",
    "            match self.get_index():\n",
    "                case Ok(index):\n",
    "                    ...\n",
    "                case Err(e):\n",
    "                    return Err(e)\n",
    "\n",
    "        self._ndims = index.ndim\n",
    "        print(\"Opening index\")\n",
    "        return Ok(index)\n",
    "\n",
    "    def search(\n",
    "        self,\n",
    "        query: NDArray[np.float32],\n",
    "        limit: int = 10,\n",
    "        include: list[int] | None = None,\n",
    "        exclude: list[int] | None = None,\n",
    "    ) -> Result[pl.DataFrame, str]:\n",
    "        return self.vector_search(query, limit, include, exclude)\n",
    "\n",
    "    def vector_search(\n",
    "        self,\n",
    "        query: NDArray[np.float32],\n",
    "        limit: int = 10,\n",
    "        include: list[int] | None = None,\n",
    "        exclude: list[int] | None = None,\n",
    "        exact: bool = False,\n",
    "    ) -> Result[pl.DataFrame, str]:\n",
    "        output = self.index.search(vectors=query, count=limit, log=True, exact=exact)\n",
    "\n",
    "        print(f\"Visited members: {output.visited_members}\")\n",
    "        print(f\"Computed distances: {output.computed_distances}\")\n",
    "\n",
    "        # Extract keys (geonameids) and distances\n",
    "        keys = output.keys\n",
    "        distances = output.distances\n",
    "\n",
    "        # Create a DataFrame from the search results\n",
    "        results_df = pl.LazyFrame(\n",
    "            data={self.id_column: keys, \"score\": distances},\n",
    "            schema={self.id_column: pl.UInt32, \"score\": pl.Float32},\n",
    "        )\n",
    "        if self.metric == \"haversine\":\n",
    "            results_df = results_df.with_columns(pl.col(\"score\") * 6371.0)\n",
    "\n",
    "        results_df = results_df.sort(\n",
    "            \"score\"\n",
    "        )  # TODO: ascending descending depending on metric.\n",
    "\n",
    "        return Ok(results_df.collect())\n",
    "\n",
    "\n",
    "class FTSIndex:\n",
    "    default_index_path = Path(\"./data/indexes/fts\")\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        index_name: str,\n",
    "        data: pl.DataFrame | None = None,\n",
    "        id_column: str = \"geonameId\",\n",
    "        main_column: str = \"name\",\n",
    "    ):\n",
    "        self._index_path = self.default_index_path / index_name\n",
    "        self._column_types = {}\n",
    "        self._id_column = id_column\n",
    "        self._main_column = main_column\n",
    "        index = self.get_or_build_index(data)\n",
    "        if isinstance(index, Err):\n",
    "            print(\n",
    "                f\"Index does not exist at '{self.index_path}', build index with 'build_index' method.\"\n",
    "            )\n",
    "            self._index = None  # type: ignore\n",
    "        else:\n",
    "            self._index: tantivy.Index = index.ok_value\n",
    "\n",
    "    @property\n",
    "    def index(self) -> tantivy.Index:\n",
    "        self._index.reload()\n",
    "        return self._index\n",
    "\n",
    "    @property\n",
    "    def column_types(self) -> dict[str, str]:\n",
    "        return self._column_types\n",
    "\n",
    "    @property\n",
    "    def id_column(self) -> str:\n",
    "        return self._id_column\n",
    "\n",
    "    @property\n",
    "    def main_column(self) -> str:\n",
    "        return self._main_column\n",
    "\n",
    "    @property\n",
    "    def index_path(self) -> Path:\n",
    "        return self._index_path\n",
    "\n",
    "    @property\n",
    "    def columns_not_id(self) -> list[str]:\n",
    "        return [col for col in self.column_types if col != self.id_column]\n",
    "\n",
    "    def _build_index(\n",
    "        self,\n",
    "        df: pl.DataFrame,\n",
    "        split_field: dict[str, list[str] | str] | None = None,\n",
    "    ) -> Result[tantivy.Index, str]:\n",
    "        \"\"\"Only pass in data which you wish to build the ftx index with. split_field is a dictionary of fields to split by a delimiter. eg {\",\": [\"field1\", \"field2\"]} will split field1 and field2 by comma.\"\"\"\n",
    "        # TODO: this programmatically into tantivy schema\n",
    "        schema_builder = tantivy.SchemaBuilder()\n",
    "\n",
    "        if self.id_column not in df.columns:\n",
    "            return Err(f\"'{self.id_column}' column not found in DataFrame\")\n",
    "\n",
    "        col_types = {}\n",
    "        for col in df.columns:\n",
    "            if col == self.id_column:\n",
    "                schema_builder.add_integer_field(\n",
    "                    self.id_column, stored=True, indexed=True, fast=True\n",
    "                )\n",
    "            # TODO: ADD support for other types\n",
    "            else:\n",
    "                schema_builder.add_text_field(col)\n",
    "            col_types[col] = df[col].dtype._string_repr()\n",
    "\n",
    "        self._column_types = col_types\n",
    "\n",
    "        schema = schema_builder.build()\n",
    "        print(f\"Creating index with columns:\\n{json.dumps(col_types, indent=2)}\")\n",
    "\n",
    "        index = tantivy.Index(schema, path=self.index_path.as_posix(), reuse=False)\n",
    "        writer = index.writer()\n",
    "        for row in df.rows(named=True):\n",
    "            if split_field:\n",
    "                for splitter, fields in split_field.items():\n",
    "                    if isinstance(fields, str):\n",
    "                        fields = [fields]\n",
    "                    for field in fields:\n",
    "                        print(f\"Splitting {field} by {splitter}...\")\n",
    "                        row[field] = row[field].split(splitter)\n",
    "            writer.add_document(tantivy.Document(**row))\n",
    "        writer.commit()\n",
    "        writer.wait_merging_threads()\n",
    "        return Ok(index)\n",
    "\n",
    "    def get_index(self) -> Result[tantivy.Index, str]:\n",
    "        if tantivy.Index.exists(self.index_path.as_posix()):\n",
    "            print(f\"Opening index at '{self.index_path}'\")\n",
    "            return Ok(tantivy.Index.open(self.index_path.as_posix()))\n",
    "        return Err(f\"Index does not exist at '{self.index_path}'\")\n",
    "\n",
    "    def get_or_build_index(\n",
    "        self, df: pl.DataFrame | None = None\n",
    "    ) -> Result[tantivy.Index, str]:\n",
    "        if not self.index_path.exists() and df is None:\n",
    "            return Err(\"Index does not exist. DataFrame is required to create index\")\n",
    "\n",
    "        self.index_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        if not tantivy.Index.exists(self.index_path.as_posix()):\n",
    "            if df is None:\n",
    "                return Err(\"DataFrame is required to create index\")\n",
    "            match self._build_index(df):\n",
    "                case Ok(index):\n",
    "                    ...\n",
    "                case Err(e):\n",
    "                    return Err(e)\n",
    "        else:\n",
    "            match self.get_index():\n",
    "                case Ok(index):\n",
    "                    ...\n",
    "                case Err(e):\n",
    "                    return Err(e)\n",
    "        schema = json.loads((self.index_path / \"meta.json\").read_text())[\"schema\"]\n",
    "        sc = {}\n",
    "        for v in schema:\n",
    "            type_ = v[\"type\"]\n",
    "            if type_ == \"text\":\n",
    "                type_ = pl.Utf8\n",
    "            elif type_ == \"i64\":\n",
    "                type_ = pl.UInt32\n",
    "            sc[v[\"name\"]] = type_\n",
    "\n",
    "        self._column_types = sc\n",
    "        print(\"Schema Loaded\")\n",
    "        print(\"Opening country index\")\n",
    "        return Ok(index)\n",
    "\n",
    "    def convert_fts_results(\n",
    "        self, hits: tantivy.SearchResult, searcher: tantivy.Searcher\n",
    "    ) -> pl.DataFrame:\n",
    "        print(f\"FTS hits from search: {hits.count}\")  # type: ignore\n",
    "\n",
    "        scores, gids = zip(\n",
    "            *[\n",
    "                (score, searcher.doc(doc).get_first(self.id_column))\n",
    "                for score, doc in hits.hits\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            pl.LazyFrame(\n",
    "                {\"geonameId\": list(gids), \"score\": list(scores)},\n",
    "                schema={\"geonameId\": pl.UInt32, \"score\": pl.Float32},\n",
    "            )\n",
    "            .sort(\"score\", descending=True, maintain_order=True)\n",
    "            .collect()\n",
    "        )\n",
    "\n",
    "    def search(\n",
    "        self,\n",
    "        query: str,\n",
    "        limit: int = 10,\n",
    "        include: list[int] | None = None,\n",
    "        exclude: list[int] | None = None,\n",
    "    ) -> Result[pl.DataFrame, str]:\n",
    "        return self.fts_search(\n",
    "            query,\n",
    "            limit=limit,\n",
    "            include=include,\n",
    "            exclude=exclude,\n",
    "        )\n",
    "\n",
    "    def fts_search(\n",
    "        self,\n",
    "        query: str,\n",
    "        limit: int = 10,\n",
    "        include: list[int] | None = None,\n",
    "        exclude: list[int] | None = None,\n",
    "        main_term_query_boost: float = 3.0,\n",
    "        fuzzy_term_query_boost: float = 2.0,\n",
    "        max_fuzzy_distance: int = 2,\n",
    "        phrase: bool = True,\n",
    "    ) -> Result[pl.DataFrame, str]:\n",
    "        # Create for list of queries (batch search)\n",
    "        if phrase:\n",
    "            query = f\"'{query}'\"\n",
    "        else:\n",
    "            query = query.strip(\"\\\"'\")\n",
    "        query = query.strip()\n",
    "        index = self.index\n",
    "\n",
    "        searcher = index.searcher()\n",
    "\n",
    "        bool_query_list: list[tuple[tantivy.Occur, tantivy.Query]] = []\n",
    "\n",
    "        # Calculate fuzzy distance based on query length\n",
    "        fuzzy_distance = min(max(0, len(query) - 2), max_fuzzy_distance)\n",
    "\n",
    "        if self.main_column in self.columns_not_id:\n",
    "            main_term_query = tantivy.Query.term_query(\n",
    "                index.schema, self.main_column, query\n",
    "            )\n",
    "            bool_query_list.append(\n",
    "                (\n",
    "                    tantivy.Occur.Should,\n",
    "                    tantivy.Query.boost_query(main_term_query, main_term_query_boost),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            if fuzzy_distance > 0:\n",
    "                main_fuzzy_query = tantivy.Query.fuzzy_term_query(\n",
    "                    index.schema, self.main_column, query, distance=fuzzy_distance\n",
    "                )\n",
    "\n",
    "                bool_query_list.append(\n",
    "                    (\n",
    "                        tantivy.Occur.Should,\n",
    "                        tantivy.Query.boost_query(\n",
    "                            main_fuzzy_query, fuzzy_term_query_boost\n",
    "                        ),\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            rest_of_query = index.parse_query(\n",
    "                query, list(set(self.columns_not_id) - {self.main_column})\n",
    "            )\n",
    "            bool_query_list.append((tantivy.Occur.Should, rest_of_query))\n",
    "\n",
    "        if include:\n",
    "            bool_query_list.append(\n",
    "                (\n",
    "                    tantivy.Occur.Must,\n",
    "                    tantivy.Query.term_set_query(index.schema, self.id_column, include),\n",
    "                )\n",
    "            )\n",
    "        if exclude:\n",
    "            bool_query_list.append(\n",
    "                (\n",
    "                    tantivy.Occur.MustNot,\n",
    "                    tantivy.Query.term_set_query(index.schema, self.id_column, exclude),\n",
    "                )\n",
    "            )\n",
    "        if bool_query_list:\n",
    "            final_query = tantivy.Query.boolean_query(bool_query_list)\n",
    "\n",
    "        else:\n",
    "            final_query: tantivy.Query = index.parse_query(\n",
    "                query, default_field_names=self.columns_not_id\n",
    "            )\n",
    "\n",
    "        print(final_query)\n",
    "\n",
    "        hits: tantivy.SearchResult = searcher.search(final_query, limit=limit)\n",
    "\n",
    "        if hits.count == 0:  # type: ignore\n",
    "            if phrase:\n",
    "                print(\"No results found, retrying without phrase search...\")\n",
    "                return self.fts_search(\n",
    "                    query,\n",
    "                    limit,\n",
    "                    include,\n",
    "                    exclude,\n",
    "                    main_term_query_boost,\n",
    "                    fuzzy_term_query_boost,\n",
    "                    max_fuzzy_distance,\n",
    "                    phrase=False,\n",
    "                )\n",
    "            return Err(\"No results found\")\n",
    "\n",
    "        return Ok(self.convert_fts_results(hits, searcher))\n",
    "\n",
    "\n",
    "class HybridIndex:\n",
    "    def __init__(self, fts_idx: FTSIndex, vidx: VectorIndex):\n",
    "        self._fts_idx = fts_idx\n",
    "        self._vidx = vidx\n",
    "\n",
    "    @property\n",
    "    def vector_index(self) -> VectorIndex:\n",
    "        return self._vidx\n",
    "\n",
    "    @property\n",
    "    def fts_index(self) -> FTSIndex:\n",
    "        return self._fts_idx\n",
    "\n",
    "    def search(\n",
    "        self,\n",
    "        query: str,\n",
    "        limit: int = 10,\n",
    "        include: list[int] | None = None,\n",
    "        exclude: list[int] | None = None,\n",
    "        main_term_query_boost: float = 3.0,\n",
    "        fuzzy_term_query_boost: float = 2.0,\n",
    "        max_fuzzy_distance: int = 2,\n",
    "        phrase: bool = True,\n",
    "    ) -> Result[pl.DataFrame, str]:\n",
    "        v_search = self.vector_index.vector_search\n",
    "\n",
    "\n",
    "country_index = FTSIndex(\"admin0\", con.table(\"admin0_FTS\").pl())\n",
    "country_index.fts_search(\"An Danmhairg\").unwrap().join(\n",
    "    con.table(\"admin0\").pl(), \"geonameId\", \"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (535_868, 15)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>asciiname</th><th>alternatenames</th><th>latitude</th><th>longitude</th><th>feature_class</th><th>feature_code</th><th>admin0_code</th><th>admin1_code</th><th>admin2_code</th><th>admin3_code</th><th>admin4_code</th><th>admin_level</th><th>parentId</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i32</td><td>i32</td></tr></thead><tbody><tr><td>1149756</td><td>&quot;Amphoe Yan Ta Khao&quot;</td><td>&quot;Amphoe Yan Ta Khao&quot;</td><td>&quot;Amphoe Yan Ta Khao,King Amphoe…</td><td>7.4258</td><td>99.734383</td><td>&quot;A&quot;</td><td>&quot;ADM2&quot;</td><td>&quot;TH&quot;</td><td>&quot;65&quot;</td><td>&quot;9203&quot;</td><td>null</td><td>null</td><td>2</td><td>1150006</td></tr><tr><td>1149880</td><td>&quot;Amphoe Wiang Pa Pao&quot;</td><td>&quot;Amphoe Wiang Pa Pao&quot;</td><td>&quot;Amphoe Wiang Pa Pao,Wiang Pa P…</td><td>19.3046</td><td>99.449249</td><td>&quot;A&quot;</td><td>&quot;ADM2&quot;</td><td>&quot;TH&quot;</td><td>&quot;03&quot;</td><td>&quot;5711&quot;</td><td>null</td><td>null</td><td>2</td><td>1153668</td></tr><tr><td>1149891</td><td>&quot;Amphoe Wat Phleng&quot;</td><td>&quot;Amphoe Wat Phleng&quot;</td><td>&quot;Amphoe Wat Phleng,Amphoe Wat P…</td><td>13.44705</td><td>99.869591</td><td>&quot;A&quot;</td><td>&quot;ADM2&quot;</td><td>&quot;TH&quot;</td><td>&quot;52&quot;</td><td>&quot;7009&quot;</td><td>null</td><td>null</td><td>2</td><td>1150953</td></tr><tr><td>1149914</td><td>&quot;Amphoe Wang Nuea&quot;</td><td>&quot;Amphoe Wang Nuea&quot;</td><td>&quot;Amphoe Wang Nua,Amphoe Wang Nu…</td><td>19.16011</td><td>99.647667</td><td>&quot;A&quot;</td><td>&quot;ADM2&quot;</td><td>&quot;TH&quot;</td><td>&quot;06&quot;</td><td>&quot;5207&quot;</td><td>null</td><td>null</td><td>2</td><td>1152472</td></tr><tr><td>1149936</td><td>&quot;Amphoe Wang Chin&quot;</td><td>&quot;Amphoe Wang Chin&quot;</td><td>&quot;Amphoe Wang Chin,King Amphoe W…</td><td>17.866671</td><td>99.649902</td><td>&quot;A&quot;</td><td>&quot;ADM2&quot;</td><td>&quot;TH&quot;</td><td>&quot;07&quot;</td><td>&quot;5407&quot;</td><td>null</td><td>null</td><td>2</td><td>1607551</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>12408624</td><td>&quot;Distrik Kokoda Utara&quot;</td><td>&quot;Distrik Kokoda Utara&quot;</td><td>&quot;Distrik Kokoda Utara&quot;</td><td>-2.007</td><td>132.423004</td><td>&quot;A&quot;</td><td>&quot;ADM3&quot;</td><td>&quot;ID&quot;</td><td>&quot;PD&quot;</td><td>&quot;9106&quot;</td><td>&quot;12408624&quot;</td><td>null</td><td>3</td><td>7910924</td></tr><tr><td>12409481</td><td>&quot;Kecamatan Mataraman&quot;</td><td>&quot;Kecamatan Mataraman&quot;</td><td>&quot;Kecamatan Mataraman&quot;</td><td>-3.328</td><td>115.011002</td><td>&quot;A&quot;</td><td>&quot;ADM3&quot;</td><td>&quot;ID&quot;</td><td>&quot;12&quot;</td><td>&quot;6303&quot;</td><td>&quot;12409481&quot;</td><td>null</td><td>3</td><td>1650231</td></tr><tr><td>12414734</td><td>&quot;Kota Besi&quot;</td><td>&quot;Kota Besi&quot;</td><td>&quot;Kecamatan Kota Besi,Kobes,Kota…</td><td>-2.4044</td><td>112.825684</td><td>&quot;A&quot;</td><td>&quot;ADM3&quot;</td><td>&quot;ID&quot;</td><td>&quot;13&quot;</td><td>&quot;6202&quot;</td><td>&quot;12414734&quot;</td><td>null</td><td>3</td><td>1639475</td></tr><tr><td>12439781</td><td>&quot;Beiji&quot;</td><td>&quot;Beiji&quot;</td><td>&quot;Beiji,Beiji Zhen,bei ji,bei ji…</td><td>53.47823</td><td>122.352859</td><td>&quot;A&quot;</td><td>&quot;ADM4&quot;</td><td>&quot;CN&quot;</td><td>&quot;08&quot;</td><td>&quot;2327&quot;</td><td>&quot;2035728&quot;</td><td>&quot;12439781&quot;</td><td>4</td><td>2035728</td></tr><tr><td>12441408</td><td>&quot;Kecamatan Lawe Alas&quot;</td><td>&quot;Kecamatan Lawe Alas&quot;</td><td>&quot;Kecamatan Lawe Alas&quot;</td><td>3.434</td><td>97.819</td><td>&quot;A&quot;</td><td>&quot;ADM3&quot;</td><td>&quot;ID&quot;</td><td>&quot;01&quot;</td><td>&quot;1104&quot;</td><td>&quot;12441408&quot;</td><td>null</td><td>3</td><td>1215632</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (535_868, 15)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ geonameId ┆ name      ┆ asciiname ┆ alternate ┆ … ┆ admin3_co ┆ admin4_co ┆ admin_lev ┆ parentId │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ names     ┆   ┆ de        ┆ de        ┆ el        ┆ ---      │\n",
       "│ i32       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ i32      │\n",
       "│           ┆           ┆           ┆ str       ┆   ┆ str       ┆ str       ┆ i32       ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 1149756   ┆ Amphoe    ┆ Amphoe    ┆ Amphoe    ┆ … ┆ null      ┆ null      ┆ 2         ┆ 1150006  │\n",
       "│           ┆ Yan Ta    ┆ Yan Ta    ┆ Yan Ta    ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Khao      ┆ Khao      ┆ Khao,King ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ Amphoe…   ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 1149880   ┆ Amphoe    ┆ Amphoe    ┆ Amphoe    ┆ … ┆ null      ┆ null      ┆ 2         ┆ 1153668  │\n",
       "│           ┆ Wiang Pa  ┆ Wiang Pa  ┆ Wiang Pa  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Pao       ┆ Pao       ┆ Pao,Wiang ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ Pa P…     ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 1149891   ┆ Amphoe    ┆ Amphoe    ┆ Amphoe    ┆ … ┆ null      ┆ null      ┆ 2         ┆ 1150953  │\n",
       "│           ┆ Wat       ┆ Wat       ┆ Wat Phlen ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Phleng    ┆ Phleng    ┆ g,Amphoe  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ Wat P…    ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 1149914   ┆ Amphoe    ┆ Amphoe    ┆ Amphoe    ┆ … ┆ null      ┆ null      ┆ 2         ┆ 1152472  │\n",
       "│           ┆ Wang Nuea ┆ Wang Nuea ┆ Wang Nua, ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ Amphoe    ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ Wang Nu…  ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 1149936   ┆ Amphoe    ┆ Amphoe    ┆ Amphoe    ┆ … ┆ null      ┆ null      ┆ 2         ┆ 1607551  │\n",
       "│           ┆ Wang Chin ┆ Wang Chin ┆ Wang      ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ Chin,King ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ Amphoe W… ┆   ┆           ┆           ┆           ┆          │\n",
       "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
       "│ 12408624  ┆ Distrik   ┆ Distrik   ┆ Distrik   ┆ … ┆ 12408624  ┆ null      ┆ 3         ┆ 7910924  │\n",
       "│           ┆ Kokoda    ┆ Kokoda    ┆ Kokoda    ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Utara     ┆ Utara     ┆ Utara     ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 12409481  ┆ Kecamatan ┆ Kecamatan ┆ Kecamatan ┆ … ┆ 12409481  ┆ null      ┆ 3         ┆ 1650231  │\n",
       "│           ┆ Mataraman ┆ Mataraman ┆ Mataraman ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 12414734  ┆ Kota Besi ┆ Kota Besi ┆ Kecamatan ┆ … ┆ 12414734  ┆ null      ┆ 3         ┆ 1639475  │\n",
       "│           ┆           ┆           ┆ Kota Besi ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ ,Kobes,Ko ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ ta…       ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 12439781  ┆ Beiji     ┆ Beiji     ┆ Beiji,Bei ┆ … ┆ 2035728   ┆ 12439781  ┆ 4         ┆ 2035728  │\n",
       "│           ┆           ┆           ┆ ji        ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ Zhen,bei  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ ji,bei    ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ ji…       ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 12441408  ┆ Kecamatan ┆ Kecamatan ┆ Kecamatan ┆ … ┆ 12441408  ┆ null      ┆ 3         ┆ 1215632  │\n",
       "│           ┆ Lawe Alas ┆ Lawe Alas ┆ Lawe Alas ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. PREPARE THE BASE DATA\n",
    "# Start with a comprehensive temporary table containing all admin entities\n",
    "con.execute(\"\"\"\n",
    "    CREATE OR REPLACE TEMP TABLE admin_entities AS\n",
    "    SELECT\n",
    "        a.geonameId,\n",
    "        a.name,\n",
    "        a.asciiname,\n",
    "        a.alternatenames,\n",
    "        a.latitude,\n",
    "        a.longitude,\n",
    "        a.feature_class,\n",
    "        a.feature_code,\n",
    "        a.admin0_code,\n",
    "        a.admin1_code,\n",
    "        a.admin2_code,\n",
    "        a.admin3_code,\n",
    "        a.admin4_code,\n",
    "        CASE\n",
    "            WHEN a.feature_code IN ('PCLI', 'PCLD', 'PCLF', 'PCLS', 'PCL', 'TERR') THEN 0\n",
    "            WHEN a.feature_code LIKE 'ADM1%' THEN 1\n",
    "            WHEN a.feature_code LIKE 'ADM2%' THEN 2\n",
    "            WHEN a.feature_code LIKE 'ADM3%' THEN 3\n",
    "            WHEN a.feature_code LIKE 'ADM4%' THEN 4\n",
    "            ELSE NULL\n",
    "        END AS admin_level,\n",
    "        h.parentId\n",
    "    FROM\n",
    "        allCountries a\n",
    "    LEFT JOIN\n",
    "        hierarchy h ON a.geonameId = h.childId AND h.type = 'ADM'\n",
    "    WHERE\n",
    "        a.feature_class = 'A' AND\n",
    "        (a.feature_code IN ('PCLI', 'PCLD', 'PCLF', 'PCLS', 'PCL', 'TERR') OR\n",
    "         a.feature_code LIKE 'ADM%')\n",
    "    \"\"\")\n",
    "con.table(\"admin_entities\").pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (306_985, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>admin_level</th><th>id_path</th><th>name_path</th><th>depth</th><th>parent_id</th><th>root_id</th><th>path_display</th></tr><tr><td>i32</td><td>str</td><td>i32</td><td>list[i32]</td><td>list[str]</td><td>i32</td><td>i32</td><td>i32</td><td>str</td></tr></thead><tbody><tr><td>49518</td><td>&quot;Republic of Rwanda&quot;</td><td>0</td><td>[49518]</td><td>[&quot;Republic of Rwanda&quot;]</td><td>0</td><td>null</td><td>49518</td><td>&quot;Republic of Rwanda&quot;</td></tr><tr><td>6413337</td><td>&quot;Eastern Province&quot;</td><td>1</td><td>[49518, 6413337]</td><td>[&quot;Republic of Rwanda&quot;, &quot;Eastern Province&quot;]</td><td>1</td><td>49518</td><td>49518</td><td>&quot;Eastern Province, Republic of …</td></tr><tr><td>7688799</td><td>&quot;Nyagatare District&quot;</td><td>2</td><td>[49518, 6413337, 7688799]</td><td>[&quot;Republic of Rwanda&quot;, &quot;Eastern Province&quot;, &quot;Nyagatare District&quot;]</td><td>2</td><td>6413337</td><td>49518</td><td>&quot;Nyagatare District, Eastern Pr…</td></tr><tr><td>11186806</td><td>&quot;Gatunda&quot;</td><td>3</td><td>[49518, 6413337, … 11186806]</td><td>[&quot;Republic of Rwanda&quot;, &quot;Eastern Province&quot;, … &quot;Gatunda&quot;]</td><td>3</td><td>7688799</td><td>49518</td><td>&quot;Gatunda, Nyagatare District, E…</td></tr><tr><td>11188673</td><td>&quot;Nyangara&quot;</td><td>4</td><td>[49518, 6413337, … 11188673]</td><td>[&quot;Republic of Rwanda&quot;, &quot;Eastern Province&quot;, … &quot;Nyangara&quot;]</td><td>4</td><td>11186806</td><td>49518</td><td>&quot;Nyangara, Gatunda, Nyagatare D…</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>10345217</td><td>&quot;Torit County&quot;</td><td>2</td><td>[7909807, 408668, 10345217]</td><td>[&quot;South Sudan&quot;, &quot;Eastern Equatoria&quot;, &quot;Torit County&quot;]</td><td>2</td><td>408668</td><td>7909807</td><td>&quot;Torit County, Eastern Equatori…</td></tr><tr><td>10346346</td><td>&quot;Lafon County&quot;</td><td>2</td><td>[7909807, 408668, 10346346]</td><td>[&quot;South Sudan&quot;, &quot;Eastern Equatoria&quot;, &quot;Lafon County&quot;]</td><td>2</td><td>408668</td><td>7909807</td><td>&quot;Lafon County, Eastern Equatori…</td></tr><tr><td>408670</td><td>&quot;Warrap State&quot;</td><td>1</td><td>[7909807, 408670]</td><td>[&quot;South Sudan&quot;, &quot;Warrap State&quot;]</td><td>1</td><td>7909807</td><td>7909807</td><td>&quot;Warrap State, South Sudan&quot;</td></tr><tr><td>10400481</td><td>&quot;Twic County&quot;</td><td>2</td><td>[7909807, 408670, 10400481]</td><td>[&quot;South Sudan&quot;, &quot;Warrap State&quot;, &quot;Twic County&quot;]</td><td>2</td><td>408670</td><td>7909807</td><td>&quot;Twic County, Warrap State, Sou…</td></tr><tr><td>8335033</td><td>&quot;Jervis Bay Territory&quot;</td><td>0</td><td>[8335033]</td><td>[&quot;Jervis Bay Territory&quot;]</td><td>0</td><td>null</td><td>8335033</td><td>&quot;Jervis Bay Territory&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (306_985, 9)\n",
       "┌───────────┬─────────────┬────────────┬────────────┬───┬───────┬───────────┬─────────┬────────────┐\n",
       "│ geonameId ┆ name        ┆ admin_leve ┆ id_path    ┆ … ┆ depth ┆ parent_id ┆ root_id ┆ path_displ │\n",
       "│ ---       ┆ ---         ┆ l          ┆ ---        ┆   ┆ ---   ┆ ---       ┆ ---     ┆ ay         │\n",
       "│ i32       ┆ str         ┆ ---        ┆ list[i32]  ┆   ┆ i32   ┆ i32       ┆ i32     ┆ ---        │\n",
       "│           ┆             ┆ i32        ┆            ┆   ┆       ┆           ┆         ┆ str        │\n",
       "╞═══════════╪═════════════╪════════════╪════════════╪═══╪═══════╪═══════════╪═════════╪════════════╡\n",
       "│ 49518     ┆ Republic of ┆ 0          ┆ [49518]    ┆ … ┆ 0     ┆ null      ┆ 49518   ┆ Republic   │\n",
       "│           ┆ Rwanda      ┆            ┆            ┆   ┆       ┆           ┆         ┆ of Rwanda  │\n",
       "│ 6413337   ┆ Eastern     ┆ 1          ┆ [49518,    ┆ … ┆ 1     ┆ 49518     ┆ 49518   ┆ Eastern    │\n",
       "│           ┆ Province    ┆            ┆ 6413337]   ┆   ┆       ┆           ┆         ┆ Province,  │\n",
       "│           ┆             ┆            ┆            ┆   ┆       ┆           ┆         ┆ Republic   │\n",
       "│           ┆             ┆            ┆            ┆   ┆       ┆           ┆         ┆ of …       │\n",
       "│ 7688799   ┆ Nyagatare   ┆ 2          ┆ [49518,    ┆ … ┆ 2     ┆ 6413337   ┆ 49518   ┆ Nyagatare  │\n",
       "│           ┆ District    ┆            ┆ 6413337,   ┆   ┆       ┆           ┆         ┆ District,  │\n",
       "│           ┆             ┆            ┆ 7688799]   ┆   ┆       ┆           ┆         ┆ Eastern    │\n",
       "│           ┆             ┆            ┆            ┆   ┆       ┆           ┆         ┆ Pr…        │\n",
       "│ 11186806  ┆ Gatunda     ┆ 3          ┆ [49518,    ┆ … ┆ 3     ┆ 7688799   ┆ 49518   ┆ Gatunda,   │\n",
       "│           ┆             ┆            ┆ 6413337, … ┆   ┆       ┆           ┆         ┆ Nyagatare  │\n",
       "│           ┆             ┆            ┆ 11186806]  ┆   ┆       ┆           ┆         ┆ District,  │\n",
       "│           ┆             ┆            ┆            ┆   ┆       ┆           ┆         ┆ E…         │\n",
       "│ 11188673  ┆ Nyangara    ┆ 4          ┆ [49518,    ┆ … ┆ 4     ┆ 11186806  ┆ 49518   ┆ Nyangara,  │\n",
       "│           ┆             ┆            ┆ 6413337, … ┆   ┆       ┆           ┆         ┆ Gatunda,   │\n",
       "│           ┆             ┆            ┆ 11188673]  ┆   ┆       ┆           ┆         ┆ Nyagatare  │\n",
       "│           ┆             ┆            ┆            ┆   ┆       ┆           ┆         ┆ D…         │\n",
       "│ …         ┆ …           ┆ …          ┆ …          ┆ … ┆ …     ┆ …         ┆ …       ┆ …          │\n",
       "│ 10345217  ┆ Torit       ┆ 2          ┆ [7909807,  ┆ … ┆ 2     ┆ 408668    ┆ 7909807 ┆ Torit      │\n",
       "│           ┆ County      ┆            ┆ 408668,    ┆   ┆       ┆           ┆         ┆ County,    │\n",
       "│           ┆             ┆            ┆ 10345217]  ┆   ┆       ┆           ┆         ┆ Eastern    │\n",
       "│           ┆             ┆            ┆            ┆   ┆       ┆           ┆         ┆ Equatori…  │\n",
       "│ 10346346  ┆ Lafon       ┆ 2          ┆ [7909807,  ┆ … ┆ 2     ┆ 408668    ┆ 7909807 ┆ Lafon      │\n",
       "│           ┆ County      ┆            ┆ 408668,    ┆   ┆       ┆           ┆         ┆ County,    │\n",
       "│           ┆             ┆            ┆ 10346346]  ┆   ┆       ┆           ┆         ┆ Eastern    │\n",
       "│           ┆             ┆            ┆            ┆   ┆       ┆           ┆         ┆ Equatori…  │\n",
       "│ 408670    ┆ Warrap      ┆ 1          ┆ [7909807,  ┆ … ┆ 1     ┆ 7909807   ┆ 7909807 ┆ Warrap     │\n",
       "│           ┆ State       ┆            ┆ 408670]    ┆   ┆       ┆           ┆         ┆ State,     │\n",
       "│           ┆             ┆            ┆            ┆   ┆       ┆           ┆         ┆ South      │\n",
       "│           ┆             ┆            ┆            ┆   ┆       ┆           ┆         ┆ Sudan      │\n",
       "│ 10400481  ┆ Twic County ┆ 2          ┆ [7909807,  ┆ … ┆ 2     ┆ 408670    ┆ 7909807 ┆ Twic       │\n",
       "│           ┆             ┆            ┆ 408670,    ┆   ┆       ┆           ┆         ┆ County,    │\n",
       "│           ┆             ┆            ┆ 10400481]  ┆   ┆       ┆           ┆         ┆ Warrap     │\n",
       "│           ┆             ┆            ┆            ┆   ┆       ┆           ┆         ┆ State,     │\n",
       "│           ┆             ┆            ┆            ┆   ┆       ┆           ┆         ┆ Sou…       │\n",
       "│ 8335033   ┆ Jervis Bay  ┆ 0          ┆ [8335033]  ┆ … ┆ 0     ┆ null      ┆ 8335033 ┆ Jervis Bay │\n",
       "│           ┆ Territory   ┆            ┆            ┆   ┆       ┆           ┆         ┆ Territory  │\n",
       "└───────────┴─────────────┴────────────┴────────────┴───┴───────┴───────────┴─────────┴────────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. BUILD THE HIERARCHY USING RECURSIVE CTE\n",
    "# This is a key optimization - using a recursive CTE to build the full hierarchy\n",
    "# in a single SQL operation instead of multiple database calls\n",
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE admin_hierarchy_full AS\n",
    "WITH RECURSIVE hierarchy_path(geonameId, name, admin_level, id_path, name_path, depth) AS (\n",
    "    -- Base case: Start with top-level entities (countries)\n",
    "    SELECT\n",
    "        geonameId,\n",
    "        name,\n",
    "        admin_level,\n",
    "        [geonameId]::INTEGER[], -- Start with array containing just this ID\n",
    "        [name]::VARCHAR[],      -- Start with array containing just this name\n",
    "        0                        -- Depth starts at 0\n",
    "    FROM\n",
    "        admin_entities\n",
    "    WHERE\n",
    "        admin_level = 0\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    -- Recursive case: Add children to the path\n",
    "    SELECT\n",
    "        c.geonameId,\n",
    "        c.name,\n",
    "        c.admin_level,\n",
    "        p.id_path || [c.geonameId]::INTEGER[],\n",
    "        p.name_path || [c.name]::VARCHAR[], -- Append child name to name array\n",
    "        p.depth + 1                 -- Increment depth\n",
    "    FROM\n",
    "        admin_entities c\n",
    "    JOIN\n",
    "        hierarchy_path p ON c.parentId = p.geonameId\n",
    "    WHERE\n",
    "        c.admin_level > 0 AND p.depth < 5 -- Prevent infinite recursion\n",
    ")\n",
    "SELECT\n",
    "    geonameId,\n",
    "    name,\n",
    "    admin_level,\n",
    "    id_path,\n",
    "    name_path,\n",
    "    depth,\n",
    "    -- Parent ID is the second-to-last element in the path array\n",
    "    CASE\n",
    "        WHEN array_length(id_path) > 1 THEN\n",
    "            id_path[array_length(id_path) - 1]\n",
    "        ELSE NULL\n",
    "    END AS parent_id,\n",
    "    -- Root ID is always the first element in the path array\n",
    "    id_path[1] AS root_id,\n",
    "    -- Create a simple string representation for display\n",
    "    array_to_string(list_reverse(name_path), ', ') AS path_display\n",
    "FROM\n",
    "    hierarchy_path\n",
    "ORDER BY\n",
    "    id_path, admin_level;\n",
    "\n",
    "    \"\"\")\n",
    "con.table(\"admin_hierarchy_full\").pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (228_883, 15)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>asciiname</th><th>alternatenames</th><th>latitude</th><th>longitude</th><th>feature_class</th><th>feature_code</th><th>admin0_code</th><th>admin1_code</th><th>admin2_code</th><th>admin3_code</th><th>admin4_code</th><th>admin_level</th><th>parentId</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i32</td><td>i32</td></tr></thead><tbody><tr><td>11189118</td><td>&quot;Rwenyangye Parish&quot;</td><td>&quot;Rwenyangye Parish&quot;</td><td>null</td><td>-1.17127</td><td>30.17231</td><td>&quot;A&quot;</td><td>&quot;ADM5&quot;</td><td>&quot;UG&quot;</td><td>&quot;W&quot;</td><td>&quot;I8&quot;</td><td>&quot;226611&quot;</td><td>&quot;8657841&quot;</td><td>null</td><td>8657841</td></tr><tr><td>11189121</td><td>&quot;Burambira&quot;</td><td>&quot;Burambira&quot;</td><td>null</td><td>-1.29462</td><td>30.158501</td><td>&quot;A&quot;</td><td>&quot;ADM5&quot;</td><td>&quot;UG&quot;</td><td>&quot;W&quot;</td><td>&quot;34&quot;</td><td>&quot;227915&quot;</td><td>&quot;8658136&quot;</td><td>null</td><td>8658136</td></tr><tr><td>11189124</td><td>&quot;Kyabuhangwa&quot;</td><td>&quot;Kyabuhangwa&quot;</td><td>null</td><td>-1.24665</td><td>30.1744</td><td>&quot;A&quot;</td><td>&quot;ADM5&quot;</td><td>&quot;UG&quot;</td><td>&quot;W&quot;</td><td>&quot;I8&quot;</td><td>&quot;226611&quot;</td><td>&quot;8657841&quot;</td><td>null</td><td>8657841</td></tr><tr><td>11189131</td><td>&quot;Kanamba&quot;</td><td>&quot;Kanamba&quot;</td><td>null</td><td>0.22631</td><td>30.208059</td><td>&quot;A&quot;</td><td>&quot;ADM5&quot;</td><td>&quot;UG&quot;</td><td>&quot;W&quot;</td><td>&quot;40&quot;</td><td>&quot;234040&quot;</td><td>&quot;8658463&quot;</td><td>null</td><td>8658463</td></tr><tr><td>11189135</td><td>&quot;Rweibogo&quot;</td><td>&quot;Rweibogo&quot;</td><td>null</td><td>-0.74709</td><td>30.53047</td><td>&quot;A&quot;</td><td>&quot;ADM5&quot;</td><td>&quot;UG&quot;</td><td>&quot;W&quot;</td><td>&quot;52&quot;</td><td>&quot;226512&quot;</td><td>&quot;8657884&quot;</td><td>null</td><td>8657884</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>5051133</td><td>&quot;Upper Sioux Community&quot;</td><td>&quot;Upper Sioux Community&quot;</td><td>&quot;Upper Sioux Community,Upper Si…</td><td>44.761318</td><td>-95.509216</td><td>&quot;A&quot;</td><td>&quot;ADMD&quot;</td><td>&quot;US&quot;</td><td>&quot;MN&quot;</td><td>&quot;173&quot;</td><td>null</td><td>null</td><td>null</td><td>5023752</td></tr><tr><td>5052667</td><td>&quot;White Earth Reservation&quot;</td><td>&quot;White Earth Reservation&quot;</td><td>&quot;White Earth Indian Reservation…</td><td>47.227589</td><td>-95.72049</td><td>&quot;A&quot;</td><td>&quot;ADMD&quot;</td><td>&quot;US&quot;</td><td>&quot;MN&quot;</td><td>&quot;087&quot;</td><td>null</td><td>null</td><td>null</td><td>5021535</td></tr><tr><td>5051133</td><td>&quot;Upper Sioux Community&quot;</td><td>&quot;Upper Sioux Community&quot;</td><td>&quot;Upper Sioux Community,Upper Si…</td><td>44.761318</td><td>-95.509216</td><td>&quot;A&quot;</td><td>&quot;ADMD&quot;</td><td>&quot;US&quot;</td><td>&quot;MN&quot;</td><td>&quot;173&quot;</td><td>null</td><td>null</td><td>null</td><td>5053562</td></tr><tr><td>5052667</td><td>&quot;White Earth Reservation&quot;</td><td>&quot;White Earth Reservation&quot;</td><td>&quot;White Earth Indian Reservation…</td><td>47.227589</td><td>-95.72049</td><td>&quot;A&quot;</td><td>&quot;ADMD&quot;</td><td>&quot;US&quot;</td><td>&quot;MN&quot;</td><td>&quot;087&quot;</td><td>null</td><td>null</td><td>null</td><td>5017670</td></tr><tr><td>5052667</td><td>&quot;White Earth Reservation&quot;</td><td>&quot;White Earth Reservation&quot;</td><td>&quot;White Earth Indian Reservation…</td><td>47.227589</td><td>-95.72049</td><td>&quot;A&quot;</td><td>&quot;ADMD&quot;</td><td>&quot;US&quot;</td><td>&quot;MN&quot;</td><td>&quot;087&quot;</td><td>null</td><td>null</td><td>null</td><td>5036279</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (228_883, 15)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ geonameId ┆ name      ┆ asciiname ┆ alternate ┆ … ┆ admin3_co ┆ admin4_co ┆ admin_lev ┆ parentId │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ names     ┆   ┆ de        ┆ de        ┆ el        ┆ ---      │\n",
       "│ i32       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ i32      │\n",
       "│           ┆           ┆           ┆ str       ┆   ┆ str       ┆ str       ┆ i32       ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 11189118  ┆ Rwenyangy ┆ Rwenyangy ┆ null      ┆ … ┆ 226611    ┆ 8657841   ┆ null      ┆ 8657841  │\n",
       "│           ┆ e Parish  ┆ e Parish  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 11189121  ┆ Burambira ┆ Burambira ┆ null      ┆ … ┆ 227915    ┆ 8658136   ┆ null      ┆ 8658136  │\n",
       "│ 11189124  ┆ Kyabuhang ┆ Kyabuhang ┆ null      ┆ … ┆ 226611    ┆ 8657841   ┆ null      ┆ 8657841  │\n",
       "│           ┆ wa        ┆ wa        ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 11189131  ┆ Kanamba   ┆ Kanamba   ┆ null      ┆ … ┆ 234040    ┆ 8658463   ┆ null      ┆ 8658463  │\n",
       "│ 11189135  ┆ Rweibogo  ┆ Rweibogo  ┆ null      ┆ … ┆ 226512    ┆ 8657884   ┆ null      ┆ 8657884  │\n",
       "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
       "│ 5051133   ┆ Upper     ┆ Upper     ┆ Upper     ┆ … ┆ null      ┆ null      ┆ null      ┆ 5023752  │\n",
       "│           ┆ Sioux     ┆ Sioux     ┆ Sioux Com ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Community ┆ Community ┆ munity,Up ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ per Si…   ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 5052667   ┆ White     ┆ White     ┆ White     ┆ … ┆ null      ┆ null      ┆ null      ┆ 5021535  │\n",
       "│           ┆ Earth Res ┆ Earth Res ┆ Earth     ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ ervation  ┆ ervation  ┆ Indian    ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ Reservati ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ on…       ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 5051133   ┆ Upper     ┆ Upper     ┆ Upper     ┆ … ┆ null      ┆ null      ┆ null      ┆ 5053562  │\n",
       "│           ┆ Sioux     ┆ Sioux     ┆ Sioux Com ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Community ┆ Community ┆ munity,Up ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ per Si…   ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 5052667   ┆ White     ┆ White     ┆ White     ┆ … ┆ null      ┆ null      ┆ null      ┆ 5017670  │\n",
       "│           ┆ Earth Res ┆ Earth Res ┆ Earth     ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ ervation  ┆ ervation  ┆ Indian    ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ Reservati ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ on…       ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 5052667   ┆ White     ┆ White     ┆ White     ┆ … ┆ null      ┆ null      ┆ null      ┆ 5036279  │\n",
       "│           ┆ Earth Res ┆ Earth Res ┆ Earth     ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ ervation  ┆ ervation  ┆ Indian    ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ Reservati ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ on…       ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. HANDLE ORPHANED ENTITIES (Those without proper hierarchy linkage)\n",
    "con.execute(\"\"\"\n",
    "    CREATE OR REPLACE TEMP TABLE orphaned_entities AS\n",
    "    SELECT a.*\n",
    "    FROM admin_entities a\n",
    "    LEFT JOIN admin_hierarchy_full h ON a.geonameId = h.geonameId\n",
    "    WHERE h.geonameId IS NULL\n",
    "    \"\"\")\n",
    "con.execute(\"ANALYZE admin_hierarchy_full\")\n",
    "con.execute(\"ANALYZE orphaned_entities\")\n",
    "con.table(\"orphaned_entities\").pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (7_503, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>admin_level</th><th>parent_id</th></tr><tr><td>i32</td><td>str</td><td>i32</td><td>i32</td></tr></thead><tbody><tr><td>828987</td><td>&quot;Southern Finland Province&quot;</td><td>1</td><td>660013</td></tr><tr><td>828988</td><td>&quot;Eastern Finland Province&quot;</td><td>1</td><td>660013</td></tr><tr><td>828989</td><td>&quot;Länsi-Suomen Lääni&quot;</td><td>1</td><td>660013</td></tr><tr><td>6547304</td><td>&quot;Oued Ed-Dahab-Lagouira&quot;</td><td>1</td><td>2461445</td></tr><tr><td>7886994</td><td>&quot;Lukovo&quot;</td><td>1</td><td>718075</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>10942651</td><td>&quot;Kaltennordheim&quot;</td><td>4</td><td>6547388</td></tr><tr><td>2881759</td><td>&quot;Lämershagen-Gräfinghagen&quot;</td><td>4</td><td>3221125</td></tr><tr><td>2883114</td><td>&quot;Kuckau&quot;</td><td>4</td><td>2951880</td></tr><tr><td>8199004</td><td>&quot;Dhuwakot&quot;</td><td>4</td><td>12096198</td></tr><tr><td>3087718</td><td>&quot;Psie Pole&quot;</td><td>4</td><td>7531292</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (7_503, 4)\n",
       "┌───────────┬───────────────────────────┬─────────────┬───────────┐\n",
       "│ geonameId ┆ name                      ┆ admin_level ┆ parent_id │\n",
       "│ ---       ┆ ---                       ┆ ---         ┆ ---       │\n",
       "│ i32       ┆ str                       ┆ i32         ┆ i32       │\n",
       "╞═══════════╪═══════════════════════════╪═════════════╪═══════════╡\n",
       "│ 828987    ┆ Southern Finland Province ┆ 1           ┆ 660013    │\n",
       "│ 828988    ┆ Eastern Finland Province  ┆ 1           ┆ 660013    │\n",
       "│ 828989    ┆ Länsi-Suomen Lääni        ┆ 1           ┆ 660013    │\n",
       "│ 6547304   ┆ Oued Ed-Dahab-Lagouira    ┆ 1           ┆ 2461445   │\n",
       "│ 7886994   ┆ Lukovo                    ┆ 1           ┆ 718075    │\n",
       "│ …         ┆ …                         ┆ …           ┆ …         │\n",
       "│ 10942651  ┆ Kaltennordheim            ┆ 4           ┆ 6547388   │\n",
       "│ 2881759   ┆ Lämershagen-Gräfinghagen  ┆ 4           ┆ 3221125   │\n",
       "│ 2883114   ┆ Kuckau                    ┆ 4           ┆ 2951880   │\n",
       "│ 8199004   ┆ Dhuwakot                  ┆ 4           ┆ 12096198  │\n",
       "│ 3087718   ┆ Psie Pole                 ┆ 4           ┆ 7531292   │\n",
       "└───────────┴───────────────────────────┴─────────────┴───────────┘"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE TEMP TABLE fixed_orphans AS\n",
    "\n",
    "-- Level 1 orphans (join with countries)\n",
    "SELECT\n",
    "    o.geonameId,\n",
    "    o.name,\n",
    "    o.admin_level,\n",
    "    h.geonameId AS parent_id\n",
    "FROM\n",
    "    orphaned_entities o\n",
    "JOIN\n",
    "    admin_entities c ON o.admin0_code = c.admin0_code\n",
    "JOIN\n",
    "    admin_hierarchy_full h ON c.geonameId = h.geonameId AND h.admin_level = 0\n",
    "WHERE\n",
    "    o.admin_level = 1\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "-- Level 2 orphans (join with admin1)\n",
    "SELECT\n",
    "    o.geonameId,\n",
    "    o.name,\n",
    "    o.admin_level,\n",
    "    h.geonameId AS parent_id\n",
    "FROM\n",
    "    orphaned_entities o\n",
    "JOIN\n",
    "    admin_entities a1 ON o.admin0_code = a1.admin0_code\n",
    "                      AND o.admin1_code = a1.admin1_code\n",
    "JOIN\n",
    "    admin_hierarchy_full h ON a1.geonameId = h.geonameId AND h.admin_level = 1\n",
    "WHERE\n",
    "    o.admin_level = 2\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "-- Level 3 orphans (join with admin2)\n",
    "SELECT\n",
    "    o.geonameId,\n",
    "    o.name,\n",
    "    o.admin_level,\n",
    "    h.geonameId AS parent_id\n",
    "FROM\n",
    "    orphaned_entities o\n",
    "JOIN\n",
    "    admin_entities a2 ON o.admin0_code = a2.admin0_code\n",
    "                      AND o.admin1_code = a2.admin1_code\n",
    "                      AND o.admin2_code = a2.admin2_code\n",
    "JOIN\n",
    "    admin_hierarchy_full h ON a2.geonameId = h.geonameId AND h.admin_level = 2\n",
    "WHERE\n",
    "    o.admin_level = 3\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "-- Level 4 orphans (join with admin3)\n",
    "SELECT\n",
    "    o.geonameId,\n",
    "    o.name,\n",
    "    o.admin_level,\n",
    "    h.geonameId AS parent_id\n",
    "FROM\n",
    "    orphaned_entities o\n",
    "JOIN\n",
    "    admin_entities a3 ON o.admin0_code = a3.admin0_code\n",
    "                      AND o.admin1_code = a3.admin1_code\n",
    "                      AND o.admin2_code = a3.admin2_code\n",
    "                      AND o.admin3_code = a3.admin3_code\n",
    "JOIN\n",
    "    admin_hierarchy_full h ON a3.geonameId = h.geonameId AND h.admin_level = 3\n",
    "WHERE\n",
    "    o.admin_level = 4;\n",
    "    \"\"\")\n",
    "con.table(\"fixed_orphans\").pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating admin0 table...\n",
      "Created admin0 with 242 entities\n",
      "Creating admin1 table...\n",
      "Created admin1 with 4519 entities\n",
      "Creating admin2 table...\n",
      "Created admin2 with 48965 entities\n",
      "Creating admin3 table...\n",
      "Created admin3 with 151550 entities\n",
      "Creating admin4 table...\n",
      "Created admin4 with 112112 entities\n"
     ]
    }
   ],
   "source": [
    "# 4. CREATE ADMIN TABLES WITH UNIFIED APPROACH\n",
    "# Now create each admin level table with consistent structure\n",
    "admin_levels = range(0, 5)  # levels 0-4\n",
    "overwrite = True\n",
    "\n",
    "for level in admin_levels:\n",
    "    table_name = f\"admin{level}\"\n",
    "    if table_exists(con, table_name) and not overwrite:\n",
    "        print(f\"Table {table_name} exists, skipping (use overwrite=True to replace)\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Creating {table_name} table...\")\n",
    "\n",
    "    # Create the base table with rich information\n",
    "    if level == 0:  # Special case for admin0 (countries)\n",
    "        con.execute(f\"\"\"\n",
    "    CREATE OR REPLACE TABLE {table_name} AS\n",
    "    SELECT\n",
    "        a.geonameId,\n",
    "        a.name,\n",
    "        a.asciiname,\n",
    "        a.admin0_code,\n",
    "        a.cc2,\n",
    "        c.ISO,\n",
    "        c.ISO3,\n",
    "        c.ISO_Numeric,\n",
    "        c.Country AS official_name,\n",
    "        c.fips,\n",
    "        c.Population,\n",
    "        c.Area,\n",
    "        a.alternatenames,\n",
    "        a.feature_class,\n",
    "        a.feature_code,\n",
    "        -- Simple reference to root ID (same as own ID for countries)\n",
    "        a.geonameId AS root_id,\n",
    "        -- We don't need full path arrays for countries\n",
    "        NULL AS parent_id\n",
    "    FROM\n",
    "        admin_hierarchy_full h\n",
    "    JOIN\n",
    "        allCountries a ON h.geonameId = a.geonameId\n",
    "    JOIN\n",
    "        countryInfo c ON a.geonameId = c.geonameId\n",
    "    WHERE\n",
    "        h.admin_level = 0\n",
    "    ORDER BY\n",
    "        a.geonameId\n",
    "    \"\"\")\n",
    "    else:\n",
    "        # For admin levels 1-4\n",
    "        parent_level = level - 1\n",
    "        con.execute(f\"\"\"\n",
    "    CREATE OR REPLACE TABLE {table_name} AS\n",
    "    SELECT\n",
    "        a.geonameId,\n",
    "        a.name,\n",
    "        a.asciiname,\n",
    "        -- Admin codes (only include what's needed)\n",
    "        a.admin0_code,\n",
    "        a.admin1_code\n",
    "        {', a.admin2_code' if level >= 2 else ', NULL AS admin2_code'}\n",
    "        {', a.admin3_code' if level >= 3 else ', NULL AS admin3_code'}\n",
    "        {', a.admin4_code' if level >= 4 else ', NULL AS admin4_code'},\n",
    "        -- Feature classification\n",
    "        a.feature_class,\n",
    "        a.feature_code,\n",
    "        a.population,\n",
    "        -- Hierarchy references (just the essential IDs, not full arrays)\n",
    "        h.root_id AS country_id,\n",
    "        h.parent_id,\n",
    "        -- Names for display and search\n",
    "        r.name AS country_name,\n",
    "        p.name AS parent_name,\n",
    "        a.alternatenames\n",
    "    FROM\n",
    "        admin_hierarchy_full h\n",
    "    JOIN\n",
    "        allCountries a ON h.geonameId = a.geonameId\n",
    "    LEFT JOIN\n",
    "        allCountries p ON h.parent_id = p.geonameId\n",
    "    JOIN\n",
    "        allCountries r ON h.root_id = r.geonameId\n",
    "    WHERE\n",
    "        h.admin_level = {level}\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    -- Add any fixed orphans with slim structure\n",
    "    SELECT\n",
    "        a.geonameId,\n",
    "        a.name,\n",
    "        a.asciiname,\n",
    "        -- Admin codes\n",
    "        a.admin0_code,\n",
    "        a.admin1_code\n",
    "        {', a.admin2_code' if level >= 2 else ', NULL AS admin2_code'}\n",
    "        {', a.admin3_code' if level >= 3 else ', NULL AS admin3_code'}\n",
    "        {', a.admin4_code' if level >= 4 else ', NULL AS admin4_code'},\n",
    "        -- Feature classification\n",
    "        a.feature_class,\n",
    "        a.feature_code,\n",
    "        p.population,\n",
    "        -- Links to country\n",
    "        (SELECT geonameId FROM allCountries\n",
    "         WHERE admin0_code = a.admin0_code AND feature_code = 'PCLI' LIMIT 1) AS country_id,\n",
    "        f.parent_id,\n",
    "        -- Names for display and search\n",
    "        c.name AS country_name,\n",
    "        p.name AS parent_name,\n",
    "        a.alternatenames\n",
    "    FROM\n",
    "        fixed_orphans f\n",
    "    JOIN\n",
    "        admin_entities a ON f.geonameId = a.geonameId\n",
    "    LEFT JOIN\n",
    "        allCountries p ON f.parent_id = p.geonameId\n",
    "    JOIN\n",
    "        allCountries c ON a.admin0_code = c.admin0_code AND c.feature_code LIKE 'PCL%'\n",
    "    WHERE\n",
    "        a.admin_level = {level}\n",
    "    ORDER BY\n",
    "        geonameId\n",
    "    \"\"\")\n",
    "    # Create primary key and other indexes\n",
    "    con.execute(f\"CREATE INDEX idx_{table_name}_gid ON {table_name} (geonameId)\")\n",
    "\n",
    "    if level > 0:\n",
    "        # Create indexes for parent relationships\n",
    "        con.execute(f\"CREATE INDEX idx_{table_name}_parent ON {table_name} (parent_id)\")\n",
    "        con.execute(f\"CREATE INDEX idx_{table_name}_admin0_code ON {table_name} (admin0_code)\")\n",
    "\n",
    "        # Create admin code index specific to this level\n",
    "        con.execute(f\"CREATE INDEX idx_{table_name}_code ON {table_name} (admin{level}_code)\")\n",
    "\n",
    "    # Create FTS index with optimized fields for search\n",
    "    create_fts_fields = \"geonameId, name, asciiname, alternatenames\"\n",
    "    if level == 0:\n",
    "        create_fts_fields += \", official_name, ISO, ISO3, fips\"\n",
    "\n",
    "\n",
    "    con.execute(f\"\"\"\n",
    "    PRAGMA create_fts_index(\n",
    "        {table_name},\n",
    "        {create_fts_fields},\n",
    "        stemmer = 'none',\n",
    "        stopwords = 'none',\n",
    "        ignore = '(\\\\.|[^a-z0-9])+',\n",
    "        overwrite = 1\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    # Report count\n",
    "    count = con.execute(f\"SELECT COUNT(*) FROM {table_name}\").fetchone()[0]\n",
    "    print(f\"Created {table_name} with {count} entities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating unified admin search view...\n",
      "Admin hierarchy construction complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating unified admin search view...\")\n",
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE VIEW admin_search AS\n",
    "\n",
    "-- Countries (admin0)\n",
    "SELECT\n",
    "    geonameId,\n",
    "    name,\n",
    "    asciiname,\n",
    "    0 AS admin_level,\n",
    "    admin0_code,\n",
    "    NULL AS admin1_code,\n",
    "    NULL AS admin2_code,\n",
    "    NULL AS admin3_code,\n",
    "    NULL AS admin4_code,\n",
    "    NULL AS parent_name,  -- Add NULL placeholder for admin0\n",
    "    parent_id,\n",
    "    feature_class,\n",
    "    feature_code,\n",
    "    population,\n",
    "    alternatenames,\n",
    "    'admin0' AS source_table\n",
    "FROM\n",
    "    admin0\n",
    "\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    -- Admin1 entities (states/provinces)\n",
    "SELECT\n",
    "    geonameId,\n",
    "    name,\n",
    "    asciiname,\n",
    "    1 AS admin_level,\n",
    "    admin0_code,\n",
    "    admin1_code,\n",
    "    NULL AS admin2_code,\n",
    "    NULL AS admin3_code,\n",
    "    NULL AS admin4_code,\n",
    "    parent_name,\n",
    "    parent_id,\n",
    "    feature_class,\n",
    "    feature_code,\n",
    "    population,\n",
    "    alternatenames,\n",
    "    'admin1' AS source_table\n",
    "FROM\n",
    "    admin1\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    -- Admin2 entities (counties/districts)\n",
    "\n",
    "SELECT\n",
    "    geonameId,\n",
    "    name,\n",
    "    asciiname,\n",
    "    2 AS admin_level,\n",
    "    admin0_code,\n",
    "    admin1_code,\n",
    "    admin2_code,\n",
    "    NULL AS admin3_code,\n",
    "    NULL AS admin4_code,\n",
    "    parent_name,\n",
    "    parent_id,\n",
    "    feature_class,\n",
    "    feature_code,\n",
    "    population,\n",
    "    alternatenames,\n",
    "    'admin2' AS source_table\n",
    "FROM\n",
    "    admin2\n",
    "\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    -- Admin3 entities (municipalities)\n",
    "\n",
    "SELECT\n",
    "    geonameId,\n",
    "    name,\n",
    "    asciiname,\n",
    "    3 AS admin_level,\n",
    "    admin0_code,\n",
    "    admin1_code,\n",
    "    admin2_code,\n",
    "    admin3_code,\n",
    "    NULL AS admin4_code,\n",
    "    parent_name,\n",
    "    parent_id,\n",
    "    feature_class,\n",
    "    feature_code,\n",
    "    population,\n",
    "    alternatenames,\n",
    "    'admin3' AS source_table\n",
    "FROM\n",
    "    admin3\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    -- Admin4 entities (neighborhoods/villages)\n",
    "SELECT\n",
    "    geonameId,\n",
    "    name,\n",
    "    asciiname,\n",
    "    4 AS admin_level,\n",
    "    admin0_code,\n",
    "    admin1_code,\n",
    "    admin2_code,\n",
    "    admin3_code,\n",
    "    admin4_code,\n",
    "    parent_name,\n",
    "    parent_id,\n",
    "    feature_class,\n",
    "    feature_code,\n",
    "    population,\n",
    "    alternatenames,\n",
    "    'admin4' AS source_table\n",
    "FROM\n",
    "    admin4\n",
    "\n",
    "    \"\"\")\n",
    "\n",
    "    # Clean up temporary tables\n",
    "\n",
    "\n",
    "print(\"Admin hierarchy construction complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x10558b370>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"DROP TABLE IF EXISTS admin_entities\")\n",
    "con.execute(\"DROP TABLE IF EXISTS admin_hierarchy_full\")\n",
    "con.execute(\"DROP TABLE IF EXISTS orphaned_entities\")\n",
    "con.execute(\"DROP TABLE IF EXISTS fixed_orphans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 534106 entities and 508066 hierarchical relationships\n",
      "Entity columns: ['geonameId', 'name', 'feature_class', 'feature_code']\n",
      "Hierarchy columns: ['parentId', 'childId', 'type']\n"
     ]
    }
   ],
   "source": [
    "entities_df = con.execute(f\"\"\"\n",
    "    SELECT {GID}, name, feature_class, feature_code\n",
    "    FROM unique_ids\n",
    "\"\"\").pl()\n",
    "\n",
    "hierarchy_df = con.execute(\"\"\"\n",
    "    SELECT parentId, childId, type\n",
    "    FROM hierarchy\n",
    "\"\"\").pl()\n",
    "# Optional: Print some diagnostics\n",
    "print(\n",
    "    f\"Loaded {len(entities_df)} entities and {len(hierarchy_df)} hierarchical relationships\"\n",
    ")\n",
    "print(\"Entity columns:\", entities_df.columns)\n",
    "print(\"Hierarchy columns:\", hierarchy_df.columns)\n",
    "\n",
    "# 2. Setup Kuzu database connection\n",
    "gdb_path = Path(\"./data/db/graph_db\")\n",
    "gdb_path.mkdir(parents=True, exist_ok=True)\n",
    "gdb = kz.Database(gdb_path.as_posix())\n",
    "conn = kz.Connection(gdb)\n",
    "\n",
    "# 3. Create the schema in Kuzu if needed\n",
    "if \"Entity\" not in conn.execute(\"CALL SHOW_TABLES() RETURN *;\").get_as_pl().get_column(\n",
    "    \"name\"\n",
    "):\n",
    "    conn.execute(sql_file(\"create_node_entity.sql\"))\n",
    "    print(\"Created Entity table\")\n",
    "\n",
    "if \"IsIn\" not in conn.execute(\"CALL SHOW_TABLES() RETURN *;\").get_as_pl().get_column(\n",
    "    \"name\"\n",
    "):\n",
    "    conn.execute(sql_file(\"create_relation_IsIn.sql\"))\n",
    "    print(\"Created IsIn table\")\n",
    "\n",
    "    # 4. Check if tables already have data\n",
    "are_nodes = (\n",
    "    conn.execute(\"MATCH (e:Entity) RETURN count(e) > 0 AS HasData\")\n",
    "    .get_as_pl()\n",
    "    .get_column(\"HasData\")[0]\n",
    ")\n",
    "are_edges = (\n",
    "    conn.execute(\"MATCH ()-[r:IsIn]->() RETURN count(r) > 0 AS HasData\")\n",
    "    .get_as_pl()\n",
    "    .get_column(\"HasData\")[0]\n",
    ")\n",
    "\n",
    "if not are_nodes:\n",
    "    conn.execute(\n",
    "        f\"COPY Entity FROM (LOAD FROM entities_df RETURN {GID}, name, feature_class, feature_code)\"\n",
    "    )\n",
    "    print(\"Loaded Entity\")\n",
    "\n",
    "if not are_edges:\n",
    "    conn.execute(\n",
    "        \"COPY IsIn FROM (LOAD FROM hierarchy_df RETURN parentId, childId, type)\"\n",
    "    )\n",
    "    print(\"Loaded IsIn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>feature_class</th><th>feature_code</th></tr><tr><td>u32</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>11820342</td><td>&quot;Horn of Africa&quot;</td><td>&quot;L&quot;</td><td>&quot;RGN&quot;</td></tr><tr><td>6255146</td><td>&quot;Africa&quot;</td><td>&quot;L&quot;</td><td>&quot;CONT&quot;</td></tr><tr><td>7729889</td><td>&quot;Eastern Africa&quot;</td><td>&quot;L&quot;</td><td>&quot;RGN&quot;</td></tr><tr><td>11812257</td><td>&quot;Commonwealth of Nations&quot;</td><td>&quot;A&quot;</td><td>&quot;ZN&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 4)\n",
       "┌───────────┬─────────────────────────┬───────────────┬──────────────┐\n",
       "│ geonameId ┆ name                    ┆ feature_class ┆ feature_code │\n",
       "│ ---       ┆ ---                     ┆ ---           ┆ ---          │\n",
       "│ u32       ┆ str                     ┆ str           ┆ str          │\n",
       "╞═══════════╪═════════════════════════╪═══════════════╪══════════════╡\n",
       "│ 11820342  ┆ Horn of Africa          ┆ L             ┆ RGN          │\n",
       "│ 6255146   ┆ Africa                  ┆ L             ┆ CONT         │\n",
       "│ 7729889   ┆ Eastern Africa          ┆ L             ┆ RGN          │\n",
       "│ 11812257  ┆ Commonwealth of Nations ┆ A             ┆ ZN           │\n",
       "└───────────┴─────────────────────────┴───────────────┴──────────────┘"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_children_query(geoname_id: int) -> str:\n",
    "    query = f\"\"\"MATCH (p:Entity {{geonameId: {geoname_id}}})-[:IsIn]->(c:Entity)\n",
    "    RETURN c.{GID} AS {GID}, c.name AS name, c.feature_class AS feature_class, c.feature_code AS feature_code;\"\"\"\n",
    "    return query\n",
    "\n",
    "\n",
    "def get_parents_query(geoname_id):\n",
    "    query = f\"\"\"MATCH (c:Entity {{geonameId: {geoname_id}}})<-[:IsIn]-(p:Entity)\n",
    "    RETURN p.{GID} AS {GID}, p.name AS name, p.feature_class AS feature_class, p.feature_code AS feature_code;\"\"\"\n",
    "    return query\n",
    "\n",
    "\n",
    "# MATCH (c:Entity) WHERE CAST(c.geonameId, \"INT64\") IN list_creation({formatted_ids}) RETURN *;\n",
    "def get_children_querys(\n",
    "    geoname_ids: list[int] | pl.Series, traverse: bool = False\n",
    ") -> str:\n",
    "    query = f\"\"\"MATCH (p:Entity)-[:IsIn{\"*\" if traverse else \"\"}]->(c:Entity)\n",
    "    WHERE p.geonameId IN CAST({geoname_ids}, \"UINT32[]\")\n",
    "    RETURN DISTINCT c.{GID} AS {GID}, c.name AS name, c.feature_class AS feature_class, c.feature_code AS feature_code;\"\"\"\n",
    "    return query\n",
    "\n",
    "\n",
    "def get_parents_querys(\n",
    "    geoname_ids: list[int] | pl.Series, traverse: bool = False\n",
    ") -> str:\n",
    "    query = f\"\"\"MATCH (c:Entity)<-[:IsIn{\"*\" if traverse else \"\"}]-(p:Entity)\n",
    "    WHERE c.geonameId IN CAST({geoname_ids}, \"UINT32[]\")\n",
    "    RETURN DISTINCT p.{GID} AS {GID}, p.name AS name, p.feature_class AS feature_class, p.feature_code AS feature_code;\"\"\"\n",
    "    return query\n",
    "\n",
    "\n",
    "def get_highest_parent_query():\n",
    "    query = f\"\"\"\n",
    "    MATCH (entity:Entity)\n",
    "    WHERE NOT (entity)<-[:IsIn]-(:Entity)\n",
    "    RETURN entity.{GID} AS {GID}, entity.name AS name, entity.feature_class AS feature_class, entity.feature_code AS feature_code;\"\"\"\n",
    "    return query\n",
    "\n",
    "\n",
    "conn.execute(get_parents_query(49518)).get_as_pl()\n",
    "conn.execute(get_children_query(6252001)).get_as_pl()\n",
    "conn.execute(get_children_querys([49518, 51537])).get_as_pl()\n",
    "conn.execute(get_parents_querys([49518, 51537])).get_as_pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_orphaned_admin_entities(con, conn):\n",
    "    \"\"\"Fix orphaned admin entities using both admin codes and graph traversal.\"\"\"\n",
    "\n",
    "    # Find entities with admin level feature codes that aren't in any admin table\n",
    "    orphans_query = \"\"\"\n",
    "    SELECT a.geonameId, a.name, a.feature_code, a.admin0_code, a.admin1_code, a.admin2_code, a.admin3_code\n",
    "    FROM allCountries a\n",
    "    WHERE a.feature_code LIKE 'ADM%'\n",
    "    AND a.geonameId NOT IN (\n",
    "        SELECT geonameId FROM admin0\n",
    "        UNION ALL SELECT geonameId FROM admin1\n",
    "        UNION ALL SELECT geonameId FROM admin2\n",
    "        UNION ALL SELECT geonameId FROM admin3\n",
    "        UNION ALL SELECT geonameId FROM admin4\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    orphans_df = con.execute(orphans_query).pl()\n",
    "    if len(orphans_df) == 0:\n",
    "        print(\"No orphaned admin entities found!\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(orphans_df)} orphaned admin entities.\")\n",
    "\n",
    "    # Try to find parents using graph database first\n",
    "    orphan_ids = orphans_df[\"geonameId\"].to_list()\n",
    "    parents_query = f\"\"\"\n",
    "    MATCH (c:Entity)<-[:IsIn]-(p:Entity)\n",
    "    WHERE c.geonameId IN CAST({orphan_ids}, \"UINT32[]\")\n",
    "    RETURN c.geonameId AS geonameId, p.geonameId AS parent_id\n",
    "    \"\"\"\n",
    "\n",
    "    parent_links = conn.execute(parents_query).get_as_pl()\n",
    "\n",
    "    # For remaining orphans without graph parents, try to infer level and parent using admin codes\n",
    "    code_linked = 0\n",
    "    for orphan in orphans_df.filter(~pl.col(\"geonameId\").is_in(parent_links[\"geonameId\"])).iter_rows(named=True):\n",
    "        level = None\n",
    "        if \"ADM1\" in orphan[\"feature_code\"]:\n",
    "            level = 1\n",
    "        elif \"ADM2\" in orphan[\"feature_code\"]:\n",
    "            level = 2\n",
    "        elif \"ADM3\" in orphan[\"feature_code\"]:\n",
    "            level = 3\n",
    "        elif \"ADM4\" in orphan[\"feature_code\"]:\n",
    "            level = 4\n",
    "\n",
    "        if level:\n",
    "            # Based on level, try to add to appropriate admin table using code-based parent\n",
    "            con.execute(f\"\"\"\n",
    "            INSERT INTO admin{level} (\n",
    "                SELECT\n",
    "                    a.geonameId,\n",
    "                    a.name,\n",
    "                    a.asciiname,\n",
    "                    a.admin0_code,\n",
    "                    {\"a.admin1_code\" if level >= 1 else \"NULL AS admin1_code\"},\n",
    "                    {\"a.admin2_code\" if level >= 2 else \"NULL AS admin2_code\"},\n",
    "                    {\"a.admin3_code\" if level >= 3 else \"NULL AS admin3_code\"},\n",
    "                    {\"a.admin4_code\" if level >= 4 else \"NULL AS admin4_code\"},\n",
    "                    a.feature_class,\n",
    "                    a.feature_code,\n",
    "                    a.population,\n",
    "                    -- Try to find parent ID from previous level\n",
    "                    (\n",
    "                        SELECT parent.geonameId FROM admin{level-1} parent\n",
    "                        WHERE parent.admin0_code = a.admin0_code\n",
    "                        {\"AND parent.admin1_code = a.admin1_code\" if level >= 2 else \"\"}\n",
    "                        {\"AND parent.admin2_code = a.admin2_code\" if level >= 3 else \"\"}\n",
    "                        {\"AND parent.admin3_code = a.admin3_code\" if level >= 4 else \"\"}\n",
    "                        LIMIT 1\n",
    "                    ) AS parent_id,\n",
    "                    c.name AS country_name,\n",
    "                    parent.name AS parent_name,\n",
    "                    a.alternatenames\n",
    "                FROM\n",
    "                    allCountries a\n",
    "                LEFT JOIN\n",
    "                    admin0 c ON a.admin0_code = c.admin0_code\n",
    "                LEFT JOIN\n",
    "                    admin{level-1} parent ON\n",
    "                        parent.admin0_code = a.admin0_code\n",
    "                        {\"AND parent.admin1_code = a.admin1_code\" if level >= 2 else \"\"}\n",
    "                        {\"AND parent.admin2_code = a.admin2_code\" if level >= 3 else \"\"}\n",
    "                        {\"AND parent.admin3_code = a.admin3_code\" if level >= 4 else \"\"}\n",
    "                WHERE\n",
    "                    a.geonameId = {orphan[\"geonameId\"]}\n",
    "            )\n",
    "            \"\"\")\n",
    "            code_linked += 1\n",
    "\n",
    "\n",
    "    print(f\"Fixed {len(parent_links)} orphans using graph relationships and {code_linked} using admin codes\")\n",
    "\n",
    "def create_admin_search_view(con):\n",
    "    \"\"\"Create a unified view for searching across all admin levels.\"\"\"\n",
    "\n",
    "    print(\"Creating unified admin search view...\")\n",
    "    con.execute(\"\"\"\n",
    "    CREATE OR REPLACE VIEW admin_search AS\n",
    "\n",
    "    -- Countries (admin0)\n",
    "    SELECT\n",
    "        geonameId,\n",
    "        name,\n",
    "        asciiname,\n",
    "        0 AS admin_level,\n",
    "        admin0_code,\n",
    "        NULL AS admin1_code,\n",
    "        NULL AS admin2_code,\n",
    "        NULL AS admin3_code,\n",
    "        NULL AS admin4_code,\n",
    "        NULL AS parent_name,\n",
    "        NULL AS parent_id,\n",
    "        feature_class,\n",
    "        feature_code,\n",
    "        Population AS population,\n",
    "        alternatenames,\n",
    "        'admin0' AS source_table\n",
    "    FROM\n",
    "        admin0\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    -- Admin1 entities\n",
    "    SELECT\n",
    "        geonameId,\n",
    "        name,\n",
    "        asciiname,\n",
    "        1 AS admin_level,\n",
    "        admin0_code,\n",
    "        admin1_code,\n",
    "        NULL AS admin2_code,\n",
    "        NULL AS admin3_code,\n",
    "        NULL AS admin4_code,\n",
    "        parent_name,\n",
    "        parent_id,\n",
    "        feature_class,\n",
    "        feature_code,\n",
    "        population,\n",
    "        alternatenames,\n",
    "        'admin1' AS source_table\n",
    "    FROM\n",
    "        admin1\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    -- Admin2 entities\n",
    "    SELECT\n",
    "        geonameId,\n",
    "        name,\n",
    "        asciiname,\n",
    "        2 AS admin_level,\n",
    "        admin0_code,\n",
    "        admin1_code,\n",
    "        admin2_code,\n",
    "        NULL AS admin3_code,\n",
    "        NULL AS admin4_code,\n",
    "        parent_name,\n",
    "        parent_id,\n",
    "        feature_class,\n",
    "        feature_code,\n",
    "        population,\n",
    "        alternatenames,\n",
    "        'admin2' AS source_table\n",
    "    FROM\n",
    "        admin2\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    -- Admin3 entities\n",
    "    SELECT\n",
    "        geonameId,\n",
    "        name,\n",
    "        asciiname,\n",
    "        3 AS admin_level,\n",
    "        admin0_code,\n",
    "        admin1_code,\n",
    "        admin2_code,\n",
    "        admin3_code,\n",
    "        NULL AS admin4_code,\n",
    "        parent_name,\n",
    "        parent_id,\n",
    "        feature_class,\n",
    "        feature_code,\n",
    "        population,\n",
    "        alternatenames,\n",
    "        'admin3' AS source_table\n",
    "    FROM\n",
    "        admin3\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    -- Admin4 entities\n",
    "    SELECT\n",
    "        geonameId,\n",
    "        name,\n",
    "        asciiname,\n",
    "        4 AS admin_level,\n",
    "        admin0_code,\n",
    "        admin1_code,\n",
    "        admin2_code,\n",
    "        admin3_code,\n",
    "        admin4_code,\n",
    "        parent_name,\n",
    "        parent_id,\n",
    "        feature_class,\n",
    "        feature_code,\n",
    "        population,\n",
    "        alternatenames,\n",
    "        'admin4' AS source_table\n",
    "    FROM\n",
    "        admin4\n",
    "    \"\"\")\n",
    "\n",
    "    print(\"Admin search view created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_admin_tables_hybrid(con, conn, overwrite=True):\n",
    "    \"\"\"Build admin tables using graph database for relationships and DuckDB for storage.\"\"\"\n",
    "\n",
    "    print(\"Starting hybrid admin table construction...\")\n",
    "\n",
    "    # Define admin level feature code patterns\n",
    "    level_codes = {\n",
    "        0: [\"PCL\", \"PCLI\", \"PCLD\", \"PCLF\", \"PCLS\", \"TERR\"],\n",
    "        1: [\"ADM1\", \"ADM1H\"],\n",
    "        2: [\"ADM2\", \"ADM2H\"],\n",
    "        3: [\"ADM3\", \"ADM3H\"],\n",
    "        4: [\"ADM4\", \"ADM4H\"]\n",
    "    }\n",
    "\n",
    "    # Track entities at each admin level\n",
    "    admin_entities = {}\n",
    "\n",
    "    # Build admin tables one by one\n",
    "    for level in range(0, 5):\n",
    "        table_name = f\"admin{level}\"\n",
    "\n",
    "        if table_exists(con, table_name) and not overwrite:\n",
    "            print(f\"Table {table_name} already exists. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Building {table_name} table...\")\n",
    "\n",
    "        # Step 1: Identify entities of this admin level by feature code\n",
    "        feature_patterns = \"', '\".join([code for code in level_codes[level]])\n",
    "        base_entities_query = f\"\"\"\n",
    "            SELECT geonameId\n",
    "            FROM allCountries\n",
    "            WHERE feature_code IN ('{feature_patterns}')\n",
    "            OR feature_code LIKE '{level_codes[level][0]}%'\n",
    "        \"\"\"\n",
    "\n",
    "        level_entities = set(con.execute(base_entities_query).pl()[\"geonameId\"])\n",
    "        print(f\"Found {len(level_entities)} initial entities for level {level}\")\n",
    "\n",
    "        # Step 2: For levels 1-4, use graph DB to validate hierarchical placement\n",
    "        # This ensures entities are correctly placed in the admin hierarchy\n",
    "        if level > 0 and level-1 in admin_entities:\n",
    "            # Find all direct children of the previous level's entities\n",
    "            previous_level_ids = list(admin_entities[level-1])\n",
    "\n",
    "            # Use graph DB to get valid children\n",
    "            children_query = f\"\"\"\n",
    "            MATCH (p:Entity)-[:IsIn]->(c:Entity)\n",
    "            WHERE p.geonameId IN CAST({previous_level_ids}, \"UINT32[]\")\n",
    "            RETURN DISTINCT c.geonameId AS geonameId\n",
    "            \"\"\"\n",
    "\n",
    "            valid_children = set(conn.execute(children_query).get_as_pl()[\"geonameId\"])\n",
    "            print(f\"Found {len(valid_children)} valid children from graph relationships\")\n",
    "\n",
    "            # Combine feature-based and relationship-based entities\n",
    "            level_entities = level_entities.union(valid_children)\n",
    "\n",
    "        admin_entities[level] = level_entities\n",
    "\n",
    "        # Step 3: Create the admin table with appropriate fields\n",
    "        if level == 0:  # Special case for countries\n",
    "            create_query = f\"\"\"\n",
    "            CREATE OR REPLACE TABLE {table_name} AS\n",
    "            SELECT\n",
    "                a.geonameId,\n",
    "                a.name,\n",
    "                a.asciiname,\n",
    "                a.admin0_code,\n",
    "                a.feature_class,\n",
    "                a.feature_code,\n",
    "                c.ISO,\n",
    "                c.ISO3,\n",
    "                c.ISO_Numeric,\n",
    "                c.Country AS official_name,\n",
    "                c.fips,\n",
    "                c.Population,\n",
    "                c.Area,\n",
    "                a.alternatenames,\n",
    "                NULL AS parent_id  -- No parent for countries\n",
    "            FROM\n",
    "                allCountries a\n",
    "            LEFT JOIN\n",
    "                countryInfo c ON a.geonameId = c.geonameId\n",
    "            WHERE\n",
    "                a.geonameId IN ({','.join(map(str, level_entities))})\n",
    "            ORDER BY\n",
    "                a.geonameId\n",
    "            \"\"\"\n",
    "        else:\n",
    "            # For admin levels 1-4, include parent relationship\n",
    "            create_query = f\"\"\"\n",
    "            CREATE OR REPLACE TABLE {table_name} AS\n",
    "            WITH parent_links AS (\n",
    "                SELECT\n",
    "                    childId AS geonameId,\n",
    "                    parentId AS parent_id\n",
    "                FROM\n",
    "                    hierarchy\n",
    "                WHERE\n",
    "                    type = 'ADM' AND\n",
    "                    childId IN ({','.join(map(str, level_entities))})\n",
    "            )\n",
    "            SELECT\n",
    "                a.geonameId,\n",
    "                a.name,\n",
    "                a.asciiname,\n",
    "                a.admin0_code\n",
    "                {\", a.admin1_code\" if level >= 1 else \", NULL AS admin1_code\"}\n",
    "                {\", a.admin2_code\" if level >= 2 else \", NULL AS admin2_code\"}\n",
    "                {\", a.admin3_code\" if level >= 3 else \", NULL AS admin3_code\"}\n",
    "                {\", a.admin4_code\" if level >= 4 else \", NULL AS admin4_code\"},\n",
    "                a.feature_class,\n",
    "                a.feature_code,\n",
    "                a.population,\n",
    "                p.parent_id,\n",
    "                c.name AS country_name,\n",
    "                CASE\n",
    "                    WHEN p.parent_id IS NOT NULL THEN parent.name\n",
    "                    ELSE NULL\n",
    "                END AS parent_name,\n",
    "                a.alternatenames\n",
    "            FROM\n",
    "                allCountries a\n",
    "            LEFT JOIN\n",
    "                parent_links p ON a.geonameId = p.geonameId\n",
    "            LEFT JOIN\n",
    "                allCountries parent ON p.parent_id = parent.geonameId\n",
    "            LEFT JOIN\n",
    "                admin0 c ON a.admin0_code = c.admin0_code\n",
    "            WHERE\n",
    "                a.geonameId IN ({','.join(map(str, level_entities))})\n",
    "            ORDER BY\n",
    "                a.geonameId\n",
    "            \"\"\"\n",
    "\n",
    "        # Execute the query to create the table\n",
    "        con.execute(create_query)\n",
    "\n",
    "        # Step 4: Add indexes and FTS\n",
    "        con.execute(f\"CREATE INDEX idx_{table_name}_gid ON {table_name} (geonameId)\")\n",
    "\n",
    "        if level > 0:\n",
    "            # Create indexes for parent relationships\n",
    "            con.execute(f\"CREATE INDEX idx_{table_name}_parent ON {table_name} (parent_id)\")\n",
    "            con.execute(f\"CREATE INDEX idx_{table_name}_admin0 ON {table_name} (admin0_code)\")\n",
    "\n",
    "            # Create admin code index specific to this level\n",
    "            if level <= 4:\n",
    "                con.execute(f\"CREATE INDEX idx_{table_name}_code ON {table_name} (admin{level}_code)\")\n",
    "\n",
    "        # Create FTS index for searching\n",
    "        fts_fields = \"geonameId, name, asciiname, alternatenames\"\n",
    "        if level == 0:\n",
    "            fts_fields += \", official_name, ISO, ISO3\"\n",
    "\n",
    "        con.execute(f\"\"\"\n",
    "        PRAGMA create_fts_index(\n",
    "            {table_name},\n",
    "            {fts_fields},\n",
    "            stemmer = 'none',\n",
    "            stopwords = 'none',\n",
    "            ignore = '(\\\\.|[^a-z0-9])+',\n",
    "            overwrite = 1\n",
    "        )\n",
    "        \"\"\")\n",
    "\n",
    "        # Report count\n",
    "        count = con.execute(f\"SELECT COUNT(*) FROM {table_name}\").fetchone()[0]\n",
    "        print(f\"Created {table_name} with {count} entities\")\n",
    "\n",
    "    # Step 5: Handle orphaned entities\n",
    "    print(\"\\nChecking for orphaned administrative entities...\")\n",
    "    handle_orphaned_admin_entities(con, conn)\n",
    "\n",
    "    # Step 6: Create a unified admin search view\n",
    "    create_admin_search_view(con)\n",
    "\n",
    "    print(\"Hybrid admin table construction complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hybrid admin table construction...\n",
      "Building admin0 table...\n",
      "Found 271 initial entities for level 0\n",
      "Created admin0 with 271 entities\n",
      "Building admin1 table...\n",
      "Found 4500 initial entities for level 1\n",
      "Found 4008 valid children from graph relationships\n",
      "Created admin1 with 4925 entities\n",
      "Building admin2 table...\n",
      "Found 48830 initial entities for level 2\n",
      "Found 46490 valid children from graph relationships\n",
      "Created admin2 with 55240 entities\n",
      "Building admin3 table...\n",
      "Found 169901 initial entities for level 3\n",
      "Found 155895 valid children from graph relationships\n",
      "Created admin3 with 238153 entities\n",
      "Building admin4 table...\n",
      "Found 227091 initial entities for level 4\n",
      "Found 112152 valid children from graph relationships\n",
      "Created admin4 with 270860 entities\n",
      "\n",
      "Checking for orphaned administrative entities...\n",
      "Found 90154 orphaned admin entities.\n",
      "Fixed 14952 orphans using graph relationships and 0 using admin codes\n",
      "Creating unified admin search view...\n",
      "Admin search view created!\n",
      "Hybrid admin table construction complete!\n"
     ]
    }
   ],
   "source": [
    "build_admin_tables_hybrid(con, conn, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4_925, 15)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>asciiname</th><th>admin0_code</th><th>admin1_code</th><th>admin2_code</th><th>admin3_code</th><th>admin4_code</th><th>feature_class</th><th>feature_code</th><th>population</th><th>parent_id</th><th>country_name</th><th>parent_name</th><th>alternatenames</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i32</td><td>i32</td><td>i32</td><td>str</td><td>str</td><td>i64</td><td>i32</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>12</td><td>&quot;Takht-e Qeyşar&quot;</td><td>&quot;Takht-e Qeysar&quot;</td><td>&quot;IR&quot;</td><td>&quot;15&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;P&quot;</td><td>&quot;PPL&quot;</td><td>1266</td><td>null</td><td>&quot;Islamic Republic of Iran&quot;</td><td>null</td><td>&quot;Takht-e Azadi,Takht-e Qeysar,T…</td></tr><tr><td>13</td><td>&quot;Takht Arreh Yek&quot;</td><td>&quot;Takht Arreh Yek&quot;</td><td>&quot;IR&quot;</td><td>&quot;15&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;P&quot;</td><td>&quot;PPL&quot;</td><td>0</td><td>null</td><td>&quot;Islamic Republic of Iran&quot;</td><td>null</td><td>&quot;Takht Arreh Yek,tkht arh yk,تخ…</td></tr><tr><td>432</td><td>&quot;Kūh-e Qal‘eh Toshak&quot;</td><td>&quot;Kuh-e Qal`eh Toshak&quot;</td><td>&quot;IR&quot;</td><td>&quot;35&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;T&quot;</td><td>&quot;MT&quot;</td><td>0</td><td>null</td><td>&quot;Islamic Republic of Iran&quot;</td><td>null</td><td>&quot;Kuh-e Ab-e Sefid,Kuh-e Qal`eh …</td></tr><tr><td>50360</td><td>&quot;Gobolka Woqooyi Galbeed&quot;</td><td>&quot;Gobolka Woqooyi Galbeed&quot;</td><td>&quot;SO&quot;</td><td>&quot;20&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM1&quot;</td><td>1240000</td><td>51537</td><td>&quot;Somalia&quot;</td><td>&quot;Somalia&quot;</td><td>&quot;Gobolka Woqooyi Galbeed,Hargei…</td></tr><tr><td>51230</td><td>&quot;Gobolka Togdheer&quot;</td><td>&quot;Gobolka Togdheer&quot;</td><td>&quot;SO&quot;</td><td>&quot;19&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM1&quot;</td><td>350000</td><td>51537</td><td>&quot;Somalia&quot;</td><td>&quot;Somalia&quot;</td><td>&quot;Burao,Dohdayr,Gobolka Togdheer…</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>12902746</td><td>&quot;Ouham-Fafa&quot;</td><td>&quot;Ouham-Fafa&quot;</td><td>&quot;CF&quot;</td><td>&quot;20&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM1&quot;</td><td>225479</td><td>239880</td><td>&quot;Central African Republic&quot;</td><td>&quot;Central African Republic&quot;</td><td>null</td></tr><tr><td>12902747</td><td>&quot;Lim-Pendé&quot;</td><td>&quot;Lim-Pende&quot;</td><td>&quot;CF&quot;</td><td>&quot;21&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM1&quot;</td><td>442151</td><td>239880</td><td>&quot;Central African Republic&quot;</td><td>&quot;Central African Republic&quot;</td><td>null</td></tr><tr><td>12902749</td><td>&quot;Central Ethiopia Regional Stat…</td><td>&quot;Central Ethiopia Regional Stat…</td><td>&quot;ET&quot;</td><td>&quot;55&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM1&quot;</td><td>9382700</td><td>337996</td><td>&quot;Federal Democratic Republic of…</td><td>&quot;Federal Democratic Republic of…</td><td>null</td></tr><tr><td>12902766</td><td>&quot;South Ethiopia Regional State&quot;</td><td>&quot;South Ethiopia Regional State&quot;</td><td>&quot;ET&quot;</td><td>&quot;56&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM1&quot;</td><td>7728100</td><td>337996</td><td>&quot;Federal Democratic Republic of…</td><td>&quot;Federal Democratic Republic of…</td><td>null</td></tr><tr><td>12902784</td><td>&quot;South West Ethiopia Peoples&#x27; R…</td><td>&quot;South West Ethiopia Peoples&#x27; R…</td><td>&quot;ET&quot;</td><td>&quot;SW&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM1&quot;</td><td>2437200</td><td>337996</td><td>&quot;Federal Democratic Republic of…</td><td>&quot;Federal Democratic Republic of…</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4_925, 15)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ geonameId ┆ name      ┆ asciiname ┆ admin0_co ┆ … ┆ parent_id ┆ country_n ┆ parent_na ┆ alternat │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ de        ┆   ┆ ---       ┆ ame       ┆ me        ┆ enames   │\n",
       "│ i32       ┆ str       ┆ str       ┆ ---       ┆   ┆ i32       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆           ┆ str       ┆   ┆           ┆ str       ┆ str       ┆ str      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 12        ┆ Takht-e   ┆ Takht-e   ┆ IR        ┆ … ┆ null      ┆ Islamic   ┆ null      ┆ Takht-e  │\n",
       "│           ┆ Qeyşar    ┆ Qeysar    ┆           ┆   ┆           ┆ Republic  ┆           ┆ Azadi,Ta │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ of Iran   ┆           ┆ kht-e    │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ Qeysar,T │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ …        │\n",
       "│ 13        ┆ Takht     ┆ Takht     ┆ IR        ┆ … ┆ null      ┆ Islamic   ┆ null      ┆ Takht    │\n",
       "│           ┆ Arreh Yek ┆ Arreh Yek ┆           ┆   ┆           ┆ Republic  ┆           ┆ Arreh    │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ of Iran   ┆           ┆ Yek,tkht │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ arh      │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ yk,تخ…   │\n",
       "│ 432       ┆ Kūh-e     ┆ Kuh-e     ┆ IR        ┆ … ┆ null      ┆ Islamic   ┆ null      ┆ Kuh-e    │\n",
       "│           ┆ Qal‘eh    ┆ Qal`eh    ┆           ┆   ┆           ┆ Republic  ┆           ┆ Ab-e Sef │\n",
       "│           ┆ Toshak    ┆ Toshak    ┆           ┆   ┆           ┆ of Iran   ┆           ┆ id,Kuh-e │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ Qal`eh … │\n",
       "│ 50360     ┆ Gobolka   ┆ Gobolka   ┆ SO        ┆ … ┆ 51537     ┆ Somalia   ┆ Somalia   ┆ Gobolka  │\n",
       "│           ┆ Woqooyi   ┆ Woqooyi   ┆           ┆   ┆           ┆           ┆           ┆ Woqooyi  │\n",
       "│           ┆ Galbeed   ┆ Galbeed   ┆           ┆   ┆           ┆           ┆           ┆ Galbeed, │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ Hargei…  │\n",
       "│ 51230     ┆ Gobolka   ┆ Gobolka   ┆ SO        ┆ … ┆ 51537     ┆ Somalia   ┆ Somalia   ┆ Burao,Do │\n",
       "│           ┆ Togdheer  ┆ Togdheer  ┆           ┆   ┆           ┆           ┆           ┆ hdayr,Go │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ bolka    │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ Togdheer │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ …        │\n",
       "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
       "│ 12902746  ┆ Ouham-Faf ┆ Ouham-Faf ┆ CF        ┆ … ┆ 239880    ┆ Central   ┆ Central   ┆ null     │\n",
       "│           ┆ a         ┆ a         ┆           ┆   ┆           ┆ African   ┆ African   ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ Republic  ┆ Republic  ┆          │\n",
       "│ 12902747  ┆ Lim-Pendé ┆ Lim-Pende ┆ CF        ┆ … ┆ 239880    ┆ Central   ┆ Central   ┆ null     │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ African   ┆ African   ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ Republic  ┆ Republic  ┆          │\n",
       "│ 12902749  ┆ Central   ┆ Central   ┆ ET        ┆ … ┆ 337996    ┆ Federal   ┆ Federal   ┆ null     │\n",
       "│           ┆ Ethiopia  ┆ Ethiopia  ┆           ┆   ┆           ┆ Democrati ┆ Democrati ┆          │\n",
       "│           ┆ Regional  ┆ Regional  ┆           ┆   ┆           ┆ c         ┆ c         ┆          │\n",
       "│           ┆ Stat…     ┆ Stat…     ┆           ┆   ┆           ┆ Republic  ┆ Republic  ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ of…       ┆ of…       ┆          │\n",
       "│ 12902766  ┆ South     ┆ South     ┆ ET        ┆ … ┆ 337996    ┆ Federal   ┆ Federal   ┆ null     │\n",
       "│           ┆ Ethiopia  ┆ Ethiopia  ┆           ┆   ┆           ┆ Democrati ┆ Democrati ┆          │\n",
       "│           ┆ Regional  ┆ Regional  ┆           ┆   ┆           ┆ c         ┆ c         ┆          │\n",
       "│           ┆ State     ┆ State     ┆           ┆   ┆           ┆ Republic  ┆ Republic  ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ of…       ┆ of…       ┆          │\n",
       "│ 12902784  ┆ South     ┆ South     ┆ ET        ┆ … ┆ 337996    ┆ Federal   ┆ Federal   ┆ null     │\n",
       "│           ┆ West      ┆ West      ┆           ┆   ┆           ┆ Democrati ┆ Democrati ┆          │\n",
       "│           ┆ Ethiopia  ┆ Ethiopia  ┆           ┆   ┆           ┆ c         ┆ c         ┆          │\n",
       "│           ┆ Peoples'  ┆ Peoples'  ┆           ┆   ┆           ┆ Republic  ┆ Republic  ┆          │\n",
       "│           ┆ R…        ┆ R…        ┆           ┆   ┆           ┆ of…       ┆ of…       ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.table(\"admin1\").pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created composite indexes on admin code columns\n"
     ]
    }
   ],
   "source": [
    "def build_clean_admin_hierarchy(create_views=False, create_fts=True, overwrite=False):\n",
    "    \"\"\"Build admin hierarchy with strict level separation and clean boundaries.\"\"\"\n",
    "    print(\"Building clean administrative hierarchy...\")\n",
    "\n",
    "    # Check if country table exists\n",
    "    if not table_exists(con, \"admin0\"):\n",
    "        print(\"Error: admin0 table must exist first\")\n",
    "        return\n",
    "\n",
    "    # Define the distinct feature codes for each level\n",
    "    level_codes = {\n",
    "        1: [\"ADM1\", \"ADM1H\"],\n",
    "        2: [\"ADM2\", \"ADM2H\"],\n",
    "        3: [\"ADM3\", \"ADM3H\"],\n",
    "        4: [\"ADM4\", \"ADM4H\"],\n",
    "    }\n",
    "\n",
    "    # Get all country IDs first to exclude them from all admin tables\n",
    "    country_ids = set(con.execute(\"SELECT geonameId FROM admin0\").pl().to_series())\n",
    "    admin_ids = {0: country_ids}  # Level 0 = countries\n",
    "\n",
    "    # Process each level in sequence\n",
    "    for level in range(1, 5):\n",
    "        print(f\"\\n=== Building admin{level} table ===\")\n",
    "\n",
    "        # Skip if exists and not overwriting\n",
    "        if table_exists(con, f\"admin{level}\") and not overwrite:\n",
    "            print(f\"Table admin{level} already exists. Skipping.\")\n",
    "            admin_ids[level] = set(\n",
    "                con.execute(f\"SELECT geonameId FROM admin{level}\").pl().to_series()\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        # Get candidates with the correct feature code\n",
    "        feature_code_pattern = \", \".join([f\"'{code}'\" for code in level_codes[level]])\n",
    "        code_candidates = set(\n",
    "            con.execute(f\"\"\"\n",
    "            SELECT geonameId\n",
    "            FROM allCountries\n",
    "            WHERE feature_code IN ({feature_code_pattern})\n",
    "        \"\"\")\n",
    "            .pl()\n",
    "            .to_series()\n",
    "        )\n",
    "\n",
    "        # Get candidates from graph database parentage (direct children of previous level)\n",
    "        graph_candidates = set()\n",
    "        if level > 1 and level - 1 in admin_ids:\n",
    "            parent_ids = admin_ids[level - 1]\n",
    "            if parent_ids:\n",
    "                children_df = conn.execute(\n",
    "                    get_children_querys(list(parent_ids))\n",
    "                ).get_as_pl()\n",
    "                if not children_df.is_empty():\n",
    "                    graph_candidates = set(children_df[\"geonameId\"])\n",
    "\n",
    "        # Combine candidates\n",
    "        all_candidates = code_candidates.union(graph_candidates)\n",
    "\n",
    "        # Build exclusion set - exclude all entities from other admin levels\n",
    "        excluded_ids = set().union(*[ids for ids in admin_ids.values()])\n",
    "\n",
    "        # Get final set of IDs for this level\n",
    "        final_ids = all_candidates - excluded_ids\n",
    "\n",
    "        if not final_ids:\n",
    "            print(f\"Warning: No entities found for admin{level} table!\")\n",
    "            admin_ids[level] = set()\n",
    "            continue\n",
    "\n",
    "        # Create strict level condition\n",
    "        level_condition = f\"a.feature_code LIKE 'ADM{level}%' AND\"\n",
    "        if level == 1:\n",
    "            # For admin1, ensure no admin2, admin3, or admin4 codes\n",
    "            level_condition += \"\"\"\n",
    "                (admin1_code IS NOT NULL) AND\n",
    "                (admin2_code IS NULL) AND\n",
    "                (admin3_code IS NULL) AND\n",
    "                (admin4_code IS NULL)\n",
    "            \"\"\"\n",
    "        elif level == 2:\n",
    "            # For admin2, ensure admin1_code exists, but no admin3 or admin4 codes\n",
    "            level_condition += \"\"\"\n",
    "                (admin2_code IS NOT NULL) AND\n",
    "                (admin3_code IS NULL) AND\n",
    "                (admin4_code IS NULL)\n",
    "            \"\"\"\n",
    "        elif level == 3:\n",
    "            # For admin3, ensure admin1 and admin2 codes exist, but no admin4\n",
    "            level_condition += \"\"\"\n",
    "                (admin3_code IS NOT NULL) AND\n",
    "                (admin4_code IS NULL)\n",
    "            \"\"\"\n",
    "        else:  # level == 4\n",
    "            # For admin4, ensure admin1, admin2, and admin3 codes exist\n",
    "            level_condition = \"\"\"\n",
    "                (admin4_code IS NOT NULL)\n",
    "            \"\"\"\n",
    "\n",
    "        # Create the table with SQL\n",
    "        print(f\"Creating admin{level} table with strict level constraints...\")\n",
    "        con.execute(f\"\"\"\n",
    "        CREATE OR REPLACE TABLE admin{level} AS\n",
    "        SELECT a.*\n",
    "        FROM allCountries a\n",
    "        WHERE\n",
    "            a.geonameId IN ({\",\".join(map(str, final_ids))})\n",
    "            AND {level_condition}\n",
    "        ORDER BY a.geonameId\n",
    "        \"\"\")\n",
    "\n",
    "        # Store IDs for next level\n",
    "        admin_ids[level] = set(\n",
    "            con.execute(f\"SELECT geonameId FROM admin{level}\").pl().to_series()\n",
    "        )\n",
    "\n",
    "        # Create indexes and FTS\n",
    "        print(f\"Creating index on admin{level}...\")\n",
    "        con.execute(\n",
    "            f\"CREATE INDEX IF NOT EXISTS admin{level}_gid ON admin{level} (geonameId)\"\n",
    "        )\n",
    "\n",
    "        if create_views:\n",
    "            con.execute(sql_file(\"create_view_*_NODES.sql\", table=f\"admin{level}\"))\n",
    "            con.execute(sql_file(\"create_view_*_FTS.sql\", table=f\"admin{level}\"))\n",
    "\n",
    "        if create_fts:\n",
    "            con.execute(f\"\"\"\n",
    "            PRAGMA create_fts_index(\n",
    "                admin{level},\n",
    "                geonameId, name, asciiname, alternatenames, admin{level}_code,\n",
    "                stemmer='none', stopwords='none', ignore='(\\\\.|[^a-z0-9])+', overwrite=1\n",
    "            )\n",
    "            \"\"\")\n",
    "\n",
    "        # Report results\n",
    "        count = con.execute(f\"SELECT COUNT(*) FROM admin{level}\").fetchone()[0]\n",
    "        print(f\"Completed admin{level} table with {count} entities\")\n",
    "\n",
    "    # Print final statistics\n",
    "    print(\"\\nAdministrative hierarchy successfully built!\")\n",
    "    for level in range(0, 5):\n",
    "        table = \"country\" if level == 0 else f\"admin{level}\"\n",
    "        if table_exists(con, table):\n",
    "            count = con.execute(f\"SELECT COUNT(*) FROM {table}\").fetchone()[0]\n",
    "            print(f\"{table}: {count} entities\")\n",
    "\n",
    "\n",
    "def create_admin_indexes(con: DuckDBPyConnection):\n",
    "    # Admin0 (already has indexes on ISO codes from FTS)\n",
    "\n",
    "    # Admin1 composite index\n",
    "    con.execute(\n",
    "        \"CREATE INDEX IF NOT EXISTS admin1_codes ON admin1 (admin0_code, admin1_code)\"\n",
    "    )\n",
    "\n",
    "    # Admin2 composite index\n",
    "    con.execute(\n",
    "        \"CREATE INDEX IF NOT EXISTS admin2_codes ON admin2 (admin0_code, admin1_code, admin2_code)\"\n",
    "    )\n",
    "\n",
    "    # Admin3 composite index\n",
    "    con.execute(\n",
    "        \"CREATE INDEX IF NOT EXISTS admin3_codes ON admin3 (admin0_code, admin1_code, admin2_code, admin3_code)\"\n",
    "    )\n",
    "\n",
    "    # Admin4 composite index\n",
    "    con.execute(\n",
    "        \"CREATE INDEX IF NOT EXISTS admin4_codes ON admin4 (admin0_code, admin1_code, admin2_code, admin3_code, admin4_code)\"\n",
    "    )\n",
    "\n",
    "    print(\"Created composite indexes on admin code columns\")\n",
    "\n",
    "\n",
    "#build_clean_admin_hierarchy(overwrite=True)\n",
    "create_admin_indexes(con)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for country: 'FR'\n",
      "Searching for admin1: 'Provence-Alpes-Côte d'Azur'\n",
      "Filtering by parent level 0 using admin0_code\n",
      "Found parent score column: adjusted_score_0\n",
      "Using parent score from level 0: adjusted_score_0\n",
      "Searching for admin4: 'Le Lavandou'\n",
      "Filtering by parent level 1 using admin1_code\n",
      "Found parent score column: adjusted_score_1\n",
      "Using parent score from level 1: adjusted_score_1\n",
      "Country results: shape: (3, 6)\n",
      "┌───────────┬────────────────────┬──────────────────┬─────────────┬───────────────┬──────────────┐\n",
      "│ geonameId ┆ name               ┆ adjusted_score_0 ┆ admin0_code ┆ feature_class ┆ feature_code │\n",
      "│ ---       ┆ ---                ┆ ---              ┆ ---         ┆ ---           ┆ ---          │\n",
      "│ i32       ┆ str                ┆ f64              ┆ str         ┆ str           ┆ str          │\n",
      "╞═══════════╪════════════════════╪══════════════════╪═════════════╪═══════════════╪══════════════╡\n",
      "│ 3017382   ┆ Republic of France ┆ 35.694998        ┆ FR          ┆ A             ┆ PCLI         │\n",
      "│ 3381670   ┆ Guyane             ┆ 4.95754          ┆ GF          ┆ A             ┆ PCLD         │\n",
      "│ 4030656   ┆ French Polynesia   ┆ 4.447485         ┆ PF          ┆ A             ┆ PCLD         │\n",
      "└───────────┴────────────────────┴──────────────────┴─────────────┴───────────────┴──────────────┘\n",
      "Admin1 results: shape: (10, 11)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ geonameId ┆ name      ┆ feature_c ┆ feature_c ┆ … ┆ admin3_co ┆ admin4_co ┆ adjusted_ ┆ adjusted │\n",
      "│ ---       ┆ ---       ┆ lass      ┆ ode       ┆   ┆ de        ┆ de        ┆ score_0   ┆ _score_1 │\n",
      "│ i32       ┆ str       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
      "│           ┆           ┆ str       ┆ str       ┆   ┆ i32       ┆ i32       ┆ f64       ┆ f64      │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ 2985244   ┆ Provence- ┆ A         ┆ ADM1      ┆ … ┆ null      ┆ null      ┆ 35.694998 ┆ 38.87723 │\n",
      "│           ┆ Alpes-Côt ┆           ┆           ┆   ┆           ┆           ┆           ┆ 3        │\n",
      "│           ┆ e d'Azur  ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 8378478   ┆ Alpes     ┆ A         ┆ ADM1H     ┆ … ┆ null      ┆ null      ┆ 35.694998 ┆ 14.12545 │\n",
      "│           ┆ Maritimae ┆           ┆           ┆   ┆           ┆           ┆           ┆ 7        │\n",
      "│ 8378477   ┆ Alpes     ┆ A         ┆ ADM1H     ┆ … ┆ null      ┆ null      ┆ 35.694998 ┆ 14.02064 │\n",
      "│           ┆ Graiae    ┆           ┆           ┆   ┆           ┆           ┆           ┆ 7        │\n",
      "│ 2983751   ┆ Rhône-Alp ┆ A         ┆ ADM1H     ┆ … ┆ null      ┆ null      ┆ 35.694998 ┆ 13.94395 │\n",
      "│           ┆ es        ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 11071625  ┆ Auvergne- ┆ A         ┆ ADM1      ┆ … ┆ null      ┆ null      ┆ 35.694998 ┆ 13.00187 │\n",
      "│           ┆ Rhône-Alp ┆           ┆           ┆   ┆           ┆           ┆           ┆ 1        │\n",
      "│           ┆ es        ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 3027939   ┆ Centre-Va ┆ A         ┆ ADM1      ┆ … ┆ null      ┆ null      ┆ 35.694998 ┆ 4.880054 │\n",
      "│           ┆ l de      ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ Loire     ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 11071624  ┆ Hauts-de- ┆ A         ┆ ADM1      ┆ … ┆ null      ┆ null      ┆ 35.694998 ┆ 4.690153 │\n",
      "│           ┆ France    ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 2988289   ┆ Pays de   ┆ A         ┆ ADM1      ┆ … ┆ null      ┆ null      ┆ 35.694998 ┆ 4.626843 │\n",
      "│           ┆ la Loire  ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 3012874   ┆ Île-de-Fr ┆ A         ┆ ADM1      ┆ … ┆ null      ┆ null      ┆ 35.694998 ┆ 3.272594 │\n",
      "│           ┆ ance      ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 2990119   ┆ Nord-Pas- ┆ A         ┆ ADM1H     ┆ … ┆ null      ┆ null      ┆ 35.694998 ┆ 3.215311 │\n",
      "│           ┆ de-Calais ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n",
      "Admin4 results: shape: (10, 11)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ geonameId ┆ name      ┆ feature_c ┆ feature_c ┆ … ┆ admin3_co ┆ admin4_co ┆ adjusted_ ┆ adjusted │\n",
      "│ ---       ┆ ---       ┆ lass      ┆ ode       ┆   ┆ de        ┆ de        ┆ score_1   ┆ _score_4 │\n",
      "│ i32       ┆ str       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
      "│           ┆           ┆ str       ┆ str       ┆   ┆ str       ┆ str       ┆ f64       ┆ f64      │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ 6615009   ┆ Le        ┆ A         ┆ ADM4      ┆ … ┆ 832       ┆ 83070     ┆ 38.877233 ┆ 18.91802 │\n",
      "│           ┆ Lavandou  ┆           ┆           ┆   ┆           ┆           ┆           ┆ 5        │\n",
      "│ 6615009   ┆ Le        ┆ A         ┆ ADM4      ┆ … ┆ 832       ┆ 83070     ┆ 14.125457 ┆ 13.96265 │\n",
      "│           ┆ Lavandou  ┆           ┆           ┆   ┆           ┆           ┆           ┆ 3        │\n",
      "│ 6456350   ┆ Le        ┆ A         ┆ ADM4      ┆ … ┆ 692       ┆ 69151     ┆ 14.020647 ┆ 5.358228 │\n",
      "│           ┆ Perréon   ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 6456350   ┆ Le        ┆ A         ┆ ADM4      ┆ … ┆ 692       ┆ 69151     ┆ 13.001871 ┆ 5.238326 │\n",
      "│           ┆ Perréon   ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 6455917   ┆ Le Poinço ┆ A         ┆ ADM4      ┆ … ┆ 362       ┆ 36159     ┆ 4.880054  ┆ 3.977462 │\n",
      "│           ┆ nnet      ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 6457137   ┆ Le        ┆ A         ┆ ADM4      ┆ … ┆ 851       ┆ 85031     ┆ 4.626843  ┆ 3.859781 │\n",
      "│           ┆ Boupère   ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 6456917   ┆ Le Gâvre  ┆ A         ┆ ADM4      ┆ … ┆ 445       ┆ 44062     ┆ 4.626843  ┆ 3.810752 │\n",
      "│ 6455417   ┆ Le        ┆ A         ┆ ADM4      ┆ … ┆ 783       ┆ 78650     ┆ 3.272594  ┆ 3.606109 │\n",
      "│           ┆ Vésinet   ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 6456500   ┆ Le Mesnil ┆ A         ┆ ADM4      ┆ … ┆ 783       ┆ 78396     ┆ 3.272594  ┆ 3.600083 │\n",
      "│           ┆ -le-Roi   ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 6456492   ┆ Le        ┆ A         ┆ ADM4      ┆ … ┆ 774       ┆ 77485     ┆ 3.272594  ┆ 3.366243 │\n",
      "│           ┆ Vaudoué   ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "def country_score(df: pl.LazyFrame) -> pl.LazyFrame:\n",
    "    return (\n",
    "        df.with_columns(\n",
    "            pop_multiplier=(1 + (pl.col(\"Population\").add(1).log10() / 10)),\n",
    "            area_multiplier=(1 + (pl.col(\"Area\").add(1).log10() / 20)),\n",
    "            feature_multiplier=pl.when(pl.col(\"feature_code\") == \"PCLI\")\n",
    "            .then(0.5)\n",
    "            .when(pl.col(\"feature_code\").str.contains(\"^PCL.*$\"))\n",
    "            .then(0.2)\n",
    "            .otherwise(0),\n",
    "        )\n",
    "        .with_columns(\n",
    "            adjusted_score_0=pl.col(\"score\")\n",
    "            * (\n",
    "                pl.col(\"pop_multiplier\")\n",
    "                + pl.col(\"area_multiplier\")\n",
    "                + pl.col(\"feature_multiplier\")\n",
    "            )\n",
    "        )\n",
    "        .sort(\"adjusted_score_0\", descending=True)\n",
    "        .select(\n",
    "            \"geonameId\",\n",
    "            \"name\",\n",
    "            \"adjusted_score_0\",\n",
    "            \"admin0_code\",\n",
    "            \"feature_class\",\n",
    "            \"feature_code\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def admin_score(\n",
    "    df: pl.LazyFrame, level: int, parent_weight: float = 0.3\n",
    ") -> pl.LazyFrame:\n",
    "    assert level in [1, 2, 3, 4], \"Level must be between 1 and 4\"\n",
    "    score_column = f\"adjusted_score_{level}\"\n",
    "    parent_score_column = f\"adjusted_score_{level - 1}\"\n",
    "\n",
    "    df = df.with_columns(\n",
    "        pop_multiplier=(1 + (pl.col(\"population\").add(1).log10() / 10)),\n",
    "    )\n",
    "    # Check all possible parent score columns, from highest to lowest\n",
    "    # This allows using any available parent score, not just the immediate parent\n",
    "    available_parent_scores = []\n",
    "    for parent_level in range(level - 1, -1, -1):\n",
    "        parent_score_column = f\"adjusted_score_{parent_level}\"\n",
    "        if parent_score_column in df.collect_schema().keys():\n",
    "            print(f\"Found parent score column: {parent_score_column}\")\n",
    "            available_parent_scores.append((parent_level, parent_score_column))\n",
    "            break  # Use the highest available parent level\n",
    "    if available_parent_scores:\n",
    "        # Use the highest available parent score\n",
    "        parent_level, parent_score_column = available_parent_scores[0]\n",
    "        print(f\"Using parent score from level {parent_level}: {parent_score_column}\")\n",
    "\n",
    "        # Apply scoring with parent influence\n",
    "        df = df.with_columns(\n",
    "            (\n",
    "                (pl.col(\"score\") * pl.col(\"pop_multiplier\")).pow(1 - parent_weight)\n",
    "                * pl.col(parent_score_column).pow(parent_weight)\n",
    "            ).alias(score_column),\n",
    "        )\n",
    "    else:\n",
    "        # No parent scores available, use only the current score\n",
    "        print(\"No parent score columns found. Using only current level score.\")\n",
    "        df = df.with_columns(\n",
    "            (pl.col(\"score\") * pl.col(\"pop_multiplier\")).alias(score_column),\n",
    "        )\n",
    "    # Return sorted and selected columns\n",
    "    return df.sort(score_column, descending=True).select(\n",
    "        \"geonameId\",\n",
    "        \"name\",\n",
    "        \"feature_class\",\n",
    "        \"feature_code\",\n",
    "        cs.starts_with(\"admin\"),\n",
    "        cs.starts_with(\"adjusted_score\"),\n",
    "    )\n",
    "\n",
    "    if parent_score_column in df.collect_schema().keys():\n",
    "        print(f\"Parent score column: {parent_score_column}\")\n",
    "        df = df.with_columns(\n",
    "            (\n",
    "                ((1 - parent_weight) * pl.col(\"score\") * pl.col(\"pop_multiplier\"))\n",
    "                + (parent_weight * pl.col(parent_score_column))\n",
    "            ).alias(score_column),\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Parent score column: {parent_score_column} not found\")\n",
    "        df = df.with_columns(\n",
    "            (pl.col(\"score\") * pl.col(\"pop_multiplier\")).alias(score_column),\n",
    "        )\n",
    "\n",
    "    return df.sort(score_column, descending=True).select(\n",
    "        \"geonameId\",\n",
    "        \"name\",\n",
    "        \"feature_class\",\n",
    "        \"feature_code\",\n",
    "        cs.starts_with(\"admin\"),\n",
    "        cs.starts_with(\"adjusted_score\"),\n",
    "    )\n",
    "\n",
    "\n",
    "def search_country(term: str, con: DuckDBPyConnection, limit: int = 20) -> pl.DataFrame:\n",
    "    \"\"\"Search for a country by name, ISO code, etc.\"\"\"\n",
    "    query = \"\"\"SELECT *,\n",
    "    -- High fixed score for exact matches\n",
    "    CASE\n",
    "        WHEN LOWER(ISO) = LOWER($term) THEN 10.0\n",
    "        WHEN LOWER(ISO3) = LOWER($term) THEN 8.0\n",
    "        WHEN LOWER(fips) = LOWER($term) THEN 4.0\n",
    "    END AS score\n",
    "    FROM admin0\n",
    "    WHERE\n",
    "        -- First exact match priority\n",
    "        LOWER(ISO) = LOWER($term) OR\n",
    "        LOWER(ISO3) = LOWER($term) OR\n",
    "        LOWER(fips) = LOWER($term)\n",
    "    UNION ALL\n",
    "    -- Then fall back to fuzzy search for anything not exact\n",
    "    SELECT * FROM (\n",
    "        SELECT *, fts_main_admin0.match_bm25(geonameId, $term) AS score\n",
    "        FROM admin0\n",
    "        WHERE\n",
    "            LOWER(ISO) != LOWER($term) AND\n",
    "            LOWER(ISO3) != LOWER($term) AND\n",
    "            LOWER(fips) != LOWER($term)\n",
    "    ) sq\n",
    "    WHERE score IS NOT NULL\n",
    "    ORDER BY score DESC\n",
    "    LIMIT $limit;\n",
    "    \"\"\"\n",
    "\n",
    "    results = con.execute(query, {\"term\": term, \"limit\": limit}).pl()\n",
    "\n",
    "    if not results.is_empty():\n",
    "        # Apply country-specific scoring\n",
    "        return results.lazy().pipe(country_score).collect()\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def search_admin_level(\n",
    "    term: str,\n",
    "    level: int,\n",
    "    con: DuckDBPyConnection,\n",
    "    previous_results: pl.DataFrame | None = None,\n",
    "    limit: int = 20,\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Search for a term at the specified admin level with built-in resilience.\n",
    "\n",
    "    Args:\n",
    "        term: Search term\n",
    "        level: Admin level (1=admin1, 2=admin2, etc.)\n",
    "        con: Database connection\n",
    "        previous_results: Optional results from previous level search\n",
    "        limit: Maximum results to return\n",
    "    \"\"\"\n",
    "    assert level in [1, 2, 3, 4], \"Level must be between 1 and 4\"\n",
    "    table_name = f\"admin{level}\"\n",
    "    parent_level = level - 1\n",
    "    parent_table = f\"admin{parent_level}\"\n",
    "    parent_code_col = f\"admin{parent_level}_code\"\n",
    "    parent_score_col = f\"adjusted_score_{parent_level}\"\n",
    "\n",
    "    # Check if previous results exist and have data\n",
    "    has_previous = previous_results is not None and not previous_results.is_empty()\n",
    "\n",
    "    # Base query - always needed\n",
    "    base_query = f\"\"\"\n",
    "    SELECT *, fts_main_{table_name}.match_bm25(geonameId, $term) AS score\n",
    "    FROM {table_name}\n",
    "    WHERE score IS NOT NULL\n",
    "    \"\"\"\n",
    "\n",
    "    if has_previous:\n",
    "        # Register previous results\n",
    "        temp_table = f\"temp_previous_{level}\"\n",
    "        con.register(temp_table, previous_results)\n",
    "        # Determine which admin level the previous results are from\n",
    "        parent_level = None\n",
    "\n",
    "        # Check available columns to determine parent level\n",
    "        if \"admin0_code\" in previous_results.columns:\n",
    "            # Previous results include country info\n",
    "            parent_level = 0\n",
    "\n",
    "        for i in range(1, level):\n",
    "            if f\"adjusted_score_{i}\" in previous_results.columns:\n",
    "                parent_level = i\n",
    "\n",
    "        if parent_level is not None:\n",
    "            # We found a valid parent level\n",
    "            if parent_level == 0:\n",
    "                # If parent is country, filter by admin0_code\n",
    "                parent_code_col = \"admin0_code\"\n",
    "                parent_score_col = \"adjusted_score_0\"\n",
    "            else:\n",
    "                # Otherwise use the appropriate admin code\n",
    "                parent_code_col = f\"admin{parent_level}_code\"\n",
    "                parent_score_col = f\"adjusted_score_{parent_level}\"\n",
    "\n",
    "            # Check if parent scores exist\n",
    "            has_parent_scores = parent_score_col in previous_results.columns\n",
    "\n",
    "            # With previous results, we can filter by parent and include parent scores\n",
    "            if has_parent_scores:\n",
    "                print(\n",
    "                    f\"Filtering by parent level {parent_level} using {parent_code_col}\"\n",
    "                )\n",
    "                query = f\"\"\"\n",
    "                WITH parent_data AS (\n",
    "                    SELECT DISTINCT {parent_code_col}, {parent_score_col}\n",
    "                    FROM {temp_table}\n",
    "                    WHERE {parent_score_col} IS NOT NULL\n",
    "                )\n",
    "                SELECT a.*, p.{parent_score_col}\n",
    "                FROM ({base_query}) a\n",
    "                LEFT JOIN parent_data p ON a.{parent_code_col} = p.{parent_code_col}\n",
    "                WHERE a.{parent_code_col} IN (SELECT {parent_code_col} FROM {temp_table})\n",
    "                ORDER BY a.score DESC\n",
    "                LIMIT $limit\n",
    "                \"\"\"\n",
    "            else:\n",
    "                # No parent scores available, but we can still filter by parent\n",
    "                print(\n",
    "                    f\"Filtering by parent level {parent_level} using {parent_code_col} (no scores)\"\n",
    "                )\n",
    "                # No parent scores available, but we can still filter by parent\n",
    "                query = f\"\"\"\n",
    "                SELECT a.*\n",
    "                FROM ({base_query}) a\n",
    "                WHERE a.{parent_code_col} IN (SELECT {parent_code_col} FROM {temp_table})\n",
    "                ORDER BY a.score DESC\n",
    "                LIMIT $limit\n",
    "                \"\"\"\n",
    "        else:\n",
    "            # Couldn't determine parent level, fall back to unfiltered search\n",
    "            print(\"Could not determine parent level for filtering\")\n",
    "            query = f\"\"\"\n",
    "            {base_query}\n",
    "            ORDER BY score DESC\n",
    "            LIMIT $limit\n",
    "            \"\"\"\n",
    "    else:\n",
    "        # Simple search without parent filtering\n",
    "        query = f\"\"\"\n",
    "        {base_query}\n",
    "        ORDER BY score DESC\n",
    "        LIMIT $limit\n",
    "        \"\"\"\n",
    "\n",
    "    # Execute the query\n",
    "    results = con.execute(query, {\"term\": term, \"limit\": limit}).pl()\n",
    "\n",
    "    # If we got no results with filtering, try without filtering\n",
    "    if has_previous and results.is_empty():\n",
    "        print(\"No results found with parent filtering. Trying unfiltered search...\")\n",
    "        fallback_query = f\"\"\"\n",
    "        {base_query}\n",
    "        ORDER BY score DESC\n",
    "        LIMIT $limit\n",
    "        \"\"\"\n",
    "        results = con.execute(fallback_query, {\"term\": term, \"limit\": limit}).pl()\n",
    "\n",
    "    # Apply admin-specific scoring\n",
    "    if not results.is_empty():\n",
    "        return results.lazy().pipe(admin_score, level).collect()\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def hierarchical_search(\n",
    "    search_terms: list[str | None], con: DuckDBPyConnection, limit: int = 10\n",
    ") -> dict[str, pl.DataFrame]:\n",
    "    \"\"\"\n",
    "    Perform hierarchical geographic search across admin levels.\n",
    "\n",
    "    Args:\n",
    "        search_terms: List of search terms, ordered by admin level (country, admin1, admin2, etc.)\n",
    "        con: Database connection\n",
    "        limit: Maximum results to return per level\n",
    "\n",
    "    Returns:\n",
    "        Dictionary mapping level names to search results\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    last_results = None\n",
    "    # Ensure we have enough search terms\n",
    "    if not search_terms:\n",
    "        return results\n",
    "\n",
    "    # Pad search terms if fewer than 5 are provided\n",
    "    search_terms = search_terms + [None] * (5 - len(search_terms))\n",
    "\n",
    "    # Level 0: Country search\n",
    "    if search_terms[0]:\n",
    "        print(f\"Searching for country: '{search_terms[0]}'\")\n",
    "        country_results = search_country(search_terms[0], con, limit)\n",
    "        if not country_results.is_empty():\n",
    "            results[\"country\"] = country_results\n",
    "            last_results = country_results\n",
    "\n",
    "    # Level 1: Admin1 search\n",
    "    if search_terms[1]:\n",
    "        print(f\"Searching for admin1: '{search_terms[1]}'\")\n",
    "        admin1_results = search_admin_level(\n",
    "            search_terms[1], 1, con, last_results, limit\n",
    "        )\n",
    "        if not admin1_results.is_empty():\n",
    "            results[\"admin1\"] = admin1_results\n",
    "            last_results = admin1_results\n",
    "\n",
    "    # Level 2: Admin2 search\n",
    "    if search_terms[2]:\n",
    "        print(f\"Searching for admin2: '{search_terms[2]}'\")\n",
    "        admin2_results = search_admin_level(\n",
    "            search_terms[2], 2, con, last_results, limit\n",
    "        )\n",
    "        if not admin2_results.is_empty():\n",
    "            results[\"admin2\"] = admin2_results\n",
    "            last_results = admin2_results\n",
    "\n",
    "    # Level 3: Admin3 search\n",
    "    if search_terms[3]:\n",
    "        print(f\"Searching for admin3: '{search_terms[3]}'\")\n",
    "        admin3_results = search_admin_level(\n",
    "            search_terms[3], 3, con, last_results, limit\n",
    "        )\n",
    "        if not admin3_results.is_empty():\n",
    "            results[\"admin3\"] = admin3_results\n",
    "            last_results = admin3_results\n",
    "\n",
    "    # Level 4: Admin4 search\n",
    "    if search_terms[4]:\n",
    "        print(f\"Searching for admin4: '{search_terms[4]}'\")\n",
    "        admin4_results = search_admin_level(\n",
    "            search_terms[4], 4, con, last_results, limit\n",
    "        )\n",
    "        if not admin4_results.is_empty():\n",
    "            results[\"admin4\"] = admin4_results\n",
    "            last_results = admin4_results\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Search through the admin hierarchy\n",
    "results = hierarchical_search(\n",
    "    search_terms=[\"FR\", \"Provence-Alpes-Côte d'Azur\", None, None, \"Le Lavandou\"],\n",
    "    con=con,\n",
    ")\n",
    "\n",
    "# Access results for each level\n",
    "if \"country\" in results:\n",
    "    print(\"Country results:\", results[\"country\"])\n",
    "if \"admin1\" in results:\n",
    "    print(\"Admin1 results:\", results[\"admin1\"])\n",
    "if \"admin2\" in results:\n",
    "    print(\"Admin2 results:\", results[\"admin2\"])\n",
    "if \"admin3\" in results:\n",
    "    print(\"Admin3 results:\", results[\"admin3\"])\n",
    "if \"admin4\" in results:\n",
    "    print(\"Admin4 results:\", results[\"admin4\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backfill_hierarchy(row: dict, con: DuckDBPyConnection) -> dict:\n",
    "    \"\"\"\n",
    "    Backfill complete hierarchical information for a given location.\n",
    "\n",
    "    Args:\n",
    "        row: A dictionary or DataFrame row containing admin codes\n",
    "        con: Database connection\n",
    "\n",
    "    Returns:\n",
    "        Dictionary mapping admin levels to their corresponding entity information\n",
    "    \"\"\"\n",
    "\n",
    "    def get_where_clause(codes: list[str | None]) -> str:\n",
    "        return \"WHERE \" + \" AND \".join(\n",
    "            [\n",
    "                f\"admin{i}_code = '{code}'\"\n",
    "                if code is not None\n",
    "                else f\"admin{i}_code IS NULL\"\n",
    "                for i, code in enumerate(codes)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    hierarchy = {}\n",
    "    codes = []\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(5):\n",
    "        code = row.get(f\"admin{i}_code\")\n",
    "        codes.append(code)\n",
    "        if code is not None:\n",
    "            df = con.execute(f\"\"\"\n",
    "                SELECT geonameId, name FROM admin{i}\n",
    "                {get_where_clause(codes)}\n",
    "                LIMIT 1\n",
    "            \"\"\").pl()\n",
    "            if not df.is_empty():\n",
    "                hierarchy[f\"admin{i}\"] = df.to_dicts()[0]\n",
    "\n",
    "    return hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for country: 'FR'\n",
      "Searching for admin4: 'Le Lavandou'\n",
      "Filtering by parent level 0 using admin0_code\n",
      "Found parent score column: adjusted_score_0\n",
      "Using parent score from level 0: adjusted_score_0\n",
      "{'adjusted_score_0': 35.69499808597985,\n",
      " 'adjusted_score_4': 18.439510652439495,\n",
      " 'admin0_code': 'FR',\n",
      " 'admin1_code': '93',\n",
      " 'admin2_code': '83',\n",
      " 'admin3_code': '832',\n",
      " 'admin4_code': '83070',\n",
      " 'feature_class': 'A',\n",
      " 'feature_code': 'ADM4',\n",
      " 'geonameId': 6615009,\n",
      " 'name': 'Le Lavandou'}\n",
      "{'admin0': {'geonameId': 3017382, 'name': 'Republic of France'},\n",
      " 'admin1': {'geonameId': 2985244, 'name': \"Provence-Alpes-Côte d'Azur\"},\n",
      " 'admin2': {'geonameId': 2970749, 'name': 'Var'},\n",
      " 'admin3': {'geonameId': 2972326, 'name': 'Arrondissement de Toulon'},\n",
      " 'admin4': {'geonameId': 6615009, 'name': 'Le Lavandou'}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "\n",
    "\n",
    "results = hierarchical_search(\n",
    "    search_terms=[\"FR\", None, None, None, \"Le Lavandou\"], con=con\n",
    ")\n",
    "row = results[\"admin4\"].row(0, named=True)\n",
    "pprint(row)\n",
    "\n",
    "pprint(backfill_hierarchy(row, con))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for admin1: 'FL'\n",
      "No parent score columns found. Using only current level score.\n",
      "Searching for admin3: 'Lakeland'\n",
      "Filtering by parent level 1 using admin1_code\n",
      "Found parent score column: adjusted_score_1\n",
      "Using parent score from level 1: adjusted_score_1\n",
      "{'adjusted_score_1': 5.6968534422927375,\n",
      " 'adjusted_score_3': 8.143343634356121,\n",
      " 'admin0_code': 'US',\n",
      " 'admin1_code': 'FL',\n",
      " 'admin2_code': '105',\n",
      " 'admin3_code': '7170309',\n",
      " 'admin4_code': None,\n",
      " 'feature_class': 'A',\n",
      " 'feature_code': 'ADM3',\n",
      " 'geonameId': 7170309,\n",
      " 'name': 'City of Lakeland'}\n",
      "{'admin0': {'geonameId': 6252001, 'name': 'United States'},\n",
      " 'admin1': {'geonameId': 4155751, 'name': 'Florida'},\n",
      " 'admin2': {'geonameId': 4168988, 'name': 'Polk County'},\n",
      " 'admin3': {'geonameId': 7170309, 'name': 'City of Lakeland'}}\n"
     ]
    }
   ],
   "source": [
    "results = hierarchical_search(\n",
    "    search_terms=[None, \"FL\", None, \"Lakeland\", None], con=con\n",
    ")\n",
    "row = results[\"admin3\"].row(0, named=True)\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(row)\n",
    "\n",
    "pprint(backfill_hierarchy(row, con))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (51, 16)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geonameId</th><th>name</th><th>asciiname</th><th>admin0_code</th><th>admin1_code</th><th>admin2_code</th><th>admin3_code</th><th>admin4_code</th><th>feature_class</th><th>feature_code</th><th>population</th><th>country_id</th><th>parent_id</th><th>country_name</th><th>parent_name</th><th>alternatenames</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i32</td><td>i32</td><td>str</td><td>str</td><td>i64</td><td>i32</td><td>i32</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>1276130</td><td>&quot;Bharatpur&quot;</td><td>&quot;Bharatpur&quot;</td><td>&quot;IN&quot;</td><td>&quot;24&quot;</td><td>&quot;105&quot;</td><td>null</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM2&quot;</td><td>2548462</td><td>1269750</td><td>1258899</td><td>&quot;Republic of India&quot;</td><td>&quot;State of Rājasthān&quot;</td><td>&quot;BTR,Bharatpur&quot;</td></tr><tr><td>2775088</td><td>&quot;Politischer Bezirk Jennersdorf&quot;</td><td>&quot;Politischer Bezirk Jennersdorf&quot;</td><td>&quot;AT&quot;</td><td>&quot;01&quot;</td><td>&quot;105&quot;</td><td>null</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM2&quot;</td><td>17158</td><td>2782113</td><td>2781194</td><td>&quot;Republic of Austria&quot;</td><td>&quot;Burgenland&quot;</td><td>&quot;Bezirk Jennersdorf,Jennersdorf…</td></tr><tr><td>3591849</td><td>&quot;Municipio de Palencia&quot;</td><td>&quot;Municipio de Palencia&quot;</td><td>&quot;GT&quot;</td><td>&quot;07&quot;</td><td>&quot;105&quot;</td><td>null</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM2&quot;</td><td>70973</td><td>3595528</td><td>3595530</td><td>&quot;Republic of Guatemala&quot;</td><td>&quot;Departamento de Guatemala&quot;</td><td>&quot;Municipio de Palencia,Palencia&quot;</td></tr><tr><td>3621342</td><td>&quot;Tarrazú&quot;</td><td>&quot;Tarrazu&quot;</td><td>&quot;CR&quot;</td><td>&quot;08&quot;</td><td>&quot;105&quot;</td><td>null</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM2&quot;</td><td>16280</td><td>3624060</td><td>3621837</td><td>&quot;Republic of Costa Rica&quot;</td><td>&quot;Provincia de San José&quot;</td><td>&quot;Canton Tarrazu,Canton de Tarra…</td></tr><tr><td>4082741</td><td>&quot;Perry County&quot;</td><td>&quot;Perry County&quot;</td><td>&quot;US&quot;</td><td>&quot;AL&quot;</td><td>&quot;105&quot;</td><td>null</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM2&quot;</td><td>8355</td><td>6252001</td><td>4829764</td><td>&quot;United States&quot;</td><td>&quot;Alabama&quot;</td><td>&quot;Comitatul Perry,Comte de Perry…</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>8659843</td><td>&quot;Biu&quot;</td><td>&quot;Biu&quot;</td><td>&quot;NG&quot;</td><td>&quot;27&quot;</td><td>&quot;105&quot;</td><td>null</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM2&quot;</td><td>0</td><td>2328926</td><td>2346794</td><td>&quot;Federal Republic of Nigeria&quot;</td><td>&quot;Borno State&quot;</td><td>&quot;Biu,Biu Local Government Area&quot;</td></tr><tr><td>8986342</td><td>&quot;Okres Bratislava V&quot;</td><td>&quot;Okres Bratislava V&quot;</td><td>&quot;SK&quot;</td><td>&quot;02&quot;</td><td>&quot;105&quot;</td><td>null</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM2&quot;</td><td>110801</td><td>3057568</td><td>3343955</td><td>&quot;Slovak Republic&quot;</td><td>&quot;Bratislava&quot;</td><td>&quot;B5,Pozsonyi V. jaras,Pozsonyi …</td></tr><tr><td>9610645</td><td>&quot;Pieksämäki&quot;</td><td>&quot;Pieksaemaeki&quot;</td><td>&quot;FI&quot;</td><td>&quot;10&quot;</td><td>&quot;105&quot;</td><td>null</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM2&quot;</td><td>0</td><td>660013</td><td>830695</td><td>&quot;Republic of Finland&quot;</td><td>&quot;Southern Savonia&quot;</td><td>&quot;Pieksaemaeen seutukunta,Pieksa…</td></tr><tr><td>9644335</td><td>&quot;Füzesabonyi járás&quot;</td><td>&quot;Fuezesabonyi jaras&quot;</td><td>&quot;HU&quot;</td><td>&quot;11&quot;</td><td>&quot;105&quot;</td><td>null</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM2&quot;</td><td>0</td><td>719819</td><td>720002</td><td>&quot;Hungary&quot;</td><td>&quot;Heves megye&quot;</td><td>&quot;Fuezesabonyi jaras,Füzesabonyi…</td></tr><tr><td>11497338</td><td>&quot;Thành phố Lai Châu&quot;</td><td>&quot;Thanh pho Lai Chau&quot;</td><td>&quot;VN&quot;</td><td>&quot;89&quot;</td><td>&quot;105&quot;</td><td>null</td><td>null</td><td>&quot;A&quot;</td><td>&quot;ADM2&quot;</td><td>42973</td><td>1562822</td><td>1577954</td><td>&quot;Socialist Republic of Vietnam&quot;</td><td>&quot;Tỉnh Lai Châu&quot;</td><td>&quot;Lai Chau,Lai Châu&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (51, 16)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ geonameId ┆ name      ┆ asciiname ┆ admin0_co ┆ … ┆ parent_id ┆ country_n ┆ parent_na ┆ alternat │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ de        ┆   ┆ ---       ┆ ame       ┆ me        ┆ enames   │\n",
       "│ i32       ┆ str       ┆ str       ┆ ---       ┆   ┆ i32       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆           ┆ str       ┆   ┆           ┆ str       ┆ str       ┆ str      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 1276130   ┆ Bharatpur ┆ Bharatpur ┆ IN        ┆ … ┆ 1258899   ┆ Republic  ┆ State of  ┆ BTR,Bhar │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ of India  ┆ Rājasthān ┆ atpur    │\n",
       "│ 2775088   ┆ Politisch ┆ Politisch ┆ AT        ┆ … ┆ 2781194   ┆ Republic  ┆ Burgenlan ┆ Bezirk   │\n",
       "│           ┆ er Bezirk ┆ er Bezirk ┆           ┆   ┆           ┆ of        ┆ d         ┆ Jennersd │\n",
       "│           ┆ Jennersdo ┆ Jennersdo ┆           ┆   ┆           ┆ Austria   ┆           ┆ orf,Jenn │\n",
       "│           ┆ rf        ┆ rf        ┆           ┆   ┆           ┆           ┆           ┆ ersdorf… │\n",
       "│ 3591849   ┆ Municipio ┆ Municipio ┆ GT        ┆ … ┆ 3595530   ┆ Republic  ┆ Departame ┆ Municipi │\n",
       "│           ┆ de        ┆ de        ┆           ┆   ┆           ┆ of        ┆ nto de    ┆ o de Pal │\n",
       "│           ┆ Palencia  ┆ Palencia  ┆           ┆   ┆           ┆ Guatemala ┆ Guatemala ┆ encia,Pa │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ lencia   │\n",
       "│ 3621342   ┆ Tarrazú   ┆ Tarrazu   ┆ CR        ┆ … ┆ 3621837   ┆ Republic  ┆ Provincia ┆ Canton   │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ of Costa  ┆ de San    ┆ Tarrazu, │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ Rica      ┆ José      ┆ Canton   │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ de       │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ Tarra…   │\n",
       "│ 4082741   ┆ Perry     ┆ Perry     ┆ US        ┆ … ┆ 4829764   ┆ United    ┆ Alabama   ┆ Comitatu │\n",
       "│           ┆ County    ┆ County    ┆           ┆   ┆           ┆ States    ┆           ┆ l Perry, │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ Comte de │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ Perry…   │\n",
       "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
       "│ 8659843   ┆ Biu       ┆ Biu       ┆ NG        ┆ … ┆ 2346794   ┆ Federal   ┆ Borno     ┆ Biu,Biu  │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ Republic  ┆ State     ┆ Local    │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ of        ┆           ┆ Governme │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ Nigeria   ┆           ┆ nt Area  │\n",
       "│ 8986342   ┆ Okres Bra ┆ Okres Bra ┆ SK        ┆ … ┆ 3343955   ┆ Slovak    ┆ Bratislav ┆ B5,Pozso │\n",
       "│           ┆ tislava V ┆ tislava V ┆           ┆   ┆           ┆ Republic  ┆ a         ┆ nyi V.   │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ jaras,Po │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ zsonyi … │\n",
       "│ 9610645   ┆ Pieksämäk ┆ Pieksaema ┆ FI        ┆ … ┆ 830695    ┆ Republic  ┆ Southern  ┆ Pieksaem │\n",
       "│           ┆ i         ┆ eki       ┆           ┆   ┆           ┆ of        ┆ Savonia   ┆ aeen seu │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ Finland   ┆           ┆ tukunta, │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ Pieksa…  │\n",
       "│ 9644335   ┆ Füzesabon ┆ Fuezesabo ┆ HU        ┆ … ┆ 720002    ┆ Hungary   ┆ Heves     ┆ Fuezesab │\n",
       "│           ┆ yi járás  ┆ nyi jaras ┆           ┆   ┆           ┆           ┆ megye     ┆ onyi jar │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ as,Füzes │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ abonyi…  │\n",
       "│ 11497338  ┆ Thành phố ┆ Thanh pho ┆ VN        ┆ … ┆ 1577954   ┆ Socialist ┆ Tỉnh Lai  ┆ Lai      │\n",
       "│           ┆ Lai Châu  ┆ Lai Chau  ┆           ┆   ┆           ┆ Republic  ┆ Châu      ┆ Chau,Lai │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ of        ┆           ┆ Châu     │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ Vietnam   ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.table(\"admin2\").pl().filter(pl.col(\"admin2_code\") == \"105\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backfill_hierarchy(row: dict, con: DuckDBPyConnection) -> dict:\n",
    "    \"\"\"\n",
    "    Backfill complete hierarchical information for a given location.\n",
    "\n",
    "    Args:\n",
    "        row: A dictionary or DataFrame row containing admin codes\n",
    "        con: Database connection\n",
    "\n",
    "    Returns:\n",
    "        Dictionary mapping admin levels to their corresponding entity information\n",
    "    \"\"\"\n",
    "    hierarchy = {}\n",
    "\n",
    "    # Extract admin codes from the row\n",
    "    admin0_code = row.get(\"admin0_code\")\n",
    "    admin1_code = row.get(\"admin1_code\")\n",
    "    admin2_code = row.get(\"admin2_code\")\n",
    "    admin3_code = row.get(\"admin3_code\")\n",
    "    admin4_code = row.get(\"admin4_code\")\n",
    "\n",
    "    # Try to find country (admin0)\n",
    "    if admin0_code:\n",
    "        admin0_df = con.execute(f\"\"\"\n",
    "            SELECT * FROM admin0\n",
    "            WHERE admin0_code = '{admin0_code}'\n",
    "            LIMIT 1\n",
    "        \"\"\").pl()\n",
    "        if not admin0_df.is_empty():\n",
    "            hierarchy[\"admin0\"] = admin0_df[0].to_dict()\n",
    "\n",
    "    # Try to find state/province (admin1)\n",
    "    if admin0_code and admin1_code:\n",
    "        admin1_df = con.execute(f\"\"\"\n",
    "            SELECT * FROM admin1\n",
    "            WHERE admin0_code = '{admin0_code}'\n",
    "            AND admin1_code = '{admin1_code}'\n",
    "            LIMIT 1\n",
    "        \"\"\").pl()\n",
    "        if not admin1_df.is_empty():\n",
    "            hierarchy[\"admin1\"] = admin1_df[0].to_dict()\n",
    "\n",
    "    # Try to find county/district (admin2)\n",
    "    if admin0_code and admin1_code and admin2_code:\n",
    "        admin2_df = con.execute(f\"\"\"\n",
    "            SELECT * FROM admin2\n",
    "            WHERE admin0_code = '{admin0_code}'\n",
    "            AND admin1_code = '{admin1_code}'\n",
    "            AND admin2_code = '{admin2_code}'\n",
    "            LIMIT 1\n",
    "        \"\"\").pl()\n",
    "        if not admin2_df.is_empty():\n",
    "            hierarchy[\"admin2\"] = admin2_df[0].to_dict()\n",
    "\n",
    "    # Try to find sub-district (admin3)\n",
    "    if admin0_code and admin1_code and admin2_code and admin3_code:\n",
    "        admin3_df = con.execute(f\"\"\"\n",
    "            SELECT * FROM admin3\n",
    "            WHERE admin0_code = '{admin0_code}'\n",
    "            AND admin1_code = '{admin1_code}'\n",
    "            AND admin2_code = '{admin2_code}'\n",
    "            AND admin3_code = '{admin3_code}'\n",
    "            LIMIT 1\n",
    "        \"\"\").pl()\n",
    "        if not admin3_df.is_empty():\n",
    "            hierarchy[\"admin3\"] = admin3_df[0].to_dict()\n",
    "\n",
    "    # Try to find locality (admin4)\n",
    "    if admin0_code and admin1_code and admin2_code and admin3_code and admin4_code:\n",
    "        admin4_df = con.execute(f\"\"\"\n",
    "            SELECT * FROM admin4\n",
    "            WHERE admin0_code = '{admin0_code}'\n",
    "            AND admin1_code = '{admin1_code}'\n",
    "            AND admin2_code = '{admin2_code}'\n",
    "            AND admin3_code = '{admin3_code}'\n",
    "            AND admin4_code = '{admin4_code}'\n",
    "            LIMIT 1\n",
    "        \"\"\").pl()\n",
    "        if not admin4_df.is_empty():\n",
    "            hierarchy[\"admin4\"] = admin4_df[0].to_dict()\n",
    "\n",
    "    return hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.table(\"admin1\").pl().filter(pl.col(\"admin0_code\") == \"US\").filter(\n",
    "    pl.col(\"admin1_code\") == \"FL\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.table(\"admin0\").pl().filter(pl.col(\"admin0_code\") == \"US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search through the admin hierarchy\n",
    "results = hierarchical_search(\n",
    "    search_terms=[\n",
    "        \"FR\",\n",
    "        \"Provence-Alpes-Côte d'Azur\",\n",
    "        \"Var\",\n",
    "        \"Arrondissement de Toulon\",\n",
    "        \"Le Lavandou\",\n",
    "    ],\n",
    "    con=con,\n",
    ")\n",
    "\n",
    "# Access results for each level\n",
    "if \"country\" in results:\n",
    "    print(\"Country results:\", results[\"country\"])\n",
    "if \"admin1\" in results:\n",
    "    print(\"Admin1 results:\", results[\"admin1\"])\n",
    "if \"admin2\" in results:\n",
    "    print(\"Admin2 results:\", results[\"admin2\"])\n",
    "if \"admin3\" in results:\n",
    "    print(\"Admin3 results:\", results[\"admin3\"])\n",
    "if \"admin4\" in results:\n",
    "    print(\"Admin4 results:\", results[\"admin4\"])\n",
    "results[\"admin4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"\"\"SELECT *\n",
    "FROM (\n",
    "    SELECT *, fts_main_admin0.match_bm25(\n",
    "        geonameId,\n",
    "        'EN'\n",
    "    ) AS score\n",
    "    FROM admin0\n",
    ") sq\n",
    "WHERE score IS NOT NULL\n",
    "ORDER BY score DESC;\n",
    "\"\"\").pl()  # .filter(pl.col(\"score\")>1).select(\"ISO3\")\n",
    "\n",
    "\n",
    "def country_score(df: pl.LazyFrame) -> pl.LazyFrame:\n",
    "    return (\n",
    "        df.with_columns(\n",
    "            pop_multiplier=(1 + (pl.col(\"Population\").add(1).log10() / 10)),\n",
    "            area_multiplier=(1 + (pl.col(\"Area\").add(1).log10() / 20)),\n",
    "            feature_multiplier=pl.when(pl.col(\"feature_code\") == \"PCLI\")\n",
    "            .then(0.5)\n",
    "            .when(pl.col(\"feature_code\").str.contains(\"^PCL.*$\"))\n",
    "            .then(0.2)\n",
    "            .otherwise(0),\n",
    "        )\n",
    "        .with_columns(\n",
    "            adjusted_score_0=pl.col(\"score\")\n",
    "            * (\n",
    "                pl.col(\"pop_multiplier\")\n",
    "                + pl.col(\"area_multiplier\")\n",
    "                + pl.col(\"feature_multiplier\")\n",
    "            )\n",
    "        )\n",
    "        .sort(\"adjusted_score_0\", descending=True)\n",
    "        .select(\n",
    "            \"geonameId\",\n",
    "            \"name\",\n",
    "            \"adjusted_score_0\",\n",
    "            \"admin0_code\",\n",
    "            \"feature_class\",\n",
    "            \"feature_code\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def admin_score(\n",
    "    df: pl.LazyFrame, level: int, parent_weight: float = 0.3\n",
    ") -> pl.LazyFrame:\n",
    "    assert level in [1, 2, 3, 4], \"Level must be between 1 and 4\"\n",
    "    score_column = f\"adjusted_score_{level}\"\n",
    "    parent_score_column = f\"adjusted_score_{level - 1}\"\n",
    "    parent_weight = 1 - parent_weight\n",
    "\n",
    "    df = df.with_columns(\n",
    "        pop_multiplier=(1 + (pl.col(\"population\").add(1).log10() / 10)),\n",
    "    )\n",
    "    print(df.collect_schema().keys())\n",
    "\n",
    "    if parent_score_column in df.collect_schema().keys():\n",
    "        print(f\"Parent score column: {parent_score_column}\")\n",
    "        df = df.with_columns(\n",
    "            (\n",
    "                ((1 - parent_weight) * pl.col(\"score\") * pl.col(\"pop_multiplier\"))\n",
    "                + (parent_weight * pl.col(parent_score_column))\n",
    "            ).alias(score_column),\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Parent score column: {parent_score_column} not found\")\n",
    "        df = df.with_columns(\n",
    "            (pl.col(\"score\") * pl.col(\"pop_multiplier\")).alias(score_column),\n",
    "        )\n",
    "\n",
    "    return df.sort(score_column, descending=True).select(\n",
    "        \"geonameId\",\n",
    "        \"name\",\n",
    "        \"feature_class\",\n",
    "        \"feature_code\",\n",
    "        cs.starts_with(\"admin\"),\n",
    "        cs.starts_with(\"adjusted_score\"),\n",
    "    )\n",
    "\n",
    "\n",
    "SEARCH_TERM = [\n",
    "    \"FR\",\n",
    "    \"Provence-Alpes-Côte d'Azur\",\n",
    "    \"Var\",\n",
    "    \"Arrondissement de Toulon\",\n",
    "    \"Le Lavandou\",\n",
    "]\n",
    "\n",
    "# df_con = (\n",
    "#     con.execute(\n",
    "#         \"\"\"SELECT *,\n",
    "#     -- High fixed score for exact matches\n",
    "#     CASE\n",
    "#         WHEN LOWER(ISO) = LOWER($term) THEN 10.0\n",
    "#         WHEN LOWER(ISO3) = LOWER($term) THEN 8.0\n",
    "#         WHEN LOWER(fips) = LOWER($term) THEN 4.0\n",
    "#     END AS score\n",
    "# FROM admin0\n",
    "# WHERE\n",
    "#     -- First exact match priority\n",
    "#     LOWER(ISO) = LOWER($term) OR\n",
    "#     LOWER(ISO3) = LOWER($term) OR\n",
    "#     LOWER(fips) = LOWER($term)\n",
    "# UNION ALL\n",
    "# -- Then fall back to fuzzy search for anything not exact\n",
    "# SELECT * FROM (\n",
    "#     SELECT *, fts_main_admin0.match_bm25(geonameId,\n",
    "# $term\n",
    "#     ) AS score\n",
    "#     FROM admin0\n",
    "#     WHERE\n",
    "#         LOWER(ISO) != LOWER($term) AND\n",
    "#         LOWER(ISO3) != LOWER($term) AND\n",
    "#         LOWER(fips) != LOWER($term)\n",
    "# ) sq\n",
    "# WHERE score IS NOT NULL\n",
    "# ORDER BY score DESC;\n",
    "# \"\"\",\n",
    "#         {\"term\": SEARCH_TERM[0]},\n",
    "#     )\n",
    "#     .pl()\n",
    "#     .lazy()\n",
    "#     .pipe(country_score)\n",
    "#     .collect()\n",
    "# )\n",
    "# df_con\n",
    "\n",
    "\n",
    "def search(\n",
    "    term: str,\n",
    "    con: DuckDBPyConnection,\n",
    "    level: Literal[0, 1, 2, 3, 4],\n",
    "    previous_results: pl.DataFrame | None = None,\n",
    ") -> pl.DataFrame:\n",
    "    table_name = f\"admin{level}\"\n",
    "    print(f\"Searching for '{term}' in '{table_name}' hierarchy\")\n",
    "\n",
    "    if level == 0:\n",
    "        return (\n",
    "            con.execute(\n",
    "                f\"\"\"SELECT *,\n",
    "    -- High fixed score for exact matches\n",
    "    CASE\n",
    "        WHEN LOWER(ISO) = LOWER($term) THEN 10.0\n",
    "        WHEN LOWER(ISO3) = LOWER($term) THEN 8.0\n",
    "        WHEN LOWER(fips) = LOWER($term) THEN 4.0\n",
    "    END AS score\n",
    "FROM admin{level}\n",
    "WHERE\n",
    "    -- First exact match priority\n",
    "    LOWER(ISO) = LOWER($term) OR\n",
    "    LOWER(ISO3) = LOWER($term) OR\n",
    "    LOWER(fips) = LOWER($term)\n",
    "UNION ALL\n",
    "-- Then fall back to fuzzy search for anything not exact\n",
    "SELECT * FROM (\n",
    "    SELECT *, fts_main_admin{level}.match_bm25(geonameId,\n",
    "$term\n",
    "    ) AS score\n",
    "    FROM admin{level}\n",
    "    WHERE\n",
    "        LOWER(ISO) != LOWER($term) AND\n",
    "        LOWER(ISO3) != LOWER($term) AND\n",
    "        LOWER(fips) != LOWER($term)\n",
    ") sq\n",
    "WHERE score IS NOT NULL\n",
    "ORDER BY score DESC;\n",
    "\"\"\",\n",
    "                {\"term\": SEARCH_TERM[0]},\n",
    "            )\n",
    "            .pl()\n",
    "            .lazy()\n",
    "            .pipe(country_score)\n",
    "            .collect()\n",
    "        )\n",
    "\n",
    "    has_previous = previous_results is not None and not previous_results.is_empty()\n",
    "    join_type = \"LEFT JOIN\" if has_previous else \"LEFT JOIN\"\n",
    "\n",
    "    with_clause = \"\"\n",
    "    join_clause = \"\"\n",
    "    parent_filter = \"\"\n",
    "    if has_previous:\n",
    "        con.register(\"previous_results\", previous_results)\n",
    "        parent_level = level - 1\n",
    "        parent_code_col = f\"admin{parent_level}_code\"\n",
    "        score_col = f\"adjusted_score_{parent_level}\"\n",
    "\n",
    "        parent_filter = f\"\"\"\n",
    "        AND a.{parent_code_col} IN (\n",
    "            SELECT {parent_code_col} FROM previous_results\n",
    "        ) \"\"\"\n",
    "\n",
    "        with_clause = f\"\"\"\n",
    "        WITH parent_scores AS (\n",
    "            SELECT {parent_code_col}, {score_col}\n",
    "            FROM previous_results\n",
    "        )\n",
    "        \"\"\"\n",
    "        join_clause = (\n",
    "            f\"{join_type} parent_scores p ON a.{parent_code_col} = p.{parent_code_col}\"\n",
    "        )\n",
    "\n",
    "    query = f\"\"\"\n",
    "        {with_clause}\n",
    "        SELECT a.*\n",
    "        FROM (\n",
    "            SELECT *, fts_main_{table_name}.match_bm25(\n",
    "                geonameId,\n",
    "                $term\n",
    "            ) AS score\n",
    "            FROM {table_name}\n",
    "        ) a\n",
    "        {join_clause}\n",
    "        WHERE score IS NOT NULL\n",
    "        {parent_filter}\n",
    "        ORDER BY score DESC;\"\"\"\n",
    "\n",
    "    print(f\"Searching {table_name} for '{term}'\")\n",
    "    results = con.execute(query, {\"term\": term}).pl()\n",
    "\n",
    "    # If we got no results with filtering, try again without filtering\n",
    "    if has_previous and results.is_empty() and parent_filter:\n",
    "        print(\"No results found with parent filtering. Trying unfiltered search...\")\n",
    "        # Simple query with no filtering\n",
    "        fallback_query = f\"\"\"\n",
    "        SELECT *\n",
    "        FROM (\n",
    "            SELECT *, fts_main_{table_name}.match_bm25(\n",
    "                geonameId,\n",
    "                $term\n",
    "            ) AS score\n",
    "            FROM {table_name}\n",
    "        ) a\n",
    "        WHERE score IS NOT NULL\n",
    "        ORDER BY score DESC;\n",
    "        \"\"\"\n",
    "        results = con.execute(fallback_query, {\"term\": term}).pl()\n",
    "\n",
    "    # Process the results with the appropriate scoring function\n",
    "    return results.lazy().pipe(admin_score, level).collect()\n",
    "\n",
    "    return None\n",
    "\n",
    "    print(f\"Searching for '{search_term}' in admin{level} hierarchy\")\n",
    "    if level < 0 or level > 4:\n",
    "        raise ValueError(\"Level must be between 0 and 4\")\n",
    "    \"\"\"Search for a term in the admin hierarchy.\"\"\"\n",
    "    if level == 0:\n",
    "        return (\n",
    "            con.execute(\n",
    "                f\"\"\"SELECT *,\n",
    "    -- High fixed score for exact matches\n",
    "    CASE\n",
    "        WHEN LOWER(ISO) = LOWER($term) THEN 10.0\n",
    "        WHEN LOWER(ISO3) = LOWER($term) THEN 8.0\n",
    "        WHEN LOWER(fips) = LOWER($term) THEN 4.0\n",
    "    END AS score\n",
    "FROM admin{level}\n",
    "WHERE\n",
    "    -- First exact match priority\n",
    "    LOWER(ISO) = LOWER($term) OR\n",
    "    LOWER(ISO3) = LOWER($term) OR\n",
    "    LOWER(fips) = LOWER($term)\n",
    "UNION ALL\n",
    "-- Then fall back to fuzzy search for anything not exact\n",
    "SELECT * FROM (\n",
    "    SELECT *, fts_main_admin{level}.match_bm25(geonameId,\n",
    "$term\n",
    "    ) AS score\n",
    "    FROM admin{level}\n",
    "    WHERE\n",
    "        LOWER(ISO) != LOWER($term) AND\n",
    "        LOWER(ISO3) != LOWER($term) AND\n",
    "        LOWER(fips) != LOWER($term)\n",
    ") sq\n",
    "WHERE score IS NOT NULL\n",
    "ORDER BY score DESC;\n",
    "\"\"\",\n",
    "                {\"term\": SEARCH_TERM[0]},\n",
    "            )\n",
    "            .pl()\n",
    "            .lazy()\n",
    "            .pipe(country_score)\n",
    "            .collect()\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            con.execute(\n",
    "                f\"\"\"SELECT *\n",
    "        FROM (\n",
    "            SELECT *, fts_main_admin{level}.match_bm25(\n",
    "                geonameId,\n",
    "                $term\n",
    "            ) AS score\n",
    "            FROM admin{level}\n",
    "        ) sq\n",
    "        WHERE score IS NOT NULL\n",
    "        ORDER BY score DESC;\n",
    "        \"\"\",\n",
    "                {\"term\": search_term},\n",
    "            )\n",
    "            .pl()\n",
    "            .lazy()\n",
    "            .pipe(country_score)\n",
    "            .collect()\n",
    "        )\n",
    "    else:\n",
    "        if previous_search is None:\n",
    "            raise ValueError(\"previous_search must be provided for levels 1-4\")\n",
    "        return (\n",
    "            con.execute(\n",
    "                f\"\"\"SELECT *\n",
    "        FROM (\n",
    "            SELECT *, fts_main_admin{level}.match_bm25(\n",
    "                geonameId,\n",
    "                $term\n",
    "            ) AS score\n",
    "            FROM admin{level}\n",
    "        ) sq\n",
    "        WHERE score IS NOT NULL\n",
    "            AND admin{level - 1}_code IN (\n",
    "                SELECT admin{level - 1}_code FROM previous_search\n",
    "            )\n",
    "        ORDER BY score DESC;\n",
    "        \"\"\",\n",
    "                {\"term\": search_term},\n",
    "            )\n",
    "            .pl()\n",
    "            .lazy()\n",
    "            .pipe(admin_score, level)\n",
    "            .collect()\n",
    "        )\n",
    "\n",
    "\n",
    "a = search(SEARCH_TERM[0], con, 0)\n",
    "print(a)\n",
    "b = search(SEARCH_TERM[1], con, 1, a)\n",
    "print(b)\n",
    "c = search(SEARCH_TERM[2], con, 2, b)\n",
    "print(c)\n",
    "d = search(SEARCH_TERM[3], con, 3, c)\n",
    "print(d)\n",
    "e = search(SEARCH_TERM[4], con, 4, d)\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = search(SEARCH_TERM[3], con, 3, c)\n",
    "print(d)\n",
    "e = search(SEARCH_TERM[4], con, 4, d)\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(get_parents_query(8354456)).get_as_pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.table(\"allCountries\").pl().filter(pl.col(\"geonameId\") == 8354456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(get_children_querys([8378478])).get_as_pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.table(\"country\").pl().select(pl.col(\"feature_class\").value_counts()).unnest(\n",
    "    \"feature_class\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"SELECT geonameId FROM country\").pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "\n",
    "CREATE OR REPLACE TABLE\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = con.table(\"allCountries\").pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.table(\"area\").pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(pl.col(\"country_code\") == \"US\").filter(pl.col(\"admin1_code\") == \"GA\").filter(\n",
    "    pl.col(\"name\").str.contains(\"Tabernacle\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(pl.col(GID) == 4225563)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df.filter(pl.col(\"admin1_code\") == \"GA\")\n",
    "    .filter(pl.col(\"admin2_code\") == \"279\")\n",
    "    .filter(pl.col(\"feature_class\").is_in([\"A\", \"P\"]))\n",
    "    .filter(pl.col(\"feature_code\").is_in([\"ADM1\", \"ADM2\"]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df.filter(pl.col(\"feature_class\").is_in([\"P\", \"A\"]))\n",
    "    # .filter(pl.col(\"name\") == \"Islington\")\n",
    "    # .filter(pl.col(\"admin1_code\") == \"NY\")\n",
    "    .filter(pl.col(GID).is_in([2545, 43702, 124193, 124271, 7147616]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.table(\"allCountries\").pl().filter(pl.col(\"geonameId\") == 3038832)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter((pl.col(\"admin4_code\").is_not_null())).sample(10).filter(\n",
    "    pl.col(\"feature_class\").is_in([\"P\", \"A\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(pl.col(\"admin3_code\") == \"77152\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(get_parents_querys([6556042], traverse=False)).get_as_pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(get_parents_querys([6255148], traverse=False)).get_as_pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.table(\"area\").pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_ids = con.execute(\"SELECT geonameId FROM country\").pl().to_series()\n",
    "output_df = (\n",
    "    conn.execute(get_children_querys(country_ids.to_list()))\n",
    "    .get_as_pl()\n",
    "    .lazy()\n",
    "    .unique(\"geonameId\")\n",
    "    .select(\"geonameId\")\n",
    "    .collect()\n",
    "    .to_series()\n",
    ")\n",
    "admin1_ids = set(\n",
    "    con.execute(\"SELECT geonameId FROM allCountries WHERE feature_code LIKE 'ADM1%'\")\n",
    "    .pl()\n",
    "    .to_series()\n",
    "    .append(output_df)\n",
    "    .unique()\n",
    ") - set(country_ids)\n",
    "con.execute(\n",
    "    f\"CREATE OR REPLACE TABLE admin1 AS SELECT * FROM allCountries WHERE allCountries.geonameId IN ({','.join(map(str, admin1_ids))}) ORDER BY geonameId;\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.table(\"country\").pl().filter(pl.col(\"feature_code\") == \"PCLH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.table(\"country\").pl().select(pl.col(\"feature_code\").value_counts()).unnest(\n",
    "    \"feature_code\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admin1_ids = con.execute(\"select geonameid from admin1\").pl().to_series()\n",
    "output_df = (\n",
    "    conn.execute(get_children_querys(admin1_ids.to_list()))\n",
    "    .get_as_pl()\n",
    "    .lazy()\n",
    "    .unique(\"geonameId\")\n",
    "    .select(\"geonameId\")\n",
    "    .collect()\n",
    "    .to_series()\n",
    ")\n",
    "admin2_ids = (\n",
    "    set(\n",
    "        con.execute(\n",
    "            \"SELECT geonameId FROM allCountries WHERE feature_code LIKE 'ADM2%'\"\n",
    "        )\n",
    "        .pl()\n",
    "        .to_series()\n",
    "        .append(output_df)\n",
    "        .unique()\n",
    "    )\n",
    "    - set(admin1_ids)\n",
    "    - set(country_ids)\n",
    ")\n",
    "con.execute(\n",
    "    f\"CREATE OR REPLACE TABLE admin2 AS SELECT * FROM allCountries WHERE allCountries.geonameId IN ({','.join(map(str, admin2_ids))}) ORDER BY geonameId;\"\n",
    ")\n",
    "con.table(\"admin2\").pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.table(\"admin2\").pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admin2_ids = con.execute(\"select geonameid from admin2\").pl().to_series()\n",
    "output_df = (\n",
    "    conn.execute(get_children_querys(admin2_ids.to_list()))\n",
    "    .get_as_pl()\n",
    "    .lazy()\n",
    "    .unique(\"geonameId\")\n",
    "    .select(\"geonameId\")\n",
    "    .collect()\n",
    "    .to_series()\n",
    ")\n",
    "admin3_ids = (\n",
    "    set(\n",
    "        con.execute(\n",
    "            \"SELECT geonameId FROM allCountries WHERE feature_code LIKE 'ADM3%'\"\n",
    "        )\n",
    "        .pl()\n",
    "        .to_series()\n",
    "        .append(output_df)\n",
    "        .unique()\n",
    "    )\n",
    "    - set(admin2_ids)\n",
    "    - set(admin1_ids)\n",
    "    - set(country_ids)\n",
    ")\n",
    "con.execute(\n",
    "    f\"CREATE OR REPLACE TABLE admin3 AS SELECT * FROM allCountries WHERE allCountries.geonameId IN ({','.join(map(str, admin3_ids))}) ORDER BY geonameId;\"\n",
    ")\n",
    "con.table(\"admin3\").pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.table(\"admin3\").pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admin3_ids = con.execute(\"select geonameid from admin3\").pl().to_series()\n",
    "output_df = (\n",
    "    conn.execute(get_children_querys(admin3_ids.to_list()))\n",
    "    .get_as_pl()\n",
    "    .lazy()\n",
    "    .unique(\"geonameId\")\n",
    "    .select(\"geonameId\")\n",
    "    .collect()\n",
    "    .to_series()\n",
    ")\n",
    "admin4_ids = (\n",
    "    set(\n",
    "        con.execute(\n",
    "            \"SELECT geonameId FROM allCountries WHERE feature_code LIKE 'ADM4%'\"\n",
    "        )\n",
    "        .pl()\n",
    "        .to_series()\n",
    "        .append(output_df)\n",
    "        .unique()\n",
    "    )\n",
    "    - set(admin3_ids)\n",
    "    - set(admin2_ids)\n",
    "    - set(admin1_ids)\n",
    "    - set(country_ids)\n",
    ")\n",
    "con.execute(\n",
    "    f\"CREATE OR REPLACE TABLE admin4 AS SELECT * FROM allCountries WHERE allCountries.geonameId IN ({','.join(map(str, admin4_ids))}) ORDER BY geonameId;\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.table(\"admin4\").pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admin4_ids = con.execute(\"select geonameid from admin4\").pl().to_series()\n",
    "output_df = (\n",
    "    conn.execute(get_children_querys(admin4_ids.to_list()))\n",
    "    .get_as_pl()\n",
    "    .lazy()\n",
    "    .unique(\"geonameId\")\n",
    "    .select(\"geonameId\")\n",
    "    .collect()\n",
    "    .to_series()\n",
    ")\n",
    "admin5_ids = (\n",
    "    set(\n",
    "        con.execute(\n",
    "            \"SELECT geonameId FROM allCountries WHERE feature_code LIKE 'ADM5%'\"\n",
    "        )\n",
    "        .pl()\n",
    "        .to_series()\n",
    "        .append(output_df)\n",
    "        .unique()\n",
    "    )\n",
    "    - set(admin4_ids)\n",
    "    - set(admin3_ids)\n",
    "    - set(admin2_ids)\n",
    "    - set(admin1_ids)\n",
    "    - set(country_ids)\n",
    ")\n",
    "con.execute(\n",
    "    f\"CREATE OR REPLACE TABLE admin5 AS SELECT allCountries.*, adminCode5.adm5code AS admin5_code FROM allCountries LEFT JOIN adminCode5 ON allCountries.geonameId = adminCode5.geonameId WHERE allCountries.geonameId IN ({','.join(map(str, admin5_ids))}) ORDER BY allCountries.geonameId;\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.table(\"admin5\").pl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan\n",
    "\n",
    "Some larger teretory one. -> Country -> State -> District -> Subdistrict -> City -> Some generic search field for everything else.\n",
    "\n",
    "### Country, use country table. (Historic filter?)\n",
    "\n",
    "- From country info table\n",
    "\n",
    "### Larger teretorys.\n",
    "\n",
    "- Get ids from country table, get all parents (recursive?) from country table, remove any duplicates (american samoa to USA) (Could be filters?)\n",
    "\n",
    "### State\n",
    "\n",
    "- Get all states (ADM1) (historic filter?) and then get all sub regions of countries? (potential country duplicate? If found in country table, when orchestrating change state found to country?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = con.table(\"allCountries\").pl().lazy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort(\"modification_date\", descending=True).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a query to find gids where (gid.a & gid.b) where, name, asciiname, country_code, admin1_code, admin2_code, admin3_code, admin4_code, timezone timezone are the same but feature class are A and P respectively\n",
    "q = (\n",
    "    df.filter(pl.col(\"feature_class\") == \"A\")\n",
    "    .join(\n",
    "        df.filter(pl.col(\"feature_class\") == \"P\"),\n",
    "        on=[\n",
    "            \"name\",\n",
    "            \"asciiname\",\n",
    "            \"country_code\",\n",
    "            \"admin1_code\",\n",
    "            \"admin2_code\",\n",
    "            \"admin3_code\",\n",
    "            \"admin4_code\",\n",
    "            \"timezone\",\n",
    "        ],\n",
    "        how=\"inner\",\n",
    "        suffix=\"_p\",\n",
    "        nulls_equal=True,\n",
    "    )\n",
    "    .rename({\"geonameId\": \"geonameId_a\"})\n",
    "    .select(\"geonameId_a\", \"geonameId_p\")\n",
    "    .sort(\"geonameId_a\", \"geonameId_p\")\n",
    ")\n",
    "ab = q.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEFT JOIN P Equivalents to A tables\n",
    "\n",
    "df.filter(pl.col(\"feature_class\") == \"P\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.table(\"equivalent\").pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_coordinates = np.array(geocoder.ip(\"me\").latlng, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = con.table(\"allCountries\").pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    con.execute(\"SELECT geonameId, latitude, longitude FROM allCountries\")\n",
    "    .pl()\n",
    "    .select(\n",
    "        pl.col(\"geonameId\"),\n",
    "        pl.concat_list(pl.col(\"latitude\"), pl.col(\"longitude\"))\n",
    "        .cast(pl.Array(pl.Float32, 2))\n",
    "        .alias(\"vectors\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_coordinates1 = np.array([51.549902, -0.121696], dtype=np.float32)\n",
    "my_coordinates2 = np.array([37.77493, -122.41942], dtype=np.float32)\n",
    "\n",
    "vidx = VectorIndex(\"latlon\", data, metric=\"haversine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vidx.vector_search(my_coordinates1).unwrap().join(df, \"geonameId\", \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (path := Path(\"./data/processed/latlon.index\")).exists():\n",
    "    print(\"Loading index...\")\n",
    "    index = Index.restore(path, view=True)\n",
    "    if index is None:\n",
    "        raise ValueError(\"Failed to load index\")\n",
    "else:\n",
    "    print(\"Creating index...\")\n",
    "    coordinates = df.select([\"latitude\", \"longitude\"]).to_numpy(order=\"c\")\n",
    "    labels = df[\"geonameId\"].to_numpy()\n",
    "    index: Index = Index(ndim=2, metric=\"haversine\", dtype=\"f32\")\n",
    "    index.add(keys=labels, vectors=coordinates, log=True)\n",
    "    index.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example function to search and return results with distances\n",
    "def search_with_distances(\n",
    "    index: Index,\n",
    "    my_coordinates: NDArray[np.float32],\n",
    "    original_df: pl.LazyFrame,\n",
    "    k=10,\n",
    "    exact=False,\n",
    "):\n",
    "    # Perform the search\n",
    "    output = index.search(vectors=my_coordinates, count=k, log=True, exact=exact)\n",
    "\n",
    "    print(f\"Visited members: {output.visited_members}\")\n",
    "    print(f\"Computed distances: {output.computed_distances}\")\n",
    "\n",
    "    # Extract keys (geonameids) and distances\n",
    "    keys = output.keys\n",
    "    distances = output.distances\n",
    "\n",
    "    # Create a DataFrame from the search results\n",
    "    results_df = pl.LazyFrame(\n",
    "        data={\"geonameId\": keys, \"distance\": distances},\n",
    "        schema={\"geonameId\": pl.UInt32, \"distance\": pl.Float32},\n",
    "    ).with_columns(pl.col(\"distance\") * 6371.0)\n",
    "\n",
    "    # Join the results with the original DataFrame to get detailed information\n",
    "    detailed_results_df = results_df.join(original_df, on=\"geonameId\", how=\"left\")\n",
    "\n",
    "    # Sort by distance\n",
    "    sorted_results_df = detailed_results_df.sort(\"distance\")\n",
    "\n",
    "    return sorted_results_df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_with_distances(index, my_coordinates2, df.lazy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output: Matches = index.search(vectors=my_coordinates1, count=10, log=True)\n",
    "print(f\"{output.computed_distances=}\")\n",
    "print(f\"{output.visited_members=}\")\n",
    "df.filter(pl.col(\"geonameId\").is_in(output.keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output: Matches = index.search(vectors=my_coordinates1, count=10, log=True)\n",
    "df.filter(pl.col(\"geonameId\").is_in(output.keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(pl.col(\"feature_code\") == \"LTER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Country\n",
    "\n",
    "feature code is `PCL*` in the `geoname` table.\n",
    "\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(pl.col(\"geonameId\") == 15904)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_q = pl.scan_csv(\n",
    "    \"./data/geonames/hierarchy.txt\",\n",
    "    separator=\"\\t\",\n",
    "    has_header=False,\n",
    "    schema={\n",
    "        \"from\": pl.Int32,\n",
    "        \"to\": pl.Int32,\n",
    "        \"type\": pl.Utf8,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_df = hi_q.head(500).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_df = hi_q.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_df.write_parquet(\"./data/processed/hierarchy.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_df.filter(pl.col(\"from\") == 2635167)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(pl.col(\"geonameid\") == 2635167)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdb = kz.Database(\"./data/graph_db\")\n",
    "\n",
    "conn = kz.Connection(gdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\n",
    "    \"CREATE NODE TABLE Entity(geonameid INT32, name STRING, feature_class STRING, feature_code STRING, country_code STRING, population INT64, PRIMARY KEY(geonameid))\"\n",
    ")\n",
    "conn.execute(\"CREATE REL TABLE IsIn(FROM Entity TO Entity, type STRING)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"Copy Entity FROM './data/processed/geonames.parquet'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"Copy IsIn FROM './data/processed/hierarchy.parquet'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = conn.execute(\"MATCH (a)-[b]->(c) RETURN *;\")\n",
    "G = res.get_as_networkx(directed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "pageranks = nx.pagerank(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"geonameid\": list(pageranks.keys()), \"pagerank\": list(pageranks.values())}\n",
    "pageranks_df = pl.DataFrame(\n",
    "    data, schema={\"geonameid\": pl.Utf8, \"pagerank\": pl.Float64}\n",
    ").with_columns(pl.col(\"geonameid\").str.strip_chars_start(\"Entity_\").cast(pl.Int32))\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageranks_df.sort(\"pagerank\", descending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(pl.col(\"geonameid\") == 3169070)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
